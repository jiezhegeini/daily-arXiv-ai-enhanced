{"id": "2510.21748", "categories": ["eess.SP", "cs.SY", "eess.SY", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.21748", "abs": "https://arxiv.org/abs/2510.21748", "authors": ["Kiana Kiashemshaki", "Sina Samieirad", "Sarvenaz Erfani", "Aryan Jalaeianbanayan", "Nasibeh Asadi Isakan", "Hossein Najafzadeh"], "title": "Automated Tinnitus Detection Through Dual-Modality Neuroimaging: EEG Microstate Analysis and Resting-State fMRI Classification Using Deep Learning", "comment": null, "summary": "Objective: Tinnitus affects 10-15% of the population yet lacks objective\ndiagnostic biomarkers. This study applied machine learning to EEG and fMRI data\nto identify neural signatures distinguishing tinnitus patients from healthy\ncontrols. Methods: Two datasets were analyzed: 64-channel EEG recordings from\n80 participants (40 tinnitus, 40 controls) and resting-state fMRI data from 38\nparticipants (19 tinnitus, 19 controls). EEG analysis extracted microstate\nfeatures across four to seven clustering states and five frequency bands,\nproducing 440 features per subject. Global Field Power signals were also\ntransformed into wavelet images for deep learning. fMRI data were analyzed\nusing slice-wise convolutional neural networks and hybrid models combining\npre-trained architectures (VGG16, ResNet50) with Decision Tree, Random Forest,\nand SVM classifiers. Model performance was evaluated using 5-fold\ncross-validation based on accuracy, precision, recall, F1-score, and ROC-AUC.\nResults: EEG microstate analysis revealed altered network dynamics in tinnitus,\nparticularly reduced gamma-band microstate B occurrence (healthy: 56.56 vs\ntinnitus: 43.81, p < 0.001) and diminished alpha coverage. Tree-based\nclassifiers achieved up to 98.8% accuracy, while VGG16 on wavelet-transformed\nEEG yielded 95.4% and 94.1% accuracy for delta and alpha bands, respectively.\nfMRI analysis identified 12 high-performing axial slices (>=90% accuracy), with\nslice 17 reaching 99.0%. The hybrid VGG16-Decision Tree model achieved 98.95%\n+/- 2.94% accuracy. Conclusion: EEG and fMRI provided effective neural\nbiomarkers for tinnitus classification. Tree-based and hybrid models\ndemonstrated superior performance, highlighting tinnitus as a multi-network\ndisorder requiring multimodal analysis.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u673a\u5668\u5b66\u4e60\u5206\u6790\u8111\u7535\u56fe(EEG)\u548c\u529f\u80fd\u6027\u78c1\u5171\u632f\u6210\u50cf(fMRI)\u6570\u636e\uff0c\u6210\u529f\u8bc6\u522b\u51fa\u533a\u5206\u8033\u9e23\u60a3\u8005\u4e0e\u5065\u5eb7\u5bf9\u7167\u7ec4\u7684\u795e\u7ecf\u7279\u5f81\uff0c\u4e3a\u8033\u9e23\u7684\u5ba2\u89c2\u8bca\u65ad\u63d0\u4f9b\u4e86\u751f\u7269\u6807\u5fd7\u7269\u3002", "motivation": "\u8033\u9e23\u5f71\u54cd\u5e7f\u6cdb\u4f46\u7f3a\u4e4f\u5ba2\u89c2\u8bca\u65ad\u751f\u7269\u6807\u5fd7\u7269\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u673a\u5668\u5b66\u4e60\u8bc6\u522b\u533a\u5206\u8033\u9e23\u60a3\u8005\u4e0e\u5065\u5eb7\u5bf9\u7167\u7ec4\u7684\u795e\u7ecf\u7279\u5f81\u3002", "method": "\u5206\u6790\u4e8680\u540d\u53c2\u4e0e\u8005\uff0840\u540d\u8033\u9e23\uff0c40\u540d\u5bf9\u7167\u7ec4\uff09\u768464\u901a\u9053EEG\u6570\u636e\u548c38\u540d\u53c2\u4e0e\u8005\uff0819\u540d\u8033\u9e23\uff0c19\u540d\u5bf9\u7167\u7ec4\uff09\u7684\u9759\u606f\u6001fMRI\u6570\u636e\u3002EEG\u5206\u6790\u63d0\u53d6\u4e86\u5fae\u72b6\u6001\u7279\u5f81\u548c\u5168\u7403\u573a\u529f\u7387\u4fe1\u53f7\u7684\u5c0f\u6ce2\u56fe\u50cf\u3002fMRI\u6570\u636e\u91c7\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u6df7\u5408\u6a21\u578b\u8fdb\u884c\u5206\u6790\u3002\u6a21\u578b\u6027\u80fd\u901a\u8fc75\u6298\u4ea4\u53c9\u9a8c\u8bc1\u8bc4\u4f30\u3002", "result": "EEG\u5fae\u72b6\u6001\u5206\u6790\u663e\u793a\u8033\u9e23\u60a3\u8005\u7684\u7f51\u7edc\u52a8\u529b\u5b66\u53d1\u751f\u6539\u53d8\uff0c\u7279\u522b\u662fgamma\u6ce2\u6bb5\u5fae\u72b6\u6001B\u7684\u53d1\u751f\u7387\u964d\u4f4e\uff08\u5065\u5eb7\u7ec4\uff1a56.56 vs \u8033\u9e23\u7ec4\uff1a43.81, p < 0.001\uff09\u4ee5\u53caalpha\u6ce2\u6bb5\u7684\u8986\u76d6\u5ea6\u51cf\u5c0f\u3002\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u5206\u7c7b\u5668\u51c6\u786e\u7387\u9ad8\u8fbe98.8%\uff0cVGG16\u6a21\u578b\u5728\u5c0f\u6ce2\u53d8\u6362\u7684EEG\u6570\u636e\u4e0a\u5206\u522b\u8fbe\u523095.4%\u548c94.1%\u7684\u51c6\u786e\u7387\uff08delta\u548calpha\u6ce2\u6bb5\uff09\u3002fMRI\u5206\u6790\u8bc6\u522b\u51fa12\u4e2a\u9ad8\u7cbe\u5ea6\uff08>=90%\uff09\u7684\u8f74\u5411\u5207\u7247\uff0c\u5176\u4e2d\u5207\u724717\u8fbe\u523099.0%\u3002VGG16-\u51b3\u7b56\u6811\u6df7\u5408\u6a21\u578b\u51c6\u786e\u7387\u4e3a98.95% +/- 2.94%\u3002", "conclusion": "EEG\u548cfMRI\u6570\u636e\u80fd\u591f\u6709\u6548\u63d0\u4f9b\u8033\u9e23\u5206\u7c7b\u7684\u795e\u7ecf\u751f\u7269\u6807\u5fd7\u7269\u3002\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u548c\u6df7\u5408\u6a21\u578b\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u8868\u660e\u8033\u9e23\u662f\u4e00\u79cd\u9700\u8981\u591a\u6a21\u6001\u5206\u6790\u7684\u591a\u7f51\u7edc\u75be\u75c5\u3002"}}
{"id": "2510.21789", "categories": ["eess.SP", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.21789", "abs": "https://arxiv.org/abs/2510.21789", "authors": ["Beyazit Bestami Yuksel"], "title": "Monitoring Real-Time ECG Signals on Mobile Systems", "comment": "10 figure, 4 pages", "summary": "This study focuses on the connection of a development kit that enables\nreal-time monitoring of electrocardiogram (ECG) signals using a mobile system.\nA software developed on the Visual Studio .NET platform reads real-time ECG\nsignals from the human body through non invasive methods and displays them\ngraphically on the mobile system. ECG electrodes placed on specific areas of\nthe body using the method known as Einthoven's triangle. Subsequently, the\nsoftware initiates data flow through the serial port, and these data displayed\nas signal values on the mobile device's screen via a graphical interface. When\nthe monitored ECG signals fall below a certain threshold or reach a critical\nvalue, the system provides feedback with an alert based on medical data. The\ndeveloped system is fully portable. Additionally, the implemented system has\nthe potential to form the basis for a multi-purpose system in the future, such\nas online patient monitoring, patient location tracking, and even initial\nintervention using the defibrillation method.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5229\u7528\u79fb\u52a8\u7cfb\u7edf\u5b9e\u65f6\u76d1\u6d4b\u5fc3\u7535\u56fe\u4fe1\u53f7\u7684\u5f00\u53d1\u5957\u4ef6\u3002", "motivation": "\u4f7f\u7528\u975e\u4fb5\u5165\u5f0f\u65b9\u6cd5\u901a\u8fc7\u79fb\u52a8\u7cfb\u7edf\u5b9e\u65f6\u76d1\u6d4b\u5fc3\u7535\u56fe\u4fe1\u53f7\uff0c\u5e76\u5728\u4fe1\u53f7\u5f02\u5e38\u65f6\u63d0\u4f9b\u8b66\u62a5\u3002", "method": "\u901a\u8fc7 Einthoven's triangle \u65b9\u6cd5\u5c06\u7535\u6781\u653e\u7f6e\u5728\u4eba\u4f53\u7279\u5b9a\u533a\u57df\uff0c\u4f7f\u7528 Visual Studio .NET \u5e73\u53f0\u5f00\u53d1\u7684\u8f6f\u4ef6\u901a\u8fc7\u4e32\u884c\u7aef\u53e3\u8bfb\u53d6\u548c\u663e\u793a\u5fc3\u7535\u56fe\u4fe1\u53f7\uff0c\u5e76\u5728\u4fe1\u53f7\u503c\u4f4e\u4e8e\u6216\u8fbe\u5230\u4e34\u754c\u503c\u65f6\u63d0\u4f9b\u8b66\u62a5\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5b8c\u5168\u4fbf\u643a\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u5b9e\u65f6\u663e\u793a\u5fc3\u7535\u56fe\u4fe1\u53f7\u5e76\u901a\u8fc7\u56fe\u5f62\u754c\u9762\u63d0\u4f9b\u8b66\u62a5\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6709\u6f5c\u529b\u6210\u4e3a\u672a\u6765\u591a\u529f\u80fd\u7cfb\u7edf\u7684\u57fa\u7840\uff0c\u4f8b\u5982\u5728\u7ebf\u60a3\u8005\u76d1\u62a4\u3001\u60a3\u8005\u4f4d\u7f6e\u8ddf\u8e2a\u751a\u81f3\u4f7f\u7528\u9664\u98a4\u5668\u8fdb\u884c\u521d\u6b65\u5e72\u9884\u3002"}}
{"id": "2510.21969", "categories": ["eess.SP", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.21969", "abs": "https://arxiv.org/abs/2510.21969", "authors": ["Weiyu Chen", "Arnaud Delorme"], "title": "Adaptive Split-MMD Training for Small-Sample Cross-Dataset P300 EEG Classification", "comment": "8 pages, 5 figures. Submitted to IEEE BIBM 2025 Workshop on Machine\n  Learning for EEG Signal Processing (MLESP)", "summary": "Detecting single-trial P300 from EEG is difficult when only a few labeled\ntrials are available. When attempting to boost a small target set with a large\nsource dataset through transfer learning, cross-dataset shift arises. To\naddress this challenge, we study transfer between two public visual-oddball ERP\ndatasets using five shared electrodes (Fz, Pz, P3, P4, Oz) under a strict\nsmall-sample regime (target: 10 trials/subject; source: 80 trials/subject). We\nintroduce Adaptive Split Maximum Mean Discrepancy Training (AS-MMD), which\ncombines (i) a target-weighted loss with warm-up tied to the square root of the\nsource/target size ratio, (ii) Split Batch Normalization (Split-BN) with shared\naffine parameters and per-domain running statistics, and (iii) a parameter-free\nlogit-level Radial Basis Function kernel Maximum Mean Discrepancy (RBF-MMD)\nterm using the median-bandwidth heuristic. Implemented on an EEG Conformer,\nAS-MMD is backbone-agnostic and leaves the inference-time model unchanged.\nAcross both transfer directions, it outperforms target-only and pooled training\n(Active Visual Oddball: accuracy/AUC 0.66/0.74; ERP CORE P3: 0.61/0.65), with\ngains over pooling significant under corrected paired t-tests. Ablations\nattribute improvements to all three components.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u6807\u6ce8\u6570\u636e\u7a00\u5c11\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u5728\u4e24\u4e2a\u89c6\u89c9 oddball ERP \u6570\u636e\u96c6\u4e4b\u95f4\u8fdb\u884c P300 \u4fe1\u53f7\u68c0\u6d4b\u7684\u8de8\u6570\u636e\u96c6\u8fc1\u79fb\u95ee\u9898\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a AS-MMD \u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u76ee\u6807\u52a0\u6743\u635f\u5931\u3001Split Batch Normalization \u548c RBF-MMD \u635f\u5931\u9879\uff0c\u5e76\u5728 EEG Conformer \u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002\u7ed3\u679c\u8868\u660e\uff0cAS-MMD \u76f8\u6bd4\u4e8e\u4ec5\u4f7f\u7528\u76ee\u6807\u6570\u636e\u6216\u6df7\u5408\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u5728 P300 \u68c0\u6d4b\u7684\u51c6\u786e\u7387\u548c AUC \u6307\u6807\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u4e14\u6a21\u578b\u7684\u6539\u8fdb\u53ef\u4ee5\u5f52\u56e0\u4e8e AS-MMD \u7684\u5404\u4e2a\u7ec4\u6210\u90e8\u5206\u3002", "motivation": "\u5728\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece EEG \u4e2d\u68c0\u6d4b\u5355\u6b21 P300 \u4fe1\u53f7\u975e\u5e38\u56f0\u96be\u3002\u5f53\u8bd5\u56fe\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u7528\u5927\u91cf\u6e90\u6570\u636e\u96c6\u6765\u589e\u5f3a\u5c11\u91cf\u76ee\u6807\u6570\u636e\u96c6\u65f6\uff0c\u4f1a\u51fa\u73b0\u8de8\u6570\u636e\u96c6\u504f\u79fb\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u5206\u88c2\u6700\u5927\u5747\u503c\u5dee\u5f02\u8bad\u7ec3 (AS-MMD) \u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\uff08i\uff09\u4e00\u4e2a\u76ee\u6807\u52a0\u6743\u7684\u3001\u4e0e\u6e90/\u76ee\u6807\u5927\u5c0f\u6bd4\u7684\u5e73\u65b9\u6839\u76f8\u5173\u7684\u9884\u70ed\u635f\u5931\uff0c\uff08ii\uff09\u5177\u6709\u5171\u4eab\u4eff\u5c04\u53c2\u6570\u548c\u6bcf\u4e2a\u57df\u7684\u8fd0\u884c\u7edf\u8ba1\u7684\u5206\u88c2\u6279\u91cf\u5f52\u4e00\u5316 (Split-BN)\uff0c\u4ee5\u53ca\uff08iii\uff09\u4e00\u4e2a\u4f7f\u7528\u4e2d\u503c\u5e26\u5bbd\u542f\u53d1\u5f0f\u7684\u65e0\u53c2\u6570\u3001\u5bf9\u6570\u7ea7\u522b\u7684\u5f84\u5411\u57fa\u51fd\u6570\u6838\u6700\u5927\u5747\u503c\u5dee\u5f02 (RBF-MMD) \u9879\u3002AS-MMD \u88ab\u5b9e\u73b0\u4e3a\u4e00\u4e2a\u9aa8\u5e72\u7f51\u7edc\u65e0\u5173\u7684\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u63a8\u7406\u65f6\u4fdd\u6301\u4e0d\u53d8\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5171\u89c6\u89c9 oddball ERP \u6570\u636e\u96c6\u4e4b\u95f4\uff0cAS-MMD \u5728\u4e24\u4e2a\u8fc1\u79fb\u65b9\u5411\u4e0a\u5747\u4f18\u4e8e\u4ec5\u4f7f\u7528\u76ee\u6807\u6570\u636e\u548c\u6df7\u5408\u8bad\u7ec3\u7684\u65b9\u6cd5\uff08Active Visual Oddball\uff1a\u51c6\u786e\u7387/AUC 0.66/0.74\uff1bERP CORE P3\uff1a0.61/0.65\uff09\uff0c\u5e76\u4e14\u5728\u7ecf\u8fc7\u6821\u6b63\u7684\u914d\u5bf9 t \u68c0\u9a8c\u4e0b\uff0c\u4f18\u4e8e\u6df7\u5408\u8bad\u7ec3\u7684\u65b9\u6cd5\u3002\u6a21\u578b\u5206\u6790\u8868\u660e\uff0cAS-MMD \u7684\u6240\u6709\u4e09\u4e2a\u7ec4\u6210\u90e8\u5206\u90fd\u5bf9\u6027\u80fd\u63d0\u5347\u505a\u51fa\u4e86\u8d21\u732e\u3002", "conclusion": "AS-MMD \u80fd\u591f\u6709\u6548\u5730\u89e3\u51b3\u5c0f\u6837\u672c P300 \u68c0\u6d4b\u4e2d\u7684\u8de8\u6570\u636e\u96c6\u8fc1\u79fb\u95ee\u9898\uff0c\u5e76\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u7684\u8fc1\u79fb\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2510.22180", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.22180", "abs": "https://arxiv.org/abs/2510.22180", "authors": ["Maximilian Bauhofer", "Marcus Henninger", "Meik Kottkamp", "Lucas Giroto", "Philip Grill", "Alexander Felix", "Thorsten Wild", "Stephan ten Brink", "Silvio Mandelli"], "title": "Experimental Demonstration of Multi-Object Tracking in Integrated Sensing and Communication", "comment": null, "summary": "For a wide range of envisioned integrated sensing and communication (ISAC)\nuse cases, it is necessary to incorporate tracking techniques into cellular\ncommunication systems. While numerous multi-object tracking algorithms exist,\nthey have not yet been applied to real-world ISAC, with its challenges such as\nclutter and non-optimal hardware. In this work, we showcase multi-object\ntracking based on the probability hypothesis density (PHD) filter in the range\nand Doppler speed domain. The measurements are taken with a 5G compliant ISAC\nproof-of-concept in a real factory environment, where the pedestrian-like\nobjects are generated by a radar object emulator. We detail the complete\npipeline, from measurement acquisition to evaluation, with a focus on the\npost-processing of the raw captured data and the tracking itself. Our\nend-to-end evaluation and comparison to simulations show good multi-object\ntracking performance with mean absolute error <1.5m and detection rates >91%\nfor realistic but challenging scenarios.", "AI": {"tldr": "\u672c\u6587\u5c06\u57fa\u4e8e\u6982\u7387\u5047\u8bbe\u5bc6\u5ea6\uff08PHD\uff09\u6ee4\u6ce2\u5668\u7684\u591a\u76ee\u6807\u8ddf\u8e2a\u6280\u672f\u5e94\u7528\u4e8e5G\u901a\u4fe1\u7cfb\u7edf\uff0c\u4ee5\u5e94\u5bf9\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u6311\u6218\u3002", "motivation": "\u5728\u96c6\u6210\u7684\u4f20\u611f\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u5e94\u7528\u573a\u666f\u4e2d\uff0c\u9700\u8981\u5728\u8702\u7a9d\u901a\u4fe1\u7cfb\u7edf\u4e2d\u96c6\u6210\u8ddf\u8e2a\u6280\u672f\uff0c\u4f46\u73b0\u6709\u7684\u591a\u76ee\u6807\u8ddf\u8e2a\u7b97\u6cd5\u5c1a\u672a\u5e94\u7528\u4e8e\u5177\u6709\u6742\u6ce2\u548c\u975e\u6700\u4f18\u786c\u4ef6\u7b49\u6311\u6218\u7684\u5b9e\u9645ISAC\u573a\u666f\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u5047\u8bbe\u5bc6\u5ea6\uff08PHD\uff09\u6ee4\u6ce2\u5668\u7684\u3001\u5728\u8ddd\u79bb-\u591a\u666e\u52d2\u901f\u5ea6\u57df\u5185\u8fdb\u884c\u7684\u591a\u76ee\u6807\u8ddf\u8e2a\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528\u7b26\u54085G\u6807\u51c6\u7684ISAC\u6982\u5ff5\u9a8c\u8bc1\u7cfb\u7edf\u548c\u96f7\u8fbe\u76ee\u6807\u6a21\u62df\u5668\u5728\u5b9e\u9645\u5de5\u5382\u73af\u5883\u4e2d\u8fdb\u884c\u6570\u636e\u91c7\u96c6\u3002", "result": "\u8be5\u7aef\u5230\u7aef\u8bc4\u4f30\u663e\u793a\uff0c\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86<1.5m\u7684\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\u548c>91%\u7684\u68c0\u6d4b\u7387\uff0c\u8bc1\u660e\u4e86\u5176\u826f\u597d\u7684\u591a\u76ee\u6807\u8ddf\u8e2a\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8ePHD\u6ee4\u6ce2\u5668\u7684\u591a\u76ee\u6807\u8ddf\u8e2a\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u5b9e\u9645ISAC\u573a\u666f\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u53d6\u5f97\u4f18\u5f02\u7684\u8ddf\u8e2a\u6027\u80fd\u3002"}}
{"id": "2510.22297", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.22297", "abs": "https://arxiv.org/abs/2510.22297", "authors": ["Alexander Felix", "Rudolf Hoffmann", "Marcus Henninger", "Stephan ten Brink", "Silvio Mandelli"], "title": "Angular Estimation Comparison with ISAC PoC", "comment": null, "summary": "The introduction of Integrated Sensing and Communications (ISAC) in cellular\nsystems is not expected to result in a shift away from the popular choice of\ncost- and energy-efficient analog or hybrid beamforming structures. However,\nthis comes at the cost of limiting the angular capabilities to a confined space\nper acquisitions. Thus, as a prerequisite for the successful implementation of\nnumerous ISAC use cases, the need for an optimal angular estimation of targets\nand their separation based on the minimal number of angular samples arises.\n  In this work, different approaches for angular estimation based on a minimal,\nDFT-based set of angular samples are evaluated. The samples are acquired\nthrough sweeping multiple beams of an ISAC proof of concept (PoC) in the\nindustrial scenario of the ARENA2036. The study's findings indicate that\ninterpolation approaches are more effective for generalizing across different\ntypes of angular scenarios. While the orthogonal matching pursuit (OMP)\napproach exhibits the most accurate estimation for a single, strong and clearly\ndiscriminable target, the DFT-based interpolation approach demonstrates the\nbest overall estimation performance.", "AI": {"tldr": "ISAC\u7cfb\u7edf\u5e94\u91c7\u7528\u6a21\u62df\u6216\u6df7\u5408\u6ce2\u675f\u5f62\u6210\u7ed3\u6784\uff0c\u4f46\u4f1a\u9650\u5236\u89d2\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u6700\u5c11\u6570\u91cf\u7684\u89d2\u6837\u672c\u6765\u83b7\u5f97\u6700\u4f73\u89d2\u5ea6\u4f30\u8ba1\u548c\u5206\u79bb\u3002", "motivation": "ISAC\u7cfb\u7edf\u9700\u8981\u6700\u4f18\u7684\u89d2\u5ea6\u4f30\u8ba1\u548c\u5206\u79bb\uff0c\u4ee5\u6ee1\u8db3\u5176\u5e94\u7528\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u5728ARENA2036\u7684\u5de5\u4e1a\u573a\u666f\u4e2d\uff0c\u4f7f\u7528ISAC\u6982\u5ff5\u9a8c\u8bc1\uff08PoC\uff09\u7684\u591a\u4e2a\u626b\u63cf\u6ce2\u675f\u6765\u83b7\u53d6\u6700\u5c11\u6570\u91cf\u7684\u89d2\u6837\u672c\uff0c\u5e76\u8bc4\u4f30\u57fa\u4e8e\u8fd9\u4e9b\u6837\u672c\u7684\u4e0d\u540c\u89d2\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "DFT-based\u63d2\u503c\u65b9\u6cd5\u5728\u6574\u4f53\u4f30\u8ba1\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u800cOMP\u65b9\u6cd5\u5728\u4f30\u8ba1\u5355\u4e00\u3001\u5f3a\u5927\u4e14\u53ef\u533a\u5206\u7684\u76ee\u6807\u65f6\u6700\u4e3a\u51c6\u786e\u3002\u63d2\u503c\u65b9\u6cd5\u5728\u4e0d\u540c\u89d2\u5ea6\u573a\u666f\u4e0b\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "DFT-based\u63d2\u503c\u65b9\u6cd5\u662fISAC\u7cfb\u7edf\u89d2\u5ea6\u4f30\u8ba1\u7684\u6700\u4f73\u9009\u62e9\u3002"}}
{"id": "2510.22406", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.22406", "abs": "https://arxiv.org/abs/2510.22406", "authors": ["Anargyros Michaloliakos", "Benjamin J. Chang", "Lawrence A. Bergman", "Alexander F. Vakakis"], "title": "Data-driven, Wavelet-based Identification and Reduced-order Modeling of Linear Systems with Closely Spaced Modes", "comment": null, "summary": "This work presents a purely data-driven, wavelet-based framework for modal\nidentification and reduced-order modeling of mechanical systems with assumed\nlinear dynamics characterized by closely spaced modes with classical or\nnon-classical damping distribution. Traditional Fourier-based methods often\nfail to reliably identify closely spaced modes or accurately capture modal\ninteractions and complexities. To address these limitations, we propose a\nmethodology leveraging the enhanced time -frequency resolution capabilities of\nthe continuous wavelet transform (CWT). By selecting appropriate harmonic\nregions within the wavelet spectra, we effectively isolate modes, and then\ninvert them back in the temporal domain by applying the inverse CWT (ICWT). In\nthis way we reconstruct the corresponding modal dynamics in the time domain.\nUsing the Hilbert transform, instantaneous phases are extracted for each\nidentified mode, enabling the introduction of a complexified modal matrix which\nrobustly characterizes the system's modal properties, even under challenging\nperturbations such as noise and uncertainties due to modal interference and\nunmodeled effects. The identified modal parameters are utilized to reconstruct\nthe frequency response functions (FRFs) of the system and to develop a\nreduced-order model (ROM) that captures accurately the system's dominant\ndynamical behavior valid in a specified frequency range.. Validation of the\nmethodology is conducted both with a numerical non-classical damping and an\nexperimental testbed representing a model of an airplane structure. Results\ndemonstrate the effectiveness of the proposed approach in resolving intricate\nmodal interactions and accurately reproducing the dynamic response of complex\nstructural systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5c0f\u6ce2\u53d8\u6362\u7684\u6a21\u6001\u8bc6\u522b\u548c\u964d\u9636\u6a21\u578b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5904\u7406\u5177\u6709\u7d27\u5bc6\u95f4\u9694\u6a21\u6001\u7684\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edf\u5085\u91cc\u53f6\u65b9\u6cd5\u5728\u5904\u7406\u7d27\u5bc6\u95f4\u9694\u6a21\u6001\u548c\u6a21\u6001\u4ea4\u4e92\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u3002 ", "method": "\u5229\u7528\u8fde\u7eed\u5c0f\u6ce2\u53d8\u6362\uff08CWT\uff09\u589e\u5f3a\u65f6\u9891\u5206\u8fa8\u7387\uff0c\u9009\u62e9\u8c10\u6ce2\u533a\u57df\u6765\u5206\u79bb\u6a21\u6001\uff0c\u7136\u540e\u901a\u8fc7\u9006\u8fde\u7eed\u5c0f\u6ce2\u53d8\u6362\uff08ICWT\uff09\u5c06\u6a21\u6001\u53cd\u6f14\u56de\u65f6\u57df\u3002\u63d0\u53d6\u77ac\u65f6\u76f8\u4f4d\u4ee5\u6784\u5efa\u590d\u6a21\u6001\u77e9\u9635\uff0c\u7528\u4e8e\u8bc6\u522b\u6a21\u6001\u53c2\u6570\uff0c\u8fdb\u800c\u91cd\u6784\u9891\u7387\u54cd\u5e94\u51fd\u6570\uff08FRFs\uff09\u5e76\u5f00\u53d1\u964d\u9636\u6a21\u578b\uff08ROM\uff09\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5206\u79bb\u6a21\u6001\uff0c\u7cbe\u786e\u6355\u6349\u6a21\u6001\u4ea4\u4e92\uff0c\u5e76\u51c6\u786e\u91cd\u6784\u7cfb\u7edf\u7684\u52a8\u6001\u884c\u4e3a\u3002\u901a\u8fc7\u6570\u503c\u6a21\u62df\u548c\u98de\u673a\u7ed3\u6784\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6570\u636e\u9a71\u52a8\u7684\u5c0f\u6ce2\u53d8\u6362\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5177\u6709\u6311\u6218\u6027\u7684\u6a21\u6001\u53c2\u6570\uff0c\u5e76\u4e3a\u590d\u6742\u7ed3\u6784\u7cfb\u7edf\u6784\u5efa\u51c6\u786e\u7684\u964d\u9636\u6a21\u578b\u3002"}}
{"id": "2510.22417", "categories": ["eess.SP", "cs.NE", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.22417", "abs": "https://arxiv.org/abs/2510.22417", "authors": ["Laura Train", "Rodrigo Castellanos", "Miguel G\u00f3mez-L\u00f3pez"], "title": "Genetic Optimization of a Software-Defined GNSS Receiver", "comment": null, "summary": "Commercial off-the-shelf (COTS) Global Navigation Satellite System (GNSS)\nreceivers face significant limitations under high-dynamic conditions,\nparticularly in high-acceleration environments such as those experienced by\nlaunch vehicles. These performance degradations, often observed as\ndiscontinuities in the navigation solution, arise from the inability of\ntraditional tracking loop bandwidths to cope with rapid variations in\nsynchronization parameters. Software-Defined Radio (SDR) receivers overcome\nthese constraints by enabling flexible reconfiguration of tracking loops;\nhowever, manual tuning involves a complex, multidimensional search and seldom\nensures optimal performance. This work introduces a genetic algorithm-based\noptimization framework that autonomously explores the receiver configuration\nspace to determine optimal loop parameters for phase, frequency, and delay\ntracking. The approach is validated within an SDR environment using\nrealistically simulated GPS L1 signals for three representative dynamic regimes\n-guided rocket flight, Low Earth Orbit (LEO) satellite, and static\nreceiver-processed with the open-source GNSS-SDR architecture. Results\ndemonstrate that evolutionary optimization enables SDR receivers to maintain\nrobust and accurate Position, Velocity, and Time (PVT) solutions across diverse\ndynamic conditions. The optimized configurations yielded maximum position and\nvelocity errors of approximately 6 m and 0.08 m/s for the static case, 12 m and\n2.5 m/s for the rocket case, and 5 m and 0.2 m/s for the LEO case.", "AI": {"tldr": "COTS GNSS\u63a5\u6536\u5668\u5728\u9ad8\u52a8\u6001\u6761\u4ef6\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0cSDR\u63a5\u6536\u5668\u53ef\u4ee5\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u8ddf\u8e2a\u73af\u8def\u53c2\u6570\u6765\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfGNSS\u63a5\u6536\u5668\u5728\u706b\u7bad\u53d1\u5c04\u7b49\u9ad8\u52a8\u6001\u6761\u4ef6\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u5bfc\u822a\u89e3\u51b3\u65b9\u6848\u51fa\u73b0\u4e0d\u8fde\u7eed\u3002SDR\u63a5\u6536\u5668\u867d\u7136\u7075\u6d3b\uff0c\u4f46\u624b\u52a8\u8c03\u4f18\u590d\u6742\u4e14\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9057\u4f20\u7b97\u6cd5\u7684\u4f18\u5316\u6846\u67b6\uff0c\u81ea\u52a8\u641c\u7d22SDR\u63a5\u6536\u5668\u914d\u7f6e\u7a7a\u95f4\uff0c\u4ee5\u786e\u5b9a\u6700\u4f18\u7684\u76f8\u4f4d\u3001\u9891\u7387\u548c\u5ef6\u8fdf\u8ddf\u8e2a\u73af\u8def\u53c2\u6570\u3002", "result": "\u5728\u6a21\u62df\u7684GPS L1\u4fe1\u53f7\u548c\u4e09\u79cd\u52a8\u6001\u6a21\u578b\uff08\u706b\u7bad\u3001LEO\u536b\u661f\u3001\u9759\u6001\uff09\u4e0b\uff0c\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u663e\u8457\u63d0\u9ad8\u4e86SDR\u63a5\u6536\u5668\u7684\u8ddf\u8e2a\u6027\u80fd\u3002\u4f18\u5316\u540e\u7684\u914d\u7f6e\u5728\u9759\u6001\u3001\u706b\u7bad\u548cLEO\u60c5\u51b5\u4e0b\uff0c\u6700\u5927\u4f4d\u7f6e\u8bef\u5dee\u5206\u522b\u4e3a\u7ea66\u7c73\u300112\u7c73\u548c5\u7c73\uff0c\u6700\u5927\u901f\u5ea6\u8bef\u5dee\u5206\u522b\u4e3a\u7ea60.08\u7c73/\u79d2\u30012.5\u7c73/\u79d2\u548c0.2\u7c73/\u79d2\u3002", "conclusion": "\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u6846\u67b6\u80fd\u591f\u4f7fSDR\u63a5\u6536\u5668\u5728\u5404\u79cd\u52a8\u6001\u6761\u4ef6\u4e0b\u4fdd\u6301\u7a33\u5065\u4e14\u7cbe\u786e\u7684\u4f4d\u7f6e\u3001\u901f\u5ea6\u548c\u65f6\u95f4\uff08PVT\uff09\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.22472", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.22472", "abs": "https://arxiv.org/abs/2510.22472", "authors": ["Yohei Kono", "Yoshiyuki Tajima"], "title": "Data-driven Exponential Framing for Pulsive Temporal Patterns without Repetition or Singularity", "comment": "16 pages", "summary": "Extracting pulsive temporal patterns from a small dataset without their\nrepetition or singularity shows significant importance in manufacturing\napplications but does not sufficiently attract scientific attention. We propose\nto quantify how long temporal patterns appear without relying on their\nrepetition or singularity, enabling to extract such temporal patterns from a\nsmall dataset. Inspired by the celebrated time delay embedding and data-driven\nHankel matrix analysis, we introduce a linear dynamical system model on the\ntime-delay coordinates behind the data to derive the discrete-time bases each\nof which has a distinct exponential decay constant. The derived bases are\nfitted onto subsequences that are extracted with a sliding window in order to\nquantify how long patterns are dominant in the set of subsequences. We call the\nquantification method Data-driven Exponential Framing (DEF). A toy model-based\nexperiment shows that DEF can identify multiple patterns with distinct lengths.\nDEF is also applied to electric current measurement on a punching machine,\nshowing its possibility to extract multiple patterns from real-world\noscillatory data.", "AI": {"tldr": "\u4ece\u5305\u542b\u91cd\u590d\u6216\u5355\u4e00\u4e8b\u4ef6\u7684\u5c0f\u578b\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u8109\u51b2\u5f0f\u65f6\u95f4\u6a21\u5f0f\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u672a\u83b7\u5f97\u8db3\u591f\u7684\u79d1\u5b66\u5173\u6ce8\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u91cd\u590d\u6216\u5355\u4e00\u4e8b\u4ef6\u5373\u53ef\u91cf\u5316\u65f6\u95f4\u6a21\u5f0f\u51fa\u73b0\u65f6\u957f\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u80fd\u591f\u4ece\u5c0f\u578b\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u6b64\u7c7b\u65f6\u95f4\u6a21\u5f0f\u3002", "motivation": "\u5728\u5236\u9020\u4e1a\u5e94\u7528\u4e2d\uff0c\u4ece\u5305\u542b\u91cd\u590d\u6216\u5355\u4e00\u4e8b\u4ef6\u7684\u5c0f\u578b\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u8109\u51b2\u5f0f\u65f6\u95f4\u6a21\u5f0f\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4f46\u76ee\u524d\u5c1a\u672a\u5f15\u8d77\u8db3\u591f\u7684\u79d1\u5b66\u5173\u6ce8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u5ef6\u8fdf\u5d4c\u5165\u548c\u6570\u636e\u9a71\u52a8\u7684Hankel\u77e9\u9635\u5206\u6790\u7684\u7ebf\u6027\u52a8\u529b\u5b66\u7cfb\u7edf\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4f5c\u7528\u4e8e\u6570\u636e\u80cc\u540e\u65f6\u5ef6\u5750\u6807\uff0c\u4ee5\u5bfc\u51fa\u5177\u6709\u4e0d\u540c\u6307\u6570\u8870\u51cf\u5e38\u6570\u7684\u79bb\u6563\u65f6\u95f4\u57fa\u3002\u7136\u540e\u5c06\u8fd9\u4e9b\u57fa\u62df\u5408\u5230\u7528\u6ed1\u52a8\u7a97\u53e3\u63d0\u53d6\u7684\u5b50\u5e8f\u5217\u4e0a\uff0c\u4ee5\u91cf\u5316\u6a21\u5f0f\u5728\u5b50\u5e8f\u5217\u96c6\u4e2d\u7684\u4e3b\u5bfc\u65f6\u957f\u3002\u6b64\u91cf\u5316\u65b9\u6cd5\u79f0\u4e3a\u6570\u636e\u9a71\u52a8\u6307\u6570\u6846\u67b6\uff08DEF\uff09\u3002", "result": "\u57fa\u4e8e\u73a9\u5177\u6a21\u578b\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDEF\u80fd\u591f\u8bc6\u522b\u5177\u6709\u4e0d\u540c\u65f6\u957f\u7684\u591a\u4e2a\u6a21\u5f0f\u3002\u5c06DEF\u5e94\u7528\u4e8e\u51b2\u538b\u673a\u7684\u7535\u6d41\u6d4b\u91cf\uff0c\u663e\u793a\u4e86\u4ece\u771f\u5b9e\u4e16\u754c\u632f\u8361\u6570\u636e\u4e2d\u63d0\u53d6\u591a\u4e2a\u6a21\u5f0f\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "DEF\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4ece\u5c0f\u578b\u6570\u636e\u96c6\u4e2d\u91cf\u5316\u548c\u63d0\u53d6\u8109\u51b2\u5f0f\u65f6\u95f4\u6a21\u5f0f\uff0c\u8fd9\u5728\u5236\u9020\u4e1a\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2510.22557", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.22557", "abs": "https://arxiv.org/abs/2510.22557", "authors": ["Wang Liu", "Cunhua Pan", "Hong Ren", "Wei Zhang", "Cheng-Xiang Wang", "Jiangzhou Wang"], "title": "Large-Model AI for Near Field Beam Prediction: A CNN-GPT2 Framework for 6G XL-MIMO", "comment": null, "summary": "The emergence of extremely large-scale antenna arrays (ELAA) in\nmillimeter-wave (mmWave) communications, particularly in high-mobility\nscenarios, highlights the importance of near-field beam prediction. Unlike the\nconventional far-field assumption, near-field beam prediction requires\ncodebooks that jointly sample the angular and distance domains, which leads to\na dramatic increase in pilot overhead. Moreover, unlike the far-field case\nwhere the optimal beam evolution is temporally smooth, the optimal near-field\nbeam index exhibits abrupt and nonlinear dynamics due to its joint dependence\non user angle and distance, posing significant challenges for temporal\nmodeling. To address these challenges, we propose a novel Convolutional Neural\nNetwork-Generative Pre-trained Transformer 2 (CNN-GPT2) based near-field beam\nprediction framework. Specifically, an uplink pilot transmission strategy is\ndesigned to enable efficient channel probing through widebeam analog precoding\nand frequency-varying digital precoding. The received pilot signals are\npreprocessed and passed through a CNN-based feature extractor, followed by a\nGPT-2 model that captures temporal dependencies across multiple frames and\ndirectly predicts the near-field beam index in an end-to-end manner.", "AI": {"tldr": "CNN-GPT2\u6846\u67b6\u7528\u4e8e\u6beb\u7c73\u6ce2\u901a\u4fe1\u4e2d\u7684\u8fd1\u573a\u6ce2\u675f\u9884\u6d4b\uff0c\u4ee5\u89e3\u51b3\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e0b\u7684\u6311\u6218\u3002", "motivation": "\u6beb\u7c73\u6ce2\u901a\u4fe1\u548c\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e2d\u6781\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\uff08ELAA\uff09\u7684\u51fa\u73b0\uff0c\u51f8\u663e\u4e86\u8fd1\u573a\u6ce2\u675f\u9884\u6d4b\u7684\u91cd\u8981\u6027\u3002\u8fd1\u573a\u6ce2\u675f\u9884\u6d4b\u9700\u8981\u8054\u5408\u91c7\u6837\u89d2\u5ea6\u548c\u8ddd\u79bb\u57df\u7684\u7801\u672c\uff0c\u5bfc\u81f4\u5bfc\u9891\u5f00\u9500\u6025\u5267\u589e\u52a0\u3002\u6b64\u5916\uff0c\u4e0e\u6700\u4f18\u6ce2\u675f\u6f14\u5316\u65f6\u95f4\u5e73\u6ed1\u7684\u8fdc\u573a\u60c5\u51b5\u4e0d\u540c\uff0c\u6700\u4f18\u8fd1\u573a\u6ce2\u675f\u7d22\u5f15\u7531\u4e8e\u540c\u65f6\u4f9d\u8d56\u7528\u6237\u89d2\u5ea6\u548c\u8ddd\u79bb\u800c\u8868\u73b0\u51fa\u7a81\u7136\u7684\u975e\u7ebf\u6027\u52a8\u6001\uff0c\u5bf9\u65f6\u95f4\u5efa\u6a21\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc-\u751f\u6210\u5f0f\u9884\u8bad\u7ec3Transformer 2\uff08CNN-GPT2\uff09\u7684\u8fd1\u573a\u6ce2\u675f\u9884\u6d4b\u6846\u67b6\u3002\u8bbe\u8ba1\u4e86\u4e00\u79cd\u4e0a\u884c\u5bfc\u9891\u4f20\u8f93\u7b56\u7565\uff0c\u901a\u8fc7\u5bbd\u6ce2\u675f\u6a21\u62df\u9884\u7f16\u7801\u548c\u9891\u7387\u53d8\u5316\u7684\u6570\u5b57\u9884\u7f16\u7801\u6765\u5b9e\u73b0\u6709\u6548\u7684\u4fe1\u9053\u63a2\u6d4b\u3002\u5c06\u63a5\u6536\u5230\u7684\u5bfc\u9891\u4fe1\u53f7\u8fdb\u884c\u9884\u5904\u7406\uff0c\u901a\u8fc7\u57fa\u4e8eCNN\u7684\u7279\u5f81\u63d0\u53d6\u5668\uff0c\u7136\u540e\u901a\u8fc7\u6355\u83b7\u591a\u5e27\u65f6\u95f4\u4f9d\u8d56\u6027\u7684GPT-2\u6a21\u578b\uff0c\u4ee5\u7aef\u5230\u7aef\u7684\u65b9\u5f0f\u76f4\u63a5\u9884\u6d4b\u8fd1\u573a\u6ce2\u675f\u7d22\u5f15\u3002", "result": "CNN-GPT2\u6a21\u578b\u80fd\u591f\u6709\u6548\u6355\u83b7\u8fd1\u573a\u6ce2\u675f\u7d22\u5f15\u7684\u52a8\u6001\uff0c\u5e76\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684\u8fd1\u573a\u6ce2\u675f\u9884\u6d4b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684CNN-GPT2\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8fd1\u573a\u6ce2\u675f\u9884\u6d4b\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u5728\u9ad8\u79fb\u52a8\u6027\u6beb\u7c73\u6ce2\u901a\u4fe1\u573a\u666f\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u6ce2\u675f\u7ba1\u7406\u3002"}}
{"id": "2510.22621", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.22621", "abs": "https://arxiv.org/abs/2510.22621", "authors": ["Md. Shahriar Sadid", "Ali A. Nasir", "Saad Al-Ahmadi", "Samir Al-Ghadhban"], "title": "Parametric Channel Estimation and Design for Active-RIS-Assisted Communications", "comment": null, "summary": "Reconfigurable Intelligent Surface (RIS) technology has emerged as a key\nenabler for future wireless communications. However, its potential is\nconstrained by the difficulty of acquiring accurate user-to-RIS channel state\ninformation (CSI), due to the cascaded channel structure and the high pilot\noverhead of non-parametric methods. Unlike a passive RIS, where the reflected\nsignal suffers from multiplicative path loss, an active RIS amplifies the\nsignal, improving its practicality in real deployments. In this letter, we\npropose a parametric channel estimation method tailored for active RISs. The\nproposed approach integrates an active RIS model with an adaptive Maximum\nLikelihood Estimator (MLE) to recover the main channel parameters using a\nminimal number of pilots. To further enhance performance, an adaptive active\nRIS configuration strategy is employed, which refines the beam direction based\non an initial user location estimate. Moreover, an orthogonal angle-pair\ncodebook is used instead of the conventional Discrete Fourier Transform (DFT)\ncodebook, significantly reducing the codebook size and ensuring reliable\noperation for both far-field and near-field users. Extensive simulations\ndemonstrate that the proposed method achieves near-optimal performance with\nvery few pilots compared to non-parametric approaches. Its performance is also\nbenchmarked against that of a traditional passive RIS under the same total\npower budget to ensure fairness. Results show that active RIS yields higher\nspectral efficiency (SE) by eliminating the multiplicative fading inherent in\npassive RISs and allocating more resources to data transmission", "AI": {"tldr": "\u6709\u6e90RIS\u7684\u53c2\u6570\u5316\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u96c6\u6210\u6709\u6e90RIS\u6a21\u578b\u548c\u81ea\u9002\u5e94\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\uff0c\u5e76\u7ed3\u5408\u81ea\u9002\u5e94\u6709\u6e90RIS\u914d\u7f6e\u7b56\u7565\u548c\u6b63\u4ea4\u89d2\u5ea6-\u5bf9\u7801\u672c\uff0c\u80fd\u591f\u4ee5\u6700\u5c0f\u7684\u5bfc\u9891\u5f00\u9500\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4f18\u4e8e\u4f20\u7edf\u7684\u65e0\u6e90RIS\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u73b0\u6709\u65e0\u6e90RIS\u6280\u672f\u4e2d\u7528\u6237\u5230RIS\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff08CSI\uff09\u83b7\u53d6\u56f0\u96be\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8RIS\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6709\u6e90RIS\u7684\u53c2\u6570\u5316\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u96c6\u6210\u4e86\u6709\u6e90RIS\u6a21\u578b\u548c\u81ea\u9002\u5e94\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5668\uff08MLE\uff09\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u6709\u6e90RIS\u914d\u7f6e\u7b56\u7565\u548c\u6b63\u4ea4\u89d2\u5ea6-\u5bf9\u7801\u672c\u3002", "result": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4e0e\u4f20\u7edf\u7684\u65e0\u6e90RIS\u76f8\u6bd4\uff0c\u5728\u76f8\u540c\u7684\u603b\u529f\u7387\u9884\u7b97\u4e0b\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u9891\u8c31\u6548\u7387\uff08SE\uff09\uff0c\u56e0\u4e3a\u5b83\u6d88\u9664\u4e86\u65e0\u6e90RIS\u56fa\u6709\u7684\u4e58\u6027\u8870\u843d\uff0c\u5e76\u5c06\u66f4\u591a\u8d44\u6e90\u5206\u914d\u7ed9\u6570\u636e\u4f20\u8f93\u3002", "conclusion": "\u6709\u6e90RIS\u901a\u8fc7\u6d88\u9664\u4e58\u6027\u8870\u843d\u5e76\u4f18\u5316\u8d44\u6e90\u5206\u914d\uff0c\u5728\u4fe1\u9053\u4f30\u8ba1\u548c\u6574\u4f53\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u65e0\u6e90RIS\u3002"}}
{"id": "2510.22731", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.22731", "abs": "https://arxiv.org/abs/2510.22731", "authors": ["Yong Huang", "Wenjing Wang", "Dalong Zhang", "Junjie Wang", "Chen Chen", "Yan Cao", "Wei Wang"], "title": "Enhancing WiFi CSI Fingerprinting: A Deep Auxiliary Learning Approach", "comment": "To appear in the IEEE Internet of Things", "summary": "Radio frequency (RF) fingerprinting techniques provide a promising supplement\nto cryptography-based approaches but rely on dedicated equipment to capture\nin-phase and quadrature (IQ) samples, hindering their wide adoption. Recent\nadvances advocate easily obtainable channel state information (CSI) by\ncommercial WiFi devices for lightweight RF fingerprinting, while falling short\nin addressing the challenges of coarse granularity of CSI measurements in an\nopen-world setting. In this paper, we propose CSI2Q, a novel CSI fingerprinting\nsystem that achieves comparable performance to IQ-based approaches. Instead of\nextracting fingerprints directly from raw CSI measurements, CSI2Q first\ntransforms frequency-domain CSI measurements into time-domain signals that\nshare the same feature space with IQ samples. Then, we employ a deep auxiliary\nlearning strategy to transfer useful knowledge from an IQ fingerprinting model\nto the CSI counterpart. Finally, the trained CSI model is combined with an\nOpenMax function to estimate the likelihood of unknown ones. We evaluate CSI2Q\non one synthetic CSI dataset involving 85 devices and two real CSI datasets,\nincluding 10 and 25 WiFi routers, respectively. Our system achieves accuracy\nincreases of at least 16% on the synthetic CSI dataset, 20% on the in-lab CSI\ndataset, and 17% on the in-the-wild CSI dataset.", "AI": {"tldr": "CSI2Q\u901a\u8fc7\u5c06CSI\u8f6c\u6362\u4e3aIQ\u6837\u672c\u7684\u7279\u5f81\u7a7a\u95f4\uff0c\u5e76\u5229\u7528\u6df1\u5ea6\u8f85\u52a9\u5b66\u4e60\u548cOpenMax\u51fd\u6570\uff0c\u5b9e\u73b0\u4e86\u4e0eIQ\u6837\u672c\u76f8\u5f53\u7684\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u6027\u80fd\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff08CSI\uff09\u7684\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\u5b58\u5728\u7c92\u5ea6\u7c97\u7cd9\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u5e7f\u6cdb\u5e94\u7528\u3002\u800c\u57fa\u4e8eIQ\u6837\u672c\u7684\u65b9\u6cd5\u9700\u8981\u4e13\u7528\u8bbe\u5907\uff0c\u9650\u5236\u4e86\u5176\u666e\u53ca\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u5546\u7528WiFi\u8bbe\u5907\u83b7\u53d6\u7684CSI\uff0c\u5e76\u8fbe\u5230\u4e0eIQ\u6837\u672c\u76f8\u5f53\u7684\u6027\u80fd\u7684\u8f7b\u91cf\u7ea7\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u7cfb\u7edf\u3002", "method": "CSI2Q\u7cfb\u7edf\u9996\u5148\u5c06\u9891\u7387\u57df\u7684CSI\u6d4b\u91cf\u503c\u8f6c\u6362\u4e3a\u4e0eIQ\u6837\u672c\u5171\u4eab\u540c\u4e00\u7279\u5f81\u7a7a\u95f4\u7684\u65f6\u57df\u4fe1\u53f7\u3002\u7136\u540e\uff0c\u5229\u7528\u6df1\u5ea6\u8f85\u52a9\u5b66\u4e60\u7b56\u7565\u5c06IQ\u6307\u7eb9\u8bc6\u522b\u6a21\u578b\u7684\u77e5\u8bc6\u8fc1\u79fb\u5230CSI\u6a21\u578b\u3002\u6700\u540e\uff0c\u7ed3\u5408OpenMax\u51fd\u6570\u6765\u4f30\u8ba1\u672a\u77e5\u6837\u672c\u7684\u76f8\u4f3c\u5ea6\u3002", "result": "\u5728\u5305\u542b85\u4e2a\u8bbe\u5907\u7684\u5408\u6210CSI\u6570\u636e\u96c6\u300110\u4e2aWiFi\u8def\u7531\u5668\u7684\u5ba4\u5185CSI\u6570\u636e\u96c6\u4ee5\u53ca25\u4e2aWiFi\u8def\u7531\u5668\u7684\u5b9e\u9645CSI\u6570\u636e\u96c6\u4e0a\uff0cCSI2Q\u7684\u51c6\u786e\u7387\u5206\u522b\u63d0\u9ad8\u4e86\u81f3\u5c1116%\u300120%\u548c17%\u3002", "conclusion": "CSI2Q\u6210\u529f\u514b\u670d\u4e86\u73b0\u6709CSI\u6307\u7eb9\u8bc6\u522b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u4e0e\u57fa\u4e8eIQ\u6837\u672c\u7684\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\uff0c\u4e3a\u5728\u5f00\u653e\u4e16\u754c\u73af\u5883\u4e2d\u5e7f\u6cdb\u5e94\u7528\u8f7b\u91cf\u7ea7\u5c04\u9891\u6307\u7eb9\u8bc6\u522b\u6280\u672f\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.22772", "categories": ["eess.SP", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.22772", "abs": "https://arxiv.org/abs/2510.22772", "authors": ["Yizhuo Wu", "Francesco Fioranelli", "Chang Gao"], "title": "Neural-HAR: A Dimension-Gated CNN Accelerator for Real-Time Radar Human Activity Recognition", "comment": null, "summary": "Radar-based human activity recognition (HAR) is attractive for unobtrusive\nand privacy-preserving monitoring, yet many CNN/RNN solutions remain too heavy\nfor edge deployment, and even lightweight ViT/SSM variants often exceed\npractical compute and memory budgets. We introduce Neural-HAR, a\ndimension-gated CNN accelerator tailored for real-time radar HAR on\nresource-constrained platforms. At its core is GateCNN, a parameter-efficient\nDoppler-temporal network that (i) embeds Doppler vectors to emphasize frequency\nevolution over time and (ii) applies dual-path gated convolutions that modulate\nDoppler-aware content features with temporal gates, complemented by a residual\npath for stable training. On the University of Glasgow UoG2020 continuous radar\ndataset, GateCNN attains 86.4% accuracy with only 2.7k parameters and 0.28M\nFLOPs per inference, comparable to CNN-BiGRU at a fraction of the complexity.\nOur FPGA prototype on Xilinx Zynq-7000 Z-7007S reaches 107.5 $\\mu$s latency and\n15 mW dynamic power using LUT-based ROM and distributed RAM only (zero\nDSP/BRAM), demonstrating real-time, energy-efficient edge inference. Code and\nHLS conversion scripts are available at https://github.com/lab-emi/AIRHAR.", "AI": {"tldr": "Neural-HAR\u662f\u4e00\u79cd\u9488\u5bf9\u8fb9\u7f18\u8bbe\u5907\u7684\u96f7\u8fbe\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\uff08HAR\uff09\u52a0\u901f\u5668\uff0c\u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u7684GateCNN\u7f51\u7edc\uff0c\u5728UoG2020\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8686.4%\u7684\u51c6\u786e\u7387\uff0c\u53c2\u6570\u91cf\u4ec52.7k\uff0c\u63a8\u7406\u7b97\u529b0.28M FLOPs\u3002FPGA\u539f\u578b\u5b9e\u73b0\u4e86107.5 \u03bcs\u7684\u4f4e\u5ef6\u8fdf\u548c15 mW\u7684\u52a8\u6001\u529f\u8017\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eCNN/RNN\u7684\u96f7\u8fbe\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\uff08HAR\uff09\u65b9\u6cd5\u8fc7\u4e8e\u5e9e\u5927\uff0c\u4e0d\u9002\u5408\u8fb9\u7f18\u90e8\u7f72\uff1b\u8f7b\u91cf\u7ea7\u7684ViT/SSM\u53d8\u4f53\u4e5f\u5e38\u5e38\u8d85\u51fa\u5b9e\u9645\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u9650\u5236\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5b9e\u73b0\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u7684\u5b9e\u65f6\u96f7\u8fbeHAR\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNeural-HAR\u7684\u7ef4\u5ea6\u95e8\u63a7CNN\u52a0\u901f\u5668\uff0c\u6838\u5fc3\u662fGateCNN\u3002GateCNN\u662f\u4e00\u4e2a\u53c2\u6570\u9ad8\u6548\u7684\u591a\u666e\u52d2-\u65f6\u95f4\u7f51\u7edc\uff0c\u5b83\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5de5\u4f5c\uff1a\uff081\uff09\u5d4c\u5165\u591a\u666e\u52d2\u5411\u91cf\u4ee5\u5728\u65f6\u95f4\u4e0a\u5f3a\u8c03\u9891\u7387\u6f14\u53d8\uff1b\uff082\uff09\u5e94\u7528\u53cc\u8def\u5f84\u95e8\u63a7\u5377\u79ef\uff0c\u7528\u591a\u666e\u52d2\u611f\u77e5\u7684\u5185\u5bb9\u7279\u5f81\u8c03\u5236\u65f6\u95f4\u95e8\uff1b\uff083\uff09\u7ed3\u5408\u6b8b\u5dee\u8def\u5f84\u4ee5\u5b9e\u73b0\u7a33\u5b9a\u7684\u8bad\u7ec3\u3002", "result": "GateCNN\u5728UoG2020\u8fde\u7eed\u96f7\u8fbe\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e8686.4%\u7684\u51c6\u786e\u7387\uff0c\u4ec5\u4f7f\u7528\u4e862.7k\u53c2\u6570\u548c\u6bcf\u6b21\u63a8\u74060.28M FLOPs\uff0c\u5176\u590d\u6742\u6027\u4ec5\u662fCNN-BiGRU\u7684\u51e0\u5206\u4e4b\u4e00\u3002FPGA\u539f\u578b\u5728Xilinx Zynq-7000 Z-7007S\u4e0a\u5b9e\u73b0\u4e86107.5 \u03bcs\u7684\u5ef6\u8fdf\u548c15 mW\u7684\u52a8\u6001\u529f\u8017\uff0c\u4e14\u4ec5\u4f7f\u7528\u4e86LUT\u548c\u5206\u5e03\u5f0fRAM\uff0c\u6ca1\u6709\u4f7f\u7528DSP/BRAM\u3002", "conclusion": "Neural-HAR\u901a\u8fc7\u5176\u521b\u65b0\u7684GateCNN\u7f51\u7edc\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u7684\u5b9e\u65f6\u3001\u9ad8\u80fd\u6548\u7684\u96f7\u8fbeHAR\u3002\u5176\u53c2\u6570\u6548\u7387\u548c\u4f4e\u529f\u8017\u7279\u6027\u4f7f\u5176\u975e\u5e38\u9002\u5408\u90e8\u7f72\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u3002"}}
{"id": "2510.22895", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.22895", "abs": "https://arxiv.org/abs/2510.22895", "authors": ["Wang Hao", "Kuang Zhang", "Hou Chengyu", "Yang Yifan", "Tan Chenxing", "Fu Weifeng"], "title": "Rmd: Robust Modal Decomposition with Constrained Bandwidth", "comment": null, "summary": "Modal decomposition techniques, such as Empirical Mode Decomposition (EMD),\nVariational Mode Decomposition (VMD), and Singular Spectrum Analysis (SSA),\nhave advanced time-frequency signal analysis since the early 21st century.\nThese methods are generally classified into two categories: numerical\noptimization-based methods (EMD, VMD) and spectral decomposition methods (SSA)\nthat consider the physical meaning of signals. The former can produce spurious\nmodes due to the lack of physical constraints, while the latter is more\nsensitive to noise and struggles with nonlinear signals. Despite continuous\nimprovements in these methods, a modal decomposition approach that effectively\ncombines the strengths of both categories remains elusive. This paper thus\nproposes a Robust Modal Decomposition (RMD) method with constrained bandwidth,\nwhich preserves the intrinsic structure of the signal by mapping the time\nseries into its trajectory-GRAM matrix in phase space. Moreover, the method\nincorporates bandwidth constraints during the decomposition process, enhancing\nnoise resistance. Extensive experiments on synthetic and real-world datasets,\nincluding millimeter-wave radar echoes, electrocardiogram (ECG),\nphonocardiogram (PCG), and bearing fault detection data, demonstrate the\nmethod's effectiveness and versatility. All code and dataset samples are\navailable on GitHub: https://github.com/Einstein-sworder/RMD.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u9c81\u68d2\u6a21\u6001\u5206\u89e3\uff08RMD\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u4fe1\u53f7\u5206\u6790\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u5728\u76f8\u7a7a\u95f4\u4e2d\u6620\u5c04\u65f6\u95f4\u5e8f\u5217\u5230\u5176\u8f68\u8ff9-GRAM\u77e9\u9635\u5e76\u5f15\u5165\u5e26\u5bbd\u7ea6\u675f\u6765\u63d0\u9ad8\u566a\u58f0\u62b5\u6297\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u6a21\u6001\u5206\u89e3\u6280\u672f\uff08\u5982EMD\u3001VMD\u548cSSA\uff09\u5404\u6709\u4f18\u7f3a\u70b9\uff0c\u4f8b\u5982\u57fa\u4e8e\u6570\u503c\u4f18\u5316\u7684\u65b9\u6cd5\u53ef\u80fd\u4ea7\u751f\u4f2a\u6a21\u5f0f\uff0c\u800c\u57fa\u4e8e\u9891\u8c31\u5206\u89e3\u7684\u65b9\u6cd5\u5bf9\u566a\u58f0\u654f\u611f\u4e14\u96be\u4ee5\u5904\u7406\u975e\u7ebf\u6027\u4fe1\u53f7\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u7ed3\u5408\u4e24\u8005\u4f18\u70b9\u5e76\u514b\u670d\u5176\u5c40\u9650\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u6a21\u6001\u5206\u89e3\uff08RMD\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u65f6\u95f4\u5e8f\u5217\u6620\u5c04\u5230\u5176\u5728\u76f8\u7a7a\u95f4\u4e2d\u7684\u8f68\u8ff9-GRAM\u77e9\u9635\u6765\u4fdd\u7559\u4fe1\u53f7\u7684\u5185\u5728\u7ed3\u6784\uff0c\u5e76\u5728\u5206\u89e3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u5e26\u5bbd\u7ea6\u675f\u4ee5\u589e\u5f3a\u6297\u566a\u58f0\u80fd\u529b\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff08\u5305\u62ec\u6beb\u7c73\u6ce2\u96f7\u8fbe\u56de\u6ce2\u3001\u5fc3\u7535\u56fe\u3001\u5fc3\u97f3\u56fe\u548c\u8f74\u627f\u6545\u969c\u68c0\u6d4b\u6570\u636e\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cRMD\u65b9\u6cd5\u5177\u6709\u6709\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "RMD\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u76f8\u7a7a\u95f4\u6620\u5c04\u548c\u5e26\u5bbd\u7ea6\u675f\uff0c\u6709\u6548\u5730\u514b\u670d\u4e86\u73b0\u6709\u6a21\u6001\u5206\u89e3\u6280\u672f\u7684\u7f3a\u70b9\uff0c\u5728\u4fe1\u53f7\u5206\u6790\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.22913", "categories": ["eess.SP", "cs.HC", "cs.LG", "cs.RO", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.22913", "abs": "https://arxiv.org/abs/2510.22913", "authors": ["Thanyanee Srichaisak", "Arissa Ieochai", "Aueaphum Aueawattthanaphisut"], "title": "Clinic-Oriented Feasibility of a Sensor-Fused Wearable for Upper-Limb Function", "comment": "19 pages, 7 figures, 5 Tables", "summary": "Background: Upper-limb weakness and tremor (4--12 Hz) limit activities of\ndaily living (ADL) and reduce adherence to home rehabilitation. Objective: To\nassess technical feasibility and clinician-relevant signals of a sensor-fused\nwearable targeting the triceps brachii and extensor pollicis brevis. Methods: A\nlightweight node integrates surface EMG (1 kHz), IMU (100--200 Hz), and\nflex/force sensors with on-device INT8 inference (Tiny 1D-CNN/Transformer) and\na safety-bounded assist policy (angle/torque/jerk limits; stall/time-out).\nHealthy adults (n = 12) performed three ADL-like tasks. Primary outcomes:\nTremor Index (TI), range of motion (ROM), repetitions (Reps min$^{-1}$).\nSecondary: EMG median-frequency slope (fatigue trend), closed-loop latency,\nsession completion, and device-related adverse events. Analyses used\nsubject-level paired medians with BCa 95\\% CIs; exact Wilcoxon $p$-values are\nreported in the Results. Results: Assistance was associated with lower tremor\nprominence and improved task throughput: TI decreased by $-0.092$ (95\\% CI\n[$-0.102$, $-0.079$]), ROM increased by $+12.65\\%$ (95\\% CI [$+8.43$,\n$+13.89$]), and Reps rose by $+2.99$ min$^{-1}$ (95\\% CI [$+2.61$, $+3.35$]).\nMedian on-device latency was 8.7 ms at a 100 Hz loop rate; all sessions were\ncompleted with no device-related adverse events. Conclusions: Multimodal\nsensing with low-latency, safety-bounded assistance produced improved movement\nquality (TI $\\downarrow$) and throughput (ROM, Reps $\\uparrow$) in a pilot\ntechnical-feasibility setting, supporting progression to IRB-approved patient\nstudies. Trial registration: Not applicable (pilot non-clinical).", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u8868\u9762\u808c\u7535\u56fe\uff08EMG\uff09\u3001\u60ef\u6027\u6d4b\u91cf\u5355\u5143\uff08IMU\uff09\u4ee5\u53ca\u67d4\u6027/\u529b\u4f20\u611f\u5668\u7684\u591a\u6a21\u6001\u53ef\u7a7f\u6234\u8bbe\u5907\uff0c\u7528\u4e8e\u5e2e\u52a9\u4e0a\u80a2\u65e0\u529b\u548c\u9707\u98a4\u7684\u60a3\u8005\u8fdb\u884c\u5eb7\u590d\u8bad\u7ec3\u3002\u8be5\u8bbe\u5907\u901a\u8fc7\u5728\u8bbe\u5907\u7aef\u8fdb\u884cINT8\u63a8\u7406\u548c\u5b89\u5168\u7ea6\u675f\u7684\u8f85\u52a9\u7b56\u7565\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u9707\u98a4\uff0c\u63d0\u9ad8\u4e86\u8fd0\u52a8\u8303\u56f4\u548c\u4efb\u52a1\u5b8c\u6210\u7387\uff0c\u4e14\u5177\u6709\u4f4e\u5ef6\u8fdf\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u4e0a\u80a2\u65e0\u529b\u548c\u9707\u98a4\uff084-12 Hz\uff09\u4e25\u91cd\u5f71\u54cd\u65e5\u5e38\u751f\u6d3b\u6d3b\u52a8\uff08ADL\uff09\u5e76\u964d\u4f4e\u5bb6\u5ead\u5eb7\u590d\u4f9d\u4ece\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u4e00\u79cd\u9488\u5bf9\u80b1\u4e09\u5934\u808c\u548c\u62c7\u957f\u5c55\u808c\u7684\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u7684\u6280\u672f\u53ef\u884c\u6027\u53ca\u5176\u4ea7\u751f\u7684\u4fe1\u53f7\u662f\u5426\u4e0e\u4e34\u5e8a\u76f8\u5173\u3002", "method": "\u7814\u7a76\u4eba\u5458\u96c6\u6210\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u8282\u70b9\uff0c\u8be5\u8282\u70b9\u5305\u542b\u8868\u9762\u808c\u7535\u56fe\uff081 kHz\uff09\u3001\u60ef\u6027\u6d4b\u91cf\u5355\u5143\uff08100-200 Hz\uff09\u548c\u67d4\u6027/\u529b\u4f20\u611f\u5668\u3002\u8bbe\u5907\u7aef\u5229\u7528INT8\u63a8\u7406\uff08Tiny 1D-CNN/Transformer\uff09\u5b9e\u73b0\u4f4e\u529f\u8017\u8ba1\u7b97\uff0c\u5e76\u91c7\u7528\u5177\u6709\u5b89\u5168\u8fb9\u754c\uff08\u89d2\u5ea6/\u626d\u77e9/\u52a0\u52a0\u901f\u5ea6\u9650\u5236\uff1b\u5835\u8f6c/\u8d85\u65f6\u4fdd\u62a4\uff09\u7684\u8f85\u52a9\u7b56\u7565\u3002\u62db\u52df\u4e8612\u540d\u5065\u5eb7\u6210\u5e74\u4eba\uff0c\u8ba9\u4ed6\u4eec\u6267\u884c\u4e09\u9879ADL\u7c7b\u4efb\u52a1\u3002\u4e3b\u8981\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u9707\u98a4\u6307\u6570\uff08TI\uff09\u3001\u8fd0\u52a8\u8303\u56f4\uff08ROM\uff09\u548c\u6bcf\u5206\u949f\u91cd\u590d\u6b21\u6570\uff08Reps min$^{-1}$\uff09\u3002\u6b21\u8981\u6307\u6807\u5305\u62ecEMG\u4e2d\u503c\u9891\u7387\u659c\u7387\uff08\u8bc4\u4f30\u75b2\u52b3\u8d8b\u52bf\uff09\u3001\u95ed\u73af\u5ef6\u8fdf\u3001\u4f1a\u8bdd\u5b8c\u6210\u60c5\u51b5\u4ee5\u53ca\u8bbe\u5907\u76f8\u5173\u7684\u4e0d\u826f\u4e8b\u4ef6\u3002", "result": "\u4e0e\u65e0\u8f85\u52a9\u76f8\u6bd4\uff0c\u8f85\u52a9\u6cbb\u7597\u663e\u8457\u964d\u4f4e\u4e86\u9707\u98a4\u7684\u5e45\u5ea6\uff0c\u5e76\u63d0\u9ad8\u4e86\u4efb\u52a1\u541e\u5410\u91cf\uff1a\u9707\u98a4\u6307\u6570\uff08TI\uff09\u964d\u4f4e\u4e86-0.092\uff0895%\u7f6e\u4fe1\u533a\u95f4[-0.102, -0.079]\uff09\uff0c\u8fd0\u52a8\u8303\u56f4\uff08ROM\uff09\u589e\u52a0\u4e86+12.65%\uff0895%\u7f6e\u4fe1\u533a\u95f4[+8.43%, +13.89%]\uff09\uff0c\u6bcf\u5206\u949f\u91cd\u590d\u6b21\u6570\uff08Reps\uff09\u589e\u52a0\u4e86+2.99 min$^{-1}$\uff0895%\u7f6e\u4fe1\u533a\u95f4[+2.61 min$^{-1}$, +3.35 min$^{-1}$]\uff09\u3002\u8bbe\u5907\u7aef\u7684\u4e2d\u503c\u5ef6\u8fdf\u4e3a8.7\u6beb\u79d2\uff0c\u5faa\u73af\u7387\u4e3a100 Hz\u3002\u6240\u6709\u53d7\u8bd5\u8005\u5747\u5b8c\u6210\u4e86\u8bad\u7ec3\uff0c\u672a\u53d1\u751f\u4efb\u4f55\u8bbe\u5907\u76f8\u5173\u7684 ao \u6076\u6027\u4e8b\u4ef6\u3002", "conclusion": "\u5728\u672c\u9879\u8bd5\u70b9\u6280\u672f\u53ef\u884c\u6027\u7814\u7a76\u4e2d\uff0c\u7ed3\u5408\u4e86\u591a\u6a21\u6001\u4f20\u611f\u3001\u4f4e\u5ef6\u8fdf\u548c\u5b89\u5168\u7ea6\u675f\u7684\u8f85\u52a9\u7b56\u7565\uff0c\u80fd\u591f\u6539\u5584\u8fd0\u52a8\u8d28\u91cf\uff08TI\u964d\u4f4e\uff09\u548c\u4efb\u52a1\u541e\u5410\u91cf\uff08ROM\u548cReps\u589e\u52a0\uff09\uff0c\u652f\u6301\u8be5\u8bbe\u5907\u5411\u7b26\u5408IRB\u6279\u51c6\u7684\u60a3\u8005\u7814\u7a76\u8fdb\u884c\u63a8\u8fdb\u3002"}}
{"id": "2510.22947", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.22947", "abs": "https://arxiv.org/abs/2510.22947", "authors": ["Yi Tao", "Zhen Gao", "Fangquan Ye", "Jingbo Xu", "Tao Song", "Weidong Li", "Yu Su", "Lu Peng", "Xiaomei Wu", "Tong Qin", "Zhongxiang Li", "Dezhi Zheng"], "title": "Intelligent Multimodal Multi-Sensor Fusion-Based UAV Identification, Localization, and Countermeasures for Safeguarding Low-Altitude Economy", "comment": null, "summary": "The development of the low-altitude economy has led to a growing prominence\nof uncrewed aerial vehicle (UAV) safety management issues. Therefore, accurate\nidentification, real-time localization, and effective countermeasures have\nbecome core challenges in airspace security assurance. This paper introduces an\nintegrated UAV management and control system based on deep learning, which\nintegrates multimodal multi-sensor fusion perception, precise positioning, and\ncollaborative countermeasures. By incorporating deep learning methods, the\nsystem combines radio frequency (RF) spectral feature analysis, radar\ndetection, electro-optical identification, and other methods at the detection\nlevel to achieve the identification and classification of UAVs. At the\nlocalization level, the system relies on multi-sensor data fusion and the\nair-space-ground integrated communication network to conduct real-time tracking\nand prediction of UAV flight status, providing support for early warning and\ndecision-making. At the countermeasure level, it adopts comprehensive measures\nthat integrate ``soft kill'' and ``hard kill'', including technologies such as\nelectromagnetic signal jamming, navigation spoofing, and physical interception,\nto form a closed-loop management and control process from early warning to\nfinal disposal, which significantly enhances the response efficiency and\ndisposal accuracy of low-altitude UAV management.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u96c6\u6210\u65e0\u4eba\u673a\u7ba1\u7406\u4e0e\u63a7\u5236\u7cfb\u7edf\uff0c\u901a\u8fc7\u591a\u4f20\u611f\u5668\u878d\u5408\u611f\u77e5\u3001\u7cbe\u51c6\u5b9a\u4f4d\u548c\u534f\u540c\u53cd\u5236\uff0c\u63d0\u5347\u4f4e\u7a7a\u65e0\u4eba\u673a\u5b89\u5168\u7ba1\u7406\u6c34\u5e73\u3002", "motivation": "\u4f4e\u7a7a\u7ecf\u6d4e\u53d1\u5c55\u5e26\u6765\u4e86\u65e0\u4eba\u673a\u5b89\u5168\u7ba1\u7406\u95ee\u9898\uff0c\u56e0\u6b64\uff0c\u7cbe\u51c6\u8bc6\u522b\u3001\u5b9e\u65f6\u5b9a\u4f4d\u548c\u6709\u6548\u53cd\u5236\u6210\u4e3a\u7a7a\u57df\u5b89\u5168\u4fdd\u969c\u7684\u6838\u5fc3\u6311\u6218\u3002", "method": "\u8be5\u7cfb\u7edf\u96c6\u6210\u591a\u6a21\u6001\u591a\u4f20\u611f\u5668\u878d\u5408\u611f\u77e5\u3001\u7cbe\u51c6\u5b9a\u4f4d\u548c\u534f\u540c\u53cd\u5236\u3002\u5728\u63a2\u6d4b\u5c42\u9762\uff0c\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u7ed3\u5408\u5c04\u9891\uff08RF\uff09\u9891\u8c31\u7279\u5f81\u5206\u6790\u3001\u96f7\u8fbe\u63a2\u6d4b\u3001\u5149\u7535\u8bc6\u522b\u7b49\u624b\u6bb5\uff0c\u5b9e\u73b0\u65e0\u4eba\u673a\u7684\u8bc6\u522b\u4e0e\u5206\u7c7b\uff1b\u5728\u5b9a\u4f4d\u5c42\u9762\uff0c\u901a\u8fc7\u591a\u4f20\u611f\u5668\u6570\u636e\u878d\u5408\u53ca\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u901a\u4fe1\u7f51\u7edc\uff0c\u5b9e\u65f6\u8ffd\u8e2a\u548c\u9884\u6d4b\u65e0\u4eba\u673a\u98de\u884c\u72b6\u6001\uff1b\u5728\u53cd\u5236\u5c42\u9762\uff0c\u7efc\u5408\u8fd0\u7528\u201c\u8f6f\u6740\u4f24\u201d\u548c\u201c\u786c\u6740\u4f24\u201d\u63aa\u65bd\uff0c\u5305\u62ec\u7535\u78c1\u5e72\u6270\u3001\u5bfc\u822a\u6b3a\u9a97\u548c\u7269\u7406\u62e6\u622a\u7b49\u6280\u672f\uff0c\u5f62\u6210\u4ece\u9884\u8b66\u5230\u5904\u7f6e\u7684\u95ed\u73af\u7ba1\u7406\u3002", "result": "\u8be5\u7cfb\u7edf\u663e\u8457\u63d0\u9ad8\u4e86\u4f4e\u7a7a\u65e0\u4eba\u673a\u7ba1\u7406\u7684\u5b89\u5168\u54cd\u5e94\u6548\u7387\u548c\u5904\u7f6e\u51c6\u786e\u6027\u3002", "conclusion": "\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u96c6\u6210\u65e0\u4eba\u673a\u7ba1\u7406\u4e0e\u63a7\u5236\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u4f4e\u7a7a\u65e0\u4eba\u673a\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218\u3002"}}
{"id": "2510.22948", "categories": ["eess.SP", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.22948", "abs": "https://arxiv.org/abs/2510.22948", "authors": ["Zhaoming Hu", "Ruikang Zhong", "Xidong Mu", "Dengao Li", "Yuanwei Liu"], "title": "PASS-Enhanced MEC: Joint Optimization of Task Offloading and Uplink PASS Beamforming", "comment": null, "summary": "A pinching-antenna system (PASS)-enhanced mobile edge computing (MEC)\narchitecture is investigated to improve the task offloading efficiency and\nlatency performance in dynamic wireless environments. By leveraging dielectric\nwaveguides and flexibly adjustable pinching antennas, PASS establishes\nshort-distance line-of-sight (LoS) links while effectively mitigating the\nsignificant path loss and potential signal blockage, making it a promising\nsolution for high-frequency MEC systems. We formulate a network latency\nminimization problem to joint optimize uplink PASS beamforming and task\noffloading. The resulting problem is modeled as a Markov decision process (MDP)\nand solved via the deep reinforcement learning (DRL) method. To address the\ninstability introduced by the $\\max$ operator in the objective function, we\npropose a load balancing-aware proximal policy optimization (LBPPO) algorithm.\nLBPPO incorporates both node-level and waveguide-level load balancing\ninformation into the policy design, maintaining computational and transmission\ndelay equilibrium, respectively. Simulation results demonstrate that the\nproposed PASS-enhanced MEC with adaptive uplink PASS beamforming exhibit\nstronger convergence capability than fixed-PA baselines and conventional\nMIMO-assisted MEC, especially in scenarios with a large number of UEs or high\ntransmit power.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u5929\u7ebf\u6280\u672f\u548c\u8fb9\u7f18\u8ba1\u7b97\u7684\u7cfb\u7edf\uff08PASS-MEC\uff09\uff0c\u4ee5\u63d0\u9ad8\u79fb\u52a8\u8bbe\u5907\u5728\u65e0\u7ebf\u73af\u5883\u4e0b\u7684\u4efb\u52a1\u5904\u7406\u6548\u7387\u548c\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u5728\u52a8\u6001\u65e0\u7ebf\u73af\u5883\u4e2d\uff0c\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\uff08MEC\uff09\u9762\u4e34\u4efb\u52a1\u5378\u8f7d\u6548\u7387\u4f4e\u548c\u5ef6\u8fdf\u5927\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ecb\u8d28\u6ce2\u5bfc\u548c\u53ef\u8c03\u8c10\u634f\u5929\u7ebf\uff08PASS\uff09\u7684MEC\u67b6\u6784\u3002\u8be5\u67b6\u6784\u901a\u8fc7\u5efa\u7acb\u77ed\u8ddd\u79bb\u89c6\u8ddd\uff08LoS\uff09\u94fe\u8def\u6765\u514b\u670d\u9ad8\u9891\u901a\u4fe1\u4e2d\u7684\u8def\u5f84\u635f\u8017\u548c\u4fe1\u53f7\u963b\u585e\u95ee\u9898\u3002\u5c06\u7f51\u7edc\u5ef6\u8fdf\u6700\u5c0f\u5316\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\uff0c\u5e76\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLBPPO\u7684\u8d1f\u8f7d\u5747\u8861\u611f\u77e5\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u6765\u89e3\u51b3\u76ee\u6807\u51fd\u6570\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002LBPPO\u7b97\u6cd5\u7ed3\u5408\u4e86\u8282\u70b9\u7ea7\u548c\u6ce2\u5bfc\u7ea7\u7684\u8d1f\u8f7d\u5747\u8861\u4fe1\u606f\u6765\u4f18\u5316\u7b56\u7565\uff0c\u4ee5\u7ef4\u6301\u8ba1\u7b97\u548c\u4f20\u8f93\u5ef6\u8fdf\u7684\u5e73\u8861\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684PASS\u589e\u5f3aMEC\u7cfb\u7edf\u5728\u5177\u6709\u81ea\u9002\u5e94\u4e0a\u884c\u94fe\u8defPASS\u6ce2\u675f\u6210\u5f62\u65f6\uff0c\u76f8\u6bd4\u4e8e\u56fa\u5b9aPA\u57fa\u7ebf\u548c\u4f20\u7edfMIMO\u8f85\u52a9MEC\uff0c\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6536\u655b\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u7528\u6237\u6570\u91cf\u591a\u6216\u53d1\u5c04\u529f\u7387\u9ad8\u7684\u573a\u666f\u4e0b\u3002", "conclusion": "PASS-MEC\u67b6\u6784\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u9ad8\u9891MEC\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u5408\u5148\u8fdb\u7684\u5929\u7ebf\u6280\u672f\u548c\u4f18\u5316\u7684\u8d44\u6e90\u5206\u914d\u7b56\u7565\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u7684\u6027\u80fd\u3002"}}
{"id": "2510.23021", "categories": ["eess.SP", "cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.23021", "abs": "https://arxiv.org/abs/2510.23021", "authors": ["Xibin Jin", "Guoliang Li", "Shuai Wang", "Fan Liu", "Miaowen Wen", "Huseyin Arslan", "Derrick Wing Kwan Ng", "Chengzhong Xu"], "title": "Planning Oriented Integrated Sensing and Communication", "comment": null, "summary": "Integrated sensing and communication (ISAC) enables simultaneous\nlocalization, environment perception, and data exchange for connected\nautonomous vehicles. However, most existing ISAC designs prioritize sensing\naccuracy and communication throughput, treating all targets uniformly and\noverlooking the impact of critical obstacles on motion efficiency. To overcome\nthis limitation, we propose a planning-oriented ISAC (PISAC) framework that\nreduces the sensing uncertainty of planning-bottleneck obstacles and expands\nthe safe navigable path for the ego-vehicle, thereby bridging the gap between\nphysical-layer optimization and motion-level planning. The core of PISAC lies\nin deriving a closed-form safety bound that explicitly links ISAC transmit\npower to sensing uncertainty, based on the Cram\\'er-Rao Bound and occupancy\ninflation principles. Using this model, we formulate a bilevel power allocation\nand motion planning (PAMP) problem, where the inner layer optimizes the ISAC\nbeam power distribution and the outer layer computes a collision-free\ntrajectory under uncertainty-aware safety constraints. Comprehensive\nsimulations in high-fidelity urban driving environments demonstrate that PISAC\nachieves up to 40% higher success rates and over 5% shorter traversal times\nthan existing ISAC-based and communication-oriented benchmarks, validating its\neffectiveness in enhancing both safety and efficiency."}
{"id": "2510.23147", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23147", "abs": "https://arxiv.org/abs/2510.23147", "authors": ["Parisa Kanani", "Mohammad Javad Omidi", "Mahmoud Modarres-Hashemi", "Halim Yanikomeroglu"], "title": "HAPS-ISAC for 6G: Architecture, Design Trade-offs, and a Practical Roadmap", "comment": null, "summary": "To meet the ambitious goals of next-generation 6G networks, including\nultra-high data rates and ubiquitous coverage, we propose a novel high-altitude\nplatform station (HAPS)-based integrated sensing and communication (ISAC)\narchitecture. Operating in the stratosphere, the HAPS functions as both a\npowerful communication hub and an advanced environmental sensor. Combined with\na fleet of cooperative uncrewed aerial vehicles (UAVs), this dual-purpose\nsystem forms a scalable and intelligent 3D network. Simulation results indicate\nthat this approach significantly boosts network performance, improves sensing\naccuracy, and ensures a fairer service distribution across users, outperforming\nconventional UAV-only baselines. We conclude by outlining the prospective\napplications and a deployment roadmap for this technology for smart cities and\nother large-scale environments."}
{"id": "2510.23186", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23186", "abs": "https://arxiv.org/abs/2510.23186", "authors": ["Lukas Henneke", "Frank Kurth"], "title": "Approaching Domain Generalization with Embeddings for Robust Discrimination and Recognition of RF Communication Signals", "comment": null, "summary": "Radio frequency (RF) signal recognition plays a critical role in modern\nwireless communication and security applications. Deep learning-based\napproaches have achieved strong performance but typically rely heavily on\nextensive training data and often fail to generalize to unseen signals. In this\npaper, we propose a method to learn discriminative embeddings without relying\non real-world RF signal recordings by training on signals of synthetic wireless\nprotocols. We validate the approach on a dataset of real RF signals and show\nthat the learned embeddings capture features enabling accurate discrimination\nof previously unseen real-world signals, highlighting its potential for robust\nRF signal classification and anomaly detection."}
{"id": "2510.23355", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23355", "abs": "https://arxiv.org/abs/2510.23355", "authors": ["Pengyu Gao", "Qu Luo", "Jing Zhu", "Gaojie Chen", "Pei Xiao", "Chuan Heng Foh"], "title": "Uplink SCMA-empowered Uncoordinated Random Access for Future mMTC", "comment": null, "summary": "In this paper, a novel uncoordinated random access (URA) protocol is\npresented to address the pressing demand for massive connectivity with low\naccess latency in future massive machine type communication (mMTC) scenarios.\nThe proposed URA scheme integrates the classical slotted ALOHA (S-ALOHA)\nprotocol with sparse code multiple access (SCMA) technique, referred to as\nSCMA-empowered URA. Specifically, active users randomly choose an SCMA codebook\nto access the communication network in an arbitrary time slot whenever they\nwant without scheduling. However, due to the lack of central coordination in\nthe proposed URA scheme, SCMA codebook collisions become inevitable, making\ndecoding challenging and leading to increased access failures. To cope with the\ndecoding issue, an interference-canceling (IC) first decoding strategy is\nproposed at the access point (AP), which can partially tackles collision\nproblems, contributing to a higher system throughput. Taking the proposed\nIC-first decoding strategy into account, a closed-form theoretical expression\nof the throughput is derived. Moreover, to alleviate the throughput degradation\nunder the congested user traffic, a user barring mechanism is introduced to\nmanage the traffic load. Firstly, a closed-form expression of idle codebook\nprobability is developed to help indicate the system state, i.e., congested or\nnot. Then, in addition to the estimated real-time load, the AP adaptively\nadjusts the access probability and redistributes the actual access load.\nFinally, simulation results demonstrate that the proposed SCMA-empowered URA\nscheme enjoys higher maximum throughput, compared to the conventional\northogonal multiple access (OMA) based URA scheme. Moreover, the accuracy of\nthe presented theoretical analysis and the effectiveness of the user barring\nmechanism are verified."}
{"id": "2510.23440", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23440", "abs": "https://arxiv.org/abs/2510.23440", "authors": ["Donatella Darsena", "Ivan Iudice", "Vincenzo Galdi", "Francesco Verde"], "title": "Randomized Space-Time Coded Stacked Intelligent Metasurfaces for Massive Multiuser Downlink Connectivity", "comment": "12 pages, 6 figures, 2 tables", "summary": "Stacked intelligent metasurfaces (SIMs) represent a key enabler for\nnext-generation wireless networks, offering beamforming gains while\nsignificantly reducing radio-frequency chain requirements. In conventional\nspace-only SIM architectures, the rate of reconfigurability of the SIM is equal\nto the inverse of the channel coherence time. This paper investigates a novel\nbeamforming strategy for massive downlink connectivity using a randomized\nspace-time (ST) coded SIM. In addition to conventional space-only metasurface\nlayers, the proposed design integrates a ST metasurface layer at the input\nstage of the SIM that introduces random time variations over each channel\ncoherence time interval. These artificial time variations enable opportunistic\nuser scheduling and exploitation of multiuser diversity under slow channel\ndynamics. To mitigate the prohibitive overhead associated with full channel\nstate information at the transmitter (CSIT), we propose a partial-CSIT-based\nbeamforming scheme that leverages randomized steering vectors and limited\nuser-side feedback based on signal quality measurements. Numerical results\ndemonstrate that the proposed ST-SIM architecture achieves satisfactory\nsum-rate performance while significantly reducing CSIT acquisition and feedback\noverhead, thereby enabling scalable downlink connectivity in dense networks."}
{"id": "2510.23467", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23467", "abs": "https://arxiv.org/abs/2510.23467", "authors": ["Shreya Khisa", "Ali Amhaz", "Mohamed Elhattab", "Chadi Assi", "Sanaa Sharafeddine"], "title": "Joint Uplink and Downlink Resource Allocation and Antenna Activation for Pinching Antenna Systems", "comment": null, "summary": "In this paper, we explore a novel joint uplink and downlink framework\nutilizing a pinching antenna system (PASS). We consider two waveguides, one\ndedicated to transmission and one to reception, and both of them are connected\nto a base station (BS). Each type of waveguide consists of several pinching\nantennas (PAs) in some preconfigured positions. In this framework, we assume\nthe BS can serve downlink and uplink user equipments (UEs) at the same time\nusing the same spectrum resources through the presented PASS. In this aspect,\nwe formulate a sum rate optimization problem that jointly optimizes the antenna\nactivation factor, the BS transmit power, and the UE's transmit power, subject\nto power budget constraints for the BS and the UEs, as well as minimum rate\nrequirements for the UEs. The formulated problem is highly non-convex and\ndifficult to solve directly. Hence, we divide the main problem into two\nsub-problems: the antenna activation sub-problem and the power allocation\nsub-problem. Then, we solve the antenna activation problem utilizing a distance\nand spatial correlation-based algorithm. Meanwhile, the resource allocation\nproblem is solved using a successive convex approximation (SCA)-based\nalgorithm. Numerical results show that our proposed framework can achieve\naround 60-90\\% performance gains over its time division duplex (TDD) where the\nuplink and downlink transmissions are served in different orthogonal time\nslots."}
