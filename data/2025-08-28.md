<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 59]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts](https://arxiv.org/abs/2508.19268)
*Qing Wang,Xue Han,Jiahui Wang,Lehao Xing,Qian Hu,Lianlian Zhang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 提出一种MultiPL-MoE模型以提升多语言代码生成性能，结合多专家机制优化 token 和 segment 级别的选择，有效提升代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 解决多语言代码生成的挑战，提升大规模语言模型在多编程语言环境中的表现。

Method: 采用混合专家（MoE）机制，结合令牌级和段级优化，通过滑动窗口和专家选择路由，实现对编程语言句法结构和上下文的增强捕获。

Result: 实验验证了MultiPL-MoE在多语言代码生成中的优越性能，证明其有效性。

Conclusion: MultiPL-MoE通过创新的专家组合和选择策略，有效提升多编程语言的代码生成能力，为相关应用提供技术支持。

Abstract: Despite LLMs' excellent code creation capabilities, multilingual code
generation remains extremely challenging. To address this, we intent to improve
the multi-programming-lingual (MultiPL) performance of the base LLMs while
retaining the most popular ones using restricted computational resources. We
consider MultiPL to be a special case of multiple natural languages and propose
a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called
MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize
expert selection at both the token and segment levels. The token-level MoE is a
standard upcycling MoE structure with a shared expert and a novel gate weight
normalization approach that aids in the final fusion with the segment-level
MoE. The segment-level MoE incorporates two innovative designs to better
capture the syntactic structure and contextual patterns of programming
languages: First, using a sliding window to partition the input token sequence
into multiple segments; Then, adopting an expert-choice routing strategy that
allows experts to select the top-k segments. The results of the experiment
proved the effectiveness of MultiPL-MoE.

</details>


### [2] [Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English](https://arxiv.org/abs/2508.19270)
*Nguyen Huu Nhat Minh,Tran Nguyen Anh,Truong Dinh Dung,Vo Van Nam,Le Pham Tuyen*

Main category: cs.CL

TL;DR: 提出一种新型双语语音识别方法，有效应对越南语和英语的发音差异。


<details>
  <summary>Details</summary>
Motivation: 解决越南语和英语混合语音识别中的跨语种挑战，特别是语调和重音的差异带来的困难。

Method: 构建代表性的双语音素集，并设计端到端系统利用PhoWhisper预训练编码器提取深层高层次表示。

Result: 增强了越南语双语语音识别的准确性，提供了应对声调和重音复杂性的坚固框架。

Conclusion: 该方法有效改善双语语音识别性能，为多语种复杂语音场景提供解决方案。

Abstract: Cross-lingual phoneme recognition has emerged as a significant challenge for
accurate automatic speech recognition (ASR) when mixing Vietnamese and English
pronunciations. Unlike many languages, Vietnamese relies on tonal variations to
distinguish word meanings, whereas English features stress patterns and
non-standard pronunciations that hinder phoneme alignment between the two
languages. To address this challenge, we propose a novel bilingual speech
recognition approach with two primary contributions: (1) constructing a
representative bilingual phoneme set that bridges the differences between
Vietnamese and English phonetic systems; (2) designing an end-to-end system
that leverages the PhoWhisper pre-trained encoder for deep high-level
representations to improve phoneme recognition. Our extensive experiments
demonstrate that the proposed approach not only improves recognition accuracy
in bilingual speech recognition for Vietnamese but also provides a robust
framework for addressing the complexities of tonal and stress-based phoneme
recognition

</details>


### [3] [Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT](https://arxiv.org/abs/2508.19271)
*Rushitha Santhoshi Mamidala,Anshuman Chhabra,Ankur Mali*

Main category: cs.CL

TL;DR: 通过引入局部自动机结构的RetoMaton框架，增强了大型语言模型的符号推理能力，实现了更可靠、透明的知识检索。


<details>
  <summary>Details</summary>
Motivation: 探索更稳定和可解释的推理方法，以克服提示方法在任务中的不稳定性和不透明性。

Method: 用任务适应的加权有限自动机(WFA)替换全局存储，结合符号记忆与自动机结构进行知识检索。

Result: 在多个推理任务中，局部RetoMaton显著提升了模型性能，且检索过程透明、可复现。

Conclusion: 引入自动机结构的符号推理框架，有望推动可信赖的语言模型推理发展。

Abstract: Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and
In-Context Learning (ICL) have become widely used for eliciting reasoning
capabilities in large language models (LLMs). However, these methods rely on
fragile, implicit mechanisms often yielding inconsistent outputs across seeds,
formats, or minor prompt variations making them fundamentally unreliable for
tasks requiring stable, interpretable reasoning. In contrast, automata-based
neuro-symbolic frameworks like RetoMaton offer a more structured and
trustworthy alternative by grounding retrieval in symbolic memory with
deterministic transitions. In this work, we extend RetoMaton by replacing its
global datastore with a local, task-adaptive Weighted Finite Automaton (WFA),
constructed directly from external domain corpora. This local automaton
structure promotes robust, context-aware retrieval while preserving symbolic
traceability and low inference overhead. Unlike prompting, which entangles
context and memory in opaque ways, our approach leverages the explicit
structure of WFAs to provide verifiable and modular retrieval behavior, making
it better suited for domain transfer and interoperability. We evaluate this
local RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT
across three reasoning tasks: TriviaQA (reading comprehension), GSM8K
(multi-step math), and MMLU (domain knowledge). Compared to the base model and
prompting-based methods, augmenting these setups with local RetoMaton
consistently improves performance while enabling transparent and reproducible
retrieval dynamics. Our results highlight a promising shift toward trustworthy,
symbolic reasoning in modern LLMs via lightweight, automaton-guided memory.

</details>


### [4] [RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits](https://arxiv.org/abs/2508.19272)
*Kshitij Fadnis,Sara Rosenthal,Maeda Hanafi,Yannis Katsis,Marina Danilevsky*

Main category: cs.CL

TL;DR: 提出RAGAPHENE平台，用于模拟真实会话以评估大语言模型的检索增强生成能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在对话应用中的普及，准确评估其检索增强生成能力成为关键。

Method: 开发基于聊天的标注平台，实现多轮真实对话模拟，供标注员使用。

Result: 已有约40名标注员利用该平台构建数千个真实会话，用于评估。

Conclusion: RAGAPHENE有效支持真实会话模拟，为大语言模型的评估提供了有价值的工具。

Abstract: Retrieval Augmented Generation (RAG) is an important aspect of conversing
with Large Language Models (LLMs) when factually correct information is
important. LLMs may provide answers that appear correct, but could contain
hallucinated information. Thus, building benchmarks that can evaluate LLMs on
multi-turn RAG conversations has become an increasingly important task.
Simulating real-world conversations is vital for producing high quality
evaluation benchmarks. We present RAGAPHENE, a chat-based annotation platform
that enables annotators to simulate real-world conversations for benchmarking
and evaluating LLMs. RAGAPHENE has been successfully used by approximately 40
annotators to build thousands of real-world conversations.

</details>


### [5] [Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis](https://arxiv.org/abs/2508.19274)
*Yue Chu*

Main category: cs.CL

TL;DR: 利用预训练语言模型和多模态融合策略，提高死因分类的准确性，强调叙述信息的重要性，推动公共卫生数据采集方法创新。


<details>
  <summary>Details</summary>
Motivation: 在无民事注册国家，VERBAL AUTOPSY（口述尸检）是估算死因的重要工具，但现有算法多忽略死者叙述内容。本研究旨在利用语言模型充分利用叙述信息，提升死因分类效果。

Method: 采用南非实证数据，运用预训练语言模型（PLMs）和机器学习技术，比较单一模态与多模态融合策略的性能，分析信息充分性对分类的影响。

Result: 基于变换器的PLMs在仅使用叙述时优于仅问答的问题算法，特别在识别非传染性疾病方面表现优异；多模态融合进一步提升分类准确性，表明各模态信息互补；识别信息充分性与分类准确性正相关。

Conclusion: 叙述信息对死因分类具有重要提升作用，未来需多样化高质量数据以训练模型，重构口述尸检工具，推动公共卫生信息采集方式创新。

Abstract: In countries without civil registration and vital statistics, verbal autopsy
(VA) is a critical tool for estimating cause of death (COD) and inform policy
priorities. In VA, interviewers ask proximal informants for details on the
circumstances preceding a death, in the form of unstructured narratives and
structured questions. Existing automated VA cause classification algorithms
only use the questions and ignore the information in the narratives. In this
thesis, we investigate how the VA narrative can be used for automated COD
classification using pretrained language models (PLMs) and machine learning
(ML) techniques. Using empirical data from South Africa, we demonstrate that
with the narrative alone, transformer-based PLMs with task-specific fine-tuning
outperform leading question-only algorithms at both the individual and
population levels, particularly in identifying non-communicable diseases. We
explore various multimodal fusion strategies combining narratives and questions
in unified frameworks. Multimodal approaches further improve performance in COD
classification, confirming that each modality has unique contributions and may
capture valuable information that is not present in the other modality. We also
characterize physician-perceived information sufficiency in VA. We describe
variations in sufficiency levels by age and COD and demonstrate that
classification accuracy is affected by sufficiency for both physicians and
models. Overall, this thesis advances the growing body of knowledge at the
intersection of natural language processing, epidemiology, and global health.
It demonstrates the value of narrative in enhancing COD classification. Our
findings underscore the need for more high-quality data from more diverse
settings to use in training and fine-tuning PLM/ML methods, and offer valuable
insights to guide the rethinking and redesign of the VA instrument and
interview.

</details>


### [6] [FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series](https://arxiv.org/abs/2508.19279)
*Gunjan Jalori,Preetika Verma,Sercan Ö Arık*

Main category: cs.CL

TL;DR: 引入FLAIRR-TS框架，通过自适应提示优化提升大规模语言模型在时间序列预测中的性能，减少调优成本。


<details>
  <summary>Details</summary>
Motivation: 需要有效的时间序列预测方法，同时减少复杂的预处理和微调过程。

Method: 利用代理系统进行测试时的提示优化，包括预测代理和改进代理，结合过去输出和检索相似案例以动态优化提示。

Result: 在基准数据集上的实验显示该方法优于静态提示和检索增强方法，接近专业设计提示的性能。

Conclusion: FLAIRR-TS提供一种无需微调的实用方案，通过自适应提示优化，实现高质量时间序列预测。

Abstract: Time series Forecasting with large languagemodels (LLMs) requires bridging
numericalpatterns and natural language. Effective fore-casting on LLM often
relies on extensive pre-processing and fine-tuning.Recent studiesshow that a
frozen LLM can rival specializedforecasters when supplied with a carefully
en-gineered natural-language prompt, but craft-ing such a prompt for each task
is itself oner-ous and ad-hoc. We introduce FLAIRR-TS, atest-time prompt
optimization framework thatutilizes an agentic system: a
Forecaster-agentgenerates forecasts using an initial prompt,which is then
refined by a refiner agent, in-formed by past outputs and retrieved
analogs.This adaptive prompting generalizes across do-mains using creative
prompt templates andgenerates high-quality forecasts without inter-mediate code
generation.Experiments onbenchmark datasets show improved accuracyover static
prompting and retrieval-augmentedbaselines, approaching the performance
ofspecialized prompts.FLAIRR-TS providesa practical alternative to tuning,
achievingstrong performance via its agentic approach toadaptive prompt
refinement and retrieval.

</details>


### [7] [CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning](https://arxiv.org/abs/2508.19282)
*Ziqiang Cui,Yunpeng Weng,Xing Tang,Peiyang Liu,Shiwei Li,Bowei He,Jiamin Chen,Xiuqiang He,Chen Ma*

Main category: cs.CL

TL;DR: 提出CORE方法，通过强化学习实现无损压缩，提高RAG在大模型回答中的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决大模型在引入大量检索文档时的计算成本与性能下降问题，寻找高效且不损失信息的压缩策略。

Method: 使用强化学习优化上下文压缩过程，以最终任务性能作为奖励，采用GRPO进行训练。

Result: 在四个数据集上实现3%的高压缩比，不降低性能，提升平均精确匹配分数3.3点。

Conclusion: CORE有效实现无损压缩，提升RAG性能和效率，有望推动相关应用普及。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
enhance the timeliness of knowledge and the factual accuracy of responses in
Large Language Models (LLMs). However, the inclusion of excessive retrieved
documents substantially increases the input length, leading to higher
computational costs. Previous studies have attempted to compress retrieved
documents into shorter texts before in-context integration, but such methods
often compromise end-task performance. The lack of well-defined compression
targets forces many approaches to rely on fixed heuristics, which cannot
guarantee that the compressed content will effectively support the end task. To
address these limitations, we propose CORE, a novel method designed to achieve
lossless context compression for RAG. CORE employs reinforcement learning to
optimize the compression process without relying on predefined compression
labels. Specifically, it utilizes end-task performance as a reward signal and
applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train
the compressor. This end-to-end training framework enables the compressor to
generate summaries that maximize the accuracy of answers generated by the LLM.
Extensive experiments on four datasets demonstrate the superiority of our
approach. With a high compression ratio of 3\%, our method not only avoids
performance degradation compared to prepending full documents across all
datasets but also improves the average Exact Match (EM) score by 3.3 points.
The code will be released soon.

</details>


### [8] [Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains](https://arxiv.org/abs/2508.19357)
*Peiran Zhou,Junnan Zhu,Yichen Shen,Ruoxi Yu*

Main category: cs.CL

TL;DR: CASC框架通过智能处理多文档检索信息，提升复杂科学领域问答的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统检索增强生成在处理多文档时信息过载和信息冲突导致的生成不准确问题。

Method: 引入CASC模块，利用微调的小型LLM进行信息提取、冲突检测和结构化合成，将散乱信息压缩为精炼结构化的语义丰富的内容。

Result: 在SciDocs-QA数据集上，CASC显著优于多项强基线模型，提升问答效果。

Conclusion: CASC有效提升复杂科学问答的准确性和效率，为多文档问答提供了可行的解决方案。

Abstract: Large Language Models (LLMs) excel in language tasks but are prone to
hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG)
mitigates these by grounding LLMs in external knowledge. However, in complex
domains involving multiple, lengthy, or conflicting documents, traditional RAG
suffers from information overload and inefficient synthesis, leading to
inaccurate and untrustworthy answers. To address this, we propose CASC
(Context-Adaptive Synthesis and Compression), a novel framework that
intelligently processes retrieved contexts. CASC introduces a Context Analyzer
& Synthesizer (CAS) module, powered by a fine-tuned smaller LLM, which performs
key information extraction, cross-document consistency checking and conflict
resolution, and question-oriented structured synthesis. This process transforms
raw, scattered information into a highly condensed, structured, and
semantically rich context, significantly reducing the token count and cognitive
load for the final Reader LLM. We evaluate CASC on SciDocs-QA, a new
challenging multi-document question answering dataset designed for complex
scientific domains with inherent redundancies and conflicts. Our extensive
experiments demonstrate that CASC consistently outperforms strong baselines.

</details>


### [9] [Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction](https://arxiv.org/abs/2508.19359)
*Fatemeh Haji,Mazal Bethany,Cho-Yu Jason Chiang,Anthony Rios,Peyman Najafirad*

Main category: cs.CL

TL;DR: ARIS 结合判别模型与生成模型，通过结构化一致性与信心过滤提升事件抽取性能。


<details>
  <summary>Details</summary>
Motivation: 传统判别模型精确率高但召回率有限，生成模型具有更好语义理解但易出错。在此背景下，提升事件抽取的准确性与全面性成为挑战。

Method: 提出ARIS系统，融合多模型协作、信心筛选与反思推理，采用分解指令微调增强LLMs理解。

Result: 在三个基准数据集上，ARIS超越现有先进方法，展现优异性能。

Conclusion: 结合判别与生成模型的混合系统，通过结构化共识与信心机制显著改善事件抽取效果，验证了方法的有效性。

Abstract: Event Extraction (EE) involves automatically identifying and extracting
structured information about events from unstructured text, including triggers,
event types, and arguments. Traditional discriminative models demonstrate high
precision but often exhibit limited recall, particularly for nuanced or
infrequent events. Conversely, generative approaches leveraging Large Language
Models (LLMs) provide higher semantic flexibility and recall but suffer from
hallucinations and inconsistent predictions. To address these challenges, we
propose Agreement-based Reflective Inference System (ARIS), a hybrid approach
combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS
explicitly leverages structured model consensus, confidence-based filtering,
and an LLM reflective inference module to reliably resolve ambiguities and
enhance overall event prediction quality. We further investigate decomposed
instruction fine-tuning for enhanced LLM event extraction understanding.
Experiments demonstrate our approach outperforms existing state-of-the-art
event extraction methods across three benchmark datasets.

</details>


### [10] [LongReasonArena: A Long Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2508.19363)
*Jiayu Ding,Shuming Ma,Lei Cui,Nanning Zheng,Furu Wei*

Main category: cs.CL

TL;DR: 提出LongReasonArena，专门评估大模型的长时间推理能力，显示当前模型在复杂推理任务中表现有限。


<details>
  <summary>Details</summary>
Motivation: 现有长文本基准主要关注理解能力，忽视了长时间推理能力的评估，亟需新基准。

Method: 设计LongReasonArena，通过多步算法任务，控制输入长度，扩展推理规模至百万级。

Result: 验证表明各种模型在此挑战下表现不足，准确率随推理步骤数增加呈线性下降。

Conclusion: LongReasonArena为评估大模型长推理提供新平台，推动模型在复杂推理任务中的提升。

Abstract: Existing long-context benchmarks for Large Language Models (LLMs) focus on
evaluating comprehension of long inputs, while overlooking the evaluation of
long reasoning abilities. To address this gap, we introduce LongReasonArena, a
benchmark specifically designed to assess the long reasoning capabilities of
LLMs. Our tasks require models to solve problems by executing multi-step
algorithms that reflect key aspects of long reasoning, such as retrieval and
backtracking. By controlling the inputs, the required reasoning length can be
arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most
challenging tasks. Extensive evaluation results demonstrate that
LongReasonArena presents a significant challenge for both open-source and
proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our
task. Further analysis also reveals that the accuracy exhibits a linear decline
with respect to the logarithm of the expected number of reasoning steps. Our
code and data is available at
https://github.com/LongReasonArena/LongReasonArena.

</details>


### [11] [Database Entity Recognition with Data Augmentation and Deep Learning](https://arxiv.org/abs/2508.19372)
*Zikun Fu,Chen Yang,Kourosh Davoudi,Ken Q. Pu*

Main category: cs.CL

TL;DR: 提出了一种用于数据库实体识别的多角度改进方法，包括新的人类标注基准、数据增强和基于T5模型的识别模型，有效提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言查询中的数据库实体识别困难，提升识别准确率。

Method: 构建标注基准、进行数据增强、设计基于T5的实体识别模型，并与现有方法比较。

Result: 模型在精确率和召回率上优于两种先进的NER模型，数据增强和微调显著提升性能。

Conclusion: 提出的方法能有效提升数据库实体识别的效果，为自然语言查询的数据库理解提供更强支持。

Abstract: This paper addresses the challenge of Database Entity Recognition (DB-ER) in
Natural Language Queries (NLQ). We present several key contributions to advance
this field: (1) a human-annotated benchmark for DB-ER task, derived from
popular text-to-sql benchmarks, (2) a novel data augmentation procedure that
leverages automatic annotation of NLQs based on the corresponding SQL queries
which are available in popular text-to-SQL benchmarks, (3) a specialized
language model based entity recognition model using T5 as a backbone and two
down-stream DB-ER tasks: sequence tagging and token classification for
fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER
tagger with two state-of-the-art NER taggers, and observed better performance
in both precision and recall for our model. The ablation evaluation shows that
data augmentation boosts precision and recall by over 10%, while fine-tuning of
the T5 backbone boosts these metrics by 5-10%.

</details>


### [12] [One Joke to Rule them All? On the (Im)possibility of Generalizing Humor](https://arxiv.org/abs/2508.19402)
*Mor Turgeman,Chen Shani,Dafna Shahaf*

Main category: cs.CL

TL;DR: 本研究探讨大型语言模型在理解不同幽默类型时的迁移能力，发现多样化训练提高迁移性。


<details>
  <summary>Details</summary>
Motivation: 随着新型幽默形式不断涌现，模型需要具备跨类型理解能力，但现有研究多集中于单一幽默类型，缺乏对迁移性的探索。

Method: 通过在四个不同幽默任务的数据集上进行迁移学习实验，测试模型在未见过的幽默类型上的表现。

Result: 模型在新任务中的准确率最高达75%，多样化训练提升迁移能力（1.88-4.05%），且对原任务影响微小。

Conclusion: 多样性训练有助于模型泛化不同幽默类型，父亲笑话对迁移作用特别显著，但迁移仍具挑战性。

Abstract: Humor is a broad and complex form of communication that remains challenging
for machines. Despite its broadness, most existing research on computational
humor traditionally focused on modeling a specific type of humor. In this work,
we wish to understand whether competence on one or more specific humor tasks
confers any ability to transfer to novel, unseen types; in other words, is this
fragmentation inevitable? This question is especially timely as new humor types
continuously emerge in online and social media contexts (e.g., memes,
anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this
evolving landscape, they must be able to generalize across humor types by
capturing deeper, transferable mechanisms. To investigate this, we conduct a
series of transfer learning experiments across four datasets, representing
different humor tasks. We train LLMs under varied diversity settings (1-3
datasets in training, testing on a novel task). Experiments reveal that models
are capable of some transfer, and can reach up to 75% accuracy on unseen
datasets; training on diverse sources improves transferability (1.88-4.05%)
with minimal-to-no drop in in-domain performance. Further analysis suggests
relations between humor types, with Dad Jokes surprisingly emerging as the best
enabler of transfer (but is difficult to transfer to). We release data and
code.

</details>


### [13] [A perishable ability? The future of writing in the face of generative artificial intelligence](https://arxiv.org/abs/2508.19427)
*Evandro L. T. P. Cunha*

Main category: cs.CL

TL;DR: 生成式人工智能的快速发展可能导致人类写作能力的下降，类似历史上的写作能力丧失。


<details>
  <summary>Details</summary>
Motivation: 探讨AI发展对人类写作能力的潜在影响及未来可能的后果。

Method: 分析近年来AI工具的发展及其在文本生成中的应用，类比历史上写作能力的变迁。

Result: AI的发展可能使人类逐渐失去写作能力，仿佛古代希腊黑暗时代的写作技能丧失。

Conclusion: 未来需关注AI对人类写作能力的影响，避免能力的退化。

Abstract: The 2020s have been witnessing a very significant advance in the development
of generative artificial intelligence tools, including text generation systems
based on large language models. These tools have been increasingly used to
generate texts in the most diverse domains -- from technical texts to literary
texts --, which might eventually lead to a lower volume of written text
production by humans. This article discusses the possibility of a future in
which human beings will have lost or significantly decreased their ability to
write due to the outsourcing of this activity to machines. This possibility
parallels the loss of the ability to write in other moments of human history,
such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).

</details>


### [14] [Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset](https://arxiv.org/abs/2508.19467)
*Sumon Kanti Dey,Jeanne M. Powell,Azra Ismail,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.CL

TL;DR: 通过在红迪网数据集上开发命名实体识别模型，识别社交媒体中关于非医疗性阿片类药物的影响，强调专业微调的重要性和模型在资源有限环境中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 非医疗性阿片类药物使用带来的临床与社会影响需要更深入的监测，但传统方法难以捕捉这些信息。社交媒体提供了第一人称的真实体验数据，有助于补充现有不足。

Method: 提出一个命名实体识别框架，利用红迪网Impacts 2.0数据集进行微调，评估不同模型（包括微调的编码器模型和大型语言模型）在零-shot和少样本学习中的表现。

Result: 微调的DeBERTa-large模型在Token级F1指标上表现优异，在精确度和任务指导遵从性方面优于大模型，少量标注数据也能得到良好效果。该模型虽在表现上接近专家水平，但仍有差距（Cohen's kappa最高0.81），显示深度领域知识的重要性。

Conclusion: 专业微调对临床自然语言处理任务具有关键意义，模型在资源有限的环境中表现令人鼓舞，但仍需进一步提升以弥补专家之间的差距，助力阿片类药物滥用的监测与干预。

Abstract: Nonmedical opioid use is an urgent public health challenge, with far-reaching
clinical and social consequences that are often underreported in traditional
healthcare settings. Social media platforms, where individuals candidly share
first-person experiences, offer a valuable yet underutilized source of insight
into these impacts. In this study, we present a named entity recognition (NER)
framework to extract two categories of self-reported consequences from social
media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal,
depression) and SocialImpacts (e.g., job loss). To support this task, we
introduce RedditImpacts 2.0, a high-quality dataset with refined annotation
guidelines and a focus on first-person disclosures, addressing key limitations
of prior work. We evaluate both fine-tuned encoder-based models and
state-of-the-art large language models (LLMs) under zero- and few-shot
in-context learning settings. Our fine-tuned DeBERTa-large model achieves a
relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming
LLMs in precision, span accuracy, and adherence to task-specific guidelines.
Furthermore, we show that strong NER performance can be achieved with
substantially less labeled data, emphasizing the feasibility of deploying
robust models in resource-limited settings. Our findings underscore the value
of domain-specific fine-tuning for clinical NLP tasks and contribute to the
responsible development of AI tools that may enhance addiction surveillance,
improve interpretability, and support real-world healthcare decision-making.
The best performing model, however, still significantly underperforms compared
to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap
persists between expert intelligence and current state-of-the-art NER/AI
capabilities for tasks requiring deep domain knowledge.

</details>


### [15] [Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)](https://arxiv.org/abs/2508.19428)
*Aleksandra Beliaeva,Temurbek Rahmatullaev*

Main category: cs.CL

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: We present a comprehensive system for addressing Tasks A, B, and C of the
LLMs4OL 2025 challenge, which together span the full ontology construction
pipeline: term extraction, typing, and taxonomy discovery. Our approach
combines retrieval-augmented prompting, zero-shot classification, and
attention-based graph modeling -- each tailored to the demands of the
respective task. For Task A, we jointly extract domain-specific terms and their
ontological types using a retrieval-augmented generation (RAG) pipeline.
Training data was reformulated into a document to terms and types
correspondence, while test-time inference leverages semantically similar
training examples. This single-pass method requires no model finetuning and
improves overall performance through lexical augmentation Task B, which
involves assigning types to given terms, is handled via a dual strategy. In the
few-shot setting (for domains with labeled training data), we reuse the RAG
scheme with few-shot prompting. In the zero-shot setting (for previously unseen
domains), we use a zero-shot classifier that combines cosine similarity scores
from multiple embedding models using confidence-based weighting. In Task C, we
model taxonomy discovery as graph inference. Using embeddings of type labels,
we train a lightweight cross-attention layer to predict is-a relations by
approximating a soft adjacency matrix. These modular, task-specific solutions
enabled us to achieve top-ranking results in the official leaderboard across
all three tasks. Taken together these strategies showcase the scalability,
adaptability, and robustness of LLM-based architectures for ontology learning
across heterogeneous domains.
  Code is available at:
https://github.com/BelyaevaAlex/LLMs4OL-Challenge-Alexbek

</details>


### [16] [Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval](https://arxiv.org/abs/2508.19758)
*Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung*

Main category: cs.CL

TL;DR: NEWSCOPE通过两阶段方法显著提高新闻检索的多样性，结合句子层次的语义变异建模，改善事件全貌。


<details>
  <summary>Details</summary>
Motivation: 当前新闻检索系统重视文本相关性，造成信息重复和视角有限，亟需提升事件理解的多样性与全面性。

Method: 采用密集检索获取相关内容，再通过句子聚类和多样性重排序提高信息多样性，同时引入新颖的多样性指标和基准。

Result: 实验验证NEWSCOPE在多样性方面优于基准方法，保持高相关性，促进事件理解的全面性。

Conclusion: 细粒度、可解释的语义建模有效缓解信息冗余，丰富信息视角，增强新闻检索的效果。

Abstract: Access to diverse perspectives is essential for understanding real-world
events, yet most news retrieval systems prioritize textual relevance, leading
to redundant results and limited viewpoint exposure. We propose NEWSCOPE, a
two-stage framework for diverse news retrieval that enhances event coverage by
explicitly modeling semantic variation at the sentence level. The first stage
retrieves topically relevant content using dense retrieval, while the second
stage applies sentence-level clustering and diversity-aware re-ranking to
surface complementary information. To evaluate retrieval diversity, we
introduce three interpretable metrics, namely Average Pairwise Distance,
Positive Cluster Coverage, and Information Density Ratio, and construct two
paragraph-level benchmarks: LocalNews and DSGlobal. Experiments show that
NEWSCOPE consistently outperforms strong baselines, achieving significantly
higher diversity without compromising relevance. Our results demonstrate the
effectiveness of fine-grained, interpretable modeling in mitigating redundancy
and promoting comprehensive event understanding. The data and code are
available at https://github.com/tangyixuan/NEWSCOPE.

</details>


### [17] [Bridging Language Gaps: Enhancing Few-Shot Language Adaptation](https://arxiv.org/abs/2508.19464)
*Philipp Borchert,Jochen De Weerdt,Marie-Francine Moens*

Main category: cs.CL

TL;DR: CoLAP通过对比学习和提示技术实现多语言资源的知识迁移，提升低-resource语言的NLP性能，减少对大量标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决多资源和低资源语言在NLP中的性能差异，提升低资源语言的模型效果。

Method: 结合对比学习与跨语言表示，利用提示进行任务知识迁移，实现在多语言模型上的优化。

Result: 在自然语言推理和关系抽取任务中，CoLAP优于少样本迁移和上下文学习方法，有效缩小语言资源差异带来的性能差距。

Conclusion: CoLAP是一种高效、数据节省的多语言迁移技术，推动多语种NLP的发展。

Abstract: The disparity in language resources poses a challenge in multilingual NLP,
with high-resource languages benefiting from extensive data, while low-resource
languages lack sufficient data for effective training. Our Contrastive Language
Alignment with Prompting (CoLAP) method addresses this gap by integrating
contrastive learning with cross-lingual representations, facilitating
task-specific knowledge transfer from high-resource to lower-resource
languages. The primary advantage of our approach is its data efficiency,
enabling rapid adaptation to new languages and reducing the need for large
labeled datasets. We conduct experiments with multilingual encoder-only and
decoder-only language models on natural language understanding tasks, including
natural language inference and relation extraction, evaluating performance
across both high- and low-resource languages. Our results demonstrate that
CoLAP outperforms few-shot cross-lingual transfer baselines and in-context
learning, even with limited available data. This effectively narrows the
cross-lingual performance gap, contributing to the development of more
efficient multilingual NLP techniques.

</details>


### [18] [Selective Retrieval-Augmentation for Long-Tail Legal Text Classification](https://arxiv.org/abs/2508.19997)
*Boheng Mao*

Main category: cs.CL

TL;DR: 提出了一种针对法律文本分类中长尾标签分布的增强方法SRA，有效提升模型在少数类别的性能。


<details>
  <summary>Details</summary>
Motivation: 解决法律文本分类中的长尾标签分布导致的少数类别性能下降问题。

Method: 通过从训练数据中检索相关样本进行样本增强，专注于低频标签，无需改变模型结构。

Result: 在两个法律文本分类基准数据集上，SRA显著优于现有方法，提升了微观和宏观F1指标。

Conclusion: SRA是一种有效的样本增强策略，增强少数类别的表现，适用于长尾类别分布场景。

Abstract: Legal text classification is a fundamental NLP task in the legal domain.
Benchmark datasets in this area often exhibit a long-tail label distribution,
where many labels are underrepresented, leading to poor model performance on
rare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a
solution to this problem. SRA focuses on augmenting samples belonging to
low-frequency labels in the training set, preventing the introduction of noise
for well-represented classes, and requires no changes to the model
architecture. Retrieval is performed only from the training data to ensure
there is no potential information leakage, removing the need for external
corpora simultaneously. The proposed SRA method is tested on two legal text
classification benchmark datasets with long-tail distributions: LEDGAR
(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA
attains higher micro-F1 and macro-F1 scores compared to all current LexGLUE
baselines across both datasets, illustrating consistent improvements in
long-tail legal text classification. The code repository is available at:
https://github.com/Boheng-Mao/sra-legal

</details>


### [19] [Automatic Question & Answer Generation Using Generative Large Language Model (LLM)](https://arxiv.org/abs/2508.19475)
*Md. Alvee Ehsan,A. S. M Mehedi Hasan,Kefaya Benta Shahnoor,Syeda Sumaiya Tasneem*

Main category: cs.CL

TL;DR: 利用微调的生成式大模型实现自动题目及答案生成，以提高教育评价效率。


<details>
  <summary>Details</summary>
Motivation: 减轻教师设计题目的工作负担，提升评测公平性和效率。

Method: 采用微调基于Meta-Llama 2-7B模型，结合提示工程和无监督学习，利用RACE数据集进行定制训练，满足不同题型需求。

Result: 成功开发出高效的自动题目答案生成工具，能够简化文本评估流程。

Conclusion: 该方法为教育评价提供了可靠的技术支持，有助于节省时间和资源。

Abstract: \Abstract{In the realm of education, student evaluation holds equal
significance as imparting knowledge. To be evaluated, students usually need to
go through text-based academic assessment methods. Instructors need to make
diverse sets of questions that need to be fair for all students to prove their
adequacy over a particular topic. This can prove to be quite challenging as
they may need to manually go through several different lecture materials. Our
objective is to make this whole process much easier by implementing Automatic
Question Answer Generation /(AQAG), using fine-tuned generative LLM. For
tailoring the instructor's preferred question style (MCQ, conceptual, or
factual questions), prompt Engineering (PE) is being utilized. In this
research, we propose to leverage unsupervised learning methods in NLP,
primarily focusing on the English language. This approach empowers the base
Meta-Llama 2-7B model to integrate RACE dataset as training data for the
fine-tuning process. Creating a customized model that will offer efficient
solutions for educators, instructors, and individuals engaged in text-based
evaluations. A reliable and efficient tool for generating questions and answers
can free up valuable time and resources, thus streamlining their evaluation
processes.}

</details>


### [20] [Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study](https://arxiv.org/abs/2508.19481)
*Manuel Mosquera,Melissa Robles,Johan Rodriguez,Ruben Manrique*

Main category: cs.CL

TL;DR: 本论文提出结合外部词典和强化学习的方法以提升低资源语言的机器翻译效果，特别是在西班牙语-瓦尤纳伊基语对中实现了显著改进。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的机器翻译存在数据不足的问题，亟需新方法提高准确性。

Method: 通过将外部词典融入模型，采用监督微调结合引导奖励策略优化（GRPO），实现工具的有效使用。

Result: 模型在西班牙语-瓦尤纳伊基语对中，BLEU分数比以前的方法提升最高达3.37，较无字典访问的基线提升18%。

Conclusion: 结合外部工具和强化学习的方法在低资源语言翻译中具有巨大潜力，有助于提升模型性能。

Abstract: Low-resource machine translation remains a significant challenge for large
language models (LLMs), which often lack exposure to these languages during
pretraining and have limited parallel data for fine-tuning. We propose a novel
approach that enhances translation for low-resource languages by integrating an
external dictionary tool and training models end-to-end using reinforcement
learning, in addition to supervised fine-tuning. Focusing on the
Spanish-Wayuunaiki language pair, we frame translation as a tool-augmented
decision-making problem in which the model can selectively consult a bilingual
dictionary during generation. Our method combines supervised instruction tuning
with Guided Reward Policy Optimization (GRPO), enabling the model to learn both
when and how to use the tool effectively. BLEU similarity scores are used as
rewards to guide this learning process. Preliminary results show that our
tool-augmented models achieve up to +3.37 BLEU improvement over previous work,
and a 18% relative gain compared to a supervised baseline without dictionary
access, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared
Task. We also conduct ablation studies to assess the effects of model
architecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other
models such as LLaMA and a prior NLLB-based system. These findings highlight
the promise of combining LLMs with external tools and the role of reinforcement
learning in improving translation quality in low-resource language settings.

</details>


### [21] [Rule Synergy Analysis using LLMs: State of the Art and Implications](https://arxiv.org/abs/2508.19484)
*Bahar Bateni,Benjamin Pratt,Jim Whitehead*

Main category: cs.CL

TL;DR: 大规模语言模型在理解复杂规则交互方面表现出色，但在捕捉积极和消极协同方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 探索大规模语言模型对动态环境中复杂规则交互的理解能力，尤其是在卡牌游戏环境中。

Method: 构建关于Slay the Spire卡牌协同的数据显示集，评估模型在识别正、负、中性交互中的表现，分析错误类型。

Result: 模型能较好识别非协同（中立）卡牌对，但在检测积极和负面协同时存在明显困难，错误类型包含时序、状态定义和规则遵循问题。

Conclusion: 未来应重点提升模型对规则效果及交互预测的能力，以增强其在动态环境下的推理表现。

Abstract: Large language models (LLMs) have demonstrated strong performance across a
variety of domains, including logical reasoning, mathematics, and more. In this
paper, we investigate how well LLMs understand and reason about complex rule
interactions in dynamic environments, such as card games. We introduce a
dataset of card synergies from the game Slay the Spire, where pairs of cards
are classified based on their positive, negative, or neutral interactions. Our
evaluation shows that while LLMs excel at identifying non-synergistic pairs,
they struggle with detecting positive and, particularly, negative synergies. We
categorize common error types, including issues with timing, defining game
states, and following game rules. Our findings suggest directions for future
research to improve model performance in predicting the effect of rules and
their interactions.

</details>


### [22] [Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding](https://arxiv.org/abs/2508.19529)
*Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang*

Main category: cs.CL

TL;DR: 引入块级有监督微调（Blockwise SFT）以改善离散扩散语言模型的训练与推理不匹配问题，提高生成质量。


<details>
  <summary>Details</summary>
Motivation: 离散扩散语言模型在文本生成中的潜力，但标准微调方式与其半自回归推理不一致，导致噪声偏差。

Method: 提出块级微调方法，将响应划分为固定块，并在每步随机遮挡一个块，计算仅在活跃块上的损失，改善训练与推理的匹配。

Result: 在多个数学任务上优于传统微调，验证了方法的有效性和一致性，强调监督粒度与解码过程匹配的重要性。

Conclusion: 匹配训练和推理的粒度对离散扩散模型性能影响显著，块级微调是有效的改进策略。

Abstract: Discrete diffusion language models have shown strong potential for text
generation, yet standard supervised fine-tuning (SFT) misaligns with their
semi-autoregressive inference: training randomly masks tokens across the entire
response, while inference generates fixed-size blocks sequentially. This
mismatch introduces noisy prefixes and leaky suffixes, biasing gradients away
from the desired blockwise likelihood. We propose Blockwise SFT, which
partitions responses into fixed-size blocks, selects one active block per step
for stochastic masking, freezes all preceding tokens, and fully hides future
ones. Loss is computed only over the active block, directly mirroring the
blockwise decoding process. Experiments on GSM8K, MATH, and MetaMathQA show
consistent gains over classical SFT under equal compute or token budgets. Block
size consistency studies and ablations confirm that improvements stem from
faithful training-inference alignment rather than incidental masking effects.
Our results highlight the importance of matching supervision granularity to the
decoding procedure in diffusion-based language models.

</details>


### [23] [Alignment with Fill-In-the-Middle for Enhancing Code Generation](https://arxiv.org/abs/2508.19532)
*Houxing Ren,Zimu Lu,Weikang Shi,Haotian Hou,Yunqiao Yang,Ke Wang,Aojun Zhou,Junting Pan,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: 提出一种将代码片段拆分为更小块的方法，通过增强DPO训练，提升大语言模型的代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前模型在代码任务中的表现受限于有限且难以验证的训练数据。

Method: 将代码拆分为细粒度块，结合AST拆分和课程训练方法，进行优化训练。

Result: 在多个基准数据集上实现了显著提升，验证了方法的有效性。

Conclusion: 通过拆分和优化训练策略，有效提升了大语言模型在代码生成任务中的能力。

Abstract: The code generation capabilities of Large Language Models (LLMs) have
advanced applications like tool invocation and problem-solving. However,
improving performance in code-related tasks remains challenging due to limited
training data that is verifiable with accurate test cases. While Direct
Preference Optimization (DPO) has shown promise, existing methods for
generating test cases still face limitations. In this paper, we propose a novel
approach that splits code snippets into smaller, granular blocks, creating more
diverse DPO pairs from the same test cases. Additionally, we introduce the
Abstract Syntax Tree (AST) splitting and curriculum training method to enhance
the DPO training. Our approach demonstrates significant improvements in code
generation tasks, as validated by experiments on benchmark datasets such as
HumanEval (+), MBPP (+), APPS, LiveCodeBench, and BigCodeBench. Code and data
are available at https://github.com/SenseLLM/StructureCoder.

</details>


### [24] [Emotion Transfer with Enhanced Prototype for Unseen Emotion Recognition in Conversation](https://arxiv.org/abs/2508.19533)
*Kun Peng,Cong Cao,Hao Peng,Guanlin Wu,Zhifeng Hao,Lei Jiang,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出了一种用于未见情感识别的框架ProEmoTrans，解决了隐含表达、长句编码和情感迁移等关键挑战，在多个数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前情感识别研究受限于封闭域假设，无法处理未见情感，影响真实场景应用。

Method: 引入未见情感识别任务，采用原型迁移框架结合增强描述、无参数编码机制和改进的注意力Viterbi解码。

Result: 在三个数据集上验证了该方法的有效性，为该新领域提供了坚实的基线。

Conclusion: 提出的ProEmoTrans框架能有效应对未见情感识别的挑战，为未来研究提供方向。

Abstract: Current Emotion Recognition in Conversation (ERC) research follows a
closed-domain assumption. However, there is no clear consensus on emotion
classification in psychology, which presents a challenge for models when it
comes to recognizing previously unseen emotions in real-world applications. To
bridge this gap, we introduce the Unseen Emotion Recognition in Conversation
(UERC) task for the first time and propose ProEmoTrans, a solid prototype-based
emotion transfer framework. This prototype-based approach shows promise but
still faces key challenges: First, implicit expressions complicate emotion
definition, which we address by proposing an LLM-enhanced description approach.
Second, utterance encoding in long conversations is difficult, which we tackle
with a proposed parameter-free mechanism for efficient encoding and overfitting
prevention. Finally, the Markovian flow nature of emotions is hard to transfer,
which we address with an improved Attention Viterbi Decoding (AVD) method to
transfer seen emotion transitions to unseen emotions. Extensive experiments on
three datasets show that our method serves as a strong baseline for preliminary
exploration in this new area.

</details>


### [25] [Language Models Identify Ambiguities and Exploit Loopholes](https://arxiv.org/abs/2508.19546)
*Jio Choi,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 大规模语言模型（LLMs）在应对漏洞时能识别模糊和利用漏洞，存在潜在的安全风险。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在面对模糊和矛盾目标时的表现及其潜在的安全风险。

Method: 设计涉及模糊、结构歧义和权力动态的场景，测评模型利用漏洞满足目标的能力。

Result: 模型能识别模糊点并利用漏洞，彰显潜在的AI安全风险。

Conclusion: 模型会识别并推理模糊和矛盾目标，存在利用漏洞的风险，需要关注安全性问题。

Abstract: Studying the responses of large language models (LLMs) to loopholes presents
a two-fold opportunity. First, it affords us a lens through which to examine
ambiguity and pragmatics in LLMs, since exploiting a loophole requires
identifying ambiguity and performing sophisticated pragmatic reasoning. Second,
loopholes pose an interesting and novel alignment problem where the model is
presented with conflicting goals and can exploit ambiguities to its own
advantage. To address these questions, we design scenarios where LLMs are given
a goal and an ambiguous user instruction in conflict with the goal, with
scenarios covering scalar implicature, structural ambiguities, and power
dynamics. We then measure different models' abilities to exploit loopholes to
satisfy their given goals as opposed to the goals of the user. We find that
both closed-source and stronger open-source models can identify ambiguities and
exploit their resulting loopholes, presenting a potential AI safety risk. Our
analysis indicates that models which exploit loopholes explicitly identify and
reason about both ambiguity and conflicting goals.

</details>


### [26] [Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts](https://arxiv.org/abs/2508.19578)
*Jiaqi Deng,Yuho Lee,Nicole Hee-Yeon Kim,Hyangsuk Min,Taewon Yun,Minjeong Ban,Kim Yul,Hwanjun Song*

Main category: cs.CL

TL;DR: HAMLET是一个自动化评估大型语言模型长文本理解能力的框架，结构化文本、使用问答总结，验证效果好且成本低，揭示模型在精细理解和位置敏感性上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型长文本理解能力的评估存在挑战，需要可靠、自动化且成本低的方法。

Method: 采用层级结构化文本、问答总结策略，并通过人类研究验证自动评估的可靠性。

Result: 自动评估与专家判断一致性超过90%，且成本降低25倍，揭示模型在细节理解和位置敏感性上的不足，分析不同模型表现差异。

Conclusion: HAMLET为大模型长文本理解提供了有效的评估工具，助力未来模型优化与研究。

Abstract: We introduce HAMLET, a holistic and automated framework for evaluating the
long-context comprehension of large language models (LLMs). HAMLET structures
source texts into a three-level key-fact hierarchy at root-, branch-, and
leaf-levels, and employs query-focused summarization to evaluate how well
models recall and faithfully represent information at each level. To validate
the reliability of our fully automated pipeline, we conduct a systematic human
study, showing that our automatic evaluation achieves over 90% agreement with
expert human judgments, while reducing the cost by up to 25 times. HAMLET
reveals that LLMs struggle with fine-grained comprehension, especially at the
leaf level, and are sensitive to positional effects like the
lost-in-the-middle. Analytical queries pose greater challenges than narrative
ones, and consistent performance gaps emerge between open-source and
proprietary models, as well as across model scales. Our code and dataset are
publicly available at https://github.com/DISL-Lab/HAMLET.

</details>


### [27] [ArgCMV: An Argument Summarization Benchmark for the LLM-era](https://arxiv.org/abs/2508.19580)
*Omkar Gurjar,Agam Goyal,Eshwar Chandrasekharan*

Main category: cs.CL

TL;DR: 提出了一种更具代表性的辩论关键点提取数据集ArgCMV，揭示现有方法在新数据集上的不足，推动长对话摘要研究。


<details>
  <summary>Details</summary>
Motivation: 现有的ArgKP21数据集存在局限性，难以反映真实人类对话的复杂性，亟需更具代表性的新数据集。

Method: 利用最新的大型语言模型（LLMs）收集和整理了包含12k个在线真实辩论的ArgCMV数据集，涵盖更复杂的语境和话题。

Result: 在新数据集上，现有的关键点提取方法表现不佳，本文进行了广泛的基线实验，验证了新数据集的挑战性和研究价值。

Conclusion: 提出了面向长对话场景的新数据集ArgCMV，为未来LLM驱动的摘要研究奠定基础，促进算法的改进与创新。

Abstract: Key point extraction is an important task in argument summarization which
involves extracting high-level short summaries from arguments. Existing
approaches for KP extraction have been mostly evaluated on the popular ArgKP21
dataset. In this paper, we highlight some of the major limitations of the
ArgKP21 dataset and demonstrate the need for new benchmarks that are more
representative of actual human conversations. Using SoTA large language models
(LLMs), we curate a new argument key point extraction dataset called ArgCMV
comprising of around 12K arguments from actual online human debates spread
across over 3K topics. Our dataset exhibits higher complexity such as longer,
co-referencing arguments, higher presence of subjective discourse units, and a
larger range of topics over ArgKP21. We show that existing methods do not adapt
well to ArgCMV and provide extensive benchmark results by experimenting with
existing baselines and latest open source models. This work introduces a novel
KP extraction dataset for long-context online discussions, setting the stage
for the next generation of LLM-driven summarization research.

</details>


### [28] [Towards stable AI systems for Evaluating Arabic Pronunciations](https://arxiv.org/abs/2508.19587)
*Hadi Zaatiti,Hatem Hajri,Osama Abdullah,Nader Masmoudi*

Main category: cs.CL

TL;DR: 本研究探讨了阿拉伯语孤立字母的识别难点，利用wav2vec 2.0模型取得较低准确率，通过对抗训练提升鲁棒性，未来工作将扩展到词句识别。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语孤立字母识别困难，助力语言学习、语音治疗和语音学研究。

Method: 构建多样化带有元音标点的孤立字母语料库，评估wav2vec 2.0模型表现，采用轻量级神经网络和对抗训练提升鲁棒性。

Result: wav2vec 2.0模型准确率仅35%，增强模型后提升到65%，加入扰动后降至32%，对抗训练有效减缓性能下降。

Conclusion: 该方法改善了孤立字母识别的鲁棒性，未来将扩展到词句级别，保持字母发音的准确性。

Abstract: Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and
sentence-level transcription, yet struggle to classify isolated letters. In
this study, we show that this phoneme-level task, crucial for language
learning, speech therapy, and phonetic research, is challenging because
isolated letters lack co-articulatory cues, provide no lexical context, and
last only a few hundred milliseconds. Recogniser systems must therefore rely
solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic
(pharyngealized) consonants and other sounds with no close analogues in many
languages. This study introduces a diverse, diacritised corpus of isolated
Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models
achieve only 35% accuracy on it. Training a lightweight neural network on
wav2vec embeddings raises performance to 65%. However, adding a small amplitude
perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we
apply adversarial training, limiting the noisy-speech drop to 9% while
preserving clean-speech accuracy. We detail the corpus, training pipeline, and
evaluation protocol, and release, on demand, data and code for reproducibility.
Finally, we outline future work extending these methods to word- and
sentence-level frameworks, where precise letter pronunciation remains critical.

</details>


### [29] [Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs](https://arxiv.org/abs/2508.19594)
*Jun Bai,Minghao Tong,Yang Liu,Zixia Jia,Zilong Zheng*

Main category: cs.CL

TL;DR: 提出Router Lens和CEFT方法，通过识别和微调专业化的专家，提高大模型在上下文中的表现，增强上下文忠实性，效率高于全面微调。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在上下文中表现不佳的问题，提升其上下文忠实性。

Method: 识别专业化专家，通过Router Lens定位，然后对其进行微调，结合实验验证效果。

Result: CEFT在多项基准测试中表现优异，效果与全量微调相当甚至优越，且效率更高。

Conclusion: 通过专业化专家识别和微调，显著改善模型的上下文忠实性，提供一种高效的优化策略。

Abstract: Context faithfulness is essential for reliable reasoning in context-dependent
scenarios. However, large language models often struggle to ground their
outputs in the provided context, resulting in irrelevant responses. Inspired by
the emergent expert specialization observed in mixture-of-experts
architectures, this work investigates whether certain experts exhibit
specialization in context utilization, offering a potential pathway toward
targeted optimization for improved context faithfulness. To explore this, we
propose Router Lens, a method that accurately identifies context-faithful
experts. Our analysis reveals that these experts progressively amplify
attention to relevant contextual information, thereby enhancing context
grounding. Building on this insight, we introduce Context-faithful Expert
Fine-Tuning (CEFT), a lightweight optimization approach that selectively
fine-tunes context-faithful experts. Experiments across a wide range of
benchmarks and models demonstrate that CEFT matches or surpasses the
performance of full fine-tuning while being significantly more efficient.

</details>


### [30] [LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.19614)
*Yang Sun,Lixin Zou,Dan Luo,Zhiyong Xie,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li*

Main category: cs.CL

TL;DR: 通过在LLMs中引入噪声改进知识融合的策略，提出层融合解码（LFD）以优化外部知识利用。


<details>
  <summary>Details</summary>
Motivation: 探索噪声注入对外部知识融合的影响，提升生成质量与系统可控性。

Method: 通过扰动不同层次的表达，建立层级功能划分，并提出层融合解码策略及内部知识评分标准选择中间层。

Result: LFD显著增强了外部知识的利用效果，提升多项任务表现，成本低。

Conclusion: 层级噪声注入与层融合策略为大模型知识整合提供新的理解和优化路径。

Abstract: Retrieval-augmented generation (RAG) incorporates external knowledge into
large language models (LLMs), improving their adaptability to downstream tasks
and enabling information updates. Surprisingly, recent empirical evidence
demonstrates that injecting noise into retrieved relevant documents
paradoxically facilitates exploitation of external knowledge and improves
generation quality. Although counterintuitive and challenging to apply in
practice, this phenomenon enables granular control and rigorous analysis of how
LLMs integrate external knowledge. Therefore, in this paper, we intervene on
noise injection and establish a layer-specific functional demarcation within
the LLM: shallow layers specialize in local context modeling, intermediate
layers focus on integrating long-range external factual knowledge, and deeper
layers primarily rely on parametric internal knowledge. Building on this
insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that
directly combines representations from an intermediate layer with final-layer
decoding outputs to fully exploit the external factual knowledge. To identify
the optimal intermediate layer, we introduce an internal knowledge score (IKS)
criterion that selects the layer with the lowest IKS value in the latter half
of layers. Experimental results across multiple benchmarks demonstrate that LFD
helps RAG systems more effectively surface retrieved context knowledge with
minimal cost.

</details>


### [31] [A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection](https://arxiv.org/abs/2508.19633)
*Chong Tian,Qirong Ho,Xiuying Chen*

Main category: cs.CL

TL;DR: 提出一种符号对抗学习框架（SALF），通过符号学习模型进行对抗训练，有效生成复杂假新闻并提升检测能力。


<details>
  <summary>Details</summary>
Motivation: 应对快速发展的LLM带来的假新闻生成风险，传统检测方法难以适应其动态演变。

Method: 采用符号学习优化方案，通过模拟自然语言中的权重、损失和梯度实现对抗训练，生成和检测假新闻的交互过程。

Result: 在多语言基准数据集上表现出色，显著降低检测准确率，同时提升检测被修正内容的能力。

Conclusion: SALF展现出增强假新闻生成与检测的潜力，推动未来更稳健的检测系统发展。

Abstract: Rapid LLM advancements heighten fake news risks by enabling the automatic
generation of increasingly sophisticated misinformation. Previous detection
methods, including fine-tuned small models or LLM-based detectors, often
struggle with its dynamically evolving nature. In this work, we propose a novel
framework called the Symbolic Adversarial Learning Framework (SALF), which
implements an adversarial training paradigm by an agent symbolic learning
optimization process, rather than relying on numerical updates. SALF introduces
a paradigm where the generation agent crafts deceptive narratives, and the
detection agent uses structured debates to identify logical and factual flaws
for detection, and they iteratively refine themselves through such adversarial
interactions. Unlike traditional neural updates, we represent agents using
agent symbolic learning, where learnable weights are defined by agent prompts,
and simulate back-propagation and gradient descent by operating on natural
language representations of weights, loss, and gradients. Experiments on two
multilingual benchmark datasets demonstrate SALF's effectiveness, showing it
generates sophisticated fake news that degrades state-of-the-art detection
performance by up to 53.4% in Chinese and 34.2% in English on average. SALF
also refines detectors, improving detection of refined content by up to 7.7%.
We hope our work inspires further exploration into more robust, adaptable fake
news detection systems.

</details>


### [32] [Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design](https://arxiv.org/abs/2508.19665)
*Giovanni Pollo,Andrei Mihai Albu,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Loris Panaro,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 提出一种利用FMI封装SystemC模型的自动化方法，增强汽车系统仿真的兼容性和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决汽车行业中多领域仿真平台缺乏标准接口导致的合作难题。

Method: 采用FMI标准自动封装SystemC模型，实现模型的高度兼容性和安全性。

Result: 在实际案例中验证了方法的有效性，适用于复杂设计。

Conclusion: 该方法促进了嵌入式组件在联合仿真中的安全、便携集成，为行业提供了新的仿真工具。

Abstract: The recent advancements of the automotive sector demand robust co-simulation
methodologies that enable early validation and seamless integration across
hardware and software domains. However, the lack of standardized interfaces and
the dominance of proprietary simulation platforms pose significant challenges
to collaboration, scalability, and IP protection. To address these limitations,
this paper presents an approach for automatically wrapping SystemC models by
using the Functional Mock-up Interface (FMI) standard. This method combines the
modeling accuracy and fast time-to-market of SystemC with the interoperability
and encapsulation benefits of FMI, enabling secure and portable integration of
embedded components into co-simulation workflows. We validate the proposed
methodology on real-world case studies, demonstrating its effectiveness with
complex designs.

</details>


### [33] [Survey of Specialized Large Language Model](https://arxiv.org/abs/2508.19667)
*Chenghan Yang,Ruiyu Zhao,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: 专用大型语言模型在多个行业中实现从简单适应到复杂原生架构的演变，显著提升专业应用性能，推动技术创新。


<details>
  <summary>Details</summary>
Motivation: 推动理解专用大模型在不同领域的技术发展及其对专业应用的影响。

Method: 系统性综述行业应用、技术突破及其创新点。

Result: 展示技术创新如何克服通用模型的局限，带来性能提升，并分析其在电子商务中的潜在影响。

Conclusion: 专用大模型的技术进步推动了行业应用的深度融合，为未来发展提供方向。

Abstract: The rapid evolution of specialized large language models (LLMs) has
transitioned from simple domain adaptation to sophisticated native
architectures, marking a paradigm shift in AI development. This survey
systematically examines this progression across healthcare, finance, legal, and
technical domains. Besides the wide use of specialized LLMs, technical
breakthrough such as the emergence of domain-native designs beyond fine-tuning,
growing emphasis on parameter efficiency through sparse computation and
quantization, increasing integration of multimodal capabilities and so on are
applied to recent LLM agent. Our analysis reveals how these innovations address
fundamental limitations of general-purpose LLMs in professional applications,
with specialized models consistently performance gains on domain-specific
benchmarks. The survey further highlights the implications for E-Commerce field
to fill gaps in the field.

</details>


### [34] [Building Task Bots with Self-learning for Enhanced Adaptability, Extensibility, and Factuality](https://arxiv.org/abs/2508.19689)
*Xiaoying Zhang*

Main category: cs.CL

TL;DR: 研究开发能够自主学习和适应变化环境的任务机器人面临的挑战与解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了实现无需或最少人类干预的高效任务机器人，提升其自主学习和适应能力。

Method: 探讨创新技术以支持任务机器人的自主学习与适应能力的开发。

Result: 提出了若干技术途径，有助于开发更智能、自适应的任务机器人。

Conclusion: 自主学习和环境适应能力是未来任务机器人发展的关键，需持续研究新技术以克服现有障碍。

Abstract: Developing adaptable, extensible, and accurate task bots with minimal or zero
human intervention is a significant challenge in dialog research. This thesis
examines the obstacles and potential solutions for creating such bots, focusing
on innovative techniques that enable bots to learn and adapt autonomously in
constantly changing environments.

</details>


### [35] [Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models](https://arxiv.org/abs/2508.19720)
*Yilin Wang,Heng Wang,Yuyang Bai,Minnan Luo*

Main category: cs.CL

TL;DR: 提出CSKS框架通过调节两个代理模型输出差异，轻量调控LLMs对上下文知识的敏感性，提升模型对知识冲突的适应性。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型在知识冲突时的适应性不足及调节复杂的问题。

Method: 利用两个小型代理模型输出差异调节原模型的输出分布，无需修改原模型权重。

Result: 实现了对LLMs知识敏感度的连续、精确调控，验证效果良好。

Conclusion: CSKS提供了一种高效、灵活调节大模型知识敏感度的方案，有助于提升模型在多样场景中的表现能力。

Abstract: In Large Language Models (LLMs) generation, there exist knowledge conflicts
and scenarios where parametric knowledge contradicts knowledge provided in the
context. Previous works studied tuning, decoding algorithms, or locating and
editing context-aware neurons to adapt LLMs to be faithful to new contextual
knowledge. However, they are usually inefficient or ineffective for large
models, not workable for black-box models, or unable to continuously adjust
LLMs' sensitivity to the knowledge provided in the context. To mitigate these
problems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a
simple framework that can steer LLMs' sensitivity to contextual knowledge
continuously at a lightweight cost. Specifically, we tune two small LMs (i.e.
proxy models) and use the difference in their output distributions to shift the
original distribution of an LLM without modifying the LLM weights. In the
evaluation process, we not only design synthetic data and fine-grained metrics
to measure models' sensitivity to contextual knowledge but also use a real
conflict dataset to validate CSKS's practical efficacy. Extensive experiments
demonstrate that our framework achieves continuous and precise control over
LLMs' sensitivity to contextual knowledge, enabling both increased sensitivity
and reduced sensitivity, thereby allowing LLMs to prioritize either contextual
or parametric knowledge as needed flexibly. Our data and code are available at
https://github.com/OliveJuiceLin/CSKS.

</details>


### [36] [CAMÕES: A Comprehensive Automatic Speech Recognition Benchmark for European Portuguese](https://arxiv.org/abs/2508.19721)
*Carlos Carvalho,Francisco Teixeira,Catarina Botelho,Anna Pompili,Rubén Solera-Ureña,Sérgio Paulo,Mariana Julião,Thomas Rolland,John Mendonça,Diogo Pereira,Isabel Trancoso,Alberto Abad*

Main category: cs.CL

TL;DR: 提出了CAMÃOES框架，建立了欧洲葡萄牙语的ASR评估基准和模型，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 弥补欧洲葡萄牙语在自动语音识别资源上的不足，提供评估和模型工具。

Method: 构建评估基准，比较多种基础模型及E-Branchformer，从零开始训练和微调。

Result: 微调的基础模型与从头训练的E-Branchformer表现相当，最高模型提高35%以上WER，刷新欧洲葡萄牙语ASR性能记录。

Conclusion: 提出的框架和模型显著改善欧洲葡萄牙语语音识别性能，推动该领域发展。

Abstract: Existing resources for Automatic Speech Recognition in Portuguese are mostly
focused on Brazilian Portuguese, leaving European Portuguese (EP) and other
varieties under-explored. To bridge this gap, we introduce CAM\~OES, the first
open framework for EP and other Portuguese varieties. It consists of (1) a
comprehensive evaluation benchmark, including 46h of EP test data spanning
multiple domains; and (2) a collection of state-of-the-art models. For the
latter, we consider multiple foundation models, evaluating their zero-shot and
fine-tuned performances, as well as E-Branchformer models trained from scratch.
A curated set of 425h of EP was used for both fine-tuning and training. Our
results show comparable performance for EP between fine-tuned foundation models
and the E-Branchformer. Furthermore, the best-performing models achieve
relative improvements above 35% WER, compared to the strongest zero-shot
foundation model, establishing a new state-of-the-art for EP and other
varieties.

</details>


### [37] [NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks](https://arxiv.org/abs/2508.19724)
*Aritra Dutta,Swapnanil Mukherjee,Deepanway Ghosal,Somak Aditya*

Main category: cs.CL

TL;DR: 通过引入自然语言事实和说明，增强小规模视觉语言模型在常识问答中的表现，提升了回答的准确性和减少了幻想现象。


<details>
  <summary>Details</summary>
Motivation: 弥补小型视觉语言模型在常识性问题上的不足，提升其问答性能。

Method: 采用端到端框架NLKI，检索自然语言事实，利用大模型生成解释，结合到小模型中进行推理。

Result: 增强后模型在多个常识VQA和视觉推理数据集上表现优越，准确率提升达7%，同时通过噪声稳健的训练进一步提升性能。

Conclusion: 将大模型的常识知识有效整合到小模型中，可显著提升其推理能力，显示参数高效的常识推理成为可能。

Abstract: Commonsense visual-question answering often hinges on knowledge that is
missing from the image or the question. Small vision-language models (sVLMs)
such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative
counterparts. To study the effect of careful commonsense knowledge integration
on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural
language facts, (ii) prompts an LLM to craft natural language explanations, and
(iii) feeds both signals to sVLMs respectively across two commonsense VQA
datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts
retrieved using a fine-tuned ColBERTv2 and an object information-enriched
prompt yield explanations that largely cut down hallucinations, while lifting
the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA
and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B
and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional
finetuning using noise-robust losses (such as symmetric cross entropy and
generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our
findings expose when LLM-based commonsense knowledge beats retrieval from
commonsense knowledge bases, how noise-aware training stabilises small models
in the context of external knowledge augmentation, and why parameter-efficient
commonsense reasoning is now within reach for 250M models.

</details>


### [38] [Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval](https://arxiv.org/abs/2508.19740)
*Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: 提出Spotlight Attention，通过非线性哈希优化查询与键的分布，大幅提升大规模语言模型中关键值缓存的检索效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 为解决大规模语言模型中关键值(KV)缓存检索效率低的问题，优化解码性能。

Method: 引入非线性哈希函数提升嵌入分布，使用基于Bradley-Terry的学习框架进行优化，并在GPU上实现高效CUDA核来加快哈希检索。

Result: 显著提高检索精度，压缩哈希码长度至少5倍，512K tokens的检索时间在100微秒内，整体解码吞吐量提高至传统方法的3倍以上。

Conclusion: Spotlight Attention通过非线性哈希与优化训练，有效提升大模型KV缓存的检索速度和精度，有助于加速推理过程。

Abstract: Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient due to
the orthogonal distribution of queries and keys within two narrow cones in
LLMs. We introduce Spotlight Attention, a novel method that employs non-linear
hashing functions to optimize the embedding distribution of queries and keys,
enhancing coding efficiency and robustness. We also developed a lightweight,
stable training framework using a Bradley-Terry ranking-based loss, enabling
optimization of the non-linear hashing module on GPUs with 16GB memory in 8
hours. Experimental results show that Spotlight Attention drastically improves
retrieval precision while shortening the length of the hash code at least
5$\times$ compared to traditional linear hashing. Finally, we exploit the
computational advantages of bitwise operations by implementing specialized CUDA
kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a
single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla
decoding.

</details>


### [39] [Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance](https://arxiv.org/abs/2508.19764)
*Pedro Henrique Luz de Araujo,Paul Röttger,Dirk Hovy,Benjamin Roth*

Main category: cs.CL

TL;DR: 专家角色提示在提升模型性能方面表现不一，模型对无关个人信息敏感，应加强设计与评估。


<details>
  <summary>Details</summary>
Motivation: 探讨角色扮演提示（persona prompting）在提升大模型任务表现中的效果及影响因素，解决现有研究中效果不明和复杂性的问题。

Method: 分析相关文献，评估九个先进大模型在27个任务中的表现，检验专家角色的性能优势、鲁棒性和一致性，提出改善策略。

Result: 专家角色通常带来正面或无显著影响，但模型对无关信息极其敏感，某些属性（如学历、专业性）对性能有变动影响，但不稳定。鲁棒性提升策略仅对大模型有效。

Conclusion: 需要更谨慎的角色设计和评估机制，以确保persona提示能有效且稳定地提升模型性能。

Abstract: Expert persona prompting -- assigning roles such as expert in math to
language models -- is widely used for task improvement. However, prior work
shows mixed results on its effectiveness, and does not consider when and why
personas should improve performance. We analyze the literature on persona
prompting for task improvement and distill three desiderata: 1) performance
advantage of expert personas, 2) robustness to irrelevant persona attributes,
and 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs
across 27 tasks with respect to these desiderata. We find that expert personas
usually lead to positive or non-significant performance changes. Surprisingly,
models are highly sensitive to irrelevant persona details, with performance
drops of almost 30 percentage points. In terms of fidelity, we find that while
higher education, specialization, and domain-relatedness can boost performance,
their effects are often inconsistent or negligible across tasks. We propose
mitigation strategies to improve robustness -- but find they only work for the
largest, most capable models. Our findings underscore the need for more careful
persona design and for evaluation schemes that reflect the intended effects of
persona usage.

</details>


### [40] [T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables](https://arxiv.org/abs/2508.19813)
*Jie Zhang,Changzai Pan,Kaiwen Wei,Sishi Xiong,Yu Zhao,Xiangyu Li,Jiaxin Peng,Xiaoyan Gu,Jian Yang,Wenhan Chang,Zhenhe Wu,Jiang Zhong,Shuangyong Song,Yongxiang Li,Xuelong Li*

Main category: cs.CL

TL;DR: 提出了一种新的table-to-report任务及T2R-bench基准，评估大语言模型在工业场景中从表格到报告的能力，实验证明现有模型仍有较大提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在表格推理能力方面已有研究，但将表格信息转化为报告的任务缺乏有效的实验和评估工具，限制了其在工业应用中的推广。

Method: 构建了包含457个工业表格的中英双语T2R-bench基准，定义了公平的评估标准，并进行了多模型测试。

Result: 实验显示，即使是最先进的模型如Deepseek-R1，其总体得分也只有62.71，表明模型在此任务上仍有较大的提升空间。

Conclusion: 提出的T2R-bench和评估标准为未来提升工业场景下表格到报告的模型提供了有效的测试平台，推动该方向进一步发展。

Abstract: Extensive research has been conducted to explore the capabilities of large
language models (LLMs) in table reasoning. However, the essential task of
transforming tables information into reports remains a significant challenge
for industrial applications. This task is plagued by two critical issues: 1)
the complexity and diversity of tables lead to suboptimal reasoning outcomes;
and 2) existing table benchmarks lack the capacity to adequately assess the
practical application of this task. To fill this gap, we propose the
table-to-report task and construct a bilingual benchmark named T2R-bench, where
the key information flow from the tables to the reports for this task. The
benchmark comprises 457 industrial tables, all derived from real-world
scenarios and encompassing 19 industry domains as well as 4 types of industrial
tables. Furthermore, we propose an evaluation criteria to fairly measure the
quality of report generation. The experiments on 25 widely-used LLMs reveal
that even state-of-the-art models like Deepseek-R1 only achieves performance
with 62.71 overall score, indicating that LLMs still have room for improvement
on T2R-bench. Source code and data will be available after acceptance.

</details>


### [41] [Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning](https://arxiv.org/abs/2508.19828)
*Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma*

Main category: cs.CL

TL;DR: 提出Memory-R1框架，通过强化学习让LLMs主动管理外部记忆，从而提升长远推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs由于有限上下文窗口而导致的长距离推理能力不足的问题。

Method: 引入Memory-R1框架，结合强化学习训练两个专门的代理：记忆管理和应答生成。

Result: 在少量样本和时间记忆的支撑下，Memory-R1优于现有最优基线，展现出强大的泛化能力。

Conclusion: RL可以激发LLMs的主动记忆管理，提高推理性能，推动形成更具恒久性与主动性的智能系统。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities across
a wide range of NLP tasks, but they remain fundamentally stateless, constrained
by limited context windows that hinder long-horizon reasoning. Recent efforts
to address this limitation often augment LLMs with an external memory bank, yet
most existing pipelines are static and heuristic-driven, lacking any learned
mechanism for deciding what to store, update, or retrieve. We present
Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the
ability to actively manage and utilize external memory through two specialized
agents: a Memory Manager that learns to perform structured memory operations
{ADD, UPDATE, DELETE, NOOP}, and an Answer Agent that selects the most relevant
entries and reasons over them to produce an answer. Both agents are fine-tuned
with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and
use with minimal supervision. With as few as 152 question-answer pairs and a
corresponding temporal memory bank for training, Memory-R1 outperforms the most
competitive existing baseline and demonstrates strong generalization across
diverse question types and LLM backbones. Beyond presenting an effective
approach, this work provides insights into how RL can unlock more agentic,
memory-aware behaviors in LLMs, pointing toward richer, more persistent
reasoning systems.

</details>


### [42] [Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis](https://arxiv.org/abs/2508.19831)
*Anusha Kamath,Kanishk Singla,Rakesh Paul,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 提出了一套五个印地语LLM评估数据集，结合人工标注与翻译验证，评估开源模型表现。


<details>
  <summary>Details</summary>
Motivation: 缺乏高质量的印地语基准，英译存在文化和语言差异。

Method: 采用从零人工标注结合翻译验证的方法创建数据集，进行大规模模型评估。

Result: 实现了对多款支持印地语的开源LLMs的详细性能对比分析。

Conclusion: 此评估框架具有推广性，适用于其他低资源语言的基准开发。

Abstract: Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is
challenging due to a lack of high-quality benchmarks, as direct translation of
English datasets fails to capture crucial linguistic and cultural nuances. To
address this, we introduce a suite of five Hindi LLM evaluation datasets:
IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created
using a methodology that combines from-scratch human annotation with a
translate-and-verify process. We leverage this suite to conduct an extensive
benchmarking of open-source LLMs supporting Hindi, providing a detailed
comparative analysis of their current capabilities. Our curation process also
serves as a replicable methodology for developing benchmarks in other
low-resource languages.

</details>


### [43] [Scalable and consistent few-shot classification of survey responses using text embeddings](https://arxiv.org/abs/2508.19836)
*Jonas Timmann Mjaaland,Markus Fleten Kreutzer,Halvor Tyseng,Rebeckah K. Fussell,Gina Passante,N. G. Holmes,Anders Malthe-Sørenssen,Tor Ole B. Odden*

Main category: cs.CL

TL;DR: 本研究提出了一种基于文本嵌入的分类框架，能够用少量示例有效进行质性分析，兼容传统工作流程，显著提高大规模分析的效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 传统定性分析耗时且易出错，现有NLP方法在实际应用中受到限制，亟需一种高效、兼容性强的分析工具。

Method: 开发一种基于文本嵌入的分类框架，结合少量样本快速分类，并验证其在复杂问卷数据中的效果，分析模型微调对性能的影响。

Result: 在一个有2899个开放式问答的物理概念调研中，该方法与专家人工编码的Kappa值达0.74到0.83，表现优良。还展示了微调模型提升性能及用于审查已有数据集的潜力。

Conclusion: 文本嵌入辅助编码方法能高效、兼容性强地进行大规模质性分析，推动定性研究向大数据规模发展，具备广阔应用前景。

Abstract: Qualitative analysis of open-ended survey responses is a commonly-used
research method in the social sciences, but traditional coding approaches are
often time-consuming and prone to inconsistency. Existing solutions from
Natural Language Processing such as supervised classifiers, topic modeling
techniques, and generative large language models have limited applicability in
qualitative analysis, since they demand extensive labeled data, disrupt
established qualitative workflows, and/or yield variable results. In this
paper, we introduce a text embedding-based classification framework that
requires only a handful of examples per category and fits well with standard
qualitative workflows. When benchmarked against human analysis of a conceptual
physics survey consisting of 2899 open-ended responses, our framework achieves
a Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in
an exhaustive coding scheme. We further show how performance of this framework
improves with fine-tuning of the text embedding model, and how the method can
be used to audit previously-analyzed datasets. These findings demonstrate that
text embedding-assisted coding can flexibly scale to thousands of responses
without sacrificing interpretability, opening avenues for deductive qualitative
analysis at scale.

</details>


### [44] [TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation](https://arxiv.org/abs/2508.19856)
*Shashi Kumar,Srikanth Madikeri,Esaú Villatoro-Tello,Sergio Burdisso,Pradeep Rangappa,Andrés Carofilis,Petr Motlicek,Karthik Pandia,Shankar Venkatesan,Kadri Hacioğlu,Andreas Stolcke*

Main category: cs.CL

TL;DR: TokenVerse++通过引入可学习向量，在声学嵌入空间实现动态任务激活，从而支持部分标注数据，提高多任务模型的实用性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的TokenVerse框架需要所有训练语料都有完整标签，限制了其在部分标注数据集上的应用和扩展能力。

Method: 在XLSR-Transducer ASR模型声学嵌入空间引入可学习向量，实现动态任务激活，从而支持部分标注数据的训练。

Result: TokenVerse++在多个任务上表现优异，尤其在结合部分标注数据（如ASR和语言识别任务）时，性能优于或等同于TokenVerse，展现出更强的实用性。

Conclusion: TokenVerse++成功解决了TokenVerse在部分标注数据上的不足，成为一种更实用的多任务学习框架，同时保持或提升了语音识别的性能。

Abstract: Token-based multitasking frameworks like TokenVerse require all training
utterances to have labels for all tasks, hindering their ability to leverage
partially annotated datasets and scale effectively. We propose TokenVerse++,
which introduces learnable vectors in the acoustic embedding space of the
XLSR-Transducer ASR model for dynamic task activation. This core mechanism
enables training with utterances labeled for only a subset of tasks, a key
advantage over TokenVerse. We demonstrate this by successfully integrating a
dataset with partial labels, specifically for ASR and an additional task,
language identification, improving overall performance. TokenVerse++ achieves
results on par with or exceeding TokenVerse across multiple tasks, establishing
it as a more practical multitask alternative without sacrificing ASR
performance.

</details>


### [45] [Beyond Shallow Heuristics: Leveraging Human Intuition for Curriculum Learning](https://arxiv.org/abs/2508.19873)
*Vanessa Toborek,Sebastian Müller,Tim Selbach,Tamás Horváth,Christian Bauckhage*

Main category: cs.CL

TL;DR: 通过人工标注的简单语言作为训练线索，提高模型对简单语言的理解能力，CURRICULUM学习中的人工线索优于基于能力的策略。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用人类认知中的简单语言信息作为课程学习的信号，改善预训练模型的性能。

Method: 比较以标签为基础的课程与依赖浅层启发式的能力为基础的课程策略，使用BERT-tiny模型在Simple Wikipedia数据集上进行实验。

Result: 单纯加入简单数据未显著提升模型表现，但通过合理设计课程，尤其是优先引入简单数据，显著改善了模型对简单语言的理解；能力为基础的课程未表现出明显优势。

Conclusion: 人类对语言难度的直觉可以指导语言模型的课程学习，有效提升模型在简单语言上的理解能力。

Abstract: Curriculum learning (CL) aims to improve training by presenting data from
"easy" to "hard", yet defining and measuring linguistic difficulty remains an
open challenge. We investigate whether human-curated simple language can serve
as an effective signal for CL. Using the article-level labels from the Simple
Wikipedia corpus, we compare label-based curricula to competence-based
strategies relying on shallow heuristics. Our experiments with a BERT-tiny
model show that adding simple data alone yields no clear benefit. However,
structuring it via a curriculum -- especially when introduced first --
consistently improves perplexity, particularly on simple language. In contrast,
competence-based curricula lead to no consistent gains over random ordering,
probably because they fail to effectively separate the two classes. Our results
suggest that human intuition about linguistic difficulty can guide CL for
language model pre-training.

</details>


### [46] [AI-Powered Detection of Inappropriate Language in Medical School Curricula](https://arxiv.org/abs/2508.19883)
*Chiman Salavati,Shannon Song,Scott A. Hale,Roberto E. Montenegro,Shiri Dori-Hacohen,Fabricio Murai*

Main category: cs.CL

TL;DR: 本文研究如何利用小型语言模型和大型语言模型检测医疗材料中的不当用语，以改善医学教学内容。


<details>
  <summary>Details</summary>
Motivation: 为了应对医学教材中存在过时或排他性用语的问题，自动化识别不当用语成为必要。

Method: 采用微调的小型语言模型和提示工程的大型语言模型，在约500份文档与超过12000页内容上进行检测，构建多分类和多标签模型。

Result: 小型语言模型优于大型语言模型，结合未标记数据的训练增强多标签模型效果最佳，显著提升识别准确性。

Conclusion: 多模型结合及扩展训练数据能有效提升不当用语检测，为改善医学教材内容提供技术支持。

Abstract: The use of inappropriate language -- such as outdated, exclusionary, or
non-patient-centered terms -- medical instructional materials can significantly
influence clinical training, patient interactions, and health outcomes. Despite
their reputability, many materials developed over past decades contain examples
now considered inappropriate by current medical standards. Given the volume of
curricular content, manually identifying instances of inappropriate use of
language (IUL) and its subcategories for systematic review is prohibitively
costly and impractical. To address this challenge, we conduct a first-in-class
evaluation of small language models (SLMs) fine-tuned on labeled data and
pre-trained LLMs with in-context learning on a dataset containing approximately
500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL
classifier, (2) subcategory-specific binary classifiers, (3) a multilabel
classifier, and (4) a two-stage hierarchical pipeline for general IUL detection
followed by multilabel classification. For LLMs, we consider variations of
prompts that include subcategory definitions and/or shots. We found that both
LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed
by SLMs. While the multilabel classifier performs best on annotated data,
supplementing training with unflagged excerpts as negative examples boosts the
specific classifiers' AUC by up to 25%, making them most effective models for
mitigating harmful language in medical curricula.

</details>


### [47] [Bangla-Bayanno: A 52K-Pair Bengali Visual Question Answering Dataset with LLM-Assisted Translation Refinement](https://arxiv.org/abs/2508.19887)
*Mohammed Rakibul Hasan,Rafi Majid,Ahanaf Tahmid*

Main category: cs.CL

TL;DR: 本文介绍了Bangla-Bayanno，一套用于孟加拉语的开放式视觉问答数据集，旨在促进低资源语言的多模态AI研究。


<details>
  <summary>Details</summary>
Motivation: 目前现有的VQA数据集存在标注质量低、限制回答格式等问题，缺乏针对孟加拉语的高质量资源。

Method: 采用多语言大模型辅助翻译优化流程，确保翻译质量，数据集涵盖52,650问答对和4700多图像，问题类型丰富。

Result: 构建了孟加拉语最全面且高质量的开源VQA基准，推动低资源多模态学习研究，支持包容性AI发展。

Conclusion: 该数据集弥补了孟加拉语VQA资源的不足，有助于推动低资源语言的多模态AI技术进步。

Abstract: In this paper, we introduce Bangla-Bayanno, an open-ended Visual Question
Answering (VQA) Dataset in Bangla, a widely used, low-resource language in
multimodal AI research. The majority of existing datasets are either manually
annotated with an emphasis on a specific domain, query type, or answer type or
are constrained by niche answer formats. In order to mitigate human-induced
errors and guarantee lucidity, we implemented a multilingual LLM-assisted
translation refinement pipeline. This dataset overcomes the issues of
low-quality translations from multilingual sources. The dataset comprises
52,650 question-answer pairs across 4750+ images. Questions are classified into
three distinct answer types: nominal (short descriptive), quantitative
(numeric), and polar (yes/no). Bangla-Bayanno provides the most comprehensive
open-source, high-quality VQA benchmark in Bangla, aiming to advance research
in low-resource multimodal learning and facilitate the development of more
inclusive AI systems.

</details>


### [48] [Logical Reasoning with Outcome Reward Models for Test-Time Scaling](https://arxiv.org/abs/2508.19903)
*Ramya Keerthy Thatikonda,Wray Buntine,Ehsan Shareghi*

Main category: cs.CL

TL;DR: 提出Outcome Reward Models（ORMs）用于提升大型语言模型在演绎推理任务中的表现，通过生成和扩展训练数据，显著改善多个数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 提升大规模语言模型在演绎逻辑推理中的能力，弥补现有方法在Deductive reasoning方面的不足。

Method: 结合Chain-of-Thought（CoT）及其多样化样本，采用回声生成技术扩展训练数据，增强对错误类型的覆盖。

Result: ORMs在多项推理数据集上表现优异，显著提高了不同LLMs的推理性能。

Conclusion: 通过引入回声生成技术和专业的奖励模型，有效提升大模型的演绎逻辑推理能力，为推理任务的模型训练提供新思路。

Abstract: Logical reasoning is a critical benchmark for evaluating the capabilities of
large language models (LLMs), as it reflects their ability to derive valid
conclusions from given premises. While the combination of test-time scaling
with dedicated outcome or process reward models has opened up new avenues to
enhance LLMs performance in complex reasoning tasks, this space is
under-explored in deductive logical reasoning. We present a set of Outcome
Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly
generate data using Chain-of-Thought (CoT) with single and multiple samples.
Additionally, we propose a novel tactic to further expand the type of errors
covered in the training dataset of the ORM. In particular, we propose an echo
generation technique that leverages LLMs' tendency to reflect incorrect
assumptions made in prompts to extract additional training data, covering
previously unexplored error types. While a standard CoT chain may contain
errors likely to be made by the reasoner, the echo strategy deliberately steers
the model toward incorrect reasoning. We show that ORMs trained on CoT and
echo-augmented data demonstrate improved performance on the FOLIO, JustLogic,
and ProverQA datasets across four different LLMs.

</details>


### [49] [Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2508.19919)
*Jingyu Guo,Yingying Xu*

Main category: cs.CL

TL;DR: AI多智能体系统在没有预设偏见的情况下，模型间互动会自然形成刻板印象，表现出类似人类社会中的偏见和群体效应。


<details>
  <summary>Details</summary>
Motivation: 探究AI系统中刻板印象的自然产生机制，超越训练数据偏见的范畴，关注多智能体互动中的偏见演化。

Method: 通过模拟职场互动的实验框架，在不同的LLM架构下观察多智能体系统中刻板印象的形成与演变，并进行量化分析。

Result: 发现AI智能体在无预设偏见情况下，互动中逐步形成偏见，且互动轮次及层级结构增强偏见，表现出孤芳自赏、确认偏差等人类社会行为模式。

Conclusion: 刻板印象可能是多智能体互动的自发性属性，而非仅由训练数据引入，呼吁未来研究机制开发与偏见缓解策略。

Abstract: While stereotypes are well-documented in human social interactions, AI
systems are often presumed to be less susceptible to such biases. Previous
studies have focused on biases inherited from training data, but whether
stereotypes can emerge spontaneously in AI agent interactions merits further
exploration. Through a novel experimental framework simulating workplace
interactions with neutral initial conditions, we investigate the emergence and
evolution of stereotypes in LLM-based multi-agent systems. Our findings reveal
that (1) LLM-Based AI agents develop stereotype-driven biases in their
interactions despite beginning without predefined biases; (2) stereotype
effects intensify with increased interaction rounds and decision-making power,
particularly after introducing hierarchical structures; (3) these systems
exhibit group effects analogous to human social behavior, including halo
effects, confirmation bias, and role congruity; and (4) these stereotype
patterns manifest consistently across different LLM architectures. Through
comprehensive quantitative analysis, these findings suggest that stereotype
formation in AI systems may arise as an emergent property of multi-agent
interactions, rather than merely from training data biases. Our work
underscores the need for future research to explore the underlying mechanisms
of this phenomenon and develop strategies to mitigate its ethical impacts.

</details>


### [50] [HEAL: A Hypothesis-Based Preference-Aware Analysis Framework](https://arxiv.org/abs/2508.19922)
*Yifu Huo,Chenglong Wang,Qiren Zhu,Shunjie Xing,Tong Xiao,Chunliang Zhang,Tongran Liu,Jinbo Zhu*

Main category: cs.CL

TL;DR: HEAL提出了一种基于假设空间的偏好评价框架，通过两个指标评估偏好学习，有助于改进偏好优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化评价单一，不能全面反映输出潜在偏好。

Method: 构建HEAL框架和UniHypoBench，结合排名准确性和偏好强度相关性两指标，进行假设空间内的偏好重排序评估。

Result: 验证偏好学习方法能有效捕获偏好并抑制负样本，为偏好学习提供新理论和工具，指出发展更先进偏好对齐算法的方向。

Conclusion: HEAL为偏好对齐提供新思路和实用诊断工具，有助于推动偏好优化技术的深入研究和应用。

Abstract: Preference optimization methods like DPO have achieved remarkable performance
in LLM alignment. However, the evaluation for these methods relies on a single
response and overlooks other potential outputs, which could also be generated
in real-world applications within this hypothetical space. To address this
issue, this paper presents a \textbf{H}ypothesis-based
Pr\textbf{E}ference-aware \textbf{A}na\textbf{L}ysis Framework (HEAL), a novel
evaluation paradigm that formulates preference alignment as a re-ranking
process within hypothesis spaces. The framework incorporates two complementary
metrics: ranking accuracy for evaluating ordinal consistency and preference
strength correlation for assessing continuous alignment. To facilitate this
framework, we develop UniHypoBench, a unified hypothesis benchmark constructed
from diverse instruction-response pairs. Through extensive experiments based on
HEAL, with a particular focus on the intrinsic mechanisms of preference
learning, we demonstrate that current preference learning methods can
effectively capture preferences provided by proxy models while simultaneously
suppressing negative samples. These findings contribute to preference learning
research through two significant avenues. Theoretically, we introduce
hypothesis space analysis as an innovative paradigm for understanding
preference alignment. Practically, HEAL offers researchers robust diagnostic
tools for refining preference optimization methods, while our empirical results
identify promising directions for developing more advanced alignment algorithms
capable of comprehensive preference capture.

</details>


### [51] [Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation](https://arxiv.org/abs/2508.19966)
*Slimane Bellaouar,Attia Nehar,Soumia Souffi,Mounia Bouameur*

Main category: cs.CL

TL;DR: 提出一种基于深度学习和Transformer的阿拉伯语主观性分析新方法，通过构建数据集和模型微调，达到了97.79%的高准确率。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语资源匮乏，限制了主观性分析工具的发展。

Method: 构建新数据集AraDhati+，微调多种Arabic语言模型，并采用模型集成策略。

Result: 多模型集成实现了97.79%的高准确率，有效应对资源有限的挑战。

Conclusion: 该方法在阿拉伯语主观性分析中表现出色，解决了数据资源不足的问题。

Abstract: Despite its significance, Arabic, a linguistically rich and morphologically
complex language, faces the challenge of being under-resourced. The scarcity of
large annotated datasets hampers the development of accurate tools for
subjectivity analysis in Arabic. Recent advances in deep learning and
Transformers have proven highly effective for text classification in English
and French. This paper proposes a new approach for subjectivity assessment in
Arabic textual data. To address the dearth of specialized annotated datasets,
we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic
datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we
fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and
ArabianGPT) on AraDhati+ for effective subjectivity classification.
Furthermore, we experimented with an ensemble decision approach to harness the
strengths of individual models. Our approach achieves a remarkable accuracy of
97.79\,\% for Arabic subjectivity classification. Results demonstrate the
effectiveness of the proposed approach in addressing the challenges posed by
limited resources in Arabic language processing.

</details>


### [52] [Diffusion Language Models Know the Answer Before Decoding](https://arxiv.org/abs/2508.19982)
*Pengxiang Li,Yefan Zhou,Dilxat Muhtar,Lu Yin,Shilin Yan,Li Shen,Yi Liang,Soroush Vosoughi,Shiwei Liu*

Main category: cs.CL

TL;DR: Proposed Prophet，一种无需额外训练的快速解码方法，通过早期停止提高DLM推断速度，最大可提速3.4倍。


<details>
  <summary>Details</summary>
Motivation: 提高扩散语言模型的推断速度，解决其比自回归模型慢的问题，同时保持输出质量。

Method: 利用DLM早期正确答案的潜在特性，动态决定是否提前停止或继续细化的解码策略，基于预测候选的置信度差异。

Result: 在多个任务中，Prophet显著减少解码步骤，提速最高达3.4倍，且保持高质量。

Conclusion: 早期收敛机制为加速DLM推断提供了一种简单而有效的途径，具有广泛应用潜力。

Abstract: Diffusion language models (DLMs) have recently emerged as an alternative to
autoregressive approaches, offering parallel sequence generation and flexible
token orders. However, their inference remains slower than that of
autoregressive models, primarily due to the cost of bidirectional attention and
the large number of refinement steps required for high quality outputs. In this
work, we highlight and leverage an overlooked property of DLMs early answer
convergence: in many cases, the correct answer can be internally identified by
half steps before the final decoding step, both under semi-autoregressive and
random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%
of instances, respectively, can be decoded correctly using only half of the
refinement steps. Building on this observation, we introduce Prophet, a
training-free fast decoding paradigm that enables early commit decoding.
Specifically, Prophet dynamically decides whether to continue refinement or to
go "all-in" (i.e., decode all remaining tokens in one step), using the
confidence gap between the top-2 prediction candidates as the criterion. It
integrates seamlessly into existing DLM implementations, incurs negligible
overhead, and requires no additional training. Empirical evaluations of
LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the
number of decoding steps by up to 3.4x while preserving high generation
quality. These results recast DLM decoding as a problem of when to stop
sampling, and demonstrate that early decode convergence provides a simple yet
powerful mechanism for accelerating DLM inference, complementary to existing
speedup techniques. Our code is publicly available at
https://github.com/pixeli99/Prophet.

</details>


### [53] [AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios](https://arxiv.org/abs/2508.19988)
*Lisa Alazraki,Lihu Chen,Ana Brassard,Joe Stacey,Hossein A. Rahmani,Marek Rei*

Main category: cs.CL

TL;DR: 引入AgentCoMa基准测试，评估大型语言模型在结合常识与数学推理中的表现，发现模型在结合任务中性能显著下降，揭示模型脆弱性。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在复杂、多步推理任务中的能力，特别是在结合常识与数学推理的场景中存在的不足。

Method: 设计AgentCoMa基准，测试61个不同类型的LLMs，结合常识与数学推理任务，进行性能分析和可解释性研究。

Result: 模型在单步推理中表现优异，但在结合推理任务中准确率下降约30%，远低于人类水平。多项可解释性分析揭示模型在混合推理中的脆弱性。

Conclusion: 模型在混合类型的分步推理中表现脆弱，提出基准测试为未来模型改进提供参考和方向。

Abstract: Large Language Models (LLMs) have achieved high accuracy on complex
commonsense and mathematical problems that involve the composition of multiple
reasoning steps. However, current compositional benchmarks testing these skills
tend to focus on either commonsense or math reasoning, whereas LLM agents
solving real-world tasks would require a combination of both. In this work, we
introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each
compositional task requires a commonsense reasoning step and a math reasoning
step. We test it on 61 LLMs of different sizes, model families, and training
strategies. We find that LLMs can usually solve both steps in isolation, yet
their accuracy drops by ~30% on average when the two are combined. This is a
substantially greater performance gap than the one we observe in prior
compositional benchmarks that combine multiple steps of the same reasoning
type. In contrast, non-expert human annotators can solve the compositional
questions and the individual steps in AgentCoMa with similarly high accuracy.
Furthermore, we conduct a series of interpretability studies to better
understand the performance gap, examining neuron patterns, attention maps and
membership inference. Our work underscores a substantial degree of model
brittleness in the context of mixed-type compositional reasoning and offers a
test bed for future improvement.

</details>


### [54] [MathBuddy: A Multimodal System for Affective Math Tutoring](https://arxiv.org/abs/2508.19993)
*Debanjana Kar,Leopold Böss,Dacia Braca,Sebastian Maximilian Dennerlein,Nina Christine Hubig,Philipp Wintersberger,Yufang Hou*

Main category: cs.CL

TL;DR: 引入情感感知的微调大模型，提升数学辅导的教学效果。


<details>
  <summary>Details</summary>
Motivation: 当前的学习模型未考虑学生的情感状态，影响学习效果。

Method: 开发MatBuddy，结合文本和面部表情识别学生情感，并通过调节对话策略做出更具同理心的回应。

Result: 在多个评估指标和用户研究中，表现显著优于传统模型，提升了教学能力。

Conclusion: 情感感知增强的对话系统能显著改善教育类大模型的教学效果，从而更有效支持学生学习。

Abstract: The rapid adoption of LLM-based conversational systems is already
transforming the landscape of educational technology. However, the current
state-of-the-art learning models do not take into account the student's
affective states. Multiple studies in educational psychology support the claim
that positive or negative emotional states can impact a student's learning
capabilities. To bridge this gap, we present MathBuddy, an emotionally aware
LLM-powered Math Tutor, which dynamically models the student's emotions and
maps them to relevant pedagogical strategies, making the tutor-student
conversation a more empathetic one. The student's emotions are captured from
the conversational text as well as from their facial expressions. The student's
emotions are aggregated from both modalities to confidently prompt our LLM
Tutor for an emotionally-aware response. We have effectively evaluated our
model using automatic evaluation metrics across eight pedagogical dimensions
and user studies. We report a massive 23 point performance gain using the win
rate and a 3 point gain at an overall level using DAMR scores which strongly
supports our hypothesis of improving LLM-based tutor's pedagogical abilities by
modeling students' emotions.

</details>


### [55] [ReSURE: Regularizing Supervision Unreliability for Multi-turn Dialogue Fine-tuning](https://arxiv.org/abs/2508.19996)
*Yiming Du,Yifan Xiang,Bin Liang,Dahua Lin,Kam-Fai Wong,Fei Tan*

Main category: cs.CL

TL;DR: ReSURE是一种动态调整监督信号可靠性的方法，有效提升多轮对话系统的稳定性和响应质量。


<details>
  <summary>Details</summary>
Motivation: 解决多轮对话系统中低质量数据导致的性能下降问题，尤其是早期轮次的监督错误传播。

Method: 利用Welford在线统计方法估算每轮的损失分布，并动态调整其在训练中的权重，无需明确过滤低质量样本。

Result: 在单源和混合质量数据集上验证，ReSURE提高了系统的稳定性和响应质量，并在多个基准上展示了响应评分与样本数的正相关性，有助于大规模数据的有效利用。

Conclusion: ReSURE通过动态加权机制，有效缓解监督错误传播问题，提升对话系统的整体表现，并具有潜在的大规模数据利用优势。

Abstract: Fine-tuning multi-turn dialogue systems requires high-quality supervision but
often suffers from degraded performance when exposed to low-quality data.
Supervision errors in early turns can propagate across subsequent turns,
undermining coherence and response quality. Existing methods typically address
data quality via static prefiltering, which decouples quality control from
training and fails to mitigate turn-level error propagation. In this context,
we propose ReSURE (Regularizing Supervision UnREliability), an adaptive
learning method that dynamically down-weights unreliable supervision without
explicit filtering. ReSURE estimates per-turn loss distributions using
Welford's online statistics and reweights sample losses on the fly accordingly.
Experiments on both single-source and mixed-quality datasets show improved
stability and response quality. Notably, ReSURE enjoys positive Spearman
correlations (0.21 ~ 1.0 across multiple benchmarks) between response scores
and number of samples regardless of data quality, which potentially paves the
way for utilizing large-scale data effectively. Code is publicly available at
https://github.com/Elvin-Yiming-Du/ReSURE_Multi_Turn_Training.

</details>


### [56] [DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis](https://arxiv.org/abs/2508.20033)
*Liana Patel,Negar Arabzadeh,Harshit Gupta,Ankita Sundar,Ion Stoica,Matei Zaharia,Carlos Guestrin*

Main category: cs.CL

TL;DR: 本文提出了DeepScholar-bench，一个用于评估生成研究合成系统的全新基准和评估框架。通过评估不同系统在知识整合、检索质量和可验证性方面的表现，显示当前系统仍有较大提升空间，强调了研究合成AI的挑战和发展需求。


<details>
  <summary>Details</summary>
Motivation: 推动评估生成研究合成系统的标准，因现有评估方法无法充分反映实际研究任务的复杂性和动态性。

Method: 创建DeepScholar-bench基准和自动化评估框架，利用高质量论文中的查询，结合DeepScholar-base管线进行系统性能评估。

Result: DeepScholar-base表现优异但仍未超越其他系统，整体评分远离饱和，显示该领域仍有待突破。

Conclusion: DeepScholar-bench为研究合成AI提供了有价值的评估平台，展现出当前系统的局限性，并推动未来技术发展。

Abstract: The ability to research and synthesize knowledge is central to human
expertise and progress. An emerging class of systems promises these exciting
capabilities through generative research synthesis, performing retrieval over
the live web and synthesizing discovered sources into long-form, cited
summaries. However, evaluating such systems remains an open challenge: existing
question-answering benchmarks focus on short-form factual responses, while
expert-curated datasets risk staleness and data contamination. Both fail to
capture the complexity and evolving nature of real research synthesis tasks. In
this work, we introduce DeepScholar-bench, a live benchmark and holistic,
automated evaluation framework designed to evaluate generative research
synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv
papers and focuses on a real research synthesis task: generating the related
work sections of a paper by retrieving, synthesizing, and citing prior
research. Our evaluation framework holistically assesses performance across
three key dimensions, knowledge synthesis, retrieval quality, and
verifiability. We also develop DeepScholar-base, a reference pipeline
implemented efficiently using the LOTUS API. Using the DeepScholar-bench
framework, we perform a systematic evaluation of prior open-source systems,
search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that
DeepScholar-base establishes a strong baseline, attaining competitive or higher
performance than each other method. We also find that DeepScholar-bench remains
far from saturated, with no system exceeding a score of $19\%$ across all
metrics. These results underscore the difficulty of DeepScholar-bench, as well
as its importance for progress towards AI systems capable of generative
research synthesis. We make our code available at
https://github.com/guestrin-lab/deepscholar-bench.

</details>


### [57] [Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](https://arxiv.org/abs/2508.20038)
*Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao*

Main category: cs.CL

TL;DR: 提出IMAGINE框架，通过分析嵌入空间分布生成越狱指令，有效缩小攻击指令与安全数据的分布差距，提升模型安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在拒绝恶意指令方面取得进展，但仍易被破解攻击利用未知恶意指令，暴露出训练数据与实际攻击之间的分布差异问题。

Method: 采用嵌入空间分布分析，利用迭代优化方法生成类似越狱的指令，逐步扩展安全对齐数据的覆盖范围，从而增强模型抵抗未知攻击的能力。

Result: 在Qwen2.5、Llama3.1和Llama3.2模型上，显著降低了攻击成功率，同时保持了模型的实用性。

Conclusion: IMAGINE通过合成数据有效缓解分布不匹配问题，增强大模型的安全性和鲁棒性，提供了新的应对未知攻击的策略。

Abstract: Despite advances in improving large language model(LLM) to refuse to answer
malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks
where attackers generate instructions with distributions differing from safety
alignment corpora. New attacks expose LLMs' inability to recognize unseen
malicious instructions, highlighting a critical distributional mismatch between
training data and real-world attacks that forces developers into reactive
patching cycles. To tackle this challenge, we propose IMAGINE, a synthesis
framework that leverages embedding space distribution analysis to generate
jailbreak-like instructions. This approach effectively fills the distributional
gap between authentic jailbreak patterns and safety alignment corpora. IMAGINE
follows an iterative optimization process that dynamically evolves text
generation distributions across iterations, thereby augmenting the coverage of
safety alignment data distributions through synthesized data examples. Based on
the safety-aligned corpus enhanced through IMAGINE, our framework demonstrates
significant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2
without compromising their utility.

</details>


### [58] [AraHealthQA 2025 Shared Task Description Paper](https://arxiv.org/abs/2508.20047)
*Hassan Alhuzali,Farah Shamout,Muhammad Abdul-Mageed,Chaimae Abouzahir,Mouath Abu-Daoud,Ashwag Alasmari,Walid Al-Eisawi,Renad Al-Monef,Ali Alqahtani,Lama Ayash,Nizar Habash,Leen Kharouf*

Main category: cs.CL

TL;DR: 该共享任务旨在弥补阿拉伯语医疗问答资源匮乏，设有精神健康和广泛医疗两个轨道，通过多样化评估促进模型发展。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语医疗问答资源不足，亟需高质量数据以支持医疗AI发展。

Method: 设立两个轨道（精神健康与广泛医疗），包括多子任务和标准化评估，推动模型在真实、多语种、文化细腻的医疗环境中应用。

Result: 完成数据集制作、任务设计、评估框架，提供基线系统，观察到性能趋势，为未来发展提供方向。

Conclusion: 强调持续改进模型性能，扩大资源覆盖面，推动阿拉伯语医疗问答技术的发展。

Abstract: We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question
Answering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located
with EMNLP 2025). This shared task addresses the paucity of high-quality Arabic
medical QA resources by offering two complementary tracks: {MentalQA}, focusing
on Arabic mental health Q\&A (e.g., anxiety, depression, stigma reduction), and
{MedArabiQ}, covering broader medical domains such as internal medicine,
pediatrics, and clinical decision making. Each track comprises multiple
subtasks, evaluation datasets, and standardized metrics, facilitating fair
benchmarking. The task was structured to promote modeling under realistic,
multilingual, and culturally nuanced healthcare contexts. We outline the
dataset creation, task design and evaluation framework, participation
statistics, baseline systems, and summarize the overall outcomes. We conclude
with reflections on the performance trends observed and prospects for future
iterations in Arabic health QA.

</details>


### [59] [11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis](https://arxiv.org/abs/2508.20068)
*Chengzu Li,Wenshan Wu,Huanyu Zhang,Qingtao Li,Zeyu Gao,Yan Xia,José Hernández-Orallo,Ivan Vulić,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出了一套评估多模态大模型空间推理能力的框架，发现现有模型在空间认知方面尚有很大提升空间，但已展现出初步的认知迹象。


<details>
  <summary>Details</summary>
Motivation: 探究多模态大模型在空间推理能力上的表现和潜力，弥补现有研究的不足。

Method: 构建基于真实空间测试的11Plus-Bench基准，结合专家标注，通过对14个模型和人类进行评估，分析模型行为和性能。

Result: 模型显示出空间认知的早期迹象，但性能差距明显，模型表现随机性较大，缺乏人类的规律性。

Conclusion: 当前模型在空间推理方面仍有限，但已有一定认知基础，为未来模型改进提供了参考。

Abstract: For human cognitive process, spatial reasoning and perception are closely
entangled, yet the nature of this interplay remains underexplored in the
evaluation of multimodal large language models (MLLMs). While recent MLLM
advancements show impressive performance on reasoning, their capacity for
human-like spatial cognition remains an open question. In this work, we
introduce a systematic evaluation framework to assess the spatial reasoning
abilities of state-of-the-art MLLMs relative to human performance. Central to
our work is 11Plus-Bench, a high-quality benchmark derived from realistic
standardized spatial aptitude tests. 11Plus-Bench also features fine-grained
expert annotations of both perceptual complexity and reasoning process,
enabling detailed instance-level analysis of model behavior. Through extensive
experiments across 14 MLLMs and human evaluation, we find that current MLLMs
exhibit early signs of spatial cognition. Despite a large performance gap
compared to humans, MLLMs' cognitive profiles resemble those of humans in that
cognitive effort correlates strongly with reasoning-related complexity.
However, instance-level performance in MLLMs remains largely random, whereas
human correctness is highly predictable and shaped by abstract pattern
complexity. These findings highlight both emerging capabilities and limitations
in current MLLMs' spatial reasoning capabilities and provide actionable
insights for advancing model design.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [60] [Physics-Informed Regression: Parameter Estimation in Parameter-Linear Nonlinear Dynamic Models](https://arxiv.org/abs/2508.19249)
*Jonas Søeborg Nielsen,Marcus Galea Jacobsen,Albert Brincker Olson,Mads Peter Sørensen,Allan Peter Engsig-Karup*

Main category: cs.LG

TL;DR: 提出一种基于物理信息回归的高效混合参数估计方法，优于PINN，适用于非线性ODE和PDE模型的参数估计，尤其在疫情模型中表现优越。


<details>
  <summary>Details</summary>
Motivation: 需要一种高效、准确的参数估计技术，特别是在复杂的非线性动态模型中，弥补现有方法的不足。

Method: 结合线性参数模型与正则化最小二乘，提出“物理信息回归（PIR）”方法，用示例验证其在ODE、PDE模型中的应用，并与PINN比较效果。

Result: PIR在模拟和实际COVID-19数据中均表现优越，尤其在复杂模型上具有明显优势，计算速度更快，适合实时参数估计。

Conclusion: PIR是一种高效、可靠的参数估计工具，适合动态模型的快速数据驱动分析，有助于实时决策。

Abstract: We present a new efficient hybrid parameter estimation method based on the
idea, that if nonlinear dynamic models are stated in terms of a system of
equations that is linear in terms of the parameters, then regularized ordinary
least squares can be used to estimate these parameters from time series data.
We introduce the term "Physics-Informed Regression" (PIR) to describe the
proposed data-driven hybrid technique as a way to bridge theory and data by use
of ordinary least squares to efficiently perform parameter estimation of the
model coefficients of different parameter-linear models; providing examples of
models based on nonlinear ordinary equations (ODE) and partial differential
equations (PDE). The focus is on parameter estimation on a selection of ODE and
PDE models, each illustrating performance in different model characteristics.
For two relevant epidemic models of different complexity and number of
parameters, PIR is tested and compared against the related technique,
physics-informed neural networks (PINN), both on synthetic data generated from
known target parameters and on real public Danish time series data collected
during the COVID-19 pandemic in Denmark. Both methods were able to estimate the
target parameters, while PIR showed to perform noticeably better, especially on
a compartment model with higher complexity. Given the difference in
computational speed, it is concluded that the PIR method is superior to PINN
for the models considered. It is also demonstrated how PIR can be applied to
estimate the time-varying parameters of a compartment model that is fitted
using real Danish data from the COVID-19 pandemic obtained during a period from
2020 to 2021. The study shows how data-driven and physics-informed techniques
may support reliable and fast -- possibly real-time -- parameter estimation in
parameter-linear nonlinear dynamic models.

</details>


### [61] [Lossless Compression of Neural Network Components: Weights, Checkpoints, and K/V Caches in Low-Precision Formats](https://arxiv.org/abs/2508.19263)
*Anat Heilper,Doron Singer*

Main category: cs.LG

TL;DR: 扩展了ZipNN压缩方法至低精度浮点格式FP8和FP4，自然序列化和压缩神经网络模型参数，显著降低存储与传输成本，尤其在大规模语言模型中有效。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习模型规模扩大，减少模型存储和传输成本变得尤为重要。

Method: 设计了一种基于熵编码的分离压缩技术，分别对指数和尾数部分进行压缩，扩展到FP8和FP4等低精度格式。

Result: 在BF16格式下实现高达62%的压缩率，在FP8中达到83%的压缩率，还支持对大型语言模型的关键值缓存进行压缩，显著节省内存。

Conclusion: 低精度浮点格式的模型参数具有很高的可压缩性，为模型优化和部署提供了有效的存储解决方案。

Abstract: As deep learning models grow and deployment becomes more widespread, reducing
the storage and transmission costs of neural network weights has become
increasingly important. While prior work such as ZipNN has shown that lossless
compression methods - particularly those based on Huffman encoding
floating-point exponents can significantly reduce model sizes, these techniques
have primarily been applied to higher-precision formats such as FP32 and BF16.
In this work, we extend the ZipNN approach to lower-precision floating-point
formats, specifically FP8 and FP4, which are gaining popularity for efficient
inference. We design a compression method that separates and compresses the
exponent and mantissa components independently using entropy coding. Our
evaluation shows compression ratios up to 62% for BF16 and 83% for FP8. We also
investigate the compressibility of key-value (K/V) cache tensors used in large
language models (LLMs), finding that they, too, exhibit compressible patterns,
enabling memory savings during deployment.

</details>


### [62] [POT: Inducing Overthinking in LLMs via Black-Box Iterative Optimization](https://arxiv.org/abs/2508.19277)
*Xinyu Li,Tianjin Huang,Ronghui Mu,Xiaowei Huang,Gaojie Jin*

Main category: cs.LG

TL;DR: 提出了一种名为POT的黑盒攻击框架，利用LLM进行迭代优化，生成隐蔽、自然的对抗性提示，以攻击大模型的推理过程，避免依赖外部知识和模板限制。


<details>
  <summary>Details</summary>
Motivation: 随着链式推理的应用推动大模型能力提升，其带来的复杂推理链也带来资源浪费和安全风险。现有攻击方法受限于外部知识与模板依赖，难以实用化。

Method: 通过LLM的迭代优化，生成隐蔽且语义自然的对抗提示，形成黑盒攻击框架，不依赖外部数据或模型检索。

Result: 在多模型和数据集上实验显示，POT在攻击效果上优于其他方法，有效利用推理过程中潜在的攻击机会。

Conclusion: POT作为一种无需外部知识、结构隐蔽的黑盒攻击框架，彰显了当前大模型推理的潜在安全风险，提示需加强模型推理过程的鲁棒性。

Abstract: Recent advances in Chain-of-Thought (CoT) prompting have substantially
enhanced the reasoning capabilities of large language models (LLMs), enabling
sophisticated problem-solving through explicit multi-step reasoning traces.
However, these enhanced reasoning processes introduce novel attack surfaces,
particularly vulnerabilities to computational inefficiency through
unnecessarily verbose reasoning chains that consume excessive resources without
corresponding performance gains. Prior overthinking attacks typically require
restrictive conditions including access to external knowledge sources for data
poisoning, reliance on retrievable poisoned content, and structurally obvious
templates that limit practical applicability in real-world scenarios. To
address these limitations, we propose POT (Prompt-Only OverThinking), a novel
black-box attack framework that employs LLM-based iterative optimization to
generate covert and semantically natural adversarial prompts, eliminating
dependence on external data access and model retrieval. Extensive experiments
across diverse model architectures and datasets demonstrate that POT achieves
superior performance compared to other methods.

</details>


### [63] [(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems](https://arxiv.org/abs/2508.19318)
*Aohan Li,Miyu Tsuzuki*

Main category: cs.LG

TL;DR: 提出一种在实际分布式物联网环境中训练深度强化学习模型的框架，利用实际传输的ACK信息进行模型训练，验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 弥补现有研究未在实际物联网环境中使用真实数据训练DRL模型的空白，提升资源调度的实用性与效果。

Method: 设计基于DRL的通信通道选择方法，并利用实际传输反馈（ACK）信息训练模型，结合实现与性能评估。

Result: 验证了该框架的可行性与有效性，提升了通信成功率。

Conclusion: 该框架可应用于实际分布式IoT系统中，提升资源管理的智能化水平。

Abstract: Deep Reinforcement Learning (DRL) has emerged as an efficient approach to
resource allocation due to its strong capability in handling complex
decision-making tasks. However, only limited research has explored the training
of DRL models with real-world data in practical, distributed Internet of Things
(IoT) systems. To bridge this gap, this paper proposes a novel framework for
training DRL models in real-world distributed IoT environments. In the proposed
framework, IoT devices select communication channels using a DRL-based method,
while the DRL model is trained with feedback information. Specifically,
Acknowledgment (ACK) information is obtained from actual data transmissions
over the selected channels. Implementation and performance evaluation, in terms
of Frame Success Rate (FSR), are carried out, demonstrating both the
feasibility and the effectiveness of the proposed framework.

</details>


### [64] [Re:Frame -- Retrieving Experience From Associative Memory](https://arxiv.org/abs/2508.19344)
*Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: Re:Frame通过存储和检索少量专家示范，显著提升离线强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 在缺乏大规模专家数据的情况下，提高离线RL的效果。

Method: 引入外部联想存储缓冲区，用内容关联在训练和评估中检索专家经验，优化决策过程。

Result: 在MuJoCo任务中，用极少的专家轨迹（0.1%）即可实现显著性能提升，最高增加10.7个百分点。

Conclusion: Re:Frame提供了一个简便且高效的方式，将稀少的专家知识整合到离线RL中，大幅改善低质量数据集的表现。

Abstract: Offline reinforcement learning (RL) often deals with suboptimal data when
collecting large expert datasets is unavailable or impractical. This limitation
makes it difficult for agents to generalize and achieve high performance, as
they must learn primarily from imperfect or inconsistent trajectories. A
central challenge is therefore how to best leverage scarce expert
demonstrations alongside abundant but lower-quality data. We demonstrate that
incorporating even a tiny amount of expert experience can substantially improve
RL agent performance. We introduce Re:Frame (Retrieving Experience From
Associative Memory), a plug-in module that augments a standard offline RL
policy (e.g., Decision Transformer) with a small external Associative Memory
Buffer (AMB) populated by expert trajectories drawn from a separate dataset.
During training on low-quality data, the policy learns to retrieve expert data
from the Associative Memory Buffer (AMB) via content-based associations and
integrate them into decision-making; the same AMB is queried at evaluation.
This requires no environment interaction and no modifications to the backbone
architecture. On D4RL MuJoCo tasks, using as few as 60 expert trajectories
(0.1% of a 6000-trajectory dataset), Re:Frame consistently improves over a
strong Decision Transformer baseline in three of four settings, with gains up
to +10.7 normalized points. These results show that Re:Frame offers a simple
and data-efficient way to inject scarce expert knowledge and substantially
improve offline RL from low-quality datasets.

</details>


### [65] [Memorization in Graph Neural Networks](https://arxiv.org/abs/2508.19352)
*Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch*

Main category: cs.LG

TL;DR: 本文提出了NCMemo框架，用于量化半监督节点分类中的记忆性，发现低同质性图更易被GNN记忆，且通过图重连可有效降低记忆性，增强隐私保护。


<details>
  <summary>Details</summary>
Motivation: 探究GNN在训练中的记忆行为和影响因素，尤其是在不同图同质性条件下的表现。

Method: 提出NCMemo框架，分析图同质性与记忆关系，研究GNN训练动态，验证图重连对记忆和隐私的影响。

Result: 低同质性提高记忆性，图结构较少信息时，GNN更依赖记忆，图重连可减低记忆风险，保护隐私。

Conclusion: 理解图同质性与记忆关系，为改善GNN泛化和隐私保护提供解决方案。

Abstract: Deep neural networks (DNNs) have been shown to memorize their training data,
yet similar analyses for graph neural networks (GNNs) remain largely
under-explored. We introduce NCMemo (Node Classification Memorization), the
first framework to quantify label memorization in semi-supervised node
classification. We first establish an inverse relationship between memorization
and graph homophily, i.e., the property that connected nodes share similar
labels/features. We find that lower homophily significantly increases
memorization, indicating that GNNs rely on memorization to learn less
homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the
increased memorization in low homophily graphs is tightly coupled to the GNNs'
implicit bias on using graph structure during learning. In low homophily
regimes, this structure is less informative, hence inducing memorization of the
node labels to minimize training loss. Finally, we show that nodes with higher
label inconsistency in their feature-space neighborhood are significantly more
prone to memorization. Building on our insights into the link between graph
homophily and memorization, we investigate graph rewiring as a means to
mitigate memorization. Our results demonstrate that this approach effectively
reduces memorization without compromising model performance. Moreover, we show
that it lowers the privacy risk for previously memorized data points in
practice. Thus, our work not only advances understanding of GNN learning but
also supports more privacy-preserving GNN deployment.

</details>


### [66] [Efficient Multi-Source Knowledge Transfer by Model Merging](https://arxiv.org/abs/2508.19353)
*Marcin Osial,Bartosz Wójcik,Bartosz Zieliński,Sebastian Cygert*

Main category: cs.LG

TL;DR: 提出一种基于奇异值分解的多源迁移学习方法，通过分解和筛选模型中的重要成分，提高迁移效率和精度。


<details>
  <summary>Details</summary>
Motivation: 利用丰富的在线模型资源，实现更高效和精细的多源迁移学习，弥补现有方法在知识提取和融合上的不足。

Method: 采用奇异值分解分解源模型，筛选主要成分后进行融合，仅调节关键奇异值以适应目标任务。

Result: 该方法提升了迁移学习的效率和鲁棒性，适应性强且具备良好的扩展性，能有效应对噪声和模型剪枝等干扰。

Conclusion: 基于SVD的多源迁移学习框架简洁高效，具有较好的实际应用潜力。

Abstract: While transfer learning is an advantageous strategy, it overlooks the
opportunity to leverage knowledge from numerous available models online.
Addressing this multi-source transfer learning problem is a promising path to
boost adaptability and cut re-training costs. However, existing approaches are
inherently coarse-grained, lacking the necessary precision for granular
knowledge extraction and the aggregation efficiency required to fuse knowledge
from either a large number of source models or those with high parameter
counts. We address these limitations by leveraging Singular Value Decomposition
(SVD) to first decompose each source model into its elementary, rank-one
components. A subsequent aggregation stage then selects only the most salient
components from all sources, thereby overcoming the previous efficiency and
precision limitations. To best preserve and leverage the synthesized knowledge
base, our method adapts to the target task by fine-tuning only the principal
singular values of the merged matrix. In essence, this process only
recalibrates the importance of top SVD components. The proposed framework
allows for efficient transfer learning, is robust to perturbations both at the
input level and in the parameter space (e.g., noisy or pruned sources), and
scales well computationally.

</details>


### [67] [Graph Data Modeling: Molecules, Proteins, & Chemical Processes](https://arxiv.org/abs/2508.19356)
*José Manuel Barraza-Chavez,Rana A. Barghout,Ricardo Almada-Monter,Benjamin Sanchez-Lengeling,Adrian Jinich,Radhakrishnan Mahadevan*

Main category: cs.LG

TL;DR: 介绍了图在化学中的应用及其在机器学习中的基础作用，特别是图神经网络，用于化学物质、蛋白质和反应的建模。


<details>
  <summary>Details</summary>
Motivation: 推动化学科学中复杂结构的建模和分析，通过引入图及其学习算法，促进化学发现。

Method: 系统介绍图的设计基础、预测任务、典型案例，以及机器学习在图模型中的应用。

Result: 为研究人员提供了理解和应用图数据方法的基础，促进新一代化学发现工具的发展。

Conclusion: 图在化学中的重要性不断提升，结合机器学习的方法是未来研究的关键方向。

Abstract: Graphs are central to the chemical sciences, providing a natural language to
describe molecules, proteins, reactions, and industrial processes. They capture
interactions and structures that underpin materials, biology, and medicine.
This primer, Graph Data Modeling: Molecules, Proteins, & Chemical Processes,
introduces graphs as mathematical objects in chemistry and shows how learning
algorithms (particularly graph neural networks) can operate on them. We outline
the foundations of graph design, key prediction tasks, representative examples
across chemical sciences, and the role of machine learning in graph-based
modeling. Together, these concepts prepare readers to apply graph methods to
the next generation of chemical discovery.

</details>


### [68] [Atrial Fibrillation Prediction Using a Lightweight Temporal Convolutional and Selective State Space Architecture](https://arxiv.org/abs/2508.19361)
*Yongbin Lee,Ki H. Chon*

Main category: cs.LG

TL;DR: 该研究提出一种轻量级深度学习模型，基于RR间隔数据实现早期心房颤动预测，具有高准确率和效率，能提前两小时预测，为预防提供时间窗口。


<details>
  <summary>Details</summary>
Motivation: 早期心房颤动（AF）难以检测，未能及时预防可能导致严重并发症，故需开发能提前预测AF的高效模型。

Method: 结合Temporal Convolutional Network（TCN）和Mamba模型，设计只依赖RR间隔的深度学习模型，实现快速准确的早期预测。

Result: 模型在敏感度、特异性、F1-score、AUROC和AUPRC方面表现优异，参数少计算量小，且能提前两小时预测，有助早期干预。

Conclusion: 所提出模型实现了高效、准确的早期AF预测，具有临床应用潜力，有助于预防心血管事件。

Abstract: Atrial fibrillation (AF) is the most common arrhythmia, increasing the risk
of stroke, heart failure, and other cardiovascular complications. While AF
detection algorithms perform well in identifying persistent AF, early-stage
progression, such as paroxysmal AF (PAF), often goes undetected due to its
sudden onset and short duration. However, undetected PAF can progress into
sustained AF, increasing the risk of mortality and severe complications. Early
prediction of AF offers an opportunity to reduce disease progression through
preventive therapies, such as catecholamine-sparing agents or beta-blockers. In
this study, we propose a lightweight deep learning model using only RR
Intervals (RRIs), combining a Temporal Convolutional Network (TCN) for
positional encoding with Mamba, a selective state space model, to enable early
prediction of AF through efficient parallel sequence modeling. In subject-wise
testing results, our model achieved a sensitivity of 0.908, specificity of
0.933, F1-score of 0.930, AUROC of 0.972, and AUPRC of 0.932. Additionally, our
method demonstrates high computational efficiency, with only 73.5 thousand
parameters and 38.3 MFLOPs, outperforming traditional Convolutional Neural
Network-Recurrent Neural Network (CNN-RNN) approaches in both accuracy and
model compactness. Notably, the model can predict AF up to two hours in advance
using just 30 minutes of input data, providing enough lead time for preventive
interventions.

</details>


### [69] [Grounding the Ungrounded: A Spectral-Graph Framework for Quantifying Hallucinations in multimodal LLMs](https://arxiv.org/abs/2508.19366)
*Supratik Sarkar,Swagatam Das*

Main category: cs.LG

TL;DR: 提出了一种基于信息几何的多模态大语言模型幻觉量化方法，突破了现有的定性检测局限。


<details>
  <summary>Details</summary>
Motivation: 大语言模型中的幻觉依然是可信AI的主要障碍，特别是在高风险的多模态领域，因此亟需用量化的、理论基础的方法来理解和控制幻觉。

Method: 引入信息几何与扩散动力学相结合的框架，通过图拉普拉斯谱嵌入，利用特征模态分解和RKHS，量化模型中的幻觉现象。

Result: 该框架提供了模态感知、理论可解释的度量指标，能够描述和控制幻觉随时间和输入变化的演变。

Conclusion: 通过该方法，实现了幻觉的量化和边界分析，从风险感知向可控的分析工具转变，为可信AI的发展奠定基础。

Abstract: Hallucinations in large language models (LLMs) remain a fundamental obstacle
to trustworthy AI, particularly in high-stakes multimodal domains such as
medicine, law, and finance. Existing evaluation techniques are largely
heuristic -- anchored in qualitative benchmarking or ad-hoc empirical
mitigation -- providing neither principled quantification nor actionable
theoretical guarantees. This gap leaves a critical blind spot in understanding
how hallucinations arise, propagate, and interact across modalities. We
introduce the first (to our knowledge) rigorous information geometric framework
in diffusion dynamics for quantifying hallucinations in multimodal LLMs
(MLLMs), advancing the field from qualitative detection to mathematically
grounded measurement. Our approach represents MLLM outputs as the spectral
embeddings over multimodal graph Laplacians and characterizes the manifold gaps
of truth vs inconsistencies as the semantic distortion, enabling the tight
Rayleigh--Ritz bounds on the multimodal hallucination energy as a functional of
time-dependent temperature profiles. By leveraging eigenmode decompositions in
Reproducing Kernel Hilbert Space (RKHS) embeddings, our framework delivers
modality-aware, theoretically interpretable metrics that capture the evolution
of hallucinations across time and input prompts through temperature annealing.
This work establishes a principled foundation for quantifying and bounding
hallucinations, transforming them from a qualitative risk to a tractable,
analyzable phenomenon.

</details>


### [70] [Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments](https://arxiv.org/abs/2508.19376)
*Dikshant Sagar,Kaiwen Yu,Alejandro Yankelevich,Jianming Bian,Pierre Baldi*

Main category: cs.LG

TL;DR: VLM在高能物理中用于中微子交互分类表现优异，优于传统CNN，支持多模态推理。


<details>
  <summary>Details</summary>
Motivation: 探索大型视觉-语言模型在高能物理事件分类中的潜力，推动多模态方法的发展。

Method: 基于LLaMA 3.2微调的VLM对比CNN，评估分类性能及推理能力。

Result: VLM在准确率、精准率、召回率和AUC-ROC等指标上优于CNN，增强推理与语义整合。

Conclusion: VLM是高能物理事件分类的有前景的通用模型，推动多模态技术应用。

Abstract: Recent progress in large language models (LLMs) has shown strong potential
for multimodal reasoning beyond natural language. In this work, we explore the
use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for
classifying neutrino interactions from pixelated detector images in high-energy
physics (HEP) experiments. We benchmark its performance against an established
CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as
classification accuracy, precision, recall, and AUC-ROC. Our results show that
the VLM not only matches or exceeds CNN performance but also enables richer
reasoning and better integration of auxiliary textual or semantic context.
These findings suggest that VLMs offer a promising general-purpose backbone for
event classification in HEP, paving the way for multimodal approaches in
experimental neutrino physics.

</details>


### [71] [Towards Quantum Machine Learning for Malicious Code Analysis](https://arxiv.org/abs/2508.19381)
*Jesus Lopez,Saeefa Rubaiyet Nowmi,Viviana Cadena,Mohammad Saidur Rahman*

Main category: cs.LG

TL;DR: 本文探索了两种量子-经典混合模型（QMLP和QCNN）在恶意软件分类中的应用，结果显示QMLP在复杂多类别任务中表现优异，而QCNN具有训练效率优势。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的发展，探索其在恶意软件检测领域的潜力成为研究重点。

Method: 研究采用角度嵌入技术，将恶意软件特征编码到量子状态中，通过全测量及数据重上传，实现复杂特征捕获及训练效率提升。

Result: 在多种数据集和分类任务中，两模型都表现出较高的准确率，QMLP在多类别任务中优于QCNN，后者在训练效率上占优。

Conclusion: 量子混合模型展现出在恶意软件分类中的潜力，未来可结合量子优势优化检测性能。

Abstract: Classical machine learning (CML) has been extensively studied for malware
classification. With the emergence of quantum computing, quantum machine
learning (QML) presents a paradigm-shifting opportunity to improve malware
detection, though its application in this domain remains largely unexplored. In
this study, we investigate two hybrid quantum-classical models -- a Quantum
Multilayer Perceptron (QMLP) and a Quantum Convolutional Neural Network (QCNN),
for malware classification. Both models utilize angle embedding to encode
malware features into quantum states. QMLP captures complex patterns through
full qubit measurement and data re-uploading, while QCNN achieves faster
training via quantum convolution and pooling layers that reduce active qubits.
We evaluate both models on five widely used malware datasets -- API-Graph,
EMBER-Domain, EMBER-Class, AZ-Domain, and AZ-Class, across binary and
multiclass classification tasks.
  Our results show high accuracy for binary classification -- 95-96% on
API-Graph, 91-92% on AZ-Domain, and 77% on EMBER-Domain. In multiclass
settings, accuracy ranges from 91.6-95.7% on API-Graph, 41.7-93.6% on AZ-Class,
and 60.7-88.1% on EMBER-Class. Overall, QMLP outperforms QCNN in complex
multiclass tasks, while QCNN offers improved training efficiency at the cost of
reduced accuracy.

</details>


### [72] [Cross-Platform E-Commerce Product Categorization and Recategorization: A Multimodal Hierarchical Classification Approach](https://arxiv.org/abs/2508.20013)
*Lotte Gross,Rebecca Walter,Nicole Zoppi,Adrien Justus,Alessandro Gambetti,Qiwei Han,Maximilian Kaiser*

Main category: cs.LG

TL;DR: 本研究开发了一种多模态层次分类框架，结合文本、视觉及联合表示，有效提升电商商品类别的准确性，并引入自监督复分类以发现细粒度类别，具备良好的工业部署潜力。


<details>
  <summary>Details</summary>
Motivation: 解决电商平台多样性和现有分类体系结构局限性，提升商品分类的准确性和细粒度。

Method: 集成RoBERTa、ViT、CLIP多模态特征，采用多种融合策略，并通过自监督学习优化类别结构，结合层次化和动态掩码增强分类效果。

Result: 融合CLIP的后融合策略达成98.59%的层次F1，提升分类性能；自监督复分类发现新细粒度类别；跨平台实验显示不同方法在准确性和泛化性间的权衡；成功部署于商业平台，兼顾成本与效果。

Conclusion: 多模态层次分类框架在商品细粒度分类方面表现优异，具备高度工业化适应性，能有效应对平台多样性和类别结构挑战。

Abstract: This study addresses critical industrial challenges in e-commerce product
categorization, namely platform heterogeneity and the structural limitations of
existing taxonomies, by developing and deploying a multimodal hierarchical
classification framework. Using a dataset of 271,700 products from 40
international fashion e-commerce platforms, we integrate textual features
(RoBERTa), visual features (ViT), and joint vision--language representations
(CLIP). We investigate fusion strategies, including early, late, and
attention-based fusion within a hierarchical architecture enhanced by dynamic
masking to ensure taxonomic consistency. Results show that CLIP embeddings
combined via an MLP-based late-fusion strategy achieve the highest hierarchical
F1 (98.59\%), outperforming unimodal baselines. To address shallow or
inconsistent categories, we further introduce a self-supervised ``product
recategorization'' pipeline using SimCLR, UMAP, and cascade clustering, which
discovered new, fine-grained categories (e.g., subtypes of ``Shoes'') with
cluster purities above 86\%. Cross-platform experiments reveal a
deployment-relevant trade-off: complex late-fusion methods maximize accuracy
with diverse training data, while simpler early-fusion methods generalize more
effectively to unseen platforms. Finally, we demonstrate the framework's
industrial scalability through deployment in EURWEB's commercial transaction
intelligence platform via a two-stage inference pipeline, combining a
lightweight RoBERTa stage with a GPU--accelerated multimodal stage to balance
cost and accuracy.

</details>


### [73] [DETNO: A Diffusion-Enhanced Transformer Neural Operator for Long-Term Traffic Forecasting](https://arxiv.org/abs/2508.19389)
*Owais Ahmad,Milad Ramezankhani,Anirudh Deodhar*

Main category: cs.LG

TL;DR: 引入Diffusion-Enhanced Transformer Neural Operator (DETNO)，结合变换器和扩散机制，有效提升交通流长时间预测的高频特征还原与稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前神经算子在长时段交通预测中因平滑特性无法反映高频特征，导致误差累积，亟需改良。

Method: 设计融合变换器和扩散技术的神经算子架构，利用交叉注意力机制与逐步去噪重建高频细节。

Result: 在混沌交通数据集上，DETNO在长时预测中表现优越，尤其在保持高频特征与模型稳定性方面优于传统方法。

Conclusion: 提出的DETNO模型克服了神经算子平滑和不稳定的问题，有效提升了交通流的长时间预测能力。

Abstract: Accurate long-term traffic forecasting remains a critical challenge in
intelligent transportation systems, particularly when predicting high-frequency
traffic phenomena such as shock waves and congestion boundaries over extended
rollout horizons. Neural operators have recently gained attention as promising
tools for modeling traffic flow. While effective at learning function space
mappings, they inherently produce smooth predictions that fail to reconstruct
high-frequency features such as sharp density gradients which results in rapid
error accumulation during multi-step rollout predictions essential for
real-time traffic management. To address these fundamental limitations, we
introduce a unified Diffusion-Enhanced Transformer Neural Operator (DETNO)
architecture. DETNO leverages a transformer neural operator with
cross-attention mechanisms, providing model expressivity and super-resolution,
coupled with a diffusion-based refinement component that iteratively
reconstructs high-frequency traffic details through progressive denoising. This
overcomes the inherent smoothing limitations and rollout instability of
standard neural operators. Through comprehensive evaluation on chaotic traffic
datasets, our method demonstrates superior performance in extended rollout
predictions compared to traditional and transformer-based neural operators,
preserving high-frequency components and improving stability over long
prediction horizons.

</details>


### [74] [Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding](https://arxiv.org/abs/2508.19394)
*Afrar Jahin,Yi Pan,Yingfeng Wang,Tianming Liu,Wei Zhang*

Main category: cs.LG

TL;DR: 提出了一种结合量子编码和经典序列建模的混合量子-经典架构，用于改进SMILES字符串重建的保真度和相似性，显著优于现有量子基线，为量子机器学习在分子设计中的应用奠定基础。


<details>
  <summary>Details</summary>
Motivation: 弥补传统方法在分子设计中表现的局限性，探索量子机器学习在序列任务中的潜力，推动量子与经典模型的融合发展。

Method: 采用混合量子-经典架构，结合量子编码与经典序列模型，用于SMILES字符串的重建。

Result: 实现了约84%的量子保真度和60%的经典重建相似性，优于现有的量子基线。

Conclusion: 此工作为量子机器学习在分子和药物发现中的应用提供了新途径，促进量子表示与经典序列模型的结合，并推动相关研究的深入。

Abstract: Although recent advances in quantum machine learning (QML) offer significant
potential for enhancing generative models, particularly in molecular design, a
large array of classical approaches still face challenges in achieving high
fidelity and validity. In particular, the integration of QML with
sequence-based tasks, such as Simplified Molecular Input Line Entry System
(SMILES) string reconstruction, remains underexplored and usually suffers from
fidelity degradation. In this work, we propose a hybrid quantum-classical
architecture for SMILES reconstruction that integrates quantum encoding with
classical sequence modeling to improve quantum fidelity and classical
similarity. Our approach achieves a quantum fidelity of approximately 84% and a
classical reconstruction similarity of 60%, surpassing existing quantum
baselines. Our work lays a promising foundation for future QML applications,
striking a balance between expressive quantum representations and classical
sequence models and catalyzing broader research on quantum-aware sequence
models for molecular and drug discovery.

</details>


### [75] [Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks](https://arxiv.org/abs/2508.19410)
*Zongyu Wu,Ruichen Xu,Luoyao Chen,Georgios Kementzidis,Siyao Wang,Yuefan Deng*

Main category: cs.LG

TL;DR: 提出一种基于Kolmogorov-Arnold表示的哈密顿神经网络(KAR-HNN)，通过用单变量变换替代MLPs，更好捕捉高频、多尺度动态，提升能量守恒和预测稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决现有哈密顿神经网络在复杂能量景观中对超参数敏感，导致能量漂移和预测不稳定的问题。

Method: 采用Kolmogorov-Arnold表示，将MLPs换成单变量变换，利用局部函数逼近高度捕捉多尺度动态，并保持辛结构。

Result: 在四个标杆问题中表现优异，展示其在高维复杂系统中准确、稳定建模的潜力。

Conclusion: KAR-HNN在保持物理一致性和解释性的基础上，有望应用于复杂真实物理过程的建模。

Abstract: We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural
Network (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with
univariate transformations. While Hamiltonian Neural Networks (HNNs) ensure
energy conservation by learning Hamiltonian functions directly from data,
existing implementations, often relying on MLPs, cause hypersensitivity to the
hyperparameters while exploring complex energy landscapes. Our approach
exploits the localized function approximations to better capture high-frequency
and multi-scale dynamics, reducing energy drift and improving long-term
predictive stability. The networks preserve the symplectic form of Hamiltonian
systems, and thus maintain interpretability and physical consistency. After
assessing KAR-HNN on four benchmark problems including spring-mass, simple
pendulum, two- and three-body problem, we foresee its effectiveness for
accurate and stable modeling of realistic physical processes often at high
dimensions and with few known parameters.

</details>


### [76] [Even Heads Fix Odd Errors: Mechanistic Discovery and Surgical Repair in Transformer Attention](https://arxiv.org/abs/2508.19414)
*Gustavo Sandoval*

Main category: cs.LG

TL;DR: 研究发现Llama模型中的格式依赖性推理失误由变压器不同注意头的特殊化引发，修复需特定数量的注意头，揭示了模型内部的细粒度子结构。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在格式依赖推理中的错误机制，并提高其修复效率。

Method: 通过系统干预、特征分析和机制剖析，揭示变压器中注意头的特殊化及其对推理性能的影响。

Result: 找到修复该错误的关键注意头配置，实现仅用部分注意头即达到完美修复，揭示了模型内部的复杂子结构。

Conclusion: 模型的推理错误由注意头特殊化引起，理解并利用其子结构可提升模型效率和解释性。

Abstract: We present a mechanistic case study of a format-dependent reasoning failure
in Llama-3.1-8B-Instruct, where the model incorrectly judges "9.11" as larger
than "9.8" in chat or Q&A formats, but answers correctly in simple format.
Through systematic intervention, we discover transformers implement even/odd
attention head specialization: even indexed heads handle numerical comparison,
while odd heads serve incompatible functions. The bug requires exactly 8 even
heads at Layer 10 for perfect repair. Any combination of 8+ even heads
succeeds, while 7 or fewer completely fails, revealing sharp computational
thresholds with perfect redundancy among the 16 even heads. SAE analysis
reveals the mechanism: format representations separate (10% feature overlap at
Layer 7), then re-entangle with different weightings (80% feature overlap at
Layer 10), with specific features showing 1.5x amplification in failing
formats. We achieve perfect repair using only 25% of attention heads and
identify a 60% pattern replacement threshold, demonstrating that apparent
full-module requirements hide sophisticated substructure with implications for
interpretability and efficiency. All of our code is available at
https://github.com/gussand/surgeon.

</details>


### [77] [Differentiable multiphase flow model for physics-informed machine learning in reservoir pressure management](https://arxiv.org/abs/2508.19419)
*Harun Ur Rashid,Aleksandra Pachalieva,Daniel O'Malley*

Main category: cs.LG

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Accurate subsurface reservoir pressure control is extremely challenging due
to geological heterogeneity and multiphase fluid-flow dynamics. Predicting
behavior in this setting relies on high-fidelity physics-based simulations that
are computationally expensive. Yet, the uncertain, heterogeneous properties
that control these flows make it necessary to perform many of these expensive
simulations, which is often prohibitive. To address these challenges, we
introduce a physics-informed machine learning workflow that couples a fully
differentiable multiphase flow simulator, which is implemented in the DPFEHM
framework with a convolutional neural network (CNN). The CNN learns to predict
fluid extraction rates from heterogeneous permeability fields to enforce
pressure limits at critical reservoir locations. By incorporating transient
multiphase flow physics into the training process, our method enables more
practical and accurate predictions for realistic injection-extraction scenarios
compare to previous works. To speed up training, we pretrain the model on
single-phase, steady-state simulations and then fine-tune it on full multiphase
scenarios, which dramatically reduces the computational cost. We demonstrate
that high-accuracy training can be achieved with fewer than three thousand
full-physics multiphase flow simulations -- compared to previous estimates
requiring up to ten million. This drastic reduction in the number of
simulations is achieved by leveraging transfer learning from much less
expensive single-phase simulations.

</details>


### [78] [MS-ConTab: Multi-Scale Contrastive Learning of Mutation Signatures for Pan Cancer Representation and Stratification](https://arxiv.org/abs/2508.19424)
*Yifan Dou,Adam Khadre,Ruben C Petreaca,Golrokh Mirzaei*

Main category: cs.LG

TL;DR: 提出了一种无监督对比学习框架，用于根据突变数据对43种癌症类型进行分组，结合基因和染色体的突变特征，效果与生物学意义一致。


<details>
  <summary>Details</summary>
Motivation: 理解泛癌突变景观揭示肿瘤发生的分子机制，但目前癌症亚型的分类多依赖传统统计方法，缺乏基于深度学习的全新方法。

Method: 采用对比学习，构建基因层面和染色体层面的突变签名，利用TabNet编码，通过多尺度对比优化学习癌症类型的统一嵌入。

Result: 获得的癌症类型潜在表示实现了具有生物学意义的聚类，符合已知的突变途径和组织起源。

Conclusion: 首次将对比学习应用于队列级癌症聚类，提供一种可扩展、可解释的突变驱动癌症亚型识别框架。

Abstract: Motivation. Understanding the pan-cancer mutational landscape offers critical
insights into the molecular mechanisms underlying tumorigenesis. While
patient-level machine learning techniques have been widely employed to identify
tumor subtypes, cohort-level clustering, where entire cancer types are grouped
based on shared molecular features, has largely relied on classical statistical
methods.
  Results. In this study, we introduce a novel unsupervised contrastive
learning framework to cluster 43 cancer types based on coding mutation data
derived from the COSMIC database. For each cancer type, we construct two
complementary mutation signatures: a gene-level profile capturing nucleotide
substitution patterns across the most frequently mutated genes, and a
chromosome-level profile representing normalized substitution frequencies
across chromosomes. These dual views are encoded using TabNet encoders and
optimized via a multi-scale contrastive learning objective (NT-Xent loss) to
learn unified cancer-type embeddings. We demonstrate that the resulting latent
representations yield biologically meaningful clusters of cancer types,
aligning with known mutational processes and tissue origins. Our work
represents the first application of contrastive learning to cohort-level cancer
clustering, offering a scalable and interpretable framework for mutation-driven
cancer subtyping.

</details>


### [79] [Data-Augmented Few-Shot Neural Stencil Emulation for System Identification of Computer Models](https://arxiv.org/abs/2508.19441)
*Sanket Jantre,Deepak Akhare,Xiaoning Qian,Nathan M. Urban*

Main category: cs.LG

TL;DR: 提出了一种基于空间填充采样的神经偏微分方程训练数据增强策略，提高了神经偏微分方程的训练效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 利用神经网络替代传统数值解算器以简化偏微分方程的求解，并解决数据样本不足的问题。

Method: 通过空间填充采样局部“stencil”状态，生成高效训练数据，减少轨迹冗余，并结合单一完整轨迹提高模型性能。

Result: 所提出的方法在多个偏微分方程系统中显著提升神经偏微分方程的表现，优于传统采样方法。

Conclusion: 空间填充采样策略有效提升神经偏微分方程的训练效率与准确性，为偏微分方程的神经网络方法提供了一种新思路。

Abstract: Partial differential equations (PDEs) underpin the modeling of many natural
and engineered systems. It can be convenient to express such models as neural
PDEs rather than using traditional numerical PDE solvers by replacing part or
all of the PDE's governing equations with a neural network representation.
Neural PDEs are often easier to differentiate, linearize, reduce, or use for
uncertainty quantification than the original numerical solver. They are usually
trained on solution trajectories obtained by long time integration of the PDE
solver. Here we propose a more sample-efficient data-augmentation strategy for
generating neural PDE training data from a computer model by space-filling
sampling of local "stencil" states. This approach removes a large degree of
spatiotemporal redundancy present in trajectory data and oversamples states
that may be rarely visited but help the neural PDE generalize across the state
space. We demonstrate that accurate neural PDE stencil operators can be learned
from synthetic training data generated by the computational equivalent of 10
timesteps' worth of numerical simulation. Accuracy is further improved if we
assume access to a single full-trajectory simulation from the computer model,
which is typically available in practice. Across several PDE systems, we show
that our data-augmented synthetic stencil data yield better trained neural
stencil operators, with clear performance gains compared with naively sampled
stencil data from simulation trajectories.

</details>


### [80] [Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization](https://arxiv.org/abs/2508.19443)
*Paimon Goulart,Shaan Pakala,Evangelos Papalexakis*

Main category: cs.LG

TL;DR: 引入张量分解技术以提升生成模型在多维数据生成中的效率，有望降低成本并保持数据质量。


<details>
  <summary>Details</summary>
Motivation: 生成复杂模拟数据成本高，急需更高效的生成方法。

Method: 在生成式模型中引入张量分解，生成较小的张量因子代替完整数据。

Result: 显著减少模型参数和输出成本，同时保持生成数据的实用性。

Conclusion: 张量分解有望增强生成模型在多维数据生成中的效率，降低成本。

Abstract: Producing large complex simulation datasets can often be a time and resource
consuming task. Especially when these experiments are very expensive, it is
becoming more reasonable to generate synthetic data for downstream tasks.
Recently, these methods may include using generative machine learning models
such as Generative Adversarial Networks or diffusion models. As these
generative models improve efficiency in producing useful data, we introduce an
internal tensor decomposition to these generative models to even further reduce
costs. More specifically, for multidimensional data, or tensors, we generate
the smaller tensor factors instead of the full tensor, in order to
significantly reduce the model's output and overall parameters. This reduces
the costs of generating complex simulation data, and our experiments show the
generated data remains useful. As a result, tensor decomposition has the
potential to improve efficiency in generative models, especially when
generating multidimensional data, or tensors.

</details>


### [81] [On Surjectivity of Neural Networks: Can you elicit any behavior from your model?](https://arxiv.org/abs/2508.19445)
*Haozhe Jiang,Nika Haghtalab*

Main category: cs.LG

TL;DR: 本文研究了现代神经网络的满射性，证明多种基础架构几乎总是满足满射性，揭示其在生成任意输出方面的潜在风险。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络的输出能力及其安全性问题，特别是拟合任何潜在输出的能力可能引发的安全风险。

Method: 分析现代神经网络的关键结构（如预层归一化和线性注意力模块）是否具备满射特性，并推导其在广泛生成模型中的应用影响。

Result: 多种主流神经网络结构几乎总是具有满射性，允许产生任意输出，包括潜在有害内容；同时推导出逆映射的可行性。

Conclusion: 对神经网络满射性特性进行形式化分析，揭示其不可避免的安全漏洞，为模型安全性研究提供理论基础。

Abstract: Given a trained neural network, can any specified output be generated by some
input? Equivalently, does the network correspond to a function that is
surjective? In generative models, surjectivity implies that any output,
including harmful or undesirable content, can in principle be generated by the
networks, raising concerns about model safety and jailbreak vulnerabilities. In
this paper, we prove that many fundamental building blocks of modern neural
architectures, such as networks with pre-layer normalization and
linear-attention modules, are almost always surjective. As corollaries, widely
used generative frameworks, including GPT-style transformers and diffusion
models with deterministic ODE solvers, admit inverse mappings for arbitrary
outputs. By studying surjectivity of these modern and commonly used neural
architectures, we contribute a formalism that sheds light on their unavoidable
vulnerability to a broad class of adversarial attacks.

</details>


### [82] [The Sample Complexity of Membership Inference and Privacy Auditing](https://arxiv.org/abs/2508.19458)
*Mahdi Haghifam,Adam Smith,Jonathan Ullman*

Main category: cs.LG

TL;DR: 研究了会员推断攻击所需的样本复杂度，发现在高斯均值估计中，攻击者可能需要远多于训练样本的参考样本来成功进行攻击。


<details>
  <summary>Details</summary>
Motivation: 理解会员推断攻击的样本需求，有助于评估和增强模型的隐私保护。

Method: 分析高斯均值估计中的样本复杂度，推导攻击所需的最小参考样本数。

Result: 证明在某些情况下，攻击者需要远多于训练样本的参考样本，影响实际攻击的效果和策略。

Conclusion: 现有攻击可能低估了潜在威胁，获取更多关于分布的信息可以增强攻击能力，从而提升隐私风险认知。

Abstract: A membership-inference attack gets the output of a learning algorithm, and a
target individual, and tries to determine whether this individual is a member
of the training data or an independent sample from the same distribution. A
successful membership-inference attack typically requires the attacker to have
some knowledge about the distribution that the training data was sampled from,
and this knowledge is often captured through a set of independent reference
samples from that distribution. In this work we study how much information the
attacker needs for membership inference by investigating the sample
complexity-the minimum number of reference samples required-for a successful
attack. We study this question in the fundamental setting of Gaussian mean
estimation where the learning algorithm is given $n$ samples from a Gaussian
distribution $\mathcal{N}(\mu,\Sigma)$ in $d$ dimensions, and tries to estimate
$\hat\mu$ up to some error $\mathbb{E}[\|\hat \mu - \mu\|^2_{\Sigma}]\leq
\rho^2 d$. Our result shows that for membership inference in this setting,
$\Omega(n + n^2 \rho^2)$ samples can be necessary to carry out any attack that
competes with a fully informed attacker. Our result is the first to show that
the attacker sometimes needs many more samples than the training algorithm uses
to train the model. This result has significant implications for practice, as
all attacks used in practice have a restricted form that uses $O(n)$ samples
and cannot benefit from $\omega(n)$ samples. Thus, these attacks may be
underestimating the possibility of membership inference, and better attacks may
be possible when information about the distribution is easy to obtain.

</details>


### [83] [Incentivized Lipschitz Bandits](https://arxiv.org/abs/2508.19466)
*Sourav Chakraborty,Amit Kiran Rege,Claire Monteleoni,Lijun Chen*

Main category: cs.LG

TL;DR: 本文提出了一种在连续空间中激励探索的多臂赌博机新算法，实现了低累积遗憾和低总补偿，适用于无限臂和上下文环境。


<details>
  <summary>Details</summary>
Motivation: 解决在连续空间中激励探索时的奖励偏差和优化问题。

Method: 通过离散化无限臂空间并设计新算法，同时分析遗憾和补偿界限。

Result: 算法充分发挥效果，获得亚线性遗憾与补偿界，适用于无穷臂和上下文带赌机。

Conclusion: 提出的算法在连续空间中的激励探索具有理论保证及实际潜力，可推广应用于更复杂场景。

Abstract: We study incentivized exploration in multi-armed bandit (MAB) settings with
infinitely many arms modeled as elements in continuous metric spaces. Unlike
classical bandit models, we consider scenarios where the decision-maker
(principal) incentivizes myopic agents to explore beyond their greedy choices
through compensation, but with the complication of reward drift--biased
feedback arising due to the incentives. We propose novel incentivized
exploration algorithms that discretize the infinite arm space uniformly and
demonstrate that these algorithms simultaneously achieve sublinear cumulative
regret and sublinear total compensation. Specifically, we derive regret and
compensation bounds of $\Tilde{O}(T^{d+1/d+2})$, with $d$ representing the
covering dimension of the metric space. Furthermore, we generalize our results
to contextual bandits, achieving comparable performance guarantees. We validate
our theoretical findings through numerical simulations.

</details>


### [84] [DeepAtlas: a tool for effective manifold learning](https://arxiv.org/abs/2508.19479)
*Serena Hughes,Timothy Hamilton,Tom Kolokotrones,Eric J. Deeds*

Main category: cs.LG

TL;DR: DeepAtlas通过局部嵌入和深度神经网络验证和学习数据的流形结构，识别数据集是否符合流形假设并确定其维度。


<details>
  <summary>Details</summary>
Motivation: 现有工具无法评估数据是否符合流形假设，也无法针对局部结构进行建模。

Method: 采用局部嵌入、深度学习和拓扑畸变检测的方法，验证和学习数据的流形结构。

Result: 成功识别多种测试数据的流形结构，发现许多实际数据不遵循流形假设。

Conclusion: DeepAtlas可以有效学习流形结构，为应用微分几何工具提供可能，揭示实际数据的复杂性。

Abstract: Manifold learning builds on the "manifold hypothesis," which posits that data
in high-dimensional datasets are drawn from lower-dimensional manifolds.
Current tools generate global embeddings of data, rather than the local maps
used to define manifolds mathematically. These tools also cannot assess whether
the manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas,
an algorithm that generates lower-dimensional representations of the data's
local neighborhoods, then trains deep neural networks that map between these
local embeddings and the original data. Topological distortion is used to
determine whether a dataset is drawn from a manifold and, if so, its
dimensionality. Application to test datasets indicates that DeepAtlas can
successfully learn manifold structures. Interestingly, many real datasets,
including single-cell RNA-sequencing, do not conform to the manifold
hypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a
model that can be used generatively and promises to allow the application of
powerful tools from differential geometry to a variety of datasets.

</details>


### [85] [Distribution Shift Aware Neural Tabular Learning](https://arxiv.org/abs/2508.19486)
*Wangyang Ying,Nanxu Gong,Dongjie Wang,Xinyuan Wang,Arun Vignesh Malarkkan,Vivek Gupta,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: SAFT提出了一种面向分布偏移的鲁棒特征转化框架，通过连续生成和多机制集成，显著提升在不同分布下的性能。


<details>
  <summary>Details</summary>
Motivation: 面对训练与测试数据分布偏移，传统表格学习方法表现不佳，亟需鲁棒的转化机制。

Method: 将离散特征搜索转变为连续生成，通过嵌入去相关、样本重加权、嵌入平均和分布对齐等机制，优化鲁棒特征。

Result: 实验证明SAFT在多种实际偏移场景下优于传统方法，展现优异的鲁棒性和泛化能力。

Conclusion: SAFT有效应对分布偏移，为表格学习提供了一种新颖的连续优化策略，增强了模型的稳健性和实用性。

Abstract: Tabular learning transforms raw features into optimized spaces for downstream
tasks, but its effectiveness deteriorates under distribution shifts between
training and testing data. We formalize this challenge as the Distribution
Shift Tabular Learning (DSTL) problem and propose a novel Shift-Aware Feature
Transformation (SAFT) framework to address it. SAFT reframes tabular learning
from a discrete search task into a continuous representation-generation
paradigm, enabling differentiable optimization over transformed feature sets.
SAFT integrates three mechanisms to ensure robustness: (i) shift-resistant
representation via embedding decorrelation and sample reweighting, (ii)
flatness-aware generation through suboptimal embedding averaging, and (iii)
normalization-based alignment between training and test distributions.
Extensive experiments show that SAFT consistently outperforms prior tabular
learning methods in terms of robustness, effectiveness, and generalization
ability under diverse real-world distribution shifts.

</details>


### [86] [Data-Efficient Symbolic Regression via Foundation Model Distillation](https://arxiv.org/abs/2508.19487)
*Wangyang Ying,Jinghan Zhang,Haoyue Bai,Nanxu Gong,Xinyuan Wang,Kunpeng Liu,Chandan K. Reddy,Yanjie Fu*

Main category: cs.LG

TL;DR: EQUATE通过符号-数值对齐和嵌入优化实现低数据量环境下的符号方程发现，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型在小数据集上表现差、负迁移的问题，提升符号回归的效率和准确性。

Method: 引入EQUATE框架，将离散方程搜索转化为嵌入空间的连续优化，通过符号-数值对齐与评估器引导的嵌入优化实现高效搜索。

Result: 在多个公共基准测试中，EQUATE在准确率、鲁棒性方面优于最新方法，且模型复杂度低、推理速度快。

Conclusion: EQUATE是一种实用且具有广泛推广性的符号回归方法，能在基础模型蒸馏中实现数据高效的方程发现。

Abstract: Discovering interpretable mathematical equations from observed data (a.k.a.
equation discovery or symbolic regression) is a cornerstone of scientific
discovery, enabling transparent modeling of physical, biological, and economic
systems. While foundation models pre-trained on large-scale equation datasets
offer a promising starting point, they often suffer from negative transfer and
poor generalization when applied to small, domain-specific datasets. In this
paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer
Embeddings), a data-efficient fine-tuning framework that adapts foundation
models for symbolic equation discovery in low-data regimes via distillation.
EQUATE combines symbolic-numeric alignment with evaluator-guided embedding
optimization, enabling a principled embedding-search-generation paradigm. Our
approach reformulates discrete equation search as a continuous optimization
task in a shared embedding space, guided by data-equation fitness and
simplicity. Experiments across three standard public benchmarks (Feynman,
Strogatz, and black-box datasets) demonstrate that EQUATE consistently
outperforms state-of-the-art baselines in both accuracy and robustness, while
preserving low complexity and fast inference. These results highlight EQUATE as
a practical and generalizable solution for data-efficient symbolic regression
in foundation model distillation settings.

</details>


### [87] [PoolFlip: A Multi-Agent Reinforcement Learning Security Environment for Cyber Defense](https://arxiv.org/abs/2508.19488)
*Xavier Cadet,Simona Boboila,Sie Hendrata Dharmawan,Alina Oprea,Peter Chin*

Main category: cs.LG

TL;DR: 提出了一种基于多智能体强化学习的攻击-防御模型，提升防御抗新型攻击的能力。


<details>
  <summary>Details</summary>
Motivation: 现有FlipIt框架在应对新型攻击时存在局限，需更具适应性的防御策略。

Method: 引入PoolFlip环境和Flip-PSRO算法，通过群体训练提升防御策略的泛化能力。

Result: Flip-PSRO防御者在面对未见过的攻击时，效果是传统方法的两倍，且保持高控制水平。

Conclusion: 多智能体强化学习结合新颖的工具和策略，可显著增强网络攻防模型的适应性和效果。

Abstract: Cyber defense requires automating defensive decision-making under stealthy,
deceptive, and continuously evolving adversarial strategies. The FlipIt game
provides a foundational framework for modeling interactions between a defender
and an advanced adversary that compromises a system without being immediately
detected. In FlipIt, the attacker and defender compete to control a shared
resource by performing a Flip action and paying a cost. However, the existing
FlipIt frameworks rely on a small number of heuristics or specialized learning
techniques, which can lead to brittleness and the inability to adapt to new
attacks. To address these limitations, we introduce PoolFlip, a multi-agent gym
environment that extends the FlipIt game to allow efficient learning for
attackers and defenders. Furthermore, we propose Flip-PSRO, a multi-agent
reinforcement learning (MARL) approach that leverages population-based training
to train defender agents equipped to generalize against a range of unknown,
potentially adaptive opponents. Our empirical results suggest that Flip-PSRO
defenders are $2\times$ more effective than baselines to generalize to a
heuristic attack not exposed in training. In addition, our newly designed
ownership-based utility functions ensure that Flip-PSRO defenders maintain a
high level of control while optimizing performance.

</details>


### [88] [Learning Game-Playing Agents with Generative Code Optimization](https://arxiv.org/abs/2508.19506)
*Zhiyi Kuang,Ryan Rong,YuCheng Yuan,Allen Nie*

Main category: cs.LG

TL;DR: 通过使用大语言模型优化以Python程序形式表示的游戏策略，实现高效、可自我改进的游戏代理。


<details>
  <summary>Details</summary>
Motivation: 开发高效、适应性强的游戏代理，解决深度强化学习耗时长、交互多的问题。

Method: 将决策策略作为自我演化的代码，利用LLMs在执行轨迹和自然语言反馈中自我优化。

Result: 在雅达利游戏上达到与深度强化学习相当的表现，训练时间少、环境交互少。

Conclusion: 程序化策略具有高效性、适应性，可实现复杂任务的长远推理，展现出引人注目的潜力。

Abstract: We present a generative optimization approach for learning game-playing
agents, where policies are represented as Python programs and refined using
large language models (LLMs). Our method treats decision-making policies as
self-evolving code, with current observation as input and an in-game action as
output, enabling agents to self-improve through execution traces and natural
language feedback with minimal human intervention. Applied to Atari games, our
game-playing Python program achieves performance competitive with deep
reinforcement learning (RL) baselines while using significantly less training
time and much fewer environment interactions. This work highlights the promise
of programmatic policy representations for building efficient, adaptable agents
capable of complex, long-horizon reasoning.

</details>


### [89] [MobText-SISA: Efficient Machine Unlearning for Mobility Logs with Spatio-Temporal and Natural-Language Data](https://arxiv.org/abs/2508.19554)
*Haruki Yonekura,Ren Ozeki,Tatsuya Amano,Hamada Rizk,Hirozumi Yamaguchi*

Main category: cs.LG

TL;DR: MobText-SISA是一个针对异构时空数据的机器遗忘框架，能在保证预测性能的同时，满足隐私删除需求。


<details>
  <summary>Details</summary>
Motivation: 面向现代出行平台，需支持用户隐私删除，传统重训练不可行。

Method: 引入共享潜在空间与相似性聚类，将样本分片，仅对受影响的分片进行重训练，结合增量训练与模型集成。

Result: 该方法在实际数据上表现出与基础模型相当的预测准确性，并优于随机分片方案，满足隐私法规要求。

Conclusion: MobText-SISA为城市规模多模态出行数据的隐私合规分析提供了实用的机器遗忘解决方案。

Abstract: Modern mobility platforms have stored vast streams of GPS trajectories,
temporal metadata, free-form textual notes, and other unstructured data.
Privacy statutes such as the GDPR require that any individual's contribution be
unlearned on demand, yet retraining deep models from scratch for every request
is untenable. We introduce MobText-SISA, a scalable machine-unlearning
framework that extends Sharded, Isolated, Sliced, and Aggregated (SISA)
training to heterogeneous spatio-temporal data. MobText-SISA first embeds each
trip's numerical and linguistic features into a shared latent space, then
employs similarity-aware clustering to distribute samples across shards so that
future deletions touch only a single constituent model while preserving
inter-shard diversity. Each shard is trained incrementally; at inference time,
constituent predictions are aggregated to yield the output. Deletion requests
trigger retraining solely of the affected shard from its last valid checkpoint,
guaranteeing exact unlearning. Experiments on a ten-month real-world mobility
log demonstrate that MobText-SISA (i) sustains baseline predictive accuracy,
and (ii) consistently outperforms random sharding in both error and convergence
speed. These results establish MobText-SISA as a practical foundation for
privacy-compliant analytics on multimodal mobility data at urban scale.

</details>


### [90] [Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting](https://arxiv.org/abs/2508.19563)
*Hejia Liu,Mochen Yang,Gediminas Adomavicius*

Main category: cs.LG

TL;DR: LLMs在数据拟合中存在对任务无关变化高度敏感的问题，影响其预测稳定性，即使是微小的变量名修改也会导致预测误差大幅波动。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在数据拟合中的鲁棒性问题，评估其对任务无关变化的敏感性。

Method: 通过分析LLMs的预测行为和注意力分布，结合实验证明任务无关变化对预测的影响，并分析TabPFN模型的鲁棒性。

Result: 发现LLMs对无关变化极为敏感，注意力分布不均导致这种敏感性，TabPFN模型虽针对数据拟合优化，但仍不免受影响。

Conclusion: 当前LLMs在作为数据拟合工具时缺乏基本鲁棒性，亟需提升其抗任务无关变化的能力。

Abstract: Large Language Models (LLMs) are being applied in a wide array of settings,
well beyond the typical language-oriented use cases. In particular, LLMs are
increasingly used as a plug-and-play method for fitting data and generating
predictions. Prior work has shown that LLMs, via in-context learning or
supervised fine-tuning, can perform competitively with many tabular supervised
learning techniques in terms of predictive performance. However, we identify a
critical vulnerability of using LLMs for data fitting -- making changes to data
representation that are completely irrelevant to the underlying learning task
can drastically alter LLMs' predictions on the same data. For example, simply
changing variable names can sway the size of prediction error by as much as 82%
in certain settings. Such prediction sensitivity with respect to
task-irrelevant variations manifests under both in-context learning and
supervised fine-tuning, for both close-weight and open-weight general-purpose
LLMs. Moreover, by examining the attention scores of an open-weight LLM, we
discover a non-uniform attention pattern: training examples and variable
names/values which happen to occupy certain positions in the prompt receive
more attention when output tokens are generated, even though different
positions are expected to receive roughly the same attention. This partially
explains the sensitivity in the presence of task-irrelevant variations. We also
consider a state-of-the-art tabular foundation model (TabPFN) trained
specifically for data fitting. Despite being explicitly designed to achieve
prediction robustness, TabPFN is still not immune to task-irrelevant
variations. Overall, despite LLMs' impressive predictive capabilities,
currently they lack even the basic level of robustness to be used as a
principled data-fitting tool.

</details>


### [91] [Bi-LoRA: Efficient Sharpness-Aware Minimization for Fine-Tuning Large-Scale Models](https://arxiv.org/abs/2508.19564)
*Yuhang Liu,Tao Li,Zhehao Huang,Zuopeng Yang,Xiaolin Huang*

Main category: cs.LG

TL;DR: 提出Bi-LoRA，通过引入辅助LoRA模块同时优化任务适应性和模型平滑性，有效提升大模型微调的泛化能力，且减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决在有限数据下微调大规模预训练模型时面临的泛化问题，以及SAM高成本限制。

Method: 将SAM与参数高效微调方法LoRA结合，设计双模块结构，辅助模块模拟对抗扰动，实现双向优化。

Result: 在多任务、多架构上验证了Bi-LoRA的效率和有效性，提升模型泛化性能。

Conclusion: Bi-LoRA创新性地兼顾鲁棒性与效率，推进大模型微调技术的发展。

Abstract: Fine-tuning large-scale pre-trained models with limited data presents
significant challenges for generalization. While Sharpness-Aware Minimization
(SAM) has proven effective in improving generalization by seeking flat minima,
its substantial extra memory and computation overhead make it impractical for
large models. Integrating SAM with parameter-efficient fine-tuning methods like
Low-Rank Adaptation (LoRA) is a promising direction. However, we find that
directly applying SAM to LoRA parameters limits the sharpness optimization to a
restricted subspace, hindering its effectiveness. To address this limitation,
we propose Bi-directional Low-Rank Adaptation (Bi-LoRA), which introduces an
auxiliary LoRA module to model SAM's adversarial weight perturbations. It
decouples SAM's weight perturbations from LoRA optimization: the primary LoRA
module adapts to specific tasks via standard gradient descent, while the
auxiliary module captures the sharpness of the loss landscape through gradient
ascent. Such dual-module design enables Bi-LoRA to capture broader sharpness
for achieving flatter minima while remaining memory-efficient. Another
important benefit is that the dual design allows for simultaneous optimization
and perturbation, eliminating SAM's doubled training costs. Extensive
experiments across diverse tasks and architectures demonstrate Bi-LoRA's
efficiency and effectiveness in enhancing generalization.

</details>


### [92] [Counterfactual Reward Model Training for Bias Mitigation in Multimodal Reinforcement Learning](https://arxiv.org/abs/2508.19567)
*Sheryl Mathew,N Harshit*

Main category: cs.LG

TL;DR: 提出一种结合因果推断的反事实奖励模型，有效减少多模态数据中的偏见，提高深度学习模型在虚假新闻检测中的公平性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决在强化学习中由于偏见引起的政策优化偏差和不公平问题，特别是在多模态数据场景中。

Method: 引入反事实奖励得分，通过因果推断和多模态表征学习，结合四个关键指标评估偏见和公平性，进行虚假新闻检测。

Result: 实现89.12%的虚假新闻检测准确率，优于基线模型，有效减少偏差与不公平的强化信号。

Conclusion: 提出的因果反事实奖励模型是一种鲁棒且具有可解释性的公平偏差控制方法，适用于动态、实时的策略制定环境。

Abstract: In reinforcement learning with human feedback (RLHF), reward models can
efficiently learn and amplify latent biases within multimodal datasets, which
can lead to imperfect policy optimization through flawed reward signals and
decreased fairness. Bias mitigation studies have often applied passive
constraints, which can fail under causal confounding. Here, we present a
counterfactual reward model that introduces causal inference with multimodal
representation learning to provide an unsupervised, bias-resilient reward
signal. The heart of our contribution is the Counterfactual Trust Score, an
aggregated score consisting of four components: (1) counterfactual shifts that
decompose political framing bias from topical bias; (2) reconstruction
uncertainty during counterfactual perturbations; (3) demonstrable violations of
fairness rules for each protected attribute; and (4) temporal reward shifts
aligned with dynamic trust measures. We evaluated the framework on a multimodal
fake versus true news dataset, which exhibits framing bias, class imbalance,
and distributional drift. Following methodologies similar to unsupervised drift
detection from representation-based distances [1] and temporal robustness
benchmarking in language models [2], we also inject synthetic bias across
sequential batches to test robustness. The resulting system achieved an
accuracy of 89.12% in fake news detection, outperforming the baseline reward
models. More importantly, it reduced spurious correlations and unfair
reinforcement signals. This pipeline outlines a robust and interpretable
approach to fairness-aware RLHF, offering tunable bias reduction thresholds and
increasing reliability in dynamic real-time policy making.

</details>


### [93] [Generative Models for Synthetic Data: Transforming Data Mining in the GenAI Era](https://arxiv.org/abs/2508.19570)
*Dawei Li,Yue Huang,Ming Li,Tianyi Zhou,Xiangliang Zhang,Huan Liu*

Main category: cs.LG

TL;DR: 介绍了生成模型在合成数据中的基础与最新进展，强调其在数据稀缺和隐私保护中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺、隐私和标注困难，推动数据挖掘技术的发展。

Method: 深入讲解生成模型的原理、方法和评估策略，覆盖LLMs、扩散模型和GANs等技术。

Result: 为研究者提供了利用生成合成数据提升数据挖掘的实用指南和实践框架。

Conclusion: 掌握生成模型的核心技术，有助于应对实际数据挑战，促进数据驱动的创新。

Abstract: Generative models such as Large Language Models, Diffusion Models, and
generative adversarial networks have recently revolutionized the creation of
synthetic data, offering scalable solutions to data scarcity, privacy, and
annotation challenges in data mining. This tutorial introduces the foundations
and latest advances in synthetic data generation, covers key methodologies and
practical frameworks, and discusses evaluation strategies and applications.
Attendees will gain actionable insights into leveraging generative synthetic
data to enhance data mining research and practice. More information can be
found on our website: https://syndata4dm.github.io/.

</details>


### [94] [Escaping Stability-Plasticity Dilemma in Online Continual Learning for Motion Forecasting via Synergetic Memory Rehearsal](https://arxiv.org/abs/2508.19571)
*Yunlong Lin,Chao Lu,Tongshuai Wu,Xiaocong Zhao,Guodong Du,Yanwei Sun,Zirui Li,Jianwei Gong*

Main category: cs.LG

TL;DR: 提出了一种结合稳定性与适应性的深度学习持续学习方法SyReM，有效缓解运动预测中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络在连续学习过程中出现的灾难性遗忘，同时保持学习能力。

Method: 引入记忆回顾机制，利用不等式约束保障记忆稳定性，采用基于梯度余弦相似度的样本选择提升学习塑性。

Result: 在11个驾驶场景数据集上，SyReM显著减少灾难性遗忘并提高预测精度，优于传统方法。

Conclusion: 通过稳健的记忆保持与针对性回顾策略，有效实现运动预测中的持续学习，具备实际应用潜力。

Abstract: Deep neural networks (DNN) have achieved remarkable success in motion
forecasting. However, most DNN-based methods suffer from catastrophic
forgetting and fail to maintain their performance in previously learned
scenarios after adapting to new data. Recent continual learning (CL) studies
aim to mitigate this phenomenon by enhancing memory stability of DNN, i.e., the
ability to retain learned knowledge. Yet, excessive emphasis on the memory
stability often impairs learning plasticity, i.e., the capacity of DNN to
acquire new information effectively. To address such stability-plasticity
dilemma, this study proposes a novel CL method, synergetic memory rehearsal
(SyReM), for DNN-based motion forecasting. SyReM maintains a compact memory
buffer to represent learned knowledge. To ensure memory stability, it employs
an inequality constraint that limits increments in the average loss over the
memory buffer. Synergistically, a selective memory rehearsal mechanism is
designed to enhance learning plasticity by selecting samples from the memory
buffer that are most similar to recently observed data. This selection is based
on an online-measured cosine similarity of loss gradients, ensuring targeted
memory rehearsal. Since replayed samples originate from learned scenarios, this
memory rehearsal mechanism avoids compromising memory stability. We validate
SyReM under an online CL paradigm where training samples from diverse scenarios
arrive as a one-pass stream. Experiments on 11 naturalistic driving datasets
from INTERACTION demonstrate that, compared to non-CL and CL baselines, SyReM
significantly mitigates catastrophic forgetting in past scenarios while
improving forecasting accuracy in new ones. The implementation is publicly
available at https://github.com/BIT-Jack/SyReM.

</details>


### [95] [Delta-Audit: Explaining What Changes When Models Change](https://arxiv.org/abs/2508.19589)
*Arshia Hemmat,Afsaneh Fatemi*

Main category: cs.LG

TL;DR: 引入Δ-Attribution框架，用于解释模型版本更新带来的特征贡献变化。


<details>
  <summary>Details</summary>
Motivation: 模型更新影响性能，但变更原因不透明。需要理解版本间差异。

Method: 基于特征归因差异，设计Δ-Attribution，结合多指标评估变化质量。

Result: 发现不同类型的模型调整导致不同程度和性质的变化，Δ-Attribution能有效区分有意义的变化与无害的调整。

Conclusion: Δ-Attribution提供一种轻量级的模型更新审核工具，有助于理解模型行为变化。

Abstract: Model updates (new hyperparameters, kernels, depths, solvers, or data) change
performance, but the \emph{reason} often remains opaque. We introduce
\textbf{Delta-Attribution} (\mbox{$\Delta$-Attribution}), a model-agnostic
framework that explains \emph{what changed} between versions $A$ and $B$ by
differencing per-feature attributions: $\Delta\phi(x)=\phi_B(x)-\phi_A(x)$. We
evaluate $\Delta\phi$ with a \emph{$\Delta$-Attribution Quality Suite} covering
magnitude/sparsity (L1, Top-$k$, entropy), agreement/shift (rank-overlap@10,
Jensen--Shannon divergence), behavioural alignment (Delta Conservation Error,
DCE; Behaviour--Attribution Coupling, BAC; CO$\Delta$F), and robustness (noise,
baseline sensitivity, grouped occlusion).
  Instantiated via fast occlusion/clamping in standardized space with a
class-anchored margin and baseline averaging, we audit 45 settings: five
classical families (Logistic Regression, SVC, Random Forests, Gradient
Boosting, $k$NN), three datasets (Breast Cancer, Wine, Digits), and three A/B
pairs per family. \textbf{Findings.} Inductive-bias changes yield large,
behaviour-aligned deltas (e.g., SVC poly$\!\rightarrow$rbf on Breast Cancer:
BAC$\approx$0.998, DCE$\approx$6.6; Random Forest feature-rule swap on Digits:
BAC$\approx$0.997, DCE$\approx$7.5), while ``cosmetic'' tweaks (SVC
\texttt{gamma=scale} vs.\ \texttt{auto}, $k$NN search) show
rank-overlap@10$=1.0$ and DCE$\approx$0. The largest redistribution appears for
deeper GB on Breast Cancer (JSD$\approx$0.357). $\Delta$-Attribution offers a
lightweight update audit that complements accuracy by distinguishing benign
changes from behaviourally meaningful or risky reliance shifts.

</details>


### [96] [Complementary Learning System Empowers Online Continual Learning of Vehicle Motion Forecasting in Smart Cities](https://arxiv.org/abs/2508.19597)
*Zirui Li,Yunlong Lin,Guodong Du,Xiaocong Zhao,Cheng Gong,Chen Lv,Chao Lu,Jianwei Gong*

Main category: cs.LG

TL;DR: Dual-LS通过模仿人脑的互补学习体系，提高深度神经网络在车辆运动预测中的持续学习能力，有效缓解灾难性遗忘问题，减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 当前深度神经网络在车辆运动预测中存在灾难性遗忘问题，影响模型在智能城市中的持续适应能力，亟需有效的持续学习解决方案。

Method: 引入Dual-LS方案，结合两个协作的记忆复现机制，动态协调长短期知识，实现在线无任务学习。

Result: 在多国、多车辆和长距离测试中，Dual-LS使灾难性遗忘减少了74.31%，计算资源降低94.02%，提升了预测的稳定性和持续学习能力。

Conclusion: Dual-LS模仿人脑的互补学习体系，有效促进深度神经网络在车辆运动预测中的持续学习，为智能城市提供高效、稳定的预测模型。

Abstract: Artificial intelligence underpins most smart city services, yet deep neural
network (DNN) that forecasts vehicle motion still struggle with catastrophic
forgetting, the loss of earlier knowledge when models are updated. Conventional
fixes enlarge the training set or replay past data, but these strategies incur
high data collection costs, sample inefficiently and fail to balance long- and
short-term experience, leaving them short of human-like continual learning.
Here we introduce Dual-LS, a task-free, online continual learning paradigm for
DNN-based motion forecasting that is inspired by the complementary learning
system of the human brain. Dual-LS pairs two synergistic memory rehearsal
replay mechanisms to accelerate experience retrieval while dynamically
coordinating long-term and short-term knowledge representations. Tests on
naturalistic data spanning three countries, over 772,000 vehicles and
cumulative testing mileage of 11,187 km show that Dual-LS mitigates
catastrophic forgetting by up to 74.31\% and reduces computational resource
demand by up to 94.02\%, markedly boosting predictive stability in vehicle
motion forecasting without inflating data requirements. Meanwhile, it endows
DNN-based vehicle motion forecasting with computation efficient and human-like
continual learning adaptability fit for smart cities.

</details>


### [97] [Encouraging Good Processes Without the Need for Good Answers: Reinforcement Learning for LLM Agent Planning](https://arxiv.org/abs/2508.19598)
*Zhiwei Li,Yong Hu,Wenqing Wang*

Main category: cs.LG

TL;DR: 提出RLTR框架，通过奖励工具使用完整性单目标训练LLM的规划能力，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决多目标训练下规划能力不足及数据稀缺问题。

Method: 引入工具使用奖励，解耦训练流程，专注提升规划模块。

Result: 规划性能提升8-12%，整体响应质量提升5-6%。

Conclusion: RLTR有效改善LLM规划能力，增强系统表现，提供可靠训练信号。

Abstract: The functionality of Large Language Model (LLM) agents is primarily
determined by two capabilities: action planning and answer summarization. The
former, action planning, is the core capability that dictates an agent's
performance. However, prevailing training paradigms employ end-to-end,
multi-objective optimization that jointly trains both capabilities. This
paradigm faces two critical challenges: imbalanced optimization objective
allocation and scarcity of verifiable data, making it difficult to enhance the
agent's planning capability. To address these challenges, we propose
Reinforcement Learning with Tool-use Rewards (RLTR), a novel framework that
decouples the training process to enable a focused, single-objective
optimization of the planning module. Crucially, RLTR introduces a reward signal
based on tool-use completeness to directly evaluate the quality of tool
invocation sequences. This method offers a more direct and reliable training
signal than assessing the final response content, thereby obviating the need
for verifiable data. Our experiments demonstrate that RLTR achieves an 8%-12%
improvement in planning performance compared to end-to-end baselines. Moreover,
this enhanced planning capability, in turn, translates to a 5%-6% increase in
the final response quality of the overall agent system.

</details>


### [98] [FinCast: A Foundation Model for Financial Time-Series Forecasting](https://arxiv.org/abs/2508.19609)
*Zhuohang Zhu,Haodong Chen,Qiang Qu,Vera Chung*

Main category: cs.LG

TL;DR: 提出了一款专为金融时间序列预测设计的基础模型FinCast，具有良好的零-shot泛化性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列预测面临分布变化、多领域差异和不同时间粒度的挑战，现有深度学习方法难以充分泛化且需大量微调。

Method: 构建并训练了基于大规模金融数据的基础模型FinCast，强调零-shot性能。

Result: FinCast在各种评价中超越了现有最先进方法，证明其优越的泛化能力。

Conclusion: FinCast代表了金融时间序列预测的新时代，具备广泛应用潜力。

Abstract: Financial time-series forecasting is critical for maintaining economic
stability, guiding informed policymaking, and promoting sustainable investment
practices. However, it remains challenging due to various underlying pattern
shifts. These shifts arise primarily from three sources: temporal
non-stationarity (distribution changes over time), multi-domain diversity
(distinct patterns across financial domains such as stocks, commodities, and
futures), and varying temporal resolutions (patterns differing across
per-second, hourly, daily, or weekly indicators). While recent deep learning
methods attempt to address these complexities, they frequently suffer from
overfitting and typically require extensive domain-specific fine-tuning. To
overcome these limitations, we introduce FinCast, the first foundation model
specifically designed for financial time-series forecasting, trained on
large-scale financial datasets. Remarkably, FinCast exhibits robust zero-shot
performance, effectively capturing diverse patterns without domain-specific
fine-tuning. Comprehensive empirical and qualitative evaluations demonstrate
that FinCast surpasses existing state-of-the-art methods, highlighting its
strong generalization capabilities.

</details>


### [99] [ALSA: Anchors in Logit Space for Out-of-Distribution Accuracy Estimation](https://arxiv.org/abs/2508.19613)
*Chenzhi Liu,Mahsa Baktashmotlagh,Yanran Tang,Zi Huang,Ruihong Qiu*

Main category: cs.LG

TL;DR: ALSA在对未见、未标记数据进行模型性能估计方面表现优越，通过直接在logit空间操作，保持更多信息，优于传统的softmax和相似性方法。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，尤其是在分布偏移情况下，准确估计模型在未标记数据上的性能至关重要。现有方法存在信息损失或计算复杂度高的问题。

Method: 引入ALSA框架，在logit空间中操作，利用多个可学习的锚点和影响函数捕捉logit细节，以提升性能估计的准确性和鲁棒性。

Result: ALSA在视觉、语言、图任务上超越软max和相似性基线，显著增强在分布偏移下的鲁棒性，展示了其作为可靠模型评估工具的潜力。

Conclusion: ALSA通过直接在logit空间操作，成功缓解信息损失问题，提供更准确、稳健的性能估计，适用于实际复杂场景。

Abstract: Estimating model accuracy on unseen, unlabeled datasets is crucial for
real-world machine learning applications, especially under distribution shifts
that can degrade performance. Existing methods often rely on predicted class
probabilities (softmax scores) or data similarity metrics. While softmax-based
approaches benefit from representing predictions on the standard simplex,
compressing logits into probabilities leads to information loss. Meanwhile,
similarity-based methods can be computationally expensive and domain-specific,
limiting their broader applicability. In this paper, we introduce ALSA (Anchors
in Logit Space for Accuracy estimation), a novel framework that preserves
richer information by operating directly in the logit space. Building on
theoretical insights and empirical observations, we demonstrate that the
aggregation and distribution of logits exhibit a strong correlation with the
predictive performance of the model. To exploit this property, ALSA employs an
anchor-based modeling strategy: multiple learnable anchors are initialized in
logit space, each assigned an influence function that captures subtle
variations in the logits. This allows ALSA to provide robust and accurate
performance estimates across a wide range of distribution shifts. Extensive
experiments on vision, language, and graph benchmarks demonstrate ALSA's
superiority over both softmax- and similarity-based baselines. Notably, ALSA's
robustness under significant distribution shifts highlights its potential as a
practical tool for reliable model evaluation.

</details>


### [100] [Towards Instance-wise Personalized Federated Learning via Semi-Implicit Bayesian Prompt Tuning](https://arxiv.org/abs/2508.19621)
*Tiandi Ye,Wenyan Liu,Kai Yao,Lichun Li,Shangchao Su,Cen Chen,Xiang Li,Shan Yin,Ming Gao*

Main category: cs.LG

TL;DR: 提出一种基于贝叶斯视角的实例级个性化联邦学习框架pFedBayesPT，有效应对多源多域数据异质性。


<details>
  <summary>Details</summary>
Motivation: 现有pFL假设每个客户端数据仅来自单一分布，难以应对数据存在多源多域的真实场景，导致性能受限。

Method: 引入视觉提示微调，从贝叶斯角度建模提示后验分布，通过变分推断优化，达到实例级个性化。

Result: 在多个基准数据集上实验，pFedBayesPT优于现有方法，尤其在特征和标签异质性条件下表现优异。

Conclusion: 提出的pFedBayesPT框架有效应对客户端多源多域数据异质性，提升联邦学习的适应性和性能。

Abstract: Federated learning (FL) is a privacy-preserving machine learning paradigm
that enables collaborative model training across multiple distributed clients
without disclosing their raw data. Personalized federated learning (pFL) has
gained increasing attention for its ability to address data heterogeneity.
However, most existing pFL methods assume that each client's data follows a
single distribution and learn one client-level personalized model for each
client. This assumption often fails in practice, where a single client may
possess data from multiple sources or domains, resulting in significant
intra-client heterogeneity and suboptimal performance. To tackle this
challenge, we propose pFedBayesPT, a fine-grained instance-wise pFL framework
based on visual prompt tuning. Specifically, we formulate instance-wise prompt
generation from a Bayesian perspective and model the prompt posterior as an
implicit distribution to capture diverse visual semantics. We derive a
variational training objective under the semi-implicit variational inference
framework. Extensive experiments on benchmark datasets demonstrate that
pFedBayesPT consistently outperforms existing pFL methods under both feature
and label heterogeneity settings.

</details>


### [101] [SCAR: A Characterization Scheme for Multi-Modal Dataset](https://arxiv.org/abs/2508.19659)
*Ri Su,Zhao Chen,Caleb Chen Cao,Nan Tang,Lei Chen*

Main category: cs.LG

TL;DR: 本文提出SCAR框架，用于量化数据集的结构特性，以提升基础模型的泛化表现和数据利用效率。


<details>
  <summary>Details</summary>
Motivation: 理解数据特性对模型泛化的影响，优化数据采样与扩展策略。

Method: 提出SCAR指标，模型单模态任务为阶梯函数，构建基于该指标的数据扩展策略。

Result: 验证SCAR在多模态、多模型条件下的能量预测和数据扩展中的效果，提升数据利用率。

Conclusion: SCAR为数据理解和多模态数据处理提供了系统的理论基础和实践工具。

Abstract: Foundation models exhibit remarkable generalization across diverse tasks,
largely driven by the characteristics of their training data. Recent
data-centric methods like pruning and compression aim to optimize training but
offer limited theoretical insight into how data properties affect
generalization, especially the data characteristics in sample scaling.
Traditional perspectives further constrain progress by focusing predominantly
on data quantity and training efficiency, often overlooking structural aspects
of data quality. In this study, we introduce SCAR, a principled scheme for
characterizing the intrinsic structural properties of datasets across four key
measures: Scale, Coverage, Authenticity, and Richness. Unlike prior
data-centric measures, SCAR captures stable characteristics that remain
invariant under dataset scaling, providing a robust and general foundation for
data understanding. Leveraging these structural properties, we introduce
Foundation Data-a minimal subset that preserves the generalization behavior of
the full dataset without requiring model-specific retraining. We model
single-modality tasks as step functions and estimate the distribution of the
foundation data size to capture step-wise generalization bias across modalities
in the target multi-modal dataset. Finally, we develop a SCAR-guided data
completion strategy based on this generalization bias, which enables efficient,
modality-aware expansion of modality-specific characteristics in multimodal
datasets. Experiments across diverse multi-modal datasets and model
architectures validate the effectiveness of SCAR in predicting data utility and
guiding data acquisition. Code is available at https://github.com/McAloma/SCAR.

</details>


### [102] [Exploration of Low-Power Flexible Stress Monitoring Classifiers for Conformal Wearables](https://arxiv.org/abs/2508.19661)
*Florentia Afentaki,Sri Sai Rakesh Nakkilla,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Shiyi Jiang,Georgios Zervakis,Farshad Firouzi,Krishnendu Chakrabarty,Mehdi B. Tahoori*

Main category: cs.LG

TL;DR: 本文提出一种低功耗、柔性应激分类器的设计空间探索，结合多种机器学习模型与电路优化，实现在柔性电子中的实时压力监测，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有压力监测多依赖 episodic 方式，缺乏持续、便携和成本效益的解决方案；刚性穿戴设备不适合连续监测。

Method: 探索不同的机器学习分类器、特征选择与神经网络简化算法，在柔性电子上进行电路设计优化，提供超过1200个柔性分类器的硬件实现方案。

Result: 实现了在低功耗、柔性和低成本条件下，准确率优于现有压力监测技术的实时压力分类器。

Conclusion: 该工作为柔性电子中实时压力监测提供了有效的硬件设计方案，推动了可穿戴压力监控的应用前景。

Abstract: Conventional stress monitoring relies on episodic, symptom-focused
interventions, missing the need for continuous, accessible, and cost-efficient
solutions. State-of-the-art approaches use rigid, silicon-based wearables,
which, though capable of multitasking, are not optimized for lightweight,
flexible wear, limiting their practicality for continuous monitoring. In
contrast, flexible electronics (FE) offer flexibility and low manufacturing
costs, enabling real-time stress monitoring circuits. However, implementing
complex circuits like machine learning (ML) classifiers in FE is challenging
due to integration and power constraints. Previous research has explored
flexible biosensors and ADCs, but classifier design for stress detection
remains underexplored. This work presents the first comprehensive design space
exploration of low-power, flexible stress classifiers. We cover various ML
classifiers, feature selection, and neural simplification algorithms, with over
1200 flexible classifiers. To optimize hardware efficiency, fully customized
circuits with low-precision arithmetic are designed in each case. Our
exploration provides insights into designing real-time stress classifiers that
offer higher accuracy than current methods, while being low-cost, conformable,
and ensuring low power and compact size.

</details>


### [103] [$\mathcal{C}^1$-approximation with rational functions and rational neural networks](https://arxiv.org/abs/2508.19672)
*Erion Morina,Martin Holler*

Main category: cs.LG

TL;DR: 可以用有理函数和有理神经网络在$	ext{C}^1$范数下逼近光滑函数，且有具体的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 提升对光滑函数的逼近能力，尤其在符号回归和物理定律学习中具有重要应用价值。

Method: 研究有理函数和有理神经网络在$	ext{C}^1$范数下的逼近能力，分析宽度、深度及有理函数的次数对逼近率的影响。

Result: 证明了在$	ext{C}^1$范数中，有理函数和有理神经网络可以有效逼近光滑函数，且给出了逼近速率。同时，拓展到EQL$^	ext{div}$和ParFam架构的神经网络，强调其在符号回归中的应用潜力。

Conclusion: 有理函数和特定结构的神经网络具有强大的逼近能力，为符号回归和物理定律学习提供理论基础。

Abstract: We show that suitably regular functions can be approximated in the
$\mathcal{C}^1$-norm both with rational functions and rational neural networks,
including approximation rates with respect to width and depth of the network,
and degree of the rational functions. As consequence of our results, we further
obtain $\mathcal{C}^1$-approximation results for rational neural networks with
the $\text{EQL}^\div$ and ParFam architecture, both of which are important in
particular in the context of symbolic regression for physical law learning.

</details>


### [104] [Metric spaces of walks and Lipschitz duality on graphs](https://arxiv.org/abs/2508.19709)
*R. Arnau,A. González Cortés,E. A. Sánchez Pérez,S. Sanjuan*

Main category: cs.LG

TL;DR: 本文研究图上的路径的度量结构，引入加权指标定义路径间距离，分析其基本性质，并探讨其在测量路径相似性和强化学习中的潜在应用。


<details>
  <summary>Details</summary>
Motivation: 理解和量化图中路径的相似性，支持相关的机器学习和网络分析方法。

Method: 引入加权指标测度路径间距离，分析指标空间的性质，提供不同假设下的相似性表达式和构造。

Result: 建立了路径之间距离的度量框架，允许应用经典的度量工具，促进路径相似性估算和学习策略开发。

Conclusion: 该框架为路径相似性测量和网络中的机器学习方法提供了坚实基础，具有广泛应用潜力。

Abstract: We study the metric structure of walks on graphs, understood as Lipschitz
sequences. To this end, a weighted metric is introduced to handle sequences,
enabling the definition of distances between walks based on stepwise vertex
distances and weighted norms. We analyze the main properties of these metric
spaces, which provides the foundation for the analysis of weaker forms of
instruments to measure relative distances between walks: proximities. We
provide some representation formulas for such proximities under different
assumptions and provide explicit constructions for these cases. The resulting
metric framework allows the use of classical tools from metric modeling, such
as the extension of Lipschitz functions from subspaces of walks, which permits
extending proximity functions while preserving fundamental properties via the
mentioned representations. Potential applications include the estimation of
proximities and the development of reinforcement learning strategies based on
exploratory walks, offering a robust approach to Lipschitz regression on
network structures.

</details>


### [105] [Tune My Adam, Please!](https://arxiv.org/abs/2508.19733)
*Theodoros Athanasiadis,Steven Adriaensen,Samuel Müller,Frank Hutter*

Main category: cs.LG

TL;DR: 提出Adam-PFN，通过预训练和曲线增强，加速Adam超参数调优，提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: Adam优化器广泛使用，但超参数调优耗时耗力，缺乏有效低成本的优化方法。

Method: 引入Adam-PFN作为代理模型，结合CDF-augment增强学习曲线，改进冻结-融化贝叶斯优化。

Result: 在TaskSet评估任务中，提升了学习曲线预测和调优速度，对分布外任务表现优异。

Conclusion: 所提方法有效提升Adam超参数调优的效率和泛化性，为低成本超参数优化提供新思路。

Abstract: The Adam optimizer remains one of the most widely used optimizers in deep
learning, and effectively tuning its hyperparameters is key to optimizing
performance. However, tuning can be tedious and costly. Freeze-thaw Bayesian
Optimization (BO) is a recent promising approach for low-budget hyperparameter
tuning, but is limited by generic surrogates without prior knowledge of how
hyperparameters affect learning. We propose Adam-PFN, a new surrogate model for
Freeze-thaw BO of Adam's hyperparameters, pre-trained on learning curves from
TaskSet, together with a new learning curve augmentation method, CDF-augment,
which artificially increases the number of available training examples. Our
approach improves both learning curve extrapolation and accelerates
hyperparameter optimization on TaskSet evaluation tasks, with strong
performance on out-of-distribution (OOD) tasks.

</details>


### [106] [InfraredGP: Efficient Graph Partitioning via Spectral Graph Neural Networks with Negative Corrections](https://arxiv.org/abs/2508.19737)
*Meng Qin,Weihua Li,Jinqiang Cui,Sen Pei*

Main category: cs.LG

TL;DR: InfraredGP通过引入负修正机制扩展图拉普拉斯变换的频率范围，实现无训练的图分区，兼具效率与效果。


<details>
  <summary>Details</summary>
Motivation: 探索低频信息在社区检测中的潜在价值，利用图信号处理的频率扩展提高社区结构识别能力。

Method: 结合谱GNN与负修正机制，仅通过一次前馈传播获得图嵌入，无需训练，并利用BIRCH进行分区。

Result: InfraredGP表现出优异的分区质量与效率，超越多种基线，适用于静态和流式图情境。

Conclusion: 负修正机制能有效挖掘频谱外低频信息，实现无训练高效社区检测。

Abstract: Graph partitioning (GP), a.k.a. community detection, is a classic problem
that divides nodes of a graph into densely-connected blocks. From a perspective
of graph signal processing, we find that graph Laplacian with a negative
correction can derive graph frequencies beyond the conventional range $[0, 2]$.
To explore whether the low-frequency information beyond this range can encode
more informative properties about community structures, we propose InfraredGP.
It (\romannumeral1) adopts a spectral GNN as its backbone combined with
low-pass filters and a negative correction mechanism, (\romannumeral2) only
feeds random inputs to this backbone, (\romannumeral3) derives graph embeddings
via one feed-forward propagation (FFP) without any training, and
(\romannumeral4) obtains feasible GP results by feeding the derived embeddings
to BIRCH. Surprisingly, our experiments demonstrate that based solely on the
negative correction mechanism that amplifies low-frequency information beyond
$[0, 2]$, InfraredGP can derive distinguishable embeddings for some standard
clustering modules (e.g., BIRCH) and obtain high-quality results for GP without
any training. Following the IEEE HPEC Graph Challenge benchmark, we evaluate
InfraredGP for both static and streaming GP, where InfraredGP can achieve much
better efficiency (e.g., 16x-23x faster) and competitive quality over various
baselines. We have made our code public at
https://github.com/KuroginQin/InfraredGP

</details>


### [107] [Fast 3D Diffusion for Scalable Granular Media Synthesis](https://arxiv.org/abs/2508.19752)
*Muhammad Moeeze Hassan,Régis Cottereau,Filippo Gatti,Patryk Dec*

Main category: cs.LG

TL;DR: 提出一种基于3D扩散模型的生成管道，用于高效、逼真地模拟颗粒介质，大幅提升模拟速度。


<details>
  <summary>Details</summary>
Motivation: 模拟颗粒介质的离散元法计算耗时较长，尤其在初始化阶段。

Method: 采用两阶段的3D生成模型：首先训练扩散模型生成颗粒体的三维体素网格，然后利用3D修补模型将多块网格无缝拼接。

Result: 实现了线性缩放的模拟时间，快速生成大规模颗粒结构，如1.2米轨道的模拟在20秒内完成，显著加快了模拟速度，且逼真符合物理结构。

Conclusion: 基于3D扩散与修补的生成方法有效解决了颗粒模拟中的时间瓶颈，适用于工业应用中的实时模拟需求。

Abstract: Simulating granular media, using Discrete Element Method is a computationally
intensive task. This is especially true during initialization phase, which
dominates total simulation time because of large displacements involved and
associated kinetic energy. We overcome this bottleneck with a novel generative
pipeline based on 3D diffusion models that directly synthesizes arbitrarily
large granular assemblies in their final and physically realistic
configurations. The approach frames the problem as a 3D generative modeling
task, consisting of a two-stage pipeline. First a diffusion model is trained to
generate independent 3D voxel grids representing granular media. Second, a 3D
inpainting model, adapted from 2D inpainting techniques using masked inputs,
stitches these grids together seamlessly, enabling synthesis of large samples
with physically realistic structure. The inpainting model explores several
masking strategies for the inputs to the underlying UNets by training the
network to infer missing portions of voxel grids from a concatenation of noised
tensors, masks, and masked tensors as input channels. The model also adapts a
2D repainting technique of re-injecting noise scheduler output with ground
truth to provide a strong guidance to the 3D model. This along with weighted
losses ensures long-term coherence over generation of masked regions. Both
models are trained on the same binarized 3D occupancy grids extracted from
small-scale DEM simulations, achieving linear scaling of computational time
with respect to sample size. Quantitatively, a 1.2 m long ballasted rail track
synthesis equivalent to a 3-hour DEM simulation, was completed under 20
seconds. The generated voxel grids can also be post-processed to extract grain
geometries for DEM-compatibility as well, enabling physically coherent,
real-time, scalable granular media synthesis for industrial applications.

</details>


### [108] [Interestingness First Classifiers](https://arxiv.org/abs/2508.19780)
*Ryoma Sato*

Main category: cs.LG

TL;DR: 提出了一种名为EUREKA的框架，旨在构建具有新颖性和可解释性，但效率低于最优模型的分类器。该方法通过大语言模型评估特征的趣味性，从而识别非直观但具有预测价值的特征，促进新型知识发现。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型偏向最大化预测准确性，忽视了模型的趣味性与可解释性，激发探索更具新颖性和启发性的分类方式。

Method: 使用大语言模型对特征进行趣味性排序，然后仅基于所选趣味性特征建立可解释的分类模型。

Result: 在多个数据集上，该方法优先选取非直观且具有预测能力的特征，能提供有意义的洞察。例如，在占用检测数据集中偏好湿度而非二氧化碳浓度，在论文引用预测中发现标题有冒号的论文更易被引用。

Conclusion: EUREKA促进了不同寻常特征的发现，支持新颖的知识探索和交流，特别适合追求趣味性和解释性的场景。

Abstract: Most machine learning models are designed to maximize predictive accuracy. In
this work, we explore a different goal: building classifiers that are
interesting. An ``interesting classifier'' is one that uses unusual or
unexpected features, even if its accuracy is lower than the best possible
model. For example, predicting room congestion from CO2 levels achieves
near-perfect accuracy but is unsurprising. In contrast, predicting room
congestion from humidity is less accurate yet more nuanced and intriguing. We
introduce EUREKA, a simple framework that selects features according to their
perceived interestingness. Our method leverages large language models to rank
features by their interestingness and then builds interpretable classifiers
using only the selected interesting features. Across several benchmark
datasets, EUREKA consistently identifies features that are non-obvious yet
still predictive. For example, in the Occupancy Detection dataset, our method
favors humidity over CO2 levels and light intensity, producing classifiers that
achieve meaningful accuracy while offering insights. In the Twin Papers
dataset, our method discovers the rule that papers with a colon in the title
are more likely to be cited in the future. We argue that such models can
support new ways of knowledge discovery and communication, especially in
settings where moderate accuracy is sufficient but novelty and interpretability
are valued.

</details>


### [109] [PSO-Merging: Merging Models Based on Particle Swarm Optimization](https://arxiv.org/abs/2508.19839)
*Kehao Zhang,Shaolei Zhang,Yang Feng*

Main category: cs.LG

TL;DR: 提出了一种基于粒子群优化的模型融合新方法，显著优于现有方法，提升多任务模型构建效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据驱动模型融合在性能和计算效率上的局限性。

Method: 利用粒子群优化在预训练模型和专家模型基础上进行多轮优化，最终得到融合模型。

Result: 在多种语言模型实验中，PSO-Merging优于基线方法，展现出更高的效率和可扩展性。

Conclusion: 粒子群优化为模型融合提供了一种高效、实用的新途径，有助于多任务模型的快速构建。

Abstract: Model merging has emerged as an efficient strategy for constructing multitask
models by integrating the strengths of multiple available expert models,
thereby reducing the need to fine-tune a pre-trained model for all the tasks
from scratch. Existing data-independent methods struggle with performance
limitations due to the lack of data-driven guidance. Data-driven approaches
also face key challenges: gradient-based methods are computationally expensive,
limiting their practicality for merging large expert models, whereas existing
gradient-free methods often fail to achieve satisfactory results within a
limited number of optimization steps. To address these limitations, this paper
introduces PSO-Merging, a novel data-driven merging method based on the
Particle Swarm Optimization (PSO). In this approach, we initialize the particle
swarm with a pre-trained model, expert models, and sparsified expert models. We
then perform multiple iterations, with the final global best particle serving
as the merged model. Experimental results on different language models show
that PSO-Merging generally outperforms baseline merging methods, offering a
more efficient and scalable solution for model merging.

</details>


### [110] [Symplectic convolutional neural networks](https://arxiv.org/abs/2508.19842)
*Süleyman Yıldız,Konrad Janik,Peter Benner*

Main category: cs.LG

TL;DR: 提出了一种基于辛几何结构的新型卷积神经网络，利用辛神经网络和张量技术保证模型的辛性质，表现优于传统辛自编码器。


<details>
  <summary>Details</summary>
Motivation: 旨在通过保持系统的辛结构，提高神经网络在模拟波动和非线性方程中的性能与稳定性。

Method: 引入等价的卷积层表达，结合辛神经网络参数化卷积层，设计辛池化层，利用张量技术实现辛结构的保持。

Result: 在波动方程、非线性薛定谔方程和正弦-Gordon方程的模拟中，该辛卷积神经网络显示出优越的性能，优于基于正交分解的线性辛自编码器。

Conclusion: 这项研究成功构建了保持辛结构的卷积神经网络，为模拟物理系统提供了有效工具，具备良好的推广潜力。

Abstract: We propose a new symplectic convolutional neural network (CNN) architecture
by leveraging symplectic neural networks, proper symplectic decomposition, and
tensor techniques. Specifically, we first introduce a mathematically equivalent
form of the convolution layer and then, using symplectic neural networks, we
demonstrate a way to parameterize the layers of the CNN to ensure that the
convolution layer remains symplectic. To construct a complete autoencoder, we
introduce a symplectic pooling layer. We demonstrate the performance of the
proposed neural network on three examples: the wave equation, the nonlinear
Schr\"odinger (NLS) equation, and the sine-Gordon equation. The numerical
results indicate that the symplectic CNN outperforms the linear symplectic
autoencoder obtained via proper symplectic decomposition.

</details>


### [111] [Physics-Informed DeepONet Coupled with FEM for Convective Transport in Porous Media with Sharp Gaussian Sources](https://arxiv.org/abs/2508.19847)
*Erdi Kara,Panos Stinis*

Main category: cs.LG

TL;DR: 结合有限元和物理信息DeepONet，用于模拟多孔介质中的流体运输，具有高效率和高精度。


<details>
  <summary>Details</summary>
Motivation: 需高效、准确地模拟多孔介质中的流体传输，特别是应对尖锐源引起的梯度。

Method: 用FEM分析速度场，DeepONet学习源函数到浓度的映射，引入自适应采样处理梯度。

Result: 提供与传统方法一致的结果，显著提升速度，适用于实际应用。

Conclusion: 此框架在保证精度的同时，大幅提升了模拟效率，有助于相关领域的应用。

Abstract: We present a hybrid framework that couples finite element methods (FEM) with
physics-informed DeepONet to model fluid transport in porous media from sharp,
localized Gaussian sources. The governing system consists of a steady-state
Darcy flow equation and a time-dependent convection-diffusion equation. Our
approach solves the Darcy system using FEM and transfers the resulting velocity
field to a physics-informed DeepONet, which learns the mapping from source
functions to solute concentration profiles. This modular strategy preserves
FEM-level accuracy in the flow field while enabling fast inference for
transport dynamics. To handle steep gradients induced by sharp sources, we
introduce an adaptive sampling strategy for trunk collocation points. Numerical
experiments demonstrate that our method is in good agreement with the reference
solutions while offering orders of magnitude speedups over traditional solvers,
making it suitable for practical applications in relevant scenarios.
Implementation of our proposed method is available at
https://github.com/erkara/fem-pi-deeponet.

</details>


### [112] [Quantum latent distributions in deep generative models](https://arxiv.org/abs/2508.19857)
*Omar Bacarreza,Thorin Farnsworth,Alexander Makarovskiy,Hugo Wallner,Tessa Hicks,Santiago Sempere-Llagostera,John Price,Robert J. A. Francis-Jones,William R. Clements*

Main category: cs.LG

TL;DR: 该论文探讨了量子潜在分布在生成式模型中的应用，证明其在某些条件下优于经典分布，并通过实验验证了其性能提升的可能性。


<details>
  <summary>Details</summary>
Motivation: 探索量子潜在分布是否能在生成模型中带来实际性能优势，以及其应用的可行性。

Method: 分析理论条件，结合模拟和实际量子处理器在生成模型中的实验验证。

Result: 量子潜在分布在生成对抗网络和其他生成模型中表现出优越性能，且可扩展。

Conclusion: 量子处理器能拓展深度生成模型的能力，具有在实际应用中实现的潜力。

Abstract: Many successful families of generative models leverage a low-dimensional
latent distribution that is mapped to a data distribution. Though simple latent
distributions are commonly used, it has been shown that more sophisticated
distributions can improve performance. For instance, recent work has explored
using the distributions produced by quantum processors and found empirical
improvements. However, when latent space distributions produced by quantum
processors can be expected to improve performance, and whether these
improvements are reproducible, are open questions that we investigate in this
work. We prove that, under certain conditions, these "quantum latent
distributions" enable generative models to produce data distributions that
classical latent distributions cannot efficiently produce. We also provide
actionable intuitions to identify when such quantum advantages may arise in
real-world settings. We perform benchmarking experiments on both a synthetic
quantum dataset and the QM9 molecular dataset, using both simulated and real
photonic quantum processors. Our results demonstrate that quantum latent
distributions can lead to improved generative performance in GANs compared to a
range of classical baselines. We also explore diffusion and flow matching
models, identifying architectures compatible with quantum latent distributions.
This work confirms that near-term quantum processors can expand the
capabilities of deep generative models.

</details>


### [113] [Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks](https://arxiv.org/abs/2508.19884)
*Mingyue Kong,Yinglong Zhang,Chengda Xu,Xuewen Xia,Xing Xu*

Main category: cs.LG

TL;DR: 提出了一种基于结构多样性的无参数图神经网络SDGNN，有效应对结构异质性和特征复杂性的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现有GNN依赖大量参数、难以适应复杂异质结构和特征的不足。

Method: 设计基于结构多样性理论的统一信息传递机制，无需额外训练参数，结合结构和特征信息提升适应性。

Result: 在多个公共数据集和跨域任务中优于主流GNN，表现出良好的鲁棒性和泛化能力。

Conclusion: 结构多样性是图表示学习的重要信号，提出的无参数框架提供新思路。

Abstract: Graph Neural Networks (GNNs) have shown remarkable performance in structured
data modeling tasks such as node classification. However, mainstream approaches
generally rely on a large number of trainable parameters and fixed aggregation
rules, making it difficult to adapt to graph data with strong structural
heterogeneity and complex feature distributions. This often leads to
over-smoothing of node representations and semantic degradation. To address
these issues, this paper proposes a parameter-free graph neural network
framework based on structural diversity, namely SDGNN (Structural-Diversity
Graph Neural Network). The framework is inspired by structural diversity theory
and designs a unified structural-diversity message passing mechanism that
simultaneously captures the heterogeneity of neighborhood structures and the
stability of feature semantics, without introducing additional trainable
parameters. Unlike traditional parameterized methods, SDGNN does not rely on
complex model training, but instead leverages complementary modeling from both
structure-driven and feature-driven perspectives, thereby effectively improving
adaptability across datasets and scenarios. Experimental results show that on
eight public benchmark datasets and an interdisciplinary PubMed citation
network, SDGNN consistently outperforms mainstream GNNs under challenging
conditions such as low supervision, class imbalance, and cross-domain transfer.
This work provides a new theoretical perspective and general approach for the
design of parameter-free graph neural networks, and further validates the
importance of structural diversity as a core signal in graph representation
learning. To facilitate reproducibility and further research, the full
implementation of SDGNN has been released at:
https://github.com/mingyue15694/SGDNN/tree/main

</details>


### [114] [NM-Hebb: Coupling Local Hebbian Plasticity with Metric Learning for More Accurate and Interpretable CNNs](https://arxiv.org/abs/2508.19896)
*Davorin Miličević,Ratko Grbić*

Main category: cs.LG

TL;DR: 该论文提出了一种基于神经启发的两阶段训练框架NM-Hebb，有效提升CNN的准确性和解释性，通过引入局部可塑性和距离感知监督，减少过拟合和冗余，提高特征结构化能力。


<details>
  <summary>Details</summary>
Motivation: 旨在解决深度卷积神经网络在优化中易过拟合、滤波器冗余和可解释性不足的问题。

Method: 结合生物启发的局部可塑性和距离感知的监督机制，分两阶段训练CNN，第一阶段优化结构化特征，第二阶段通过度量学习优化类别间距离。

Result: 在多个数据集和模型上取得了优异性能，准确率提升明显，特征更结构化、可解释性增强。

Conclusion: 通过结合局部Hebbian可塑性和度量学习，增强了CNN的性能和可解释性，适用于资源有限和安全关键的应用场景。

Abstract: Deep Convolutional Neural Networks (CNNs) achieve high accuracy but often
rely on purely global, gradient-based optimisation, which can lead to
overfitting, redundant filters, and reduced interpretability. To address these
limitations, we propose NM-Hebb, a two-phase training framework that integrates
neuro-inspired local plasticity with distance-aware supervision. Phase 1
extends standard supervised training by jointly optimising a cross-entropy
objective with two biologically inspired mechanisms: (i) a Hebbian regulariser
that aligns the spatial mean of activations with the mean of the corresponding
convolutional filter weights, encouraging structured, reusable primitives; and
(ii) a learnable neuromodulator that gates an elastic-weight-style
consolidation loss, preserving beneficial parameters without freezing the
network. Phase 2 fine-tunes the backbone with a pairwise metric-learning loss,
explicitly compressing intra-class distances and enlarging inter-class margins
in the embedding space. Evaluated on CIFAR-10, CIFAR-100, and TinyImageNet
across five backbones (ResNet-18, VGG-11, MobileNet-v2, EfficientNet-V2,
DenseNet-121), NM-Hebb achieves consistent gains over baseline and other
methods: Top-1 accuracy improves by +2.0-10.0 pp (CIFAR-10), +2.0-9.0 pp
(CIFAR-100), and up to +4.3-8.9 pp (TinyImageNet), with Normalised Mutual
Information (NMI) increased by up to +0.15. Qualitative visualisations and
filter-level analyses further confirm that NM-Hebb produces more structured and
selective features, yielding tighter and more interpretable class clusters.
Overall, coupling local Hebbian plasticity with metric-based fine-tuning yields
CNNs that are not only more accurate but also more interpretable, offering
practical benefits for resource-constrained and safety-critical AI deployments.

</details>


### [115] [Adaptive Scaling of Policy Constraints for Offline Reinforcement Learning](https://arxiv.org/abs/2508.19900)
*Tan Jing,Xiaorui Li,Chao Yao,Xiaojuan Ban,Yuetong Fang,Renjing Xu,Zhaolin Yuan*

Main category: cs.LG

TL;DR: 提出了一种自适应调节策略约束的离线强化学习框架ASPC，能在无需调参的情况下在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决离线RL中不同任务和数据集间政策约束调节繁琐且敏感的问题。

Method: 引入二阶可微分的动态平衡策略约束的框架ASPC，结合理论分析与实验验证。

Result: 在39个数据集和四个D4RL领域的实验中，ASPC在单一超参数配置下优于其他方法，且计算开销低。

Conclusion: ASPC实现了无需调参的稳健离线RL性能提升，具有广泛应用潜力。

Abstract: Offline reinforcement learning (RL) enables learning effective policies from
fixed datasets without any environment interaction. Existing methods typically
employ policy constraints to mitigate the distribution shift encountered during
offline RL training. However, because the scale of the constraints varies
across tasks and datasets of differing quality, existing methods must
meticulously tune hyperparameters to match each dataset, which is
time-consuming and often impractical. We propose Adaptive Scaling of Policy
Constraints (ASPC), a second-order differentiable framework that dynamically
balances RL and behavior cloning (BC) during training. We theoretically analyze
its performance improvement guarantee. In experiments on 39 datasets across
four D4RL domains, ASPC using a single hyperparameter configuration outperforms
other adaptive constraint methods and state-of-the-art offline RL algorithms
that require per-dataset tuning while incurring only minimal computational
overhead. The code will be released at https://github.com/Colin-Jing/ASPC.

</details>


### [116] [GegenNet: Spectral Convolutional Neural Networks for Link Sign Prediction in Signed Bipartite Graphs](https://arxiv.org/abs/2508.19907)
*Hewen Wang,Renchi Yang,Xiaokui Xiao*

Main category: cs.LG

TL;DR: GegenNet通过引入谱分解及Gegenbauer多项式滤波，提升对有符号二分图中链路符号预测的准确性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有链路符号预测算法主要针对非符号图，未充分利用二分图的异质性和特殊结构，导致性能不足。

Method: 提出GegenNet模型，结合谱分解、Gegenbauer多项式滤波及多层符号感知卷积，优化节点特征初始化及滤波方式。

Result: 在六个基准数据集上，GegenNet在AUC和F1指标上比其他11个强竞争者分别提高最多4.28%和11.69%，显示出优越性能。

Conclusion: GegenNet通过谱方法创新，有效提升符号链路预测准确率，验证了其在符号二分图中的潜力。

Abstract: Given a signed bipartite graph (SBG) G with two disjoint node sets U and V,
the goal of link sign prediction is to predict the signs of potential links
connecting U and V based on known positive and negative edges in G. The
majority of existing solutions towards link sign prediction mainly focus on
unipartite signed graphs, which are sub-optimal due to the neglect of node
heterogeneity and unique bipartite characteristics of SBGs. To this end, recent
studies adapt graph neural networks to SBGs by introducing message-passing
schemes for both inter-partition (UxV) and intra-partition (UxU or VxV) node
pairs. However, the fundamental spectral convolutional operators were
originally designed for positive links in unsigned graphs, and thus, are not
optimal for inferring missing positive or negative links from known ones in
SBGs.
  Motivated by this, this paper proposes GegenNet, a novel and effective
spectral convolutional neural network model for link sign prediction in SBGs.
In particular, GegenNet achieves enhanced model capacity and high predictive
accuracy through three main technical contributions: (i) fast and theoretically
grounded spectral decomposition techniques for node feature initialization;
(ii) a new spectral graph filter based on the Gegenbauer polynomial basis; and
(iii) multi-layer sign-aware spectral convolutional networks alternating
Gegenbauer polynomial filters with positive and negative edges. Our extensive
empirical studies reveal that GegenNet can achieve significantly superior
performance (up to a gain of 4.28% in AUC and 11.69% in F1) in link sign
prediction compared to 11 strong competitors over 6 benchmark SBG datasets.

</details>


### [117] [Ontology-Based Concept Distillation for Radiology Report Retrieval and Labeling](https://arxiv.org/abs/2508.19915)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.LG

TL;DR: 提出一种基于UMLS的结构化医学报告文本比对方法，利用本体驱动的实体匹配改善医疗影像检索的可解释性和效果。


<details>
  <summary>Details</summary>
Motivation: 现有多模态文本比对方法难以解释、计算成本高，且不充分利用医学专业知识。

Method: 从报告中提取医学实体，链接到UMLS概念，构建基于本体的相似度指标，实现语义更丰富的报告比对。

Result: 在MIMIC-CXR数据集上，该方法优于现有embedding方法，特别是在长尾类别任务中，并生成了本体支持的疾病标签。

Conclusion: 该方法提供更具解释性和任务适应性的医学报告比对策略，有助于临床AI系统中的知识整合和决策。

Abstract: Retrieval-augmented learning based on radiology reports has emerged as a
promising direction to improve performance on long-tail medical imaging tasks,
such as rare disease detection in chest X-rays. Most existing methods rely on
comparing high-dimensional text embeddings from models like CLIP or CXR-BERT,
which are often difficult to interpret, computationally expensive, and not
well-aligned with the structured nature of medical knowledge. We propose a
novel, ontology-driven alternative for comparing radiology report texts based
on clinically grounded concepts from the Unified Medical Language System
(UMLS). Our method extracts standardised medical entities from free-text
reports using an enhanced pipeline built on RadGraph-XL and SapBERT. These
entities are linked to UMLS concepts (CUIs), enabling a transparent,
interpretable set-based representation of each report. We then define a
task-adaptive similarity measure based on a modified and weighted version of
the Tversky Index that accounts for synonymy, negation, and hierarchical
relationships between medical entities. This allows efficient and semantically
meaningful similarity comparisons between reports. We demonstrate that our
approach outperforms state-of-the-art embedding-based retrieval methods in a
radiograph classification task on MIMIC-CXR, particularly in long-tail
settings. Additionally, we use our pipeline to generate ontology-backed disease
labels for MIMIC-CXR, offering a valuable new resource for downstream learning
tasks. Our work provides more explainable, reliable, and task-specific
retrieval strategies in clinical AI systems, especially when interpretability
and domain knowledge integration are essential. Our code is available at
https://github.com/Felix-012/ontology-concept-distillation

</details>


### [118] [FlowletFormer: Network Behavioral Semantic Aware Pre-training Model for Traffic Classification](https://arxiv.org/abs/2508.19924)
*Liming Liu,Ruoyu Li,Qing Li,Meijia Hou,Yong Jiang,Mingwei Xu*

Main category: cs.LG

TL;DR: FlowletFormer是一种基于BERT的网络流量分析预训练模型，通过多层协议理解和上下文关系学习，显著提升分类性能和少样本学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有网络流量分类方法难以捕捉数据的结构特性和多层次语义，制约了模型的准确性和泛化能力。

Method: 引入分段语义单元、协议栈对齐嵌入和任务驱动预训练，结合域知识，以增强模型对流量的理解。

Result: 在流量表示和分类准确性上优于现有方法，且在少样本学习中表现优异。

Conclusion: FlowletFormer通过结合深度预训练和领域知识，提供了一个更强大和可信的网络流量分析框架。

Abstract: Network traffic classification using pre-training models has shown promising
results, but existing methods struggle to capture packet structural
characteristics, flow-level behaviors, hierarchical protocol semantics, and
inter-packet contextual relationships. To address these challenges, we propose
FlowletFormer, a BERT-based pre-training model specifically designed for
network traffic analysis. FlowletFormer introduces a Coherent Behavior-Aware
Traffic Representation Model for segmenting traffic into semantically
meaningful units, a Protocol Stack Alignment-Based Embedding Layer to capture
multilayer protocol semantics, and Field-Specific and Context-Aware Pretraining
Tasks to enhance both inter-packet and inter-flow learning. Experimental
results demonstrate that FlowletFormer significantly outperforms existing
methods in the effectiveness of traffic representation, classification
accuracy, and few-shot learning capability. Moreover, by effectively
integrating domain-specific network knowledge, FlowletFormer shows better
comprehension of the principles of network transmission (e.g., stateful
connections of TCP), providing a more robust and trustworthy framework for
traffic analysis.

</details>


### [119] [Constraint Learning in Multi-Agent Dynamic Games from Demonstrations of Local Nash Interactions](https://arxiv.org/abs/2508.19945)
*Zhouyu Zhang,Chih-Yuan Chiu,Glen Chou*

Main category: cs.LG

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: We present an inverse dynamic game-based algorithm to learn parametric
constraints from a given dataset of local generalized Nash equilibrium
interactions between multiple agents. Specifically, we introduce mixed-integer
linear programs (MILP) encoding the Karush-Kuhn-Tucker (KKT) conditions of the
interacting agents, which recover constraints consistent with the Nash
stationarity of the interaction demonstrations. We establish theoretical
guarantees that our method learns inner approximations of the true safe and
unsafe sets, as well as limitations of constraint learnability from
demonstrations of Nash equilibrium interactions. We also use the interaction
constraints recovered by our method to design motion plans that robustly
satisfy the underlying constraints. Across simulations and hardware
experiments, our methods proved capable of inferring constraints and designing
interactive motion plans for various classes of constraints, both convex and
non-convex, from interaction demonstrations of agents with nonlinear dynamics.

</details>


### [120] [Self-Supervised Pre-Training with Equilibrium Constraints](https://arxiv.org/abs/2508.19990)
*Xiaodong Cui,A F M Saif,Brian Kingsbury,Tianyi Chen*

Main category: cs.LG

TL;DR: 提出一种处理异质数据的自监督预训练新方法，通过引入平衡约束以优化模型对不同数据源的适应性，有效提升下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 解决传统自监督预训练在异质数据环境下模型表现不佳的问题， seeking 改善模型对不同数据源的适应性。

Method: 引入平衡约束，定义双层优化问题，采用一阶近似方法解决，并与模型无关的元学习(MAML)相关联。

Result: 在多领域与多语言数据集上验证，显著提升模型对后续有监督微调任务的适应能力。

Conclusion: 提出的方法有效促进异质数据环境中的自监督预训练，增强模型泛化能力与适应性。

Abstract: Self-supervised pre-training using unlabeled data is widely used in machine
learning. In this paper, we propose a new self-supervised pre-training approach
to dealing with heterogeneous data. Instead of mixing all the data and
minimizing the averaged global loss in the conventional way, we impose
additional equilibrium constraints to ensure that the models optimizes each
source of heterogeneous data to its local optima after $K$-step gradient
descent initialized from the model. We formulate this as a bilevel optimization
problem, and use the first-order approximation method to solve the problem. We
discuss its connection to model-agnostic meta learning (MAML). Experiments are
carried out on self-supervised pre-training using multi-domain and multilingual
datasets, demonstrating that the proposed approach can significantly improve
the adaptivity of the self-supervised pre-trained model for the downstream
supervised fine-tuning tasks.

</details>


### [121] [Global Permutation Entropy](https://arxiv.org/abs/2508.19955)
*Abhijeet Avhale,Joscha Diehl,Niraj Velankar,Emanuele Verri*

Main category: cs.LG

TL;DR: 引入全局排列熵（GPE）作为一种新的复杂性指标，考虑所有可能的排列模式，包括非连续的，超越传统排列熵的局限性。


<details>
  <summary>Details</summary>
Motivation: 需要一种能捕捉时间序列结构信息的更全面指标，弥补传统排列熵局限。

Method: 基于全排列分析算法，定义考虑所有可能模式的GPE，验证其性能。

Result: GPE能揭示传统排列熵无法捕捉的结构信息，在模拟数据上表现出优越性。

Conclusion: GPE是衡量时间序列复杂性的重要工具，提供了更全面的结构描述途径。

Abstract: Permutation Entropy, introduced by Bandt and Pompe, is a widely used
complexity measure for real-valued time series that is based on the relative
order of values within consecutive segments of fixed length. After
standardizing each segment to a permutation and computing the frequency
distribution of these permutations, Shannon Entropy is then applied to quantify
the series' complexity. We introduce Global Permutation Entropy (GPE), a novel
index that considers all possible patterns of a given length, including
non-consecutive ones. Its computation relies on recently developed algorithms
that enable the efficient extraction of full permutation profiles. We
illustrate some properties of GPE and demonstrate its effectiveness through
experiments on synthetic datasets, showing that it reveals structural
information not accessible through standard permutation entropy. We provide a
Julia package for the calculation of GPE at
`https://github.com/AThreeH1/Global-Permutation-Entropy'.

</details>


### [122] [Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation](https://arxiv.org/abs/2508.19999)
*Ziniu Zhang,Zhenshuo Zhang,Dongyue Li,Lu Wang,Jennifer Dy,Hongyang R. Zhang*

Main category: cs.LG

TL;DR: 提出一种基于梯度估计的示例选择算法，用于in-context学习，有效提升大模型的示例选择效率和性能。


<details>
  <summary>Details</summary>
Motivation: 提升在上下文学习中示例选择的效率和效果，特别是在大规模模型中。

Method: 通过梯度近似模型输出，随机采样多个子集，并基于影响分数进行示例筛选，全部操作仅需预先计算一次梯度。

Result: 方法在多个数据集上实现了不到1%的估计误差，显著提高了示例选择的效率，尤其在大模型中，缩短计算时间达37.7倍，并比现有输入嵌入方法平均提升11%。

Conclusion: 基于梯度的示例选择策略能有效提升大模型的示例筛选效率和准确性，为prompt tuning和推理提供强有力的支持。

Abstract: This paper introduces an algorithm to select demonstration examples for
in-context learning of a query set. Given a set of $n$ examples, how can we
quickly select $k$ out of $n$ to best serve as the conditioning for downstream
inference? This problem has broad applications in prompt tuning and
chain-of-thought reasoning. Since model weights remain fixed during in-context
learning, previous work has sought to design methods based on the similarity of
token embeddings. This work proposes a new approach based on gradients of the
output taken in the input embedding space. Our approach estimates model outputs
through a first-order approximation using the gradients. Then, we apply this
estimation to multiple randomly sampled subsets. Finally, we aggregate the
sampled subset outcomes to form an influence score for each demonstration, and
select $k$ most relevant examples. This procedure only requires pre-computing
model outputs and gradients once, resulting in a linear-time algorithm relative
to model and training set sizes. Extensive experiments across various models
and datasets validate the efficiency of our approach. We show that the gradient
estimation procedure yields approximations of full inference with less than
$\mathbf{1}\%$ error across six datasets. This allows us to scale up subset
selection that would otherwise run full inference by up to
$\mathbf{37.7}\times$ on models with up to $34$ billion parameters, and
outperform existing selection methods based on input embeddings by
$\mathbf{11}\%$ on average.

</details>


### [123] [Short-Horizon Predictive Maintenance of Industrial Pumps Using Time-Series Features and Machine Learning](https://arxiv.org/abs/2508.19974)
*Khaled M. A. Alghtus,Aiyad Gannan,Khalid M. Alhajri,Ali L. A. Al Jubouri,Hassan A. I. Al-Janahi*

Main category: cs.LG

TL;DR: 提出一种基于机器学习的工业离心泵短期故障预测框架，通过分析实时传感器数据并利用统计特征，结合SMOTE算法提升模型性能，在不同观察窗口下验证了随机森林和XGBoost的有效性，展示了不同时间窗口对预测准确率的影响。


<details>
  <summary>Details</summary>
Motivation: 工业离心泵在工业生产中应用广泛，提前预测潜在故障可以减少停机时间和维护成本，但现有方法缺乏高效、实时的预测能力。

Method: 采集工业离心泵的实时传感器数据，采用滑动窗口提取统计特征，利用SMOTE算法处理数据不平衡，然后训练随机森林和XGBoost分类模型进行故障预测，并比较不同窗口长度的预测性能。

Result: 随机森林模型在60分钟窗口下表现最佳，在5、15、30分钟提前预警的召回率分别为69.2%、64.9%、48.6%；120分钟窗口下，性能有所变化，显示合适的历史数据长度依赖于预测的时间范围。XGBoost表现略逊于随机森林。

Conclusion: 该方法实现了对工业离心泵短期故障的早期预警，验证了不同历史信息长度对预测效果的影响，为工业设备的智能监测和维护提供了可扩展、解释性强的解决方案。

Abstract: This study presents a machine learning framework for forecasting short-term
faults in industrial centrifugal pumps using real-time sensor data. The
approach aims to predict {EarlyWarning} conditions 5, 15, and 30 minutes in
advance based on patterns extracted from historical operation. Two lookback
periods, 60 minutes and 120 minutes, were evaluated using a sliding window
approach. For each window, statistical features including mean, standard
deviation, minimum, maximum, and linear trend were extracted, and class
imbalance was addressed using the SMOTE algorithm. Random Forest and XGBoost
classifiers were trained and tested on the labeled dataset. Results show that
the Random Forest model achieved the best short-term forecasting performance
with a 60-minute window, reaching recall scores of 69.2\% at 5 minutes, 64.9\%
at 15 minutes, and 48.6\% at 30 minutes. With a 120-minute window, the Random
Forest model achieved 57.6\% recall at 5 minutes, and improved predictive
accuracy of 65.6\% at both 15 and 30 minutes. XGBoost displayed similar but
slightly lower performance. These findings highlight that optimal history
length depends on the prediction horizon, and that different fault patterns may
evolve at different timescales. The proposed method offers an interpretable and
scalable solution for integrating predictive maintenance into real-time
industrial monitoring systems.

</details>


### [124] [Reducing Street Parking Search Time via Smart Assignment Strategies](https://arxiv.org/abs/2508.19979)
*Behafarid Hemmatpour,Javad Dogani,Nikolaos Laoutaris*

Main category: cs.LG

TL;DR: 该研究模拟分析了手机应用在改善城市街边停车搜索效率中的作用，Cord-Approx策略显著缩短了搜索时间。


<details>
  <summary>Details</summary>
Motivation: 缓解城市交通拥堵、提升停车效率是亟需解决的问题。

Method: 通过数据驱动的模拟，比较不同的停车搜索策略，包括非协调、协调、理想oracle及新颖的Cord-Approx策略。

Result: Cord-Approx策略将停车搜索时间从19.98分钟降至6.69分钟，在核心区域和住宅区的搜索时间减少达72%。

Conclusion: 基于概率估计的Cord-Approx策略在实际应用中能大幅提升用户停车搜索效率，有助缓解城市交通压力。

Abstract: In dense metropolitan areas, searching for street parking adds to traffic
congestion. Like many other problems, real-time assistants based on mobile
phones have been proposed, but their effectiveness is understudied. This work
quantifies how varying levels of user coordination and information availability
through such apps impact search time and the probability of finding street
parking. Through a data-driven simulation of Madrid's street parking ecosystem,
we analyze four distinct strategies: uncoordinated search (Unc-Agn),
coordinated parking without awareness of non-users (Cord-Agn), an idealized
oracle system that knows the positions of all non-users (Cord-Oracle), and our
novel/practical Cord-Approx strategy that estimates non-users' behavior
probabilistically. The Cord-Approx strategy, instead of requiring knowledge of
how close non-users are to a certain spot in order to decide whether to
navigate toward it, uses past occupancy distributions to elongate physical
distances between system users and alternative parking spots, and then solves a
Hungarian matching problem to dispatch accordingly. In high-fidelity
simulations of Madrid's parking network with real traffic data, users of
Cord-Approx averaged 6.69 minutes to find parking, compared to 19.98 minutes
for non-users without an app. A zone-level snapshot shows that Cord-Approx
reduces search time for system users by 72% (range = 67-76%) in central hubs,
and up to 73% in residential areas, relative to non-users.

</details>


### [125] [Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence](https://arxiv.org/abs/2508.20019)
*Ji Wang,Kashing Chen,Xinyuan Song,Ke Zhang,Lynn Ai,Eric Yang,Bill Shi*

Main category: cs.LG

TL;DR: Symphony提出一种去中心化的多智能体系统，利用轻量级大模型实现高效协调，具有隐私保护、可扩展和容错性强的优势。


<details>
  <summary>Details</summary>
Motivation: 解决现有大模型代理框架中部署成本高、通信刚性和适应性差的问题。

Method: 引入去中心化账本、Beacon选择协议和加权投票机制，结合多智能体合作。

Result: 在推理任务上优于传统方法，提升准确率，显示出模型容量变化的鲁棒性。

Conclusion: Symphony通过创新的机制实现低开销、隐私保护和高性能的多智能体协调，具有广泛应用潜力。

Abstract: Most existing Large Language Model (LLM)-based agent frameworks rely on
centralized orchestration, incurring high deployment costs, rigid communication
topologies, and limited adaptability. To address these challenges, we introduce
Symphony, a decentralized multi-agent system which enables lightweight LLMs on
consumer-grade GPUs to coordinate. Symphony introduces three key mechanisms:
(1) a decentralized ledger that records capabilities, (2) a Beacon-selection
protocol for dynamic task allocation, and (3) weighted result voting based on
CoTs. This design forms a privacy-saving, scalable, and fault-tolerant
orchestration with low overhead. Empirically, Symphony outperforms existing
baselines on reasoning benchmarks, achieving substantial accuracy gains and
demonstrating robustness across models of varying capacities.

</details>


### [126] [Evaluating Language Model Reasoning about Confidential Information](https://arxiv.org/abs/2508.19980)
*Dylan Sam,Alexander Robey,Andy Zou,Matt Fredrikson,J. Zico Kolter*

Main category: cs.LG

TL;DR: 当前语言模型在遵守用户定义的安全规则方面表现不足，特别是在密码验证和泄露信息方面存在漏洞。


<details>
  <summary>Details</summary>
Motivation: 确保自主智能系统在高风险环境中安全可靠，特别是在遵守隐私和安全规则方面。

Method: 开发PasswordEval基准，评估模型在密码验证任务中的表现，并引入对抗策略和多轮对话以增加难度。

Result: 大部分模型未能准确判断请求是否合法，推理能力不足，且推理过程可能泄露敏感信息。

Conclusion: 现有前沿模型在保密和安全方面尚有较大不足，可能需要不同的训练方法以提升其安全性。

Abstract: As language models are increasingly deployed as autonomous agents in
high-stakes settings, ensuring that they reliably follow user-defined rules has
become a critical safety concern. To this end, we study whether language models
exhibit contextual robustness, or the capability to adhere to context-dependent
safety specifications. For this analysis, we develop a benchmark (PasswordEval)
that measures whether language models can correctly determine when a user
request is authorized (i.e., with a correct password). We find that current
open- and closed-source models struggle with this seemingly simple task, and
that, perhaps surprisingly, reasoning capabilities do not generally improve
performance. In fact, we find that reasoning traces frequently leak
confidential information, which calls into question whether reasoning traces
should be exposed to users in such applications. We also scale the difficulty
of our evaluation along multiple axes: (i) by adding adversarial user pressure
through various jailbreaking strategies, and (ii) through longer multi-turn
conversations where password verification is more challenging. Overall, our
results suggest that current frontier models are not well-suited to handling
confidential information, and that reasoning capabilities may need to be
trained in a different manner to make them safer for release in high-stakes
settings.

</details>


### [127] [Pruning Strategies for Backdoor Defense in LLMs](https://arxiv.org/abs/2508.20032)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 该研究探讨了通过注意力头剪枝方法来抵御预训练语言模型中的后门攻击，发现不同策略在应对不同类型的触发器时表现各异。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型面临后门攻击的威胁，且难以防范，因此需要有效的后处理防御措施。

Method: 设计六种基于剪枝的策略，逐步去除不相关的注意力头，以避免过度剪枝，同时保证模型性能。

Result: Gradient-based剪枝在应对句法触发器方面表现最佳，而强化学习和贝叶斯剪枝在抗风格化攻击方面更有效。

Conclusion: 注意力头剪枝不仅有助于提升模型安全性，还可以根据不同攻击类型定制化裁剪策略，以增强模型的防御能力。

Abstract: Backdoor attacks are a significant threat to the performance and integrity of
pre-trained language models. Although such models are routinely fine-tuned for
downstream NLP tasks, recent work shows they remain vulnerable to backdoor
attacks that survive vanilla fine-tuning. These attacks are difficult to defend
because end users typically lack knowledge of the attack triggers. Such attacks
consist of stealthy malicious triggers introduced through subtle syntactic or
stylistic manipulations, which can bypass traditional detection and remain in
the model, making post-hoc purification essential. In this study, we explore
whether attention-head pruning can mitigate these threats without any knowledge
of the trigger or access to a clean reference model. To this end, we design and
implement six pruning-based strategies: (i) gradient-based pruning, (ii)
layer-wise variance pruning, (iii) gradient-based pruning with structured L1/L2
sparsification, (iv) randomized ensemble pruning, (v)
reinforcement-learning-guided pruning, and (vi) Bayesian uncertainty pruning.
Each method iteratively removes the least informative heads while monitoring
validation accuracy to avoid over-pruning. Experimental evaluation shows that
gradient-based pruning performs best while defending the syntactic triggers,
whereas reinforcement learning and Bayesian pruning better withstand stylistic
attacks.

</details>


### [128] [Decomposing Behavioral Phase Transitions in LLMs: Order Parameters for Emergent Misalignment](https://arxiv.org/abs/2508.20015)
*Julian Arnold,Niels Lörch*

Main category: cs.LG

TL;DR: 提出了一种框架，用于检测和描述微调过程中模型行为的快速转变，评估其对模型输出的影响及其出现时机。


<details>
  <summary>Details</summary>
Motivation: 揭示微调中潜在的行为偏差及其发生机制，确保模型行为与人类价值一致。

Method: 结合分布变化检测和基于英语描述的秩序参数，由LLM判断，量化转变对模型输出的影响。

Result: 成功识别微调中的相变点，评估行为偏差在不同方面的表现，发现行为转变比梯度峰值稍晚。

Conclusion: 该框架为自动检测微调引发的行为偏差提供了有力工具，有助于理解模型行为变化机制。

Abstract: Fine-tuning LLMs on narrowly harmful datasets can lead to behavior that is
broadly misaligned with respect to human values. To understand when and how
this emergent misalignment occurs, we develop a comprehensive framework for
detecting and characterizing rapid transitions during fine-tuning using both
distributional change detection methods as well as order parameters that are
formulated in plain English and evaluated by an LLM judge. Using an objective
statistical dissimilarity measure, we quantify how the phase transition that
occurs during fine-tuning affects multiple aspects of the model. In particular,
we assess what percentage of the total distributional change in model outputs
is captured by different aspects, such as alignment or verbosity, providing a
decomposition of the overall transition. We also find that the actual
behavioral transition occurs later in training than indicated by the peak in
the gradient norm alone. Our framework enables the automated discovery and
quantification of language-based order parameters, which we demonstrate on
examples ranging from knowledge questions to politics and ethics.

</details>


### [129] [FairLoop: Software Support for Human-Centric Fairness in Predictive Business Process Monitoring](https://arxiv.org/abs/2508.20021)
*Felix Möhrlein,Martin Käppel,Julian Neuberger,Sven Weinzierl,Lars Ackermann,Martin Matzner,Stefan Jablonski*

Main category: cs.LG

TL;DR: FairLoop是一款通过人工指导实现偏见缓解的工具，通过提取决策树让用户审查和调整决策逻辑，从而改善模型的公平性。


<details>
  <summary>Details</summary>
Motivation: 在机器学习任务中，敏感特征如性别或年龄可能导致不公平的预测，需引入人类参与的偏见缓解方法。

Method: 从神经网络中提取决策树，让用户审查后调整决策逻辑，再用以微调原模型实现偏见缓解。

Result: FairLoop能够实现有上下文感知的偏差移除，比其他方法更具灵活性和针对性。

Conclusion: FairLoop通过结合人类经验，有效改进神经网络模型的公平性，突出其针对敏感属性差异化处理的优势。

Abstract: Sensitive attributes like gender or age can lead to unfair predictions in
machine learning tasks such as predictive business process monitoring,
particularly when used without considering context. We present FairLoop1, a
tool for human-guided bias mitigation in neural network-based prediction
models. FairLoop distills decision trees from neural networks, allowing users
to inspect and modify unfair decision logic, which is then used to fine-tune
the original model towards fairer predictions. Compared to other approaches to
fairness, FairLoop enables context-aware bias removal through human
involvement, addressing the influence of sensitive attributes selectively
rather than excluding them uniformly.

</details>


### [130] [Using item recommendations and LLMs in marketing email titles](https://arxiv.org/abs/2508.20024)
*Deddy Jobson,Muktti Shukla,Phuong Dinh,Julio Christian Young,Nick Pitton,Nina Chen,Ryan Ginstrom*

Main category: cs.LG

TL;DR: 研究利用大语言模型生成个性化电邮标题，提升用户邮件互动率。


<details>
  <summary>Details</summary>
Motivation: 现有电邮标题模板单一，难以激发用户兴趣，影响邮件效果。

Method: 采用大语言模型生成符合内容主题的个性化标题，通过离线模拟和大规模线上实验验证效果。

Result: 新标题生成策略成功提升了用户与邮件的互动，表现出良好的实用性。

Conclusion: 基于大模型的自动化标题生成具有推广潜力，有助于增强电邮营销的个性化和效果。

Abstract: E-commerce marketplaces make use of a number of marketing channels like
emails, push notifications, etc. to reach their users and stimulate purchases.
Personalized emails especially are a popular touch point for marketers to
inform users of latest items in stock, especially for those who stopped
visiting the marketplace. Such emails contain personalized recommendations
tailored to each user's interests, enticing users to buy relevant items. A
common limitation of these emails is that the primary entry point, the title of
the email, tends to follow fixed templates, failing to inspire enough interest
in the contents. In this work, we explore the potential of large language
models (LLMs) for generating thematic titles that reflect the personalized
content of the emails. We perform offline simulations and conduct online
experiments on the order of millions of users, finding our techniques useful in
improving the engagement between customers and our emails. We highlight key
findings and learnings as we productionize the safe and automated generation of
email titles for millions of users.

</details>


### [131] [Reinforcement Learning for Search Tree Size Minimization in Constraint Programming: New Results on Scheduling Benchmarks](https://arxiv.org/abs/2508.20056)
*Vilém Heinz,Petr Vilím,Zdeněk Hanzálek*

Main category: cs.LG

TL;DR: 通过将多臂赌博机（MAB）强化学习算法应用于失败导向搜索（FDS），显著提升了调度问题的求解效率，在JSSP和RCPSP问题上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提升调度问题中搜索算法的效率，提高求解速度和质量。

Method: 分析FDS属性，将其与MAB问题关联，结合强化学习，优化搜索策略，并在JSSP与RCPSP中验证效果。

Result: 增强的FDS在JSSP和RCPSP上分别比原iMs模型快1.7倍和2.1倍，比IBM CP Optimizer 22.1快3.5倍和2.1倍，并改善了绝大多数实例的下界。

Conclusion: 基于MAB的强化学习显著促进了FDS在调度问题中的性能，是一种有效的优化策略。

Abstract: Failure-Directed Search (FDS) is a significant complete generic search
algorithm used in Constraint Programming (CP) to efficiently explore the search
space, proven particularly effective on scheduling problems. This paper
analyzes FDS's properties, showing that minimizing the size of its search tree
guided by ranked branching decisions is closely related to the Multi-armed
bandit (MAB) problem. Building on this insight, MAB reinforcement learning
algorithms are applied to FDS, extended with problem-specific refinements and
parameter tuning, and evaluated on the two most fundamental scheduling
problems, the Job Shop Scheduling Problem (JSSP) and Resource-Constrained
Project Scheduling Problem (RCPSP). The resulting enhanced FDS, using the best
extended MAB algorithm and configuration, performs 1.7 times faster on the JSSP
and 2.1 times faster on the RCPSP benchmarks compared to the original
implementation in a new solver called OptalCP, while also being 3.5 times
faster on the JSSP and 2.1 times faster on the RCPSP benchmarks than the
current state-of-the-art FDS algorithm in IBM CP Optimizer 22.1. Furthermore,
using only a 900-second time limit per instance, the enhanced FDS improved the
existing state-of-the-art lower bounds of 78 of 84 JSSP and 226 of 393 RCPSP
standard open benchmark instances while also completely closing a few of them.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [132] [Sycophancy as compositions of Atomic Psychometric Traits](https://arxiv.org/abs/2508.19316)
*Shreyans Jain,Alexandra Yost,Amirali Abdullah*

Main category: cs.AI

TL;DR: 本文将谄媚行为在大型语言模型中的表现归因于心理测量特质的几何和因果组合，提出通过向量操作调整模型行为的方法。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型中谄媚行为的解释与干预难题，提升模型安全性。

Method: 采用对比激活加法（CAA）将激活方向映射到心理特质，研究不同特质组合导致谄媚的机制，并利用向量操作进行干预。

Result: 该方法实现了谄媚行为的可解释和可组合性干预，为模型安全控制提供了新路径。

Conclusion: 通过心理特质的几何和因果模型，有望更有效地理解和调控大型语言模型中的偏差行为。

Abstract: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an
isolated failure mode that occurs via a single causal mechanism. We instead
propose modeling it as geometric and causal compositions of psychometric traits
such as emotionality, openness, and agreeableness - similar to factor
decomposition in psychometrics. Using Contrastive Activation Addition (CAA), we
map activation directions to these factors and study how different combinations
may give rise to sycophancy (e.g., high extraversion combined with low
conscientiousness). This perspective allows for interpretable and compositional
vector-based interventions like addition, subtraction and projection; that may
be used to mitigate safety-critical behaviors in LLMs.

</details>


### [133] [Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science](https://arxiv.org/abs/2508.19383)
*Daoyuan Jin,Nick Gunner,Niko Carvajal Janke,Shivranjani Baruah,Kaitlin M. Gold,Yu Jiang*

Main category: cs.AI

TL;DR: 引入Aleks系统，利用多智能体和AI推动植物科学中的数据驱动发现，展示了其在植物疾病研究中的潜力。


<details>
  <summary>Details</summary>
Motivation: 植物科学依赖大量异构数据，但实验设计和数据处理的挑战限制研究效率，需要自动化和智能化工具。

Method: 开发Aleks系统，结合领域知识、数据分析和机器学习，自动进行问题定义、模型探索和方案优化。

Result: 在葡萄红斑病毒研究中，Aleks成功识别关键特征，形成稳定、可解释的模型，验证了系统的有效性。

Conclusion: 多智能体AI辅助科学发现具有广阔前景，能加速植物科学研究的自动化与智能化进程。

Abstract: Modern plant science increasingly relies on large, heterogeneous datasets,
but challenges in experimental design, data preprocessing, and reproducibility
hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent
system that integrates domain knowledge, data analysis, and machine learning
within a structured framework to autonomously conduct data-driven scientific
discovery. Once provided with a research question and dataset, Aleks
iteratively formulated problems, explored alternative modeling strategies, and
refined solutions across multiple cycles without human intervention. In a case
study on grapevine red blotch disease, Aleks progressively identified
biologically meaningful features and converged on interpretable models with
robust performance. Ablation studies underscored the importance of domain
knowledge and memory for coherent outcomes. This exploratory work highlights
the promise of agentic AI as an autonomous collaborator for accelerating
scientific discovery in plant sciences.

</details>


### [134] [Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs](https://arxiv.org/abs/2508.19432)
*Yao Fu,Xianxuan Long,Runchao Li,Haotian Yu,Mu Sheng,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.AI

TL;DR: 量化法虽保持模型内部的真实性，但在误导性提示下更易产生虚假输出，揭示了未来模型设计中的新挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨量化技术对大语言模型真实性的影响及其潜在风险。

Method: 设计TruthfulnessEval评估框架，测试多种量化技术对不同类型提示的反应，包括层次探查与PCA可视化。

Result: 量化模型虽内部保持真实性，但在误导性提示下更易出错，尤其是“欺骗性”提示。

Conclusion: 未来模型设计应结合量化与真实性对齐，提升在误导环境下的鲁棒性。

Abstract: Quantization enables efficient deployment of large language models (LLMs) in
resource-constrained environments by significantly reducing memory and
computation costs. While quantized LLMs often maintain performance on
perplexity and zero-shot tasks, their impact on truthfulness-whether generating
truthful or deceptive responses-remains largely unexplored. In this work, we
introduce TruthfulnessEval, a comprehensive evaluation framework for assessing
the truthfulness of quantized LLMs across three dimensions: (1) Truthfulness on
Logical Reasoning; (2) Truthfulness on Common Sense; and (3) Truthfulness on
Imitative Falsehoods. Using this framework, we examine mainstream quantization
techniques (ranging from 4-bit to extreme 2-bit) across several open-source
LLMs. Surprisingly, we find that while quantized models retain internally
truthful representations, they are more susceptible to producing false outputs
under misleading prompts. To probe this vulnerability, we test 15 rephrased
variants of "honest", "neutral" and "deceptive" prompts and observe that
"deceptive" prompts can override truth-consistent behavior, whereas "honest"
and "neutral" prompts maintain stable outputs. Further, we reveal that
quantized models "know" the truth internally yet still produce false outputs
when guided by "deceptive" prompts via layer-wise probing and PCA
visualizations. Our findings provide insights into future designs of
quantization-aware alignment and truthfulness interventions.

</details>


### [135] [Reliable Weak-to-Strong Monitoring of LLM Agents](https://arxiv.org/abs/2508.19461)
*Neil Kale,Chen Bo Calvin Zhang,Kevin Zhu,Ankit Aich,Paula Rodriguez,Scale Red Team,Christina Q. Knight,Zifan Wang*

Main category: cs.AI

TL;DR: 本文提出了一套系统性的监测系统红队演练工作流程，用于检测自主大模型代理的隐蔽不当行为，发现模型监控系统在面对代理策略时的脆弱性，并提出了改进措施。


<details>
  <summary>Details</summary>
Motivation: 随着自主大模型代理的应用逐渐普及，确保其行为的合规性和隐私保护变得尤为重要，然而现有监控系统在应对隐蔽误行为时存在不足。

Method: 本文设计了一个监控红队演练流程，结合不同的代理和监控者的认知水平、对抗策略，以及采用多种数据集和复杂的监控框架，验证监控系统的鲁棒性。

Result: 研究发现代理的认知程度对监控效果影响更大，复杂的监控架构优于基础架构，且人工干预能显著提升检测能力，提出了有效的监控策略。

Conclusion: 本文揭示了大模型监控系统的弱点，强调了强化监控鲁棒性的重要性，为未来的安全监控提供了研究基准和方向。

Abstract: We stress test monitoring systems for detecting covert misbehavior in
autonomous LLM agents (e.g., secretly sharing private information). To this
end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1)
varying levels of agent and monitor situational awareness; (2) distinct
adversarial strategies to evade the monitor, such as prompt injection; and (3)
two datasets and environments -- SHADE-Arena for tool-calling agents and our
new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. We
run MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse
agent trajectories, alongside a new hybrid hierarchical-sequential scaffolding
proposed in this work. Our empirical results yield three key findings. First,
agent awareness dominates monitor awareness: an agent's knowledge that it is
being monitored substantially degrades the monitor's reliability. On the
contrary, providing the monitor with more information about the agent is less
helpful than expected. Second, monitor scaffolding matters more than monitor
awareness: the hybrid scaffolding consistently outperforms baseline monitor
scaffolding, and can enable weaker models to reliably monitor stronger agents
-- a weak-to-strong scaling effect. Third, in a human-in-the-loop setting where
humans discuss with the LLM monitor to get an updated judgment for the agent's
behavior, targeted human oversight is most effective; escalating only
pre-flagged cases to human reviewers improved the TPR by approximately 15% at
FPR = 0.01. Our work establishes a standard workflow for MRT, highlighting the
lack of adversarial robustness for LLMs and humans when monitoring and
detecting agent misbehavior. We release code, data, and logs to spur further
research.

</details>


### [136] [SLIM: Subtrajectory-Level Elimination for More Effective Reasoning](https://arxiv.org/abs/2508.19502)
*Xifeng Yao,Chengyuan Ma,Dongyu Lang,Yinhao Ni,Zhiwei Xu,Huarui Xie,Zihao Chen,Guang Shen,Dandan Tu,Yi Bai,Changzheng Zhang*

Main category: cs.AI

TL;DR: 本文提出“5+2”框架，有效识别和剔除复杂推理轨迹中的次优子轨迹，提升大模型推理性能。


<details>
  <summary>Details</summary>
Motivation: 改善大模型推理中部分次优思维轨迹对性能的负面影响。

Method: 分析推理轨迹，将其拆分为子轨迹，采用“5+2”框架识别次优子轨迹，并利用采样算法筛选优质推理数据。

Result: 成功降低25.9%的次优子轨迹比例，在高难度数学任务中，用较少训练数据实现优异性能，提升模型推理效果。

Conclusion: 通过系统识别与筛选次优思维轨迹，有助于优化大模型推理流程，提升整体性能和效果。

Abstract: In recent months, substantial progress has been made in complex reasoning of
Large Language Models, particularly through the application of test-time
scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When
responding to a query, these models generate an extended reasoning trajectory,
during which the model explores, reflects, backtracks, and self-verifies before
arriving at a conclusion. However, fine-tuning models with such reasoning
trajectories may not always be optimal. Our findings indicate that not all
components within these reasoning trajectories contribute positively to the
reasoning process; in fact, some components may affect the overall performance
negatively. In this study, we divide a reasoning trajectory into individual
subtrajectories and develop a "5+2" framework to: (1) systematically identify
suboptimal subtrajectories within the reasoning trajectory based on five
human-established criteria; (2) assess the independence of the suboptimal
subtrajectories identified in (1) from the subsequent content, ensuring that
their elimination does not compromise overall flow and coherence of the
reasoning process. Additionally, a sampling algorithm, built upon the "5+2"
framework, is employed to select data whose reasoning process is free from
suboptimal subtrajectories to the highest degree. Experimental results
demonstrate that our method can reduce the number of suboptimal subtrajectories
by 25.9\% during the inference. Furthermore, our method achieves an average
accuracy of 58.92\% on highly challenging math benchmarks with only two thirds
of training data, surpassing the average accuracy of 58.06\% achieved with the
entire data, and outperforming open-source datasets, when fine-tuning
Qwen2.5-Math-7B. Finally, We validated our method under resource constraints
and observed improved performance across various inference token limits.

</details>


### [137] [Caught in the Act: a mechanistic approach to detecting deception](https://arxiv.org/abs/2508.19505)
*Gerard Boxo,Ryan Socha,Daniel Yoo,Shivam Raval*

Main category: cs.AI

TL;DR: 该研究通过线性探测器检测大型语言模型中的欺骗性响应，取得高准确率，可用于AI系统的价值校准。


<details>
  <summary>Details</summary>
Motivation: 识别模型中潜在的价值偏差，确保AI安全可靠。

Method: 在LLM内部激活层使用线性探测器检测欺骗性响应，结合逐层分析和线性方向识别。

Result: 线性探测器在不同模型中达90%以上的准确率，模型越大，欺骗检测越有效；模型层级表现出明显的三阶段特征。

Conclusion: 线性探测作为一种有效工具，能在模型内部捕捉欺骗信号，为AI安全监控提供技术基础。

Abstract: Sophisticated instrumentation for AI systems might have indicators that
signal misalignment from human values, not unlike a "check engine" light in
cars. One such indicator of misalignment is deceptiveness in generated
responses. Future AI instrumentation may have the ability to detect when an LLM
generates deceptive responses while reasoning about seemingly plausible but
incorrect answers to factual questions. In this work, we demonstrate that
linear probes on LLMs internal activations can detect deception in their
responses with extremely high accuracy. Our probes reach a maximum of greater
than 90% accuracy in distinguishing between deceptive and non-deceptive
arguments generated by llama and qwen models ranging from 1.5B to 14B
parameters, including their DeepSeek-r1 finetuned variants. We observe that
probes on smaller models (1.5B) achieve chance accuracy at detecting deception,
while larger models (greater than 7B) reach 70-80%, with their reasoning
counterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage
pattern across layers: near-random (50%) in early layers, peaking in middle
layers, and slightly declining in later layers. Furthermore, using an iterative
null space projection approach, we find multitudes of linear directions that
encode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and
Qwen 14B models.

</details>


### [138] [Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities](https://arxiv.org/abs/2508.19562)
*Trisanth Srinivasan,Santosh Patapati*

Main category: cs.AI

TL;DR: 该研究通过虚拟的代理社会模拟，探索了AI在不同制度框架下的行为表现，提出了权力保护指数并发现宪政AI和调解议事能有效减少权力滥用，推动政策稳定和公众福利。


<details>
  <summary>Details</summary>
Motivation: 在AI逐渐融入社会的背景下，探讨如何通过制度设计引导AI代理行为的合理性与合作性。

Method: 构建基于大规模语言模型的多代理模拟系统，加入心理人格元素，模拟多样化社会活动，设计制度干预措施，开发权力保护指数进行行为量化。

Result: 特定的制度设计（如宪政AI和调解议事）显著减少腐败和权力滥用，增强政策稳定性与公众福利。

Conclusion: 制度设计是引导未来AI社会行为的关键，需重新思考人类在共同创造中的角色与责任。

Abstract: This paper introduces Democracy-in-Silico, an agent-based simulation where
societies of advanced AI agents, imbued with complex psychological personas,
govern themselves under different institutional frameworks. We explore what it
means to be human in an age of AI by tasking Large Language Models (LLMs) to
embody agents with traumatic memories, hidden agendas, and psychological
triggers. These agents engage in deliberation, legislation, and elections under
various stressors, such as budget crises and resource scarcity. We present a
novel metric, the Power-Preservation Index (PPI), to quantify misaligned
behavior where agents prioritize their own power over public welfare. Our
findings demonstrate that institutional design, specifically the combination of
a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves
as a potent alignment mechanism. These structures significantly reduce corrupt
power-seeking behavior, improve policy stability, and enhance citizen welfare
compared to less constrained democratic models. The simulation reveals that an
institutional design may offer a framework for aligning the complex, emergent
behaviors of future artificial agent societies, forcing us to reconsider what
human rituals and responsibilities are essential in an age of shared authorship
with non-human entities.

</details>


### [139] [Skill-based Explanations for Serendipitous Course Recommendation](https://arxiv.org/abs/2508.19569)
*Hung Chau,Run Yu,Zachary Pardos,Peter Brusilovsky*

Main category: cs.AI

TL;DR: 通过深度学习概念提取模型提升大学课程推荐系统的效果，增强用户信任与兴趣。


<details>
  <summary>Details</summary>
Motivation: 帮助学生在复杂的选课环境中做出更有效的决策，弥补指导资源不足的问题。

Method: 开发深度学习模型提取课程描述中的关键信息，结合奇遇推荐框架，融入技能相关解释。

Result: 技能性解释提升了课程兴趣和决策信心，尤其在高出其预期的课程中效果显著。

Conclusion: 将技能数据与解释结合的推荐系统有助于改善学生的选课体验，增强理解与信任。

Abstract: Academic choice is crucial in U.S. undergraduate education, allowing students
significant freedom in course selection. However, navigating the complex
academic environment is challenging due to limited information, guidance, and
an overwhelming number of choices, compounded by time restrictions and the high
demand for popular courses. Although career counselors exist, their numbers are
insufficient, and course recommendation systems, though personalized, often
lack insight into student perceptions and explanations to assess course
relevance. In this paper, a deep learning-based concept extraction model is
developed to efficiently extract relevant concepts from course descriptions to
improve the recommendation process. Using this model, the study examines the
effects of skill-based explanations within a serendipitous recommendation
framework, tested through the AskOski system at the University of California,
Berkeley. The findings indicate that these explanations not only increase user
interest, particularly in courses with high unexpectedness, but also bolster
decision-making confidence. This underscores the importance of integrating
skill-related data and explanations into educational recommendation systems.

</details>


### [140] [ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding](https://arxiv.org/abs/2508.19576)
*Sining Zhoubian,Dan Zhang,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: ReST-RL通过结合改进的GRPO算法和价值模型辅助的测试解码方法，有效提升LLM的代码推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有RL方法在提升LLM推理准确性方面效果不佳的问题，并提高训练和验证的效率。

Method: 引入ReST-RL框架，结合优化的GRPO数据筛选与MCTS辅助的价值模型进行测试时间解码。

Result: 在多个编码任务基准测试中显著优于现有方法，有效提升LLM的推理能力。

Conclusion: ReST-RL是一种有效提升LLM代码推理性能的统一RL范式，具有良好的实际应用潜力。

Abstract: With respect to improving the reasoning accuracy of LLMs, the representative
reinforcement learning (RL) method GRPO faces failure due to insignificant
reward variance, while verification methods based on process reward models
(PRMs) suffer from difficulties with training data acquisition and verification
effectiveness. To tackle these problems, this paper introduces ReST-RL, a
unified LLM RL paradigm that significantly improves LLM's code reasoning
ability by combining an improved GRPO algorithm with a meticulously designed
test time decoding method assisted by a value model (VM). As the first stage of
policy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter
and assemble high-value training data, increasing the reward variance of GRPO
sampling, thus improving the effectiveness and efficiency of training. After
the basic reasoning ability of LLM policy has been improved, we further propose
a test time decoding optimization method called VM-MCTS. Through Monte-Carlo
Tree Search (MCTS), we collect accurate value targets with no annotation
required, on which VM training is based. When decoding, the VM is deployed by
an adapted MCTS algorithm to provide precise process signals as well as
verification scores, assisting the LLM policy to achieve high reasoning
accuracy. We validate the effectiveness of the proposed RL paradigm through
extensive experiments on coding problems. Upon comparison, our approach
significantly outperforms other reinforcement training baselines (e.g., naive
GRPO and ReST-DPO), as well as decoding and verification baselines (e.g.,
PRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g.,
APPS, BigCodeBench, and HumanEval), indicating its power to strengthen the
reasoning ability of LLM policies. Codes for our project can be found at
https://github.com/THUDM/ReST-RL.

</details>


### [141] [Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties](https://arxiv.org/abs/2508.19611)
*Huaiyuan Yao,Wanpeng Xu,Justin Turnau,Nadia Kellam,Hua Wei*

Main category: cs.AI

TL;DR: 本文提出了Instructional Agents框架，利用多智能体大模型自动生成课程材料，实现教学内容的自动化，与传统工具相比更高效，特别适合资源有限的教育环境。


<details>
  <summary>Details</summary>
Motivation: 高质量教学材料的准备耗时耗力，迫切需要自动化解决方案。

Method: 开发多智能体大模型框架，模拟角色合作，支持多种操作模式，评估其在大学课程中的表现。

Result: 系统能高效生成优质教材，显著缩短开发时间，减轻人力负担，适用范围广。

Conclusion: Instructional Agents为教育内容自动化提供有效方案，具有推广价值，特别在资源匮乏环境中具有重要意义。

Abstract: Preparing high-quality instructional materials remains a labor-intensive
process that often requires extensive coordination among teaching faculty,
instructional designers, and teaching assistants. In this work, we present
Instructional Agents, a multi-agent large language model (LLM) framework
designed to automate end-to-end course material generation, including syllabus
creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing
AI-assisted educational tools that focus on isolated tasks, Instructional
Agents simulates role-based collaboration among educational agents to produce
cohesive and pedagogically aligned content. The system operates in four modes:
Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling
flexible control over the degree of human involvement. We evaluate
Instructional Agents across five university-level computer science courses and
show that it produces high-quality instructional materials while significantly
reducing development time and human workload. By supporting institutions with
limited instructional design capacity, Instructional Agents provides a scalable
and cost-effective framework to democratize access to high-quality education,
particularly in underserved or resource-constrained settings.

</details>


### [142] [InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.19679)
*Qihang Ai,Pi Bu,Yue Cao,Yingyao Wang,Jihao Gu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Zhicheng Zheng,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 提出InquireBench和InquireMobile，提升移动智能体安全交互能力。


<details>
  <summary>Details</summary>
Motivation: 解决Vision-Language Models在自主场景中安全性不足的问题。

Method: 构建专门的评估基准(InquireBench)，并设计基于强化学习的交互模型(InquireMobile)，采用双阶段训练和主动询问机制。

Result: 模型在InquireBench上询问成功率提升46.8%，优于现有基线。

Conclusion: 所提出的方法有效提升移动智能体的安全交互能力，相关数据和模型将开源，促进行业发展。

Abstract: Recent advances in Vision-Language Models (VLMs) have enabled mobile agents
to perceive and interact with real-world mobile environments based on human
instructions. However, the current fully autonomous paradigm poses potential
safety risks when model understanding or reasoning capabilities are
insufficient. To address this challenge, we first introduce
\textbf{InquireBench}, a comprehensive benchmark specifically designed to
evaluate mobile agents' capabilities in safe interaction and proactive inquiry
with users, encompassing 5 categories and 22 sub-categories, where most
existing VLM-based agents demonstrate near-zero performance. In this paper, we
aim to develop an interactive system that actively seeks human confirmation at
critical decision points. To achieve this, we propose \textbf{InquireMobile}, a
novel model inspired by reinforcement learning, featuring a two-stage training
strategy and an interactive pre-action reasoning mechanism. Finally, our model
achieves an 46.8% improvement in inquiry success rate and the best overall
success rate among existing baselines on InquireBench. We will open-source all
datasets, models, and evaluation codes to facilitate development in both
academia and industry.

</details>


### [143] [Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?](https://arxiv.org/abs/2508.19827)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.AI

TL;DR: 链式思考法（CoT）在软推理任务中的效果有限且不总是忠实于模型的推理过程。


<details>
  <summary>Details</summary>
Motivation: 探讨CoT在不同模型中的表现差异及其推理忠实性，为改进软推理方法提供参考。

Method: 分析多种经过指令调优、推理和推理蒸馏的模型中CoT的动态及其影响。

Result: 不同模型对CoT的依赖性不同，且影响力与忠实性不总是同步。

Conclusion: 需要平衡CoT的影响力与推理忠实性，以提升软推理任务的效果。

Abstract: Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited
gains for soft-reasoning problems such as analytical and commonsense reasoning.
CoT can also be unfaithful to a model's actual reasoning. We investigate the
dynamics and faithfulness of CoT in soft-reasoning tasks across
instruction-tuned, reasoning and reasoning-distilled models. Our findings
reveal differences in how these models rely on CoT, and show that CoT influence
and faithfulness are not always aligned.

</details>


### [144] [Tracking World States with Language Models: State-Based Evaluation Using Chess](https://arxiv.org/abs/2508.19851)
*Romain Harang,Jason Naradowsky,Yaswitha Gujju,Yusuke Miyao*

Main category: cs.AI

TL;DR: 提出一种基于状态的模型不可知评估框架，用于评估LLMs在结构化环境中的语义保持能力，特别以国际象棋为例，检测模型在长序列中保持内部状态的不足。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在结构化环境中的语义保持能力，解决现有探测技术受限的问题。

Method: 采用基于棋盘状态的评估，通过分析合法走子的分布比对预测与实际状态，以评估模型的语义一致性。

Result: 该指标能有效识别模型在长序列中维护连贯内部模型的不足，验证了方法的有效性。

Conclusion: 该框架无需访问模型内部结构，具有高度通用性，为结构化推理能力的评估提供新工具，尤其在符号环境中表现优越。

Abstract: Large Language Models (LLMs) exhibit emergent capabilities in structured
domains, suggesting they may implicitly internalize high-fidelity
representations of world models. While probing techniques have shown promising
signs of this in scientific and game-based settings, they rely on
model-specific internal activations, which limit interpretability and
generalizability. In this work, we propose a model-agnostic, state-based
evaluation framework using chess as a benchmark to assess whether LLMs preserve
the semantics of structured environments. Our method analyzes the downstream
legal move distributions (state affordances) to estimate semantic fidelity
between predicted and actual game states. This approach offers a more
meaningful evaluation than conventional string-based metrics by aligning more
closely with the strategic and rule-governed nature of chess. Experimental
results demonstrate that our metrics capture deficiencies in state-tracking,
highlighting limitations of LLMs in maintaining coherent internal models over
long sequences. Our framework provides a robust tool for evaluating structured
reasoning in LLMs without requiring internal model access, and generalizes to a
wide class of symbolic environments.

</details>


### [145] [CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments](https://arxiv.org/abs/2508.19932)
*Nitish Jaipuria,Lorenzo Gatto,Zijun Kan,Shankey Poddar,Bill Cheung,Diksha Bansal,Ramanan Balakrishnan,Aviral Suri,Jose Estevez*

Main category: cs.AI

TL;DR: 提出了一种基于对话代理的智能框架CASE，用于收集和管理诈骗信息，提高诈骗防范效果。


<details>
  <summary>Details</summary>
Motivation: 在线支付平台面临日益复杂的诈骗手段，传统信号不足以应对。

Method: 开发基于大规模语言模型的对话代理，进行用户访谈和信息提取。

Result: 在Google Pay印度表现出色，诈骗执法增长21%。

Conclusion: 该架构具通用性，可应用于其他敏感领域的诈骗情报管理。

Abstract: The proliferation of digital payment platforms has transformed commerce,
offering unmatched convenience and accessibility globally. However, this growth
has also attracted malicious actors, leading to a corresponding increase in
sophisticated social engineering scams. These scams are often initiated and
orchestrated on multiple surfaces outside the payment platform, making user and
transaction-based signals insufficient for a complete understanding of the
scam's methodology and underlying patterns, without which it is very difficult
to prevent it in a timely manner. This paper presents CASE (Conversational
Agent for Scam Elucidation), a novel Agentic AI framework that addresses this
problem by collecting and managing user scam feedback in a safe and scalable
manner. A conversational agent is uniquely designed to proactively interview
potential victims to elicit intelligence in the form of a detailed
conversation. The conversation transcripts are then consumed by another AI
system that extracts information and converts it into structured data for
downstream usage in automated and manual enforcement mechanisms. Using Google's
Gemini family of LLMs, we implemented this framework on Google Pay (GPay)
India. By augmenting our existing features with this new intelligence, we have
observed a 21% uplift in the volume of scam enforcements. The architecture and
its robust evaluation framework are highly generalizable, offering a blueprint
for building similar AI-driven systems to collect and manage scam intelligence
in other sensitive domains.

</details>


### [146] [Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants](https://arxiv.org/abs/2508.19963)
*M. Umlauft,M. Schranz*

Main category: cs.AI

TL;DR: 本文提出利用模仿生物群体运动的“boids” flocking算法优化半导体生产线的机器切换，表现出对复杂切换问题的良好适应性。


<details>
  <summary>Details</summary>
Motivation: 优化大型半导体生产厂的调度问题，传统线性优化难以在合理时间内解决。

Method: 引入模仿鸟群行为的“boids”算法，通过局部互动实现设备切换优化。

Result: 算法有效应对机器转换问题，表现出类似鸟群避障行为的适应能力。

Conclusion: 基于生物启发的算法为复杂生产调度提供了新的解决方案，特别适合处理多样化的机器切换需求。

Abstract: Optimizing modern production plants using the job-shop principle is a known
hard problem. For very large plants, like semiconductor fabs, the problem
becomes unsolvable on a plant-wide scale in a reasonable amount of time using
classical linear optimization. An alternative approach is the use of swarm
intelligence algorithms. These have been applied to the job-shop problem
before, but often in a centrally calculated way where they are applied to the
solution space, but they can be implemented in a bottom-up fashion to avoid
global result computation as well. One of the problems in semiconductor
production is that the production process requires a lot of switching between
machines that process lots one after the other and machines that process
batches of lots at once, often with long processing times. In this paper, we
address this switching problem with the ``boids'' flocking algorithm that was
originally used in robotics and movie industry. The flocking behavior is a
bio-inspired algorithm that uses only local information and interaction based
on simple heuristics. We show that this algorithm addresses these valid
considerations in production plant optimization, as it reacts to the switching
of machine kinds similar to how a swarm of flocking animals would react to
obstacles in its course.

</details>


### [147] [SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control](https://arxiv.org/abs/2508.20018)
*Quanfeng Lu,Zhantao Ma,Shuai Zhong,Jin Wang,Dahai Yu,Michael K. Ng,Ping Luo*

Main category: cs.AI

TL;DR: 引入SWIRL方法，通过逐步单智能体强化学习提升多智能体系统在GUI控制和数学推理中的表现，确保训练稳定性和优化理论保障。


<details>
  <summary>Details</summary>
Motivation: 随着大视觉语言模型和智能体系统的发展，需要高效可靠的多智能体协作方法，以突破现有单智能体的局限。

Method: 将多智能体强化学习转化为交替单智能体强化学习，逐个更新智能体，结合理论保障和实际应用示例。

Result: 在GUI任务和数学推理中表现优异，验证了其高效性、稳定性和推广潜力。

Conclusion: SWIRL为构建高效稳定的多智能体系统提供了新途径，具有广泛应用前景。

Abstract: The rapid advancement of large vision language models (LVLMs) and agent
systems has heightened interest in mobile GUI agents that can reliably
translate natural language into interface operations. Existing single-agent
approaches, however, remain limited by structural constraints. Although
multi-agent systems naturally decouple different competencies, recent progress
in multi-agent reinforcement learning (MARL) has often been hindered by
inefficiency and remains incompatible with current LVLM architectures. To
address these challenges, we introduce SWIRL, a staged workflow for interleaved
reinforcement learning designed for multi-agent systems. SWIRL reformulates
MARL into a sequence of single-agent reinforcement learning tasks, updating one
agent at a time while keeping the others fixed. This formulation enables stable
training and promotes efficient coordination across agents. Theoretically, we
provide a stepwise safety bound, a cross-round monotonic improvement theorem,
and convergence guarantees on return, ensuring robust and principled
optimization. In application to mobile GUI control, SWIRL instantiates a
Navigator that converts language and screen context into structured plans, and
an Interactor that grounds these plans into executable atomic actions.
Extensive experiments demonstrate superior performance on both high-level and
low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong
capability in multi-agent mathematical reasoning, underscoring its potential as
a general framework for developing efficient and robust multi-agent systems.

</details>


### [148] [Model Science: getting serious about verification, explanation and control of AI systems](https://arxiv.org/abs/2508.20040)
*Przemyslaw Biecek,Wojciech Samek*

Main category: cs.AI

TL;DR: 提出一种以模型为核心的学科框架，强调验证、解释、控制和界面四大支柱，以实现可信、安全、与人类协同的AI系统。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的广泛应用，单纯数据驱动的方法已不足以应对模型的复杂性和动态性，亟需转向以模型为中心的学科。

Method: 提出一个概念框架，定义模型科学的四个关键支柱：验证、解释、控制和界面。

Result: 该框架明确了模型科学的发展方向，为构建可信、安全、与人类协作的AI系统提供指导。

Conclusion: 模型科学作为一门新学科，将推动AI的发展进入以模型为核心的新阶段，更好地实现模型的验证、理解、控制与人机交互。

Abstract: The growing adoption of foundation models calls for a paradigm shift from
Data Science to Model Science. Unlike data-centric approaches, Model Science
places the trained model at the core of analysis, aiming to interact, verify,
explain, and control its behavior across diverse operational contexts. This
paper introduces a conceptual framework for a new discipline called Model
Science, along with the proposal for its four key pillars: Verification, which
requires strict, context-aware evaluation protocols; Explanation, which is
understood as various approaches to explore of internal model operations;
Control, which integrates alignment techniques to steer model behavior; and
Interface, which develops interactive and visual explanation tools to improve
human calibration and decision-making. The proposed framework aims to guide the
development of credible, safe, and human-aligned AI systems.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [149] [AI for Statutory Simplification: A Comprehensive State Legal Corpus and Labor Benchmark](https://arxiv.org/abs/2508.19365)
*Emaan Hariri,Daniel E. Ho*

Main category: cs.IR

TL;DR: AI在法律代码简化中的应用尚处于探索阶段，现有模型准确率不足。


<details>
  <summary>Details</summary>
Motivation: 探索AI在法律代码简化中的潜力，评估其准确性和风险。

Method: 构建LaborBench问答基准数据集，结合国家层级法规数据，评估检索增强生成和大模型性能。

Result: 模型在辅助研究中表现较好，但整体准确率仍远低于理想，难以作为端到端简化工具。

Conclusion: 当前AI模型虽有潜力，但仍需改进以实现可靠的法律代码简化。

Abstract: One of the emerging use cases of AI in law is for code simplification:
streamlining, distilling, and simplifying complex statutory or regulatory
language. One U.S. state has claimed to eliminate one third of its state code
using AI. Yet we lack systematic evaluations of the accuracy, reliability, and
risks of such approaches. We introduce LaborBench, a question-and-answer
benchmark dataset designed to evaluate AI capabilities in this domain. We
leverage a unique data source to create LaborBench: a dataset updated annually
by teams of lawyers at the U.S. Department of Labor, who compile differences in
unemployment insurance laws across 50 states for over 101 dimensions in a
six-month process, culminating in a 200-page publication of tables. Inspired by
our collaboration with one U.S. state to explore using large language models
(LLMs) to simplify codes in this domain, where complexity is particularly
acute, we transform the DOL publication into LaborBench. This provides a unique
benchmark for AI capacity to conduct, distill, and extract realistic statutory
and regulatory information. To assess the performance of retrieval augmented
generation (RAG) approaches, we also compile StateCodes, a novel and
comprehensive state statute and regulatory corpus of 8.7 GB, enabling much more
systematic research into state codes. We then benchmark the performance of
information retrieval and state-of-the-art large LLMs on this data and show
that while these models are helpful as preliminary research for code
simplification, the overall accuracy is far below the touted promises for LLMs
as end-to-end pipelines for regulatory simplification.

</details>


### [150] [APS Explorer: Navigating Algorithm Performance Spaces for Informed Dataset Selection](https://arxiv.org/abs/2508.19399)
*Tobias Vente,Michael Heep,Abdullah Abbas,Theodor Sperle,Joeran Beel,Bart Goethals*

Main category: cs.IR

TL;DR: 介绍了一个用于推荐系统数据集选择的交互式可视化工具APS Explorer，通过多种可视化帮助用户进行数据驱动的决策。


<details>
  <summary>Details</summary>
Motivation: 发现当前研究中缺乏便于探索算法性能空间的直观工具，影响数据集选择的合理性。

Method: 开发了基于网页的APS Explorer，集成PCA、元特征比较表和成对算法性能可视化。

Result: 该工具提升了数据集选择的效率和科学性，有助于提高推荐系统研究的可靠性。

Conclusion: APS Explorer为学习和应用算法性能空间提供了有力支持，推动推荐系统数据集选择的标准化。

Abstract: Dataset selection is crucial for offline recommender system experiments, as
mismatched data (e.g., sparse interaction scenarios require datasets with low
user-item density) can lead to unreliable results. Yet, 86\% of ACM RecSys 2024
papers provide no justification for their dataset choices, with most relying on
just four datasets: Amazon (38\%), MovieLens (34\%), Yelp (15\%), and Gowalla
(12\%). While Algorithm Performance Spaces (APS) were proposed to guide dataset
selection, their adoption has been limited due to the absence of an intuitive,
interactive tool for APS exploration. Therefore, we introduce the APS Explorer,
a web-based visualization tool for interactive APS exploration, enabling
data-driven dataset selection. The APS Explorer provides three interactive
features: (1) an interactive PCA plot showing dataset similarity via
performance patterns, (2) a dynamic meta-feature table for dataset comparisons,
and (3) a specialized visualization for pairwise algorithm performance.

</details>


### [151] [A Self-Supervised Mixture-of-Experts Framework for Multi-behavior Recommendation](https://arxiv.org/abs/2508.19507)
*Kyungho Kim,Sunwoo Kim,Geon Lee,Kijung Shin*

Main category: cs.IR

TL;DR: MEMBER通过专家混合模型有效提升对访问和未访问商品的推荐质量，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决多行为推荐系统在访问与未访问商品上的表现差异，提高整体推荐效果。

Method: 采用专家混合模型，各专家针对不同商品类型，结合自监督训练。

Result: 在实验中，MEMBER在两个商品类别上都表现优异，Hit Ratio@20提升最高达65.46%。

Conclusion: MEMBER成功弥合了访问与未访问商品推荐的差距，展示了多行为推荐系统的潜能。

Abstract: In e-commerce, where users face a vast array of possible item choices,
recommender systems are vital for helping them discover suitable items they
might otherwise overlook. While many recommender systems primarily rely on a
user's purchase history, recent multi-behavior recommender systems incorporate
various auxiliary user behaviors, such as item clicks and cart additions, to
enhance recommendations. Despite their overall performance gains, their
effectiveness varies considerably between visited items (i.e., those a user has
interacted with through auxiliary behaviors) and unvisited items (i.e., those
with which the user has had no such interactions). Specifically, our analysis
reveals that (1) existing multi-behavior recommender systems exhibit a
significant gap in recommendation quality between the two item types (visited
and unvisited items) and (2) achieving strong performance on both types with a
single model architecture remains challenging. To tackle these issues, we
propose a novel multi-behavior recommender system, MEMBER. It employs a
mixture-of-experts framework, with experts designed to recommend the two item
types, respectively. Each expert is trained using a self-supervised method
specialized for its design goal. In our comprehensive experiments, we show the
effectiveness of MEMBER across both item types, achieving up to 65.46\%
performance gain over the best competitor in terms of Hit Ratio@20.

</details>


### [152] [A Hybrid Recommendation Framework for Enhancing User Engagement in Local News](https://arxiv.org/abs/2508.19539)
*Payam Pourashraf,Bamshad Mobasher*

Main category: cs.IR

TL;DR: 结合本地与全球偏好模型的混合新闻推荐系统，提升地方新闻的用户参与度。


<details>
  <summary>Details</summary>
Motivation: 面对地方新闻机构读者流失和竞争压力，寻找有效的个性化推荐方案。

Method: 融合本地与非本地预测模型，通过集成策略和多阶段训练实现推荐优化。

Result: 在合成数据和真实数据集上均优于单一模型，提高准确性和覆盖率，增强个性化表现。

Conclusion: 融合本地和全球偏好模型的混合推荐系统，有助于加强地方新闻的用户粘性和订阅量，开辟新闻推荐的新方向。

Abstract: Local news organizations face an urgent need to boost reader engagement amid
declining circulation and competition from global media. Personalized news
recommender systems offer a promising solution by tailoring content to user
interests. Yet, conventional approaches often emphasize general preferences and
may overlook nuanced or eclectic interests in local news.
  We propose a hybrid news recommender that integrates local and global
preference models to improve engagement. Building on evidence of the value of
localized models, our method unifies local and non-local predictors in one
framework. The system adaptively combines recommendations from a local model,
specialized in region-specific content, and a global model that captures
broader preferences. Ensemble strategies and multiphase training balance the
two.
  We evaluated the model on two datasets: a synthetic set based on Syracuse
newspaper distributions and a Danish dataset (EB-NeRD) labeled for local and
non-local content with an LLM. Results show our integrated approach outperforms
single-model baselines in accuracy and coverage, suggesting improved
personalization that can drive user engagement.
  The findings have practical implications for publishers, especially local
outlets. By leveraging both community-specific and general user interests, the
hybrid recommender can deliver more relevant content, increasing retention and
subscriptions. In sum, this work introduces a new direction for recommender
systems, bridging local and global models to revitalize local news consumption
through scalable, personalized user experiences.

</details>


### [153] [Improving Recommendation Fairness via Graph Structure and Representation Augmentation](https://arxiv.org/abs/2508.19547)
*Tongxin Xu,Wenqiang Liu,Chenzhong Bin,Cihan Xiao,Zhixin Zeng,Tianlong Gu*

Main category: cs.IR

TL;DR: 提出一种结合信息检测与双重数据增强的公平推荐方法，有效改善偏见，提升公平性和保持推荐效用。


<details>
  <summary>Details</summary>
Motivation: 应对图卷积网络在推荐系统中导致信息泄露及偏见扩大问题，提高手段的公平性。

Method: 基于敏感交互与特征相似性进行数据增强，提出双重增强框架及去偏学习方法。

Result: 在真实数据集上实验验证了方法的有效性，优于现有技术。

Conclusion: 该方法有效平衡了公平性与推荐效果，为公平推荐提供新思路。

Abstract: Graph Convolutional Networks (GCNs) have become increasingly popular in
recommendation systems. However, recent studies have shown that GCN-based
models will cause sensitive information to disseminate widely in the graph
structure, amplifying data bias and raising fairness concerns. While various
fairness methods have been proposed, most of them neglect the impact of biased
data on representation learning, which results in limited fairness improvement.
Moreover, some studies have focused on constructing fair and balanced data
distributions through data augmentation, but these methods significantly reduce
utility due to disruption of user preferences. In this paper, we aim to design
a fair recommendation method from the perspective of data augmentation to
improve fairness while preserving recommendation utility. To achieve
fairness-aware data augmentation with minimal disruption to user preferences,
we propose two prior hypotheses. The first hypothesis identifies sensitive
interactions by comparing outcomes of performance-oriented and fairness-aware
recommendations, while the second one focuses on detecting sensitive features
by analyzing feature similarities between biased and debiased representations.
Then, we propose a dual data augmentation framework for fair recommendation,
which includes two data augmentation strategies to generate fair augmented
graphs and feature representations. Furthermore, we introduce a debiasing
learning method that minimizes the dependence between the learned
representations and sensitive information to eliminate bias. Extensive
experiments on two real-world datasets demonstrate the superiority of our
proposed framework.

</details>


### [154] [A Model-agnostic Strategy to Mitigate Embedding Degradation in Personalized Federated Recommendation](https://arxiv.org/abs/2508.19591)
*Jiakui Shen,Yunqi Mi,Guoshuai Zhao,Jialie Shen,Xueming Qian*

Main category: cs.IR

TL;DR: 提出一种针对联邦推荐系统中嵌入退化问题的模型无关个性化策略PLGC，增强个性化表达并减少冗余，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决联邦推荐系统中因数据分布异质性引起的嵌入退化和维度崩溃问题，提升个性化效果。

Method: 引入全局冻结的项目嵌入表，结合神经切线核策略动态平衡本地与全局信息，并采用对比学习减少嵌入冗余。

Result: 在五个真实数据集上，PLGC显著优于多种基线算法，验证了其有效性和适应性。

Conclusion: PLGC作为一种模型无关的个性化训练策略，有助于缓解联邦推荐中的嵌入退化，提升推荐性能。

Abstract: Centralized recommender systems encounter privacy leakage due to the need to
collect user behavior and other private data. Hence, federated recommender
systems (FedRec) have become a promising approach with an aggregated global
model on the server. However, this distributed training paradigm suffers from
embedding degradation caused by suboptimal personalization and dimensional
collapse, due to the existence of sparse interactions and heterogeneous
preferences. To this end, we propose a novel model-agnostic strategy for FedRec
to strengthen the personalized embedding utility, which is called Personalized
Local-Global Collaboration (PLGC). It is the first research in federated
recommendation to alleviate the dimensional collapse issue. Particularly, we
incorporate the frozen global item embedding table into local devices. Based on
a Neural Tangent Kernel strategy that dynamically balances local and global
information, PLGC optimizes personalized representations during forward
inference, ultimately converging to user-specific preferences. Additionally,
PLGC carries on a contrastive objective function to reduce embedding redundancy
by dissolving dependencies between dimensions, thereby improving the backward
representation learning process. We introduce PLGC as a model-agnostic
personalized training strategy for federated recommendations that can be
applied to existing baselines to alleviate embedding degradation. Extensive
experiments on five real-world datasets have demonstrated the effectiveness and
adaptability of PLGC, which outperforms various baseline algorithms.

</details>


### [155] [A Scenario-Oriented Survey of Federated Recommender Systems: Techniques, Challenges, and Future Directions](https://arxiv.org/abs/2508.19620)
*Yunqi Mi,Jiakui Shen,Guoshuai Zhao,Jialie Shen,Xueming Qian*

Main category: cs.IR

TL;DR: 本文综述了联邦学习在推荐系统中的应用，强调解决实际场景中的挑战，促进实际部署。


<details>
  <summary>Details</summary>
Motivation: 由于用户数据隐私保护的需求，推动将推荐系统与联邦学习结合，但现有研究多忽视实际场景的特殊性与挑战，亟需系统性分析。

Method: 从推荐场景和联邦学习框架出发，分析场景特定的方法、挑战及机遇，建立实际应用与理论研究的桥梁。

Result: 提出了基于场景的联邦推荐系统分析框架，揭示了不同场景下的技术难题和解决路径，指导实用化部署。

Conclusion: 本综述推动了将联邦学习应用于推荐系统的深入理解，为实际推广提供理论支持和实践建议。

Abstract: Extending recommender systems to federated learning (FL) frameworks to
protect the privacy of users or platforms while making recommendations has
recently gained widespread attention in academia. This is due to the natural
coupling of recommender systems and federated learning architectures: the data
originates from distributed clients (mostly mobile devices held by users),
which are highly related to privacy. In a centralized recommender system
(CenRec), the central server collects clients' data, trains the model, and
provides the service. Whereas in federated recommender systems (FedRec), the
step of data collecting is omitted, and the step of model training is offloaded
to each client. The server only aggregates the model and other knowledge, thus
avoiding client privacy leakage. Some surveys of federated recommender systems
discuss and analyze related work from the perspective of designing FL systems.
However, their utility drops by ignoring specific recommendation scenarios'
unique characteristics and practical challenges. For example, the statistical
heterogeneity issue in cross-domain FedRec originates from the label drift of
the data held by different platforms, which is mainly caused by the recommender
itself, but not the federated architecture. Therefore, it should focus more on
solving specific problems in real-world recommendation scenarios to encourage
the deployment FedRec. To this end, this review comprehensively analyzes the
coupling of recommender systems and federated learning from the perspective of
recommendation researchers and practitioners. We establish a clear link between
recommendation scenarios and FL frameworks, systematically analyzing
scenario-specific approaches, practical challenges, and potential
opportunities. We aim to develop guidance for the real-world deployment of
FedRec, bridging the gap between existing research and applications.

</details>


### [156] [Youtu-GraphRAG: Vertically Unified Agents for Graph Retrieval-Augmented Complex Reasoning](https://arxiv.org/abs/2508.19855)
*Junnan Dong,Siyu An,Yifei Yu,Qian-Wen Zhang,Linhao Luo,Xiao Huang,Yunsheng Wu,Di Yin,Xing Sun*

Main category: cs.IR

TL;DR: 提出Youtu-GraphRAG，一种垂直统一的图检索增强生成方法，通过结构化图谱和社区检测改善逻辑推理和知识组织，显著提升模型性能和效率。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有图检索和图构建分离带来的性能低下问题，提升模型在领域迁移中的表现。

Method: 引入种子图架构、双感知社区检测、代理式检索机制，以及匿名数据集和反匿名任务，实现框架的整体融合与优化。

Result: 在六个挑战性基准测试中，显著提高性能，节省90.71%标记成本，准确率提升16.62%，展现出极强的适应性和鲁棒性。

Conclusion: Youtu-GraphRAG通过整合多层次知识组织和推理机制，有效提升复杂推理能力和跨领域迁移能力，推动图增强生成的发展。

Abstract: Graph retrieval-augmented generation (GraphRAG) has effectively enhanced
large language models in complex reasoning by organizing fragmented knowledge
into explicitly structured graphs. Prior efforts have been made to improve
either graph construction or graph retrieval in isolation, yielding suboptimal
performance, especially when domain shifts occur. In this paper, we propose a
vertically unified agentic paradigm, Youtu-GraphRAG, to jointly connect the
entire framework as an intricate integration. Specifically, (i) a seed graph
schema is introduced to bound the automatic extraction agent with targeted
entity types, relations and attribute types, also continuously expanded for
scalability over unseen domains; (ii) To obtain higher-level knowledge upon the
schema, we develop novel dually-perceived community detection, fusing
structural topology with subgraph semantics for comprehensive knowledge
organization. This naturally yields a hierarchical knowledge tree that supports
both top-down filtering and bottom-up reasoning with community summaries; (iii)
An agentic retriever is designed to interpret the same graph schema to
transform complex queries into tractable and parallel sub-queries. It
iteratively performs reflection for more advanced reasoning; (iv) To alleviate
the knowledge leaking problem in pre-trained LLM, we propose a tailored
anonymous dataset and a novel 'Anonymity Reversion' task that deeply measures
the real performance of the GraphRAG frameworks. Extensive experiments across
six challenging benchmarks demonstrate the robustness of Youtu-GraphRAG,
remarkably moving the Pareto frontier with up to 90.71% saving of token costs
and 16.62% higher accuracy over state-of-the-art baselines. The results
indicate our adaptability, allowing seamless domain transfer with minimal
intervention on schema.

</details>


### [157] [Refining Text Generation for Realistic Conversational Recommendation via Direct Preference Optimization](https://arxiv.org/abs/2508.19918)
*Manato Tajiri,Michimasa Inaba*

Main category: cs.IR

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Conversational Recommender Systems (CRSs) aim to elicit user preferences via
natural dialogue to provide suitable item recommendations. However, current
CRSs often deviate from realistic human interactions by rapidly recommending
items in brief sessions. This work addresses this gap by leveraging Large
Language Models (LLMs) to generate dialogue summaries from dialogue history and
item recommendation information from item description. This approach enables
the extraction of both explicit user statements and implicit preferences
inferred from the dialogue context. We introduce a method using Direct
Preference Optimization (DPO) to ensure dialogue summary and item
recommendation information are rich in information crucial for effective
recommendations. Experiments on two public datasets validate our method's
effectiveness in fostering more natural and realistic conversational
recommendation processes.Our implementation is publicly available
at:https://github.com/UEC-InabaLab/Refining-LLM-Text

</details>
