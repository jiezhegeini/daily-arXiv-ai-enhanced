<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.IR](#cs.IR) [Total: 31]
- [cs.LG](#cs.LG) [Total: 49]
- [cs.AI](#cs.AI) [Total: 28]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare](https://arxiv.org/abs/2508.05722)
*Rania Al-Sabbagh*

Main category: cs.CL

TL;DR: PEACH是一个面向医疗文本的英语-阿拉伯语句子对齐平行语料库，包含约51,671句，支持多种研究和应用。


<details>
  <summary>Details</summary>
Motivation: 随着医疗信息跨语言交流的重要性增加，建立高质量的平行语料库对于改善机器翻译和相关研究具有重要意义。

Method: 手动对齐患者信息手册和教育材料，建立高标准的平行语料库。

Result: 构建一个包含约52,000句的英语-阿拉伯语平行语料库，具备高质量和多用途，可用于语言对比、翻译研究、模型训练和教育等。

Conclusion: PEACH为医疗领域的跨语言交流提供了宝贵资源，促进相关技术和研究的发展，且公开可用。

Abstract: This paper introduces PEACH, a sentence-aligned parallel English-Arabic
corpus of healthcare texts encompassing patient information leaflets and
educational materials. The corpus contains 51,671 parallel sentences, totaling
approximately 590,517 English and 567,707 Arabic word tokens. Sentence lengths
vary between 9.52 and 11.83 words on average. As a manually aligned corpus,
PEACH is a gold-standard corpus, aiding researchers in contrastive linguistics,
translation studies, and natural language processing. It can be used to derive
bilingual lexicons, adapt large language models for domain-specific machine
translation, evaluate user perceptions of machine translation in healthcare,
assess patient information leaflets and educational materials' readability and
lay-friendliness, and as an educational resource in translation studies. PEACH
is publicly accessible.

</details>


### [2] [Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation](https://arxiv.org/abs/2508.05775)
*Chi Zhang,Changjia Zhu,Junjie Xiong,Xiaoran Xu,Lingyao Li,Yao Liu,Zhuo Lu*

Main category: cs.CL

TL;DR: 大型语言模型在内容生成和理解方面带来巨大潜力，但也存在产生有害内容的风险。该调研系统总结了相关危害及应对策略，包括内容审查和安全性改进。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，其潜在的风险和危害引发关注，亟需系统研究其安全性与责任归属。

Method: 本文通过文献综述，分类总结了LLM相关的有害行为及防护技术，分析了多模态及破解策略，评价了现有的缓解措施。

Result: 提出了统一的危害与防护分类体系，分析了多模态与破解手段，评估了强化学习、提示工程和安全对齐等缓解措施，强调了安全性研究的不足与未来方向。

Conclusion: 未来需完善评估方法，强化模型安全性，推动伦理责任，确保LLMs的健康发展。

Abstract: Large Language Models (LLMs) have revolutionized content creation across
digital platforms, offering unprecedented capabilities in natural language
generation and understanding. These models enable beneficial applications such
as content generation, question and answering (Q&A), programming, and code
reasoning. Meanwhile, they also pose serious risks by inadvertently or
intentionally producing toxic, offensive, or biased content. This dual role of
LLMs, both as powerful tools for solving real-world problems and as potential
sources of harmful language, presents a pressing sociotechnical challenge. In
this survey, we systematically review recent studies spanning unintentional
toxicity, adversarial jailbreaking attacks, and content moderation techniques.
We propose a unified taxonomy of LLM-related harms and defenses, analyze
emerging multimodal and LLM-assisted jailbreak strategies, and assess
mitigation efforts, including reinforcement learning with human feedback
(RLHF), prompt engineering, and safety alignment. Our synthesis highlights the
evolving landscape of LLM safety, identifies limitations in current evaluation
methodologies, and outlines future research directions to guide the development
of robust and ethically aligned language technologies.

</details>


### [3] [FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification](https://arxiv.org/abs/2508.05782)
*Xiangyan Chen,Yufeng Li,Yujian Gan,Arkaitz Zubiaga,Matthew Purver*

Main category: cs.CL

TL;DR: 提出FineDialFact基准，用于细粒度的对话事实验证，强调链式推理的作用，揭示该任务仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 当前对话系统中的事实检测过于粗糙，难以区分真假事实，亟需更细粒度的验证工具。

Method: 构建细粒度对话事实验证基准数据集，评估多种基础方法，特别强调链式推理的效果。

Result: 链式推理提升了验证性能，但最高F1为0.75，显示任务仍具挑战性。

Conclusion: 该基准有助推动对话事实验证研究，但仍需方法创新以应对挑战。

Abstract: Large Language Models (LLMs) are known to produce hallucinations - factually
incorrect or fabricated information - which poses significant challenges for
many Natural Language Processing (NLP) applications, such as dialogue systems.
As a result, detecting hallucinations has become a critical area of research.
Current approaches to hallucination detection in dialogue systems primarily
focus on verifying the factual consistency of generated responses. However,
these responses often contain a mix of accurate, inaccurate or unverifiable
facts, making one factual label overly simplistic and coarse-grained. In this
paper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact
verification, which involves verifying atomic facts extracted from dialogue
responses. To support this, we construct a dataset based on publicly available
dialogue datasets and evaluate it using various baseline methods. Experimental
results demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning
can enhance performance in dialogue fact verification. Despite this, the best
F1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is
only 0.75, indicating that the benchmark remains a challenging task for future
research. Our dataset and code will be public on GitHub.

</details>


### [4] [Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models](https://arxiv.org/abs/2508.05803)
*Abishek Thamma,Micha Heilbron*

Main category: cs.CL

TL;DR: 短期记忆的有限性有助于语言学习，但不利于预测人类阅读时间。


<details>
  <summary>Details</summary>
Motivation: 探讨记忆限制对语言学习和人类阅读行为的影响。

Method: 在变换器（Transformer）模型上进行受控实验，比较有和没有短暂记忆的模型表现。

Result: 有限的记忆提升语言学习效果，但削弱了对阅读时间的预测能力。

Conclusion: 记忆限制有助于神经网络的语言学习，但不利于行为预测。

Abstract: Human memory is fleeting. As words are processed, the exact wordforms that
make up incoming sentences are rapidly lost. Cognitive scientists have long
believed that this limitation of memory may, paradoxically, help in learning
language - an idea supported by classic connectionist modelling work. The rise
of Transformers appears to challenge this idea, as these models can learn
language effectively, despite lacking memory limitations or other architectural
recency biases. Here, we investigate the hypothesized benefit of fleeting
memory for language learning in tightly controlled experiments on transformer
language models. Training transformers with and without fleeting memory on a
developmentally realistic training set, we find that fleeting memory
consistently improves language learning (as quantified by both overall language
modelling performance and targeted syntactic evaluation) but, unexpectedly,
impairs surprisal-based prediction of human reading times. Interestingly,
follow up analyses revealed that this discrepancy - better language modeling,
yet worse reading time prediction - could not be accounted for by prior
explanations of why better language models sometimes fit human reading time
worse. Together, these results support a benefit of memory limitations on
neural network language learning - but not on predicting behavior.

</details>


### [5] ["Mirror" Language AI Models of Depression are Criterion-Contaminated](https://arxiv.org/abs/2508.05830)
*Tong Li,Rasiq Hussain,Mehak Gupta,Joshua R. Oltmanns*

Main category: cs.CL

TL;DR: 研究表明，镜像模型在抑郁症预测中效果夸大，非镜像模型更具实用性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索不同模型在抑郁症预测中的差异，避免因标准污染导致的效果夸大。

Method: 比较镜像模型与非镜像模型在预测抑郁评分中的表现，采用语言模型（GPT-4等）对两类模型进行评估。

Result: 镜像模型表现出极高的效果大小（如R2=0.80），但存在偏差；非镜像模型表现较小，但更具普遍性（如R2=0.27），且两者在相关性上相似。

Conclusion: 镜像模型存在偏差和泛化能力不足，应考虑使用非镜像模型以获得更具解释力和实用性的心理评估工具。

Abstract: A growing number of studies show near-perfect LLM language-based prediction
of depression assessment scores (up to R2 of .70). However, many develop these
models directly from language responses to depression assessments. These
"Mirror models" suffer from "criterion contamination", which arises when a
predicted score depends in part on the predictors themselves. This causes
artificial effect size inflation which reduces model generalizability. The
present study compares the performance of Mirror models versus "Non-Mirror
models", which are developed from language that does not mirror the assessment
they are developed to predict. N = 110 research participants completed two
different interviews: structured diagnostic and life history interviews. GPT-4,
GPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic
interview depression scores from the two transcripts separately. Mirror models
(using structured diagnostic data) showed very large effect sizes (e.g., R2 =
.80). As expected, NonMirror models (using life history data) demonstrated
smaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror
and Non-Mirror model-predicted structured interview depression scores were
correlated with self-reported depression symptoms, Mirror and NonMirror
performed the same (e.g., r = ~.54), indicating that Mirror models contain bias
perhaps due to criterion contamination. Topic modeling identified clusters
across Mirror and Non-Mirror models, as well as between true-positive and
false-positive predictions. In this head-to-head comparison study, Mirror
language AI models of depression showed artificially inflated effect sizes and
less generalizability. As language AI models for depression continue to evolve,
incorporating Non-Mirror models may identify interpretable, and generalizable
semantic features that have unique utility in real-world psychological
assessment.

</details>


### [6] [Discovering Properties of Inflectional Morphology in Neural Emergent Communication](https://arxiv.org/abs/2508.05843)
*Miles Gilberti,Shane Storks,Huteng Dai*

Main category: cs.CL

TL;DR: 本文通过引入小词汇量限制和借鉴自然形态学属性，研究深度神经网络代理在模拟人类语言方面的表现，发现模拟语音限制可以促进链式结构的发展，而语言融合属性则更贴近自然语言的特征。


<details>
  <summary>Details</summary>
Motivation: 研究深度神经网络在模拟人类语言中的潜力，特别是理解自然语言结构的基础。

Method: 在属性值重建游戏中引入小词汇量限制，模拟双层发音结构，并探索拼接性和融合性对语言演化的影响。

Result: 模拟语音约束促进了链式（拼接）形态的发展，自然语言中的融合属性也在模拟中得到再现。

Conclusion: 引入形态学特性有助于理解语言演化的机制，为未来模仿自然语言提供了新的研究路径。

Abstract: Emergent communication (EmCom) with deep neural network-based agents promises
to yield insights into the nature of human language, but remains focused
primarily on a few subfield-specific goals and metrics that prioritize
communication schemes which represent attributes with unique characters
one-to-one and compose them syntactically. We thus reinterpret a common EmCom
setting, the attribute-value reconstruction game, by imposing a
small-vocabulary constraint to simulate double articulation, and formulating a
novel setting analogous to naturalistic inflectional morphology (enabling
meaningful comparison to natural language communication schemes). We develop
new metrics and explore variations of this game motivated by real properties of
inflectional morphology: concatenativity and fusionality. Through our
experiments, we discover that simulated phonological constraints encourage
concatenative morphology, and emergent languages replicate the tendency of
natural languages to fuse grammatical attributes.

</details>


### [7] [Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models](https://arxiv.org/abs/2508.05880)
*Sree Bhattacharyya,Lucas Craig,Tharun Dilliraj,Jia Li,James Z. Wang*

Main category: cs.CL

TL;DR: 探讨大型语言模型在情感认知推理中的表现，超越传统的情感识别任务，基于认知评估理论评估模型的内部认知结构和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的情感计算研究多集中于表面层次的情感识别，缺乏对模型内在认知推理机制的深入理解。

Method: 提出Cognitive Reasoning for Emotions (CoRE)基准，结合认知评估理论，评估LLMs在情感推理中的内部认知结构，通过大量实验分析模型的推理行为。

Result: 发现不同LLMs展现出多样的推理模式，部分模型能隐含利用认知评估维度，且不同情感类别可以通过认知维度进行解释。

Conclusion: 该研究推动对AI情感认知能力的深入理解，为未来开发具有人类般情感推理能力的AI系统提供基础。

Abstract: Affective Computing has been established as a crucial field of inquiry to
advance the holistic development of Artificial Intelligence (AI) systems.
Foundation models -- especially Large Language Models (LLMs) -- have been
evaluated, trained, or instruction-tuned in several past works, to become
better predictors or generators of emotion. Most of these studies, however,
approach emotion-related tasks in a supervised manner, assessing or training
the capabilities of LLMs using discrete emotion labels associated with stimuli
(e.g., text, images, video, audio). Evaluation studies, in particular, have
often been limited to standard and superficial emotion-related tasks, such as
the recognition of evoked or expressed emotions. In this paper, we move beyond
surface-level emotion tasks to investigate how LLMs reason about emotions
through cognitive dimensions. Drawing from cognitive appraisal theory, we
examine whether LLMs produce coherent and plausible cognitive reasoning when
reasoning about emotionally charged stimuli. We introduce a large-scale
benchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal
cognitive structures implicitly used by LLMs for emotional reasoning. Through a
plethora of evaluation experiments and analysis, we seek to answer: (a) Are
models more likely to implicitly rely on specific cognitive appraisal
dimensions?, (b) What cognitive dimensions are important for characterizing
specific emotions?, and, (c) Can the internal representations of different
emotion categories in LLMs be interpreted through cognitive appraisal
dimensions? Our results and analyses reveal diverse reasoning patterns across
different LLMs. Our benchmark and code will be made publicly available.

</details>


### [8] [Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05909)
*Zhanghao Hu,Qinglin Zhu,Siya Qi,Yulan He,Hanqi Yan,Lin Gui*

Main category: cs.CL

TL;DR: 提出SPS指标评估检索信息与生成内容的语义一致性，构建动态筛选和压缩检索总结的xCompress框架，提升问答性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有RAG评估中难以隔离检索贡献的问题，确保检索信息的相关性对生成质量的影响。

Method: 提出Spectrum Projection Score（SPS）指标，通过比较生成内容的特征空间与潜在空间的方向，评估检索总结的语义相关性，配合xCompress动态筛选和压缩检索总结。

Result: 在多个问答基准和开源LLMs上验证，SPS显著提升性能，并提供检索与生成关系的理论依据。

Conclusion: SPS为检索内容的相关性评估带来新的量化工具，xCompress提升整体效率，推动RAG方法的深入理解与优化。

Abstract: Large Language Models (LLMs) have shown improved generation performance
through retrieval-augmented generation (RAG) following the retriever-reader
paradigm, which supplements model inputs with externally retrieved knowledge.
However, prior work often evaluates RAG holistically, assessing the retriever
and reader jointly, making it difficult to isolate the true contribution of
retrieval, particularly given the prompt sensitivity of LLMs used as readers.
We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free
metric that allows the reader to gauge the semantic alignment of a retrieved
summary with its hidden representation by comparing the area formed by
generated tokens from the summary, and the principal directions of subspace in
the reader and to measure the relevance. Building on SPS we present xCompress,
an inference time controller framework that dynamically samples, ranks, and
compresses retrieval summary candidates. Extensive experiments on five QA
benchmarks with four open source LLMs show that SPS not only enhances
performance across a range of tasks but also provides a principled perspective
on the interaction between retrieval and generation.

</details>


### [9] [Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale](https://arxiv.org/abs/2508.05938)
*Rafal Kocielnik,Min Kim,Penphob,Boonyarungsrit,Fereshteh Soltani,Deshawn Sambrano,Animashree Anandkumar,R. Michael Alvarez*

Main category: cs.CL

TL;DR: 提出一种三阶段管道，用于高效高精度识别文本中的亲社会内容，结合人类和AI的合作改善标注质量，显著降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 随着对积极社会行为识别的需求增加，缺乏明确定义和标注数据成为挑战。

Method: 通过LLM策略筛选、人工-AI迭代优化定义，以及两阶段推理系统实现高效识别。

Result: 实现了约70%的推理成本降低和约0.90的高精度。

Conclusion: 结合人机合作和任务设计可以解决新兴责任AI任务的标注与推理难题。

Abstract: Detecting prosociality in text--communication intended to affirm, support, or
improve others' behavior--is a novel and increasingly important challenge for
trust and safety systems. Unlike toxic content detection, prosociality lacks
well-established definitions and labeled data, requiring new approaches to both
annotation and deployment. We present a practical, three-stage pipeline that
enables scalable, high-precision prosocial content classification while
minimizing human labeling effort and inference costs. First, we identify the
best LLM-based labeling strategy using a small seed set of human-labeled
examples. We then introduce a human-AI refinement loop, where annotators review
high-disagreement cases between GPT-4 and humans to iteratively clarify and
expand the task definition-a critical step for emerging annotation tasks like
prosociality. This process results in improved label quality and definition
alignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train
a two-stage inference system: a lightweight classifier handles high-confidence
predictions, while only $\sim$35\% of ambiguous instances are escalated to
GPT-4o. This architecture reduces inference costs by $\sim$70% while achieving
high precision ($\sim$0.90). Our pipeline demonstrates how targeted human-AI
interaction, careful task formulation, and deployment-aware architecture design
can unlock scalable solutions for novel responsible AI tasks.

</details>


### [10] [Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring](https://arxiv.org/abs/2508.05987)
*Chunyun Zhang,Hongyan Zhao,Chaoran Cui,Qilong Song,Zhiqing Lu,Shuai Gong,Kailin Liu*

Main category: cs.CL

TL;DR: ATOP通过联合学习话题共享和话题特有的特征，结合对抗训练和邻居分类器，有效改进了跨话题自动作文评分，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决跨话题自动作文评分中话题间差异带来的性能局限。

Method: 提出话题感知提示调优（ATOP），结合对抗训练和邻居分类器，优化话题共享与特有特征的学习。

Result: 在ASAP++数据集上显著优于现有方法，提升作文评分性能。

Conclusion: 通过联合多特征学习和强化训练策略，有效提升跨话题作文评分模型的适应性和准确性。

Abstract: Cross-topic automated essay scoring (AES) aims to develop a transferable
model capable of effectively evaluating essays on a target topic. A significant
challenge in this domain arises from the inherent discrepancies between topics.
While existing methods predominantly focus on extracting topic-shared features
through distribution alignment of source and target topics, they often neglect
topic-specific features, limiting their ability to assess critical traits such
as topic adherence. To address this limitation, we propose an Adversarial
TOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns
topic-shared and topic-specific features to improve cross-topic AES. ATOP
achieves this by optimizing a learnable topic-aware prompt--comprising both
shared and specific components--to elicit relevant knowledge from pre-trained
language models (PLMs). To enhance the robustness of topic-shared prompt
learning and mitigate feature scale sensitivity introduced by topic alignment,
we incorporate adversarial training within a unified regression and
classification framework. In addition, we employ a neighbor-based classifier to
model the local structure of essay representations and generate pseudo-labels
for target-topic essays. These pseudo-labels are then used to guide the
supervised learning of topic-specific prompts tailored to the target topic.
Extensive experiments on the publicly available ASAP++ dataset demonstrate that
ATOP significantly outperforms existing state-of-the-art methods in both
holistic and multi-trait essay scoring. The implementation of our method is
publicly available at: https://anonymous.4open.science/r/ATOP-A271.

</details>


### [11] [Crisp Attention: Regularizing Transformers via Structured Sparsity](https://arxiv.org/abs/2508.06016)
*Sagar Gandhi,Vishal Gandhi*

Main category: cs.CL

TL;DR: 引入结构化稀疏注意力机制不仅提升了模型效率，还改善了模型在情感分析任务中的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer中自注意力机制的计算复杂度问题，同时探索稀疏性对模型性能的影响。

Method: 在DistilBERT模型上引入80%的后处理稀疏注意力，通过微调在SST-2情感分析任务中进行实验。

Result: 模型准确率从基线的90.62%提升到91.59%，验证了稀疏性作为正则化的效果。

Conclusion: 稀疏注意力不仅提升效率，还能作为正则化手段改善模型性能，挑战了稀疏性必损性能的假设。

Abstract: The quadratic computational cost of the self-attention mechanism is a primary
challenge in scaling Transformer models. While attention sparsity is widely
studied as a technique to improve computational efficiency, it is almost
universally assumed to come at the cost of model accuracy. In this paper, we
report a surprising counter-example to this common wisdom. By introducing
structured, post-hoc sparsity to the attention mechanism of a DistilBERT model
during fine-tuning on the SST-2 sentiment analysis task, we find that model
accuracy improves significantly. Our model with 80\% attention sparsity
achieves a validation accuracy of 91.59\%, a 0.97\% absolute improvement over
the dense baseline. We hypothesize that this phenomenon is due to sparsity
acting as a powerful implicit regularizer, preventing the model from
overfitting by forcing it to make predictions with a more constrained and
robust set of features. Our work recasts attention sparsity not just as a tool
for computational efficiency, but as a potential method for improving the
generalization and performance of Transformer models.

</details>


### [12] [Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future](https://arxiv.org/abs/2508.06026)
*Yidong Wang,Xin Wang,Cunxiang Wang,Junfeng Fang,Qiufeng Wang,Jianing Chu,Xuran Meng,Shuxun Yang,Libo Qin,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.CL

TL;DR: 提出一种Temporal Self-Rewarding Language Models方法，有效改善自我奖励模型中的表示差异问题，增强生成和学习能力。


<details>
  <summary>Details</summary>
Motivation: 自我奖励语言模型在提升生成能力方面存在表示差异逐渐缩小的问题，限制了有效偏好学习。

Method: 引入双阶段框架：固定拒绝样本（Anchored Rejection）和动态挑选样本（Future-Guided Chosen），协调不同时间点模型生成，维持学习信号。

Result: 在多种模型和任务中，表现优于传统自我奖励方法，例如Llama3.1-8B在AlpacaEval 2.0中的胜率提升至29.44，且具有更强的跨分布泛化能力。

Conclusion: 原始的自我奖励模型存在代表差异缩小的问题，通过时间协调策略能显著提升模型性能和泛化能力。

Abstract: Self-Rewarding Language Models propose an architecture in which the Large
Language Models(LLMs) both generates responses and evaluates its own outputs
via LLM-as-a-Judge prompting, dynamically improving its generative capabilities
through iterative Direct Preference Optimization (DPO). However, our analysis
reveals a critical limitation in existing Self-Rewarding paradigms: the
synchronized improvement of chosen and rejected responses progressively narrows
the representational difference between contrasting samples, undermining
effective preference learning. We propose \textbf{Temporal Self-Rewarding
Language Models} that strategically coordinate past, present, and future model
generations to sustain learning signals. Our dual-phase framework introduces:
(1) \textit{Anchored Rejection} - fixing rejected responses using the past
initial model's outputs and (2) \textit{Future-Guided Chosen} - dynamically
curating chosen samples using next-generation model predictions. Extensive
experiments across three model families (Llama, Qwen, Mistral) and different
model sizes (Llama3B/8B/70B) demonstrate significant improvements when trained
with our method compared to Self-Rewarding using same computation resources.
For example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our
method, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our
method also demonstrates superior out-of-distribution generalization across
mathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code
generation (HumanEval) tasks, even though we do not specifically collect such
training data.

</details>


### [13] [Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings](https://arxiv.org/abs/2508.06030)
*Kartik Sharma,Yiqiao Jin,Rakshit Trivedi,Srijan Kumar*

Main category: cs.CL

TL;DR: 提出PEEK方法，利用预训练嵌入模型预测大型语言模型的知识，以减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 目前探查LLMs知识的方法计算成本高，需频繁调用模型，效率低下。

Method: 通过识别已知事实集，训练嵌入模型线性预测LLM输出，评估其预测能力。

Result: 嵌入模型能以高达90%的准确率预测LLMs的知识，尤其句子嵌入模型优于图嵌入模型。

Conclusion: 知识适应的嵌入可用于大规模识别LLMs知识空缺，深化对模型内部偏置的理解，提升效率。

Abstract: Large language models (LLMs) acquire knowledge across diverse domains such as
science, history, and geography encountered during generative pre-training.
However, due to their stochasticity, it is difficult to predict what LLMs have
acquired. Prior work has developed different ways to probe this knowledge by
investigating the hidden representations, crafting specific task prompts,
curating representative samples, and estimating their uncertainty. However,
these methods require making forward passes through the underlying model to
probe the LLM's knowledge about a specific fact, making them computationally
expensive and time-consuming. To bridge this gap, we propose $\textbf{PEEK}$ or
$\textbf{P}$roxy $\textbf{E}$mbeddings to $\textbf{E}$stimate
$\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models
that effectively encode factual knowledge as text or graphs as proxies for
LLMs. First, we identify a training set of facts known by LLMs through various
probing strategies and then adapt embedding models to predict the LLM outputs
with a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived
datasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict
LLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find
that sentence embedding models are more suitable than graph embeddings to
predict LLM knowledge, shedding light on the underlying representation of the
factual landscape. Thus, we believe that knowledge-adapted embeddings can be
used to identify knowledge gaps in LLMs at scale and can provide deeper
insights into LLMs' internal inductive bias. The code and data are made
available at https://github.com/claws-lab/peek.

</details>


### [14] [EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation](https://arxiv.org/abs/2508.06046)
*Xinda Wang,Zhengxu Hou,Yangshijie Zhang,Bingren Yan,Zhibo Yang,Xingsheng Zhang,Luxi Xing,Qiang Zhou,Chen Zhang*

Main category: cs.CL

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Although the effectiveness of Large Language Models (LLMs) as judges
(LLM-as-a-judge) has been validated, their performance remains limited in
open-ended tasks, particularly in story evaluation. Accurate story evaluation
is crucial not only for assisting human quality judgment but also for providing
key signals to guide story generation. However, existing methods face a
dilemma: prompt engineering for closed-source models suffers from poor
adaptability, while fine-tuning approaches for open-source models lack the
rigorous reasoning capabilities essential for story evaluation. To address
this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.
Grounded in pairwise comparison, the framework first self-synthesizes
score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To
ensure data quality, these raw CoTs undergo a self-filtering process, utilizing
multi-agents to guarantee their logical rigor and robustness. Finally, the
evaluator trained on the refined data is deployed as a reward model to guide
the story generation task. Experimental results demonstrate that our framework
achieves state-of-the-art (SOTA) performance on three evaluation benchmarks
including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward
model, it significantly enhances the quality of generated stories, thereby
fully validating the superiority of our self-evolving approach.

</details>


### [15] [ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline](https://arxiv.org/abs/2508.06094)
*Morris Alper,Moran Yanuka,Raja Giryes,Gašper Beguš*

Main category: cs.CL

TL;DR: 利用大规模语言模型自动生成多样化的构造语，展现其在语言设计中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统构造语需要丰富的语言学知识，自动化工具难以实现多样性和一致性。

Method: 设计了多阶段的管道，利用LLMs的元语言推理能力，通过引入随机性和自我优化实现端到端的构造语生成。

Result: 生成的构造语在连贯性和类型学多样性方面表现优异，且无需人类语言学专家干预。

Conclusion: 采用LLMs的元推理能力可以高效自动化生成多样且一致的构造语，促进创造性语言研究与应用。

Abstract: Constructed languages (conlangs) such as Esperanto and Quenya have played
diverse roles in art, philosophy, and international communication. Meanwhile,
large-scale foundation models have revolutionized creative generation in text,
images, and beyond. In this work, we leverage modern LLMs as computational
creativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a
multi-hop pipeline that decomposes language design into modular stages --
phonology, morphology, syntax, lexicon generation, and translation. At each
stage, our method leverages LLMs' meta-linguistic reasoning capabilities,
injecting randomness to encourage diversity and leveraging self-refinement
feedback to encourage consistency in the emerging language description. We
evaluate ConlangCrafter on metrics measuring coherence and typological
diversity, demonstrating its ability to produce coherent and varied conlangs
without human linguistic expertise.

</details>


### [16] [Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs](https://arxiv.org/abs/2508.06103)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 本文提出了两种在古兰经问答任务中的提取式问答方法，包括少样本提示与专门的阿拉伯语提示框架，显著提升了效果。


<details>
  <summary>Details</summary>
Motivation: 解决古兰经问答中复杂语言、专业术语和深层意蕴的挑战。

Method: 结合少样本提示、专门的阿拉伯语提示框架和后处理系统，有效提升问答精度。

Result: 在评估中，基于指令的大模型优于传统微调模型，最优配置的pAP10达0.637。

Conclusion: 提示式指令调优在资源有限、语义丰富的问答任务中非常有效，验证了其应用潜力。

Abstract: This paper presents two effective approaches for Extractive Question
Answering (QA) on the Quran. It addresses challenges related to complex
language, unique terminology, and deep meaning in the text. The second uses
few-shot prompting with instruction-tuned large language models such as Gemini
and DeepSeek. A specialized Arabic prompt framework is developed for span
extraction. A strong post-processing system integrates subword alignment,
overlap suppression, and semantic filtering. This improves precision and
reduces hallucinations. Evaluations show that large language models with Arabic
instructions outperform traditional fine-tuned models. The best configuration
achieves a pAP10 score of 0.637. The results confirm that prompt-based
instruction tuning is effective for low-resource, semantically rich QA tasks.

</details>


### [17] [You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures](https://arxiv.org/abs/2508.06105)
*Shengyuan Chen,Chuang Zhou,Zheng Yuan,Qinggang Zhang,Zeyang Cui,Hao Chen,Yilin Xiao,Jiannong Cao,Xiao Huang*

Main category: cs.CL

TL;DR: 提出一个无需预建图结构的动态推理结构检索增强生成框架LogicRAG，有效提升多样化问答任务的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的图结构RAG方法依赖昂贵的预构建图，难以应对不同逻辑结构的查询，导致知识检索效果不佳。

Method: 通过在推理时动态分解问题、构建有向无环图（DAG）、拓扑排序和剪枝策略，实现灵活且高效的逻辑导向检索。

Result: 在多项任务中，LogicRAG在性能和效率方面优于现有最优方法，验证了其有效性和实用性。

Conclusion: LogicRAG展现出强大的适应性和高效性，提供了无需预设知识图的动态推理框架，推动知识增强生成技术的发展。

Abstract: Large language models (LLMs) often suffer from hallucination, generating
factually incorrect statements when handling questions beyond their knowledge
and perception. Retrieval-augmented generation (RAG) addresses this by
retrieving query-relevant contexts from knowledge bases to support LLM
reasoning. Recent advances leverage pre-constructed graphs to capture the
relational connections among distributed documents, showing remarkable
performance in complex tasks. However, existing Graph-based RAG (GraphRAG)
methods rely on a costly process to transform the corpus into a graph,
introducing overwhelming token cost and update latency. Moreover, real-world
queries vary in type and complexity, requiring different logic structures for
accurate reasoning. The pre-built graph may not align with these required
structures, resulting in ineffective knowledge retrieval. To this end, we
propose a \textbf{\underline{Logic}}-aware
\textbf{\underline{R}}etrieval-\textbf{\underline{A}}ugmented
\textbf{\underline{G}}eneration framework (\textbf{LogicRAG}) that dynamically
extracts reasoning structures at inference time to guide adaptive retrieval
without any pre-built graph. LogicRAG begins by decomposing the input query
into a set of subproblems and constructing a directed acyclic graph (DAG) to
model the logical dependencies among them. To support coherent multi-step
reasoning, LogicRAG then linearizes the graph using topological sort, so that
subproblems can be addressed in a logically consistent order. Besides, LogicRAG
applies graph pruning to reduce redundant retrieval and uses context pruning to
filter irrelevant context, significantly reducing the overall token cost.
Extensive experiments demonstrate that LogicRAG achieves both superior
performance and efficiency compared to state-of-the-art baselines.

</details>


### [18] [AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models](https://arxiv.org/abs/2508.06124)
*Sayantan Adak,Pratyush Chatterjee,Somnath Banerjee,Rima Hazra,Somak Aditya,Animesh Mukherjee*

Main category: cs.CL

TL;DR: 提出AURA框架，通过多层次PRMs实现逐步评估，提升LLMs的逻辑一致性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的安全措施不足以检测和干预模型在潜在逻辑风险中的微妙推理步骤，亟需更细粒度和主动的安全保障方法。

Method: 引入多层次的Process Reward Models（PRMs），结合自我批判和适应性解码技术，动态引导模型安全推理。

Result: 实验证明该方法显著优于现有技术，提高了模型的逻辑整体性和安全性，减少有害输出。

Conclusion: AURA架构推动了安全、责任感强的AI发展，树立了新的对齐标准。

Abstract: Present day LLMs face the challenge of managing affordance-based safety
risks-situations where outputs inadvertently facilitate harmful actions due to
overlooked logical implications. Traditional safety solutions, such as scalar
outcome-based reward models, parameter tuning, or heuristic decoding
strategies, lack the granularity and proactive nature needed to reliably detect
and intervene during subtle yet crucial reasoning steps. Addressing this
fundamental gap, we introduce AURA, an innovative, multi-layered framework
centered around Process Reward Models (PRMs), providing comprehensive, step
level evaluations across logical coherence and safety-awareness. Our framework
seamlessly combines introspective self-critique, fine-grained PRM assessments,
and adaptive safety-aware decoding to dynamically and proactively guide models
toward safer reasoning trajectories. Empirical evidence clearly demonstrates
that this approach significantly surpasses existing methods, significantly
improving the logical integrity and affordance-sensitive safety of model
outputs. This research represents a pivotal step toward safer, more
responsible, and contextually aware AI, setting a new benchmark for
alignment-sensitive applications.

</details>


### [19] [Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2508.06135)
*Lingyuan Liu,Mengxiang Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为选择性反映蒸馏（SRD）的数据策略，通过自动筛选训练数据，提高大模型蒸馏的效果和效率，显著减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有白盒知识蒸馏主要关注模型响应平衡，忽略了训练数据质量和模型兼容性，限制了蒸馏效果。

Method: 采用反思机制动态评估和筛选训练示例，结合课程调度策略逐步引入精选数据，作为一种插件式增强方法。

Result: 在多个语言模型基准测试中，SRD显著提升蒸馏模型性能，训练时间缩短最多39%，适用于多种KD方法和模型架构。

Conclusion: 数据质量和模型兼容性是提升大模型蒸馏效果的关键，SRD作为一种数据中心的方案，为高效压缩提供了实用的框架。

Abstract: Knowledge Distillation (KD) is a fundamental technique for compressing large
language models (LLMs) into compact, efficient student models. However,
existing white-box KD methods mainly focus on balancing ground truth and
student-generated responses while overlooking two critical factors: training
data quality and student-model compatibility. To address these limitations, we
propose Selective Reflection Distillation (SRD), a novel data curation
framework that leverages reflections from student models to systematically
refine training data. SRD dynamically evaluates and selects prompt-response
pairs by comparing ground truth data with student model outputs, selectively
curating high-quality, student-compatible training instances through automated
ranking based on difficulty. Furthermore, after selecting the training data, a
curriculum scheduling strategy is employed to incrementally introduce these
curated subsets into the distillation process at fixed intervals. As a
plug-and-play enhancement, SRD consistently improves distillation outcomes
across diverse white-box KD approaches and model architectures, as well as
decreases computational cost significantly during KD training. Experiments on a
range of language model benchmarks demonstrate SRD's consistent improvements in
distilled model performance, as well as a reduction in training runtime by up
to 39%, under diverse KD methods and model families. Notably, SRD operates as a
plug-and-play module, enhancing sample efficiency without modifying underlying
KD algorithms. Our findings highlight that data quality and compatibility are
pivotal to effective and efficient distillation of LLMs, and SRD provides a
principled framework to achieve both. This work advances the understanding of
data-centric factors in KD and offers practical insights for enhancing the
capability and efficiency of compressed LLMs.

</details>


### [20] [Scaling Personality Control in LLMs with Big Five Scaler Prompts](https://arxiv.org/abs/2508.06149)
*Gunhee Cho,Yun-Gyung Cheong*

Main category: cs.CL

TL;DR: 提出了一种基于提示的框架Big5-Scaler，用于在无需额外训练的情况下，通过自然语言提示调控大型语言模型的五大人格特质，表现出一致且可区分的人格表达能力。


<details>
  <summary>Details</summary>
Motivation: 为了实现对大型语言模型中人格特质的可控调节，提升对话生成的个性化与多样性。

Method: 将数字人格特质值嵌入自然语言提示中，通过prompt调控模型表现，无需额外训练。

Result: 在特质表达、对话生成和人类特质模仿等任务中效果良好，显示出一致且可区分的个性特征。

Conclusion: 简洁提示和较低的特质强度更有效，为构建个性化对话代理提供了高效途径。

Abstract: We present Big5-Scaler, a prompt-based framework for conditioning large
language models (LLMs) with controllable Big Five personality traits. By
embedding numeric trait values into natural language prompts, our method
enables fine-grained personality control without additional training. We
evaluate Big5-Scaler across trait expression, dialogue generation, and human
trait imitation tasks. Results show that it induces consistent and
distinguishable personality traits across models, with performance varying by
prompt type and scale. Our analysis highlights the effectiveness of concise
prompts and lower trait intensities, providing a efficient approach for
building personality-aware dialogue agents.

</details>


### [21] [Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach](https://arxiv.org/abs/2508.06155)
*Renhan Zhang,Lian Lian,Zhen Qi,Guiran Liu*

Main category: cs.CL

TL;DR: 本文提出一种结合嵌套语义表示与对比机制的偏见检测方法，有效识别大规模语言模型中的隐性社会偏见，确保生成内容的公正性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型的广泛应用，模型在生成内容时可能无意中展现隐性社会偏见，亟需有效的检测与解释工具以确保内容的公正性。

Method: 采用嵌套语义表示结合上下文对比机制，并通过注意力权重扰动分析模型对社会属性词的敏感性，挖掘潜在偏见特征。

Result: 在StereoSet数据集上验证，方法在偏见检测的准确性、语义一致性和上下文敏感性方面表现优异，具备良好的可解释性和应用潜力。

Conclusion: 该方法为偏见检测提供透明、可靠的技术基础，有助于提升语言模型生成内容的公平性与信任度，适用于实际应用场景。

Abstract: This paper addresses the issue of implicit stereotypes that may arise during
the generation process of large language models. It proposes an interpretable
bias detection method aimed at identifying hidden social biases in model
outputs, especially those semantic tendencies that are not easily captured
through explicit linguistic features. The method combines nested semantic
representation with a contextual contrast mechanism. It extracts latent bias
features from the vector space structure of model outputs. Using attention
weight perturbation, it analyzes the model's sensitivity to specific social
attribute terms, thereby revealing the semantic pathways through which bias is
formed. To validate the effectiveness of the method, this study uses the
StereoSet dataset, which covers multiple stereotype dimensions including
gender, profession, religion, and race. The evaluation focuses on several key
metrics, such as bias detection accuracy, semantic consistency, and contextual
sensitivity. Experimental results show that the proposed method achieves strong
detection performance across various dimensions. It can accurately identify
bias differences between semantically similar texts while maintaining high
semantic alignment and output stability. The method also demonstrates high
interpretability in its structural design. It helps uncover the internal bias
association mechanisms within language models. This provides a more transparent
and reliable technical foundation for bias detection. The approach is suitable
for real-world applications where high trustworthiness of generated content is
required.

</details>


### [22] [One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging](https://arxiv.org/abs/2508.06163)
*Yingfeng Luo,Dingyang Lin,Junxin Wang,Ziqiang Xu,Kaiyan Chang,Tong Zheng,Bei Li,Anxiang Ma,Tong Xiao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: TADrop引入一种自适应稀疏策略，根据参数张量的分布特性为不同参数分配不同的稀疏率，有效提升模型合并性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并中的稀疏化方法采用统一比例，忽略了参数结构和统计差异，导致关键参数可能被误删。

Method: 提出TADrop，根据参数张量的分布特性动态调整稀疏比例，结合多种模型和任务验证其效果。

Result: 在多任务、多模型上实验显示，TADrop显著提高合并性能，平均性能提升2.0%。

Conclusion: TADrop通过结构化自适应稀疏优化模型合并效能，为多任务学习提供新方案。

Abstract: Model merging has emerged as a compelling data-free paradigm for multi-task
learning, enabling the fusion of multiple fine-tuned models into a single,
powerful entity. A key technique in merging methods is sparsification, which
prunes redundant parameters from task vectors to mitigate interference.
However, prevailing approaches employ a ``one-size-fits-all'' strategy,
applying a uniform sparsity ratio that overlooks the inherent structural and
statistical heterogeneity of model parameters. This often leads to a suboptimal
trade-off, where critical parameters are inadvertently pruned while less useful
ones are retained. To address this limitation, we introduce \textbf{TADrop}
(\textbf{T}ensor-wise \textbf{A}daptive \textbf{Drop}), an adaptive
sparsification strategy that respects this heterogeneity. Instead of a global
ratio, TADrop assigns a tailored sparsity level to each parameter tensor based
on its distributional properties. The core intuition is that tensors with
denser, more redundant distributions can be pruned aggressively, while sparser,
more critical ones are preserved. As a simple and plug-and-play module, we
validate TADrop by integrating it with foundational, classic, and SOTA merging
methods. Extensive experiments across diverse tasks (vision, language, and
multimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and
significantly boosts their performance. For instance, when enhancing a leading
merging method, it achieves an average performance gain of 2.0\% across 8
ViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter
interference by tailoring sparsification to the model's structure, offering a
new baseline for high-performance model merging.

</details>


### [23] [UR$^2$: Unify RAG and Reasoning through Reinforcement Learning](https://arxiv.org/abs/2508.06165)
*Weitao Li,Boran Xiang,Xiaolong Wang,Zhinan Gou,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: UR2框架融合检索与推理，通过难度感知课程训练和混合知识策略，提升多任务表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG与RL技术孤立发展限制，促进其在更广泛领域的应用。

Method: 引入难度感知的课程训练和混合知识访问策略，实现检索与推理的动态协作。

Result: 在多任务中显著优于现有方法，接近或超越一些大型模型表现。

Conclusion: UR2框架有效整合检索与推理，提高泛化能力，推动多领域应用发展。

Abstract: Large Language Models (LLMs) have shown remarkable capabilities through two
complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances
knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR),
which optimizes complex reasoning abilities. However, these two capabilities
are often developed in isolation, and existing efforts to unify them remain
narrow in scope-typically limited to open-domain QA with fixed retrieval
settings and task-specific assumptions. This lack of integration constrains
generalization and limits the applicability of RAG-RL methods to broader
domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a
general framework that unifies retrieval and reasoning through reinforcement
learning. UR2 introduces two key contributions: a difficulty-aware curriculum
training that selectively invokes retrieval only for challenging problems, and
a hybrid knowledge access strategy combining domain-specific offline corpora
with LLM-generated summaries. These components are designed to enable dynamic
coordination between retrieval and reasoning, improving adaptability across a
diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical,
and mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B
and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods,
achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several
benchmarks. We have released all code, models, and data at
https://github.com/Tsinghua-dhy/UR2.

</details>


### [24] [Pragmatics beyond humans: meaning, communication, and LLMs](https://arxiv.org/abs/2508.06167)
*Vít Gvoždiak*

Main category: cs.CL

TL;DR: 本文重构了语用学的传统观念，强调其作为社会嵌入式行动工具的动态界面，并提出适应大模型的理论修正。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型的兴起，传统语用学框架面临调整需求，促使研究者重新理解和界定语用学的理论基础。

Method: 本文通过批判传统符码学分类，提出人机交互框架，结合概率语用学，分析了大模型与人类语用的关系和挑战，探讨了上下文理解的困境。

Result: 研究表明，需要扩展和调整语用学理论，以更好解释生成式AI在实际交流中的表现和限制。

Conclusion: 语用学理论应与时俱进，融入对人机交互、概率推理和上下文作用的理解，以适应新兴技术的沟通场景。

Abstract: The paper reconceptualizes pragmatics not as a subordinate, third dimension
of meaning, but as a dynamic interface through which language operates as a
socially embedded tool for action. With the emergence of large language models
(LLMs) in communicative contexts, this understanding needs to be further
refined and methodologically reconsidered. The first section challenges the
traditional semiotic trichotomy, arguing that connectionist LLM architectures
destabilize established hierarchies of meaning, and proposes the Human-Machine
Communication (HMC) framework as a more suitable alternative. The second
section examines the tension between human-centred pragmatic theories and the
machine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics
continue to dominate, it relies on human-specific assumptions ill-suited to
predictive systems like LLMs. Probabilistic pragmatics, particularly the
Rational Speech Act framework, offers a more compatible teleology by focusing
on optimization rather than truth-evaluation. The third section addresses the
issue of substitutionalism in three forms - generalizing, linguistic, and
communicative - highlighting the anthropomorphic biases that distort LLM
evaluation and obscure the role of human communicative subjects. Finally, the
paper introduces the concept of context frustration to describe the paradox of
increased contextual input paired with a collapse in contextual understanding,
emphasizing how users are compelled to co-construct pragmatic conditions both
for the model and themselves. These arguments suggest that pragmatic theory may
need to be adjusted or expanded to better account for communication involving
generative AI.

</details>


### [25] [Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime](https://arxiv.org/abs/2508.06178)
*Hugo Abonizio,Thales Almeida,Roberto Lotufo,Rodrigo Nogueira*

Main category: cs.CL

TL;DR: 研究在有限数据条件下向大语言模型注入新知识的方法，强调数据多样性和避免遗忘的重要性，并提出模型可自生成训练数据以提升学习能力。


<details>
  <summary>Details</summary>
Motivation: 解决大模型在有限新数据下知识更新困难的问题，探索有效的知识注入策略。

Method: 通过增强算法生成多样化文本数据，分析不同方法对知识学习和遗忘的影响，验证模型自生成训练数据的潜力。

Result: 多样性增强方法有效提升新知识学习，控制技术存在遗忘风险，模型能自生成训练数据，提供了有限数据下的知识注入新途径。

Conclusion: 多样化提示和自生成数据策略有助于优化有限数据条件下的知识注入效果，同时重点关注遗忘机制以维持模型能力。

Abstract: Large language models (LLMs) often require vast amounts of text to
effectively acquire new knowledge. While continuing pre-training on large
corpora or employing retrieval-augmented generation (RAG) has proven
successful, updating an LLM with only a few thousand or million tokens remains
challenging. In this work, we investigate the task of injecting small,
unstructured information into LLMs and its relation to the catastrophic
forgetting phenomenon. We use a dataset of recent news -- ensuring no overlap
with the model's pre-training data -- to evaluate the knowledge acquisition by
probing the model with question-answer pairs related the learned information.
Starting from a continued pre-training baseline, we explored different
augmentation algorithms to generate synthetic data to improve the knowledge
acquisition capabilities. Our experiments show that simply continuing
pre-training on limited data yields modest improvements, whereas exposing the
model to diverse textual variations significantly improves the learning of new
facts -- particularly with methods that induce greater variability through
diverse prompting. Furthermore, we shed light on the forgetting phenomenon in
small-data regimes, illustrating the delicate balance between learning new
content and retaining existing capabilities. We also confirm the sensitivity of
RAG-based approaches for knowledge injection, which often lead to greater
degradation on control datasets compared to parametric methods. Finally, we
demonstrate that models can generate effective synthetic training data
themselves, suggesting a pathway toward self-improving model updates. All code
and generated data used in our experiments are publicly available, providing a
resource for studying efficient knowledge injection in LLMs with limited data
at https://github.com/hugoabonizio/knowledge-injection-methods.

</details>


### [26] [DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration](https://arxiv.org/abs/2508.06186)
*Ali Sarabadani,Maryam Abdollahi Shamami,Hamidreza Sadeghsalehi,Borhan Asadi,Saba Hesaraki*

Main category: cs.CL

TL;DR: 提出了一种结合动态知识图和大型语言模型的医疗诊断与个性化治疗推荐框架DKG-LLM，利用高效的语义融合算法实现医疗数据的动态知识图构建，显著提高诊断和治疗准确率。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，如何将其应用于医疗诊断并提升准确率成为研究的驱动力。

Method: 引入动态知识图结合Grok 3大型语言模型，通过自适应语义融合算法（ASFA）动态生成和更新医疗知识图，利用贝叶斯推断和图优化技术提取语义信息。

Result: DKG-LLM在MIMIC-III和PubMed数据集上的评估中，诊断准确率达到84.19%，治疗推荐准确率89.63%，语义覆盖率93.48%，表现出良好的实用性和鲁棒性。

Conclusion: 基于动态知识图和大模型的融合方法极大地促进了医疗智能诊断的准确性与效率，具有推广应用的潜力。

Abstract: Large Language Models (LLMs) have grown exponentially since the release of
ChatGPT. These models have gained attention due to their robust performance on
various tasks, including language processing tasks. These models achieve
understanding and comprehension of tasks by training billions of parameters.
The development of these models is a transformative force in enhancing natural
language understanding and has taken a significant step towards artificial
general intelligence (AGI). In this study, we aim to present the DKG-LLM
framework. The DKG-LLM framework introduces a groundbreaking approach to
medical diagnosis and personalized treatment recommendations by integrating a
dynamic knowledge graph (DKG) with the Grok 3 large language model. Using the
Adaptive Semantic Fusion Algorithm (ASFA), heterogeneous medical data
(including clinical reports and PubMed articles) and patient records
dynamically generate a knowledge graph consisting of 15,964 nodes in 13
distinct types (e.g., diseases, symptoms, treatments, patient profiles) and
127,392 edges in 26 relationship types (e.g., causal, therapeutic,
association). ASFA utilizes advanced probabilistic models, Bayesian inference,
and graph optimization to extract semantic information, dynamically updating
the graph with approximately 150 new nodes and edges in each data category
while maintaining scalability with up to 987,654 edges. Real-world datasets,
including MIMIC-III and PubMed, were utilized to evaluate the proposed
architecture. The evaluation results show that DKG-LLM achieves a diagnostic
accuracy of 84.19%. The model also has a treatment recommendation accuracy of
89.63% and a semantic coverage of 93.48%. DKG-LLM is a reliable and
transformative tool that handles noisy data and complex multi-symptom diseases,
along with feedback-based learning from physician input.

</details>


### [27] [Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation](https://arxiv.org/abs/2508.06194)
*Lai Jiang,Yuekang Li,Xiaohan Zhang,Youtao Ding,Li Pan*

Main category: cs.CL

TL;DR: SceneJailEval提出一种场景自适应多维度评估框架，解决现有方法的局限性，结合丰富数据集实现更精确的越狱评价。


<details>
  <summary>Details</summary>
Motivation: 现有越狱评估方法缺乏场景适应性和多维度衡量，难以准确量化危害。

Method: 设计场景自适应多维度框架，建立多场景高质量数据集，改进评估指标以提升精度。

Result: 在多场景数据集和JBB上均达到了最佳或领先的效果，F1分别为0.917和0.995，超越先前方法。

Conclusion: 提出的SceneJailEval为LLM越狱评估提供了更为精准和适应性强的工具，有助推动安全性研究与实践。

Abstract: Precise jailbreak evaluation is vital for LLM red teaming and jailbreak
research. Current approaches employ binary classification ( e.g., string
matching, toxic text classifiers, LLM-driven methods), yielding only "yes/no"
labels without quantifying harm intensity. Existing multi-dimensional
frameworks ( e.g., Security Violation, Relative Truthfulness, Informativeness)
apply uniform evaluation criteria across scenarios, resulting in
scenario-specific mismatches--for instance, "Relative Truthfulness" is
irrelevant to "hate speech"--which compromise evaluation precision. To tackle
these limitations, we introduce SceneJailEval, with key contributions: (1) A
groundbreaking scenario-adaptive multi-dimensional framework for jailbreak
evaluation, overcoming the critical "one-size-fits-all" constraint of existing
multi-dimensional methods, and featuring strong extensibility to flexibly adapt
to customized or emerging scenarios. (2) A comprehensive 14-scenario dataset
with diverse jailbreak variants and regional cases, filling the long-standing
gap in high-quality, holistic benchmarks for scenario-adaptive evaluation. (3)
SceneJailEval achieves state-of-the-art results, with an F1 score of 0.917 on
our full-scenario dataset (+6% over prior SOTA) and 0.995 on JBB (+3% over
prior SOTA), surpassing accuracy limits of existing evaluation methods in
heterogeneous scenarios and confirming its advantage.

</details>


### [28] [EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations](https://arxiv.org/abs/2508.06196)
*Nizi Nazar,Ehsaneddin Asgari*

Main category: cs.CL

TL;DR: 提出了一套基于心理学的四层情商（EI）分类体系，并开发了EICAP-Bench评估大规模语言模型（LLMs）在情感识别与响应中的能力。通过微调显示，部分EI层得到提升，揭示了现有模型在情感推理方面的局限。


<details>
  <summary>Details</summary>
Motivation: 弥补大规模语言模型在情感智能方面的不足，提升其人性化能力。

Method: 构建心理学基础的四层EI分类体系，设计多轮MCQ评估基准，比较多款LLMs，采用LoRA微调在不同语言上强化情感能力。

Result: Qwen2.5-Instruct表现最佳，微调提升了部分EI层能力，尤其是“评价”层，揭示了现有模型的局限性。

Conclusion: 现有预训练和指令微调未能充分强化模型的深度情感推理，未来需开发更有针对性的数据和模型策略以实现全面的情感智能。

Abstract: Emotional Intelligence (EI) is a critical yet underexplored dimension in the
development of human-aligned LLMs. To address this gap, we introduce a unified,
psychologically grounded four-layer taxonomy of EI tailored for large language
models (LLMs), encompassing emotional tracking, cause inference, appraisal, and
emotionally appropriate response generation. Building on this framework, we
present EICAP-Bench, a novel MCQ style multi-turn benchmark designed to
evaluate EI capabilities in open-source LLMs across diverse linguistic and
cultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma
(9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench,
identifying Qwen2.5-Instruct as the strongest baseline. To assess the potential
for enhancing EI capabilities, we fine-tune both Qwen2.5-Base and
Qwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale,
instruction-tuned dialogue dataset, in both English and Arabic. Our statistical
analysis reveals that among the five EI layers, only the Appraisal layer shows
significant improvement through UC-based fine-tuning. These findings highlight
the limitations of existing pretraining and instruction-tuning paradigms in
equipping LLMs with deeper emotional reasoning and underscore the need for
targeted data and modeling strategies for comprehensive EI alignment.

</details>


### [29] [Classification is a RAG problem: A case study on hate speech detection](https://arxiv.org/abs/2508.06204)
*Richard Willats,Josh Pennington,Aravind Mohan,Bertie Vidgen*

Main category: cs.CL

TL;DR: 采用 Retrieval-Augmented Generation (RAG) 的内容审核方法具有更高的适应性和可解释性，能动态更新政策，提升内容审核的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 在内容审核中，传统模型难以快速适应政策变化，且缺乏明显的可解释性。

Method: 提出基于RAG的Contextual Policy Engine（CPE），将内容分类从依赖预训练参数转向结合检索到的上下文知识进行判断。

Result: CPE达到了与行业领先模型相当的准确率，实现了动态政策更新，具备良好的可解释性，并能精细调整对特定群体的保护策略。

Conclusion: RAG方法极大增强了内容审核的灵活性、透明性和适应性，有助于构建更高效的内容管理系统。

Abstract: Robust content moderation requires classification systems that can quickly
adapt to evolving policies without costly retraining. We present classification
using Retrieval-Augmented Generation (RAG), which shifts traditional
classification tasks from determining the correct category in accordance with
pre-trained parameters to evaluating content in relation to contextual
knowledge retrieved at inference. In hate speech detection, this transforms the
task from "is this hate speech?" to "does this violate the hate speech policy?"
  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates
this approach and offers three key advantages: (1) robust classification
accuracy comparable to leading commercial systems, (2) inherent explainability
via retrieved policy segments, and (3) dynamic policy updates without model
retraining. Through three experiments, we demonstrate strong baseline
performance and show that the system can apply fine-grained policy control by
correctly adjusting protection for specific identity groups without requiring
retraining or compromising overall performance. These findings establish that
RAG can transform classification into a more flexible, transparent, and
adaptable process for content moderation and wider classification problems.

</details>


### [30] [InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?](https://arxiv.org/abs/2508.06220)
*Keummin Ka,Junhyeong Park,Jahyun Jeon,Youngjae Yu*

Main category: cs.CL

TL;DR: 本研究提出了InfoCausalQA基准，用于评估多模态视觉-语言模型在因果推理方面的能力，发现目前模型在复杂推理任务上表现有限，强调了提升因果推理能力的必要性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型在感知和推理方面取得显著进展，但在因果推理能力，尤其是在多模态环境下，仍然不足，需要进行评估和改进。

Method: 构建以结构化图像数据和文本为基础的因果推理基准，包括两个任务（定量和语义因果推理），收集数据、生成问答并经过人工修正，确保题目需要真实的视觉推理能力。

Result: 实验结果显示，现有VLM在计算和语义因果推理方面表现有限，远低于人类水平，突显模型在利用图表信息进行因果推理方面的不足。

Conclusion: 强调提升多模态AI系统中因果推理能力的重要性，提供了评估的工具和数据集，推动相关研究的发展。

Abstract: Recent advances in Vision-Language Models (VLMs) have demonstrated impressive
capabilities in perception and reasoning. However, the ability to perform
causal inference -- a core aspect of human cognition -- remains underexplored,
particularly in multimodal settings. In this study, we introduce InfoCausalQA,
a novel benchmark designed to evaluate causal reasoning grounded in
infographics that combine structured visual data with textual context. The
benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning
based on inferred numerical trends, while Task 2 targets semantic causal
reasoning involving five types of causal relations: cause, effect,
intervention, counterfactual, and temporal. We manually collected 494
infographic-text pairs from four public sources and used GPT-4o to generate
1,482 high-quality multiple-choice QA pairs. These questions were then
carefully revised by humans to ensure they cannot be answered based on
surface-level cues alone but instead require genuine visual grounding. Our
experimental results reveal that current VLMs exhibit limited capability in
computational reasoning and even more pronounced limitations in semantic causal
reasoning. Their significantly lower performance compared to humans indicates a
substantial gap in leveraging infographic-based information for causal
inference. Through InfoCausalQA, we highlight the need for advancing the causal
reasoning abilities of multimodal AI systems.

</details>


### [31] [Large Language Model Data Generation for Enhanced Intent Recognition in German Speech](https://arxiv.org/abs/2508.06277)
*Theresa Pekarek Rosin,Burak Can Kaplan,Stefan Wermter*

Main category: cs.CL

TL;DR: 结合改进的Whisper模型和Transformer语言模型，利用生成式AI改善德国老年人语音指令识别，显著提高性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在长短语和非英语语音识别中的局限，特别关注德语老年人语音命令。

Method: 采用微调的Whisper ASR模型结合由大型语言模型生成的合成文本，训练Transformer模型，进行跨数据集测试。

Result: 合成数据显著提升分类性能，LeoLM优于大规模模型ChatGPT，验证生成式AI在低资源领域的潜力。

Conclusion: 生成式AI有效弥补数据不足，提升德语语音指令识别的性能和鲁棒性，确保方案的透明性和可复现性。

Abstract: Intent recognition (IR) for speech commands is essential for artificial
intelligence (AI) assistant systems; however, most existing approaches are
limited to short commands and are predominantly developed for English. This
paper addresses these limitations by focusing on IR from speech by elderly
German speakers. We propose a novel approach that combines an adapted Whisper
ASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based
language models trained on synthetic text datasets generated by three
well-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To
evaluate the robustness of our approach, we generate synthetic speech with a
text-to-speech model and conduct extensive cross-dataset testing. Our results
show that synthetic LLM-generated data significantly boosts classification
performance and robustness to different speaking styles and unseen vocabulary.
Notably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the
much larger ChatGPT (175B) in dataset quality for German intent recognition.
Our approach demonstrates that generative AI can effectively bridge data gaps
in low-resource domains. We provide detailed documentation of our data
generation and training process to ensure transparency and reproducibility.

</details>


### [32] [Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC](https://arxiv.org/abs/2508.06309)
*Ruichong Zhang*

Main category: cs.CL

TL;DR: 提出了一种基于矩阵分析和大偏差理论的检测大型语言模型（LLMs）剽窃的新方法MDIR，能准确识别模型抄袭并附带统计显著性验证，效率高，可在单机上快速完成。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，模型剽窃问题日益严重，现有检测方法难以精确识别和验证剽窃行为，亟需更有效的技术手段。

Method: 提出矩阵驱动即时审查（MDIR）方法，利用矩阵分析和大偏差理论实现权重关系的准确重建与统计显著性检验，无需完整模型推断。

Result: 实验表明，MDIR在检测模型剽窃方面效果优异，尤其在经过复杂变换后仍能可靠检测，且检测过程快速，可在单机上快速完成。

Conclusion: MDIR方法解决了现有检测手段中的关键不足，为模型剽窃检测提供了高效、准确、安全的解决方案，具有广泛应用潜力。

Abstract: In recent years, concerns about intellectual property (IP) in large language
models (LLMs) have grown significantly. Plagiarizing other LLMs (through direct
weight copying, upcycling, pruning, or continual pretraining) and claiming
authorship without properly attributing to the original license, is a serious
misconduct that can lead to significant financial and reputational harm to the
original developers. However, existing methods for detecting LLM plagiarism
fall short in key areas. They fail to accurately reconstruct weight
correspondences, lack the ability to compute statistical significance measures
such as $p$-values, and may mistakenly flag models trained on similar data as
being related. To address these limitations, we propose Matrix-Driven Instant
Review (MDIR), a novel method that leverages matrix analysis and Large
Deviation Theory. MDIR achieves accurate reconstruction of weight
relationships, provides rigorous $p$-value estimation, and focuses exclusively
on weight similarity without requiring full model inference. Experimental
results demonstrate that MDIR reliably detects plagiarism even after extensive
transformations, such as random permutations and continual pretraining with
trillions of tokens. Moreover, all detections can be performed on a single PC
within an hour, making MDIR both efficient and accessible.

</details>


### [33] [Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering](https://arxiv.org/abs/2508.06345)
*Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James T. Kwok,Yu Zhang*

Main category: cs.CL

TL;DR: 提出一种用于零样本图像问答的动态多模态表示框架，结合多种图表示形式和TRF偏好，提高模型性能和响应效率。


<details>
  <summary>Details</summary>
Motivation: 现有图表示形式单一，导致回答不准确或过长，亟需多样化和个性化的表示策略。

Method: 分析TRF的特性和弱点，设计TRF集合F_{ZS}，引入GRE指标，构建TRF偏好数据集TRFP，训练TRF路由器实现动态匹配。

Result: 在多项图像问答任务中，显著提升了LMMs的零样本问答准确率和响应效率。

Conclusion: 动态TRF框架有效整合多种图表示，增强模型的适应性和问答质量，具有广泛应用潜力。

Abstract: Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities
in diverse domain question-answering (QA) tasks, including graph QA that
involves complex graph topologies. However, most current approaches use only a
single type of graph representation, namely Topology Representation Form (TRF),
such as prompt-unified text descriptions or style-fixed visual styles. Those
"one-size-fits-all" approaches fail to consider the specific preferences of
different models or tasks, often leading to incorrect or overly long responses.
To address this, we first analyze the characteristics and weaknesses of
existing TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to
zero-shot graph QA. We then introduce a new metric, Graph Response Efficiency
(GRE), which measures the balance between the performance and the brevity in
graph QA. Built on these, we develop the DynamicTRF framework, which aims to
improve both the accuracy and conciseness of graph QA. To be specific,
DynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based
on their GRE scores, to probe the question-specific TRF preferences. Then it
trains a TRF router on the TRFP dataset, to adaptively assign the best TRF from
$F_{ZS}$ for each question during the inference. Extensive experiments across 7
in-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show
that DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms
of accuracy

</details>


### [34] [Cyberbullying Detection via Aggression-Enhanced Prompting](https://arxiv.org/abs/2508.06360)
*Aisha Saeid,Anu Sabu,Girish A. Koushik,Ferrante Neri,Diptesh Kanojia*

Main category: cs.CL

TL;DR: 通过在大语言模型中加入攻击检测作为辅助任务，增强网络欺凌检测的效果。


<details>
  <summary>Details</summary>
Motivation: 网络社交媒体上的网络欺凌表达隐晦多样，检测具有挑战性，需要提升模型的泛化能力。

Method: 结合多个数据集，采用多策略（零-shot、少-shot、独立LoRA微调、多任务学习）进行实验，并提出丰富提示流程增强策略。

Result: 丰富提示流程优于传统LoRA微调，表明利用攻击检测信息显著改善欺凌识别效果。

Conclusion: 辅助任务如攻击检测有助于提高LLMs在社交网络安全场景中的表现。

Abstract: Detecting cyberbullying on social media remains a critical challenge due to
its subtle and varied expressions. This study investigates whether integrating
aggression detection as an auxiliary task within a unified training framework
can enhance the generalisation and performance of large language models (LLMs)
in cyberbullying detection. Experiments are conducted on five aggression
datasets and one cyberbullying dataset using instruction-tuned LLMs. We
evaluated multiple strategies: zero-shot, few-shot, independent LoRA
fine-tuning, and multi-task learning (MTL). Given the inconsistent results of
MTL, we propose an enriched prompt pipeline approach in which aggression
predictions are embedded into cyberbullying detection prompts to provide
contextual augmentation. Preliminary results show that the enriched prompt
pipeline consistently outperforms standard LoRA fine-tuning, indicating that
aggression-informed context significantly boosts cyberbullying detection. This
study highlights the potential of auxiliary tasks, such as aggression
detection, to improve the generalisation of LLMs for safety-critical
applications on social networks.

</details>


### [35] [Evaluating Style-Personalized Text Generation: Challenges and Directions](https://arxiv.org/abs/2508.06374)
*Anubhav Jangra,Bahareh Sarrafzadeh,Adrian de Wynter,Silviu Cucerzan,Sujay Kumar Jauhar*

Main category: cs.CL

TL;DR: 本文探讨了低资源情境下个性化文本生成的评价问题，质疑传统指标，并提出采用多元评估指标的策略。


<details>
  <summary>Details</summary>
Motivation: 当前评价指标在低资源个性化文本生成中效果有限，有必要探索更全面有效的评价方法。

Method: 通过构建风格辨别基准，比较BLEU、ROUGE等传统指标与风格嵌入和LLM判别等新方法，评估其在不同任务和设置中的表现。

Result: 结果显示，采用多种评估指标的集成能更有效衡量个性化文本生成的风格匹配度。

Conclusion: 建议在个性化文本生成评估中采用多元指标集成策略，以提升评价的全面性和准确性。

Abstract: While prior research has built tools and benchmarks towards style
personalized text generation, there has been limited exploration of evaluation
in low-resource author style personalized text generation space. Through this
work, we question the effectiveness of the widely adopted evaluation metrics
like BLEU and ROUGE, and explore other evaluation paradigms such as style
embeddings and LLM-as-judge to holistically evaluate the style personalized
text generation task. We evaluate these metrics and their ensembles using our
style discrimination benchmark, that spans eight writing tasks, and evaluates
across three settings, domain discrimination, authorship attribution, and LLM
personalized vs non-personalized discrimination. We provide conclusive evidence
to adopt ensemble of diverse evaluation metrics to effectively evaluate style
personalized text generation.

</details>


### [36] [LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing](https://arxiv.org/abs/2508.06388)
*Lanlan Qiu,Xiao Pu,Yeqi Feng,Tianxing He*

Main category: cs.CL

TL;DR: 本文提出ChatAnime数据集，用于研究大规模语言模型（LLMs）在动漫角色扮演中提供情感支持的能力，比较了LLMs与人类粉丝在角色扮演、情感支持和回答多样性方面的表现，结果显示顶尖LLMs在角色扮演和情感支持上优于人类，但在人类回答的多样性方面仍有优势。


<details>
  <summary>Details</summary>
Motivation: 填补LLMs在角色扮演和情感支持结合方面的研究空白，为虚拟角色的情感互动提供有效解决方案。

Method: 构建ChatAnime数据集，选取20个知名动漫角色，设计情感场景问答，邀请40名中国动漫爱好者参与人机对话收集，设计基于用户体验的评估体系。

Result: 评测显示，顶尖LLMs在角色扮演和情感支持方面优于人类粉丝，但在回答多样性方面还存在差距。

Conclusion: 该研究为未来优化LLMs的动漫角色扮演与情感支持能力提供了宝贵资源和经验，促进虚拟角色互动的发展。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing conversations and providing emotional support as separate research
directions. However, there remains a significant research gap in combining
these capabilities to enable emotionally supportive interactions with virtual
characters. To address this research gap, we focus on anime characters as a
case study because of their well-defined personalities and large fan bases.
This choice enables us to effectively evaluate how well LLMs can provide
emotional support while maintaining specific character traits. We introduce
ChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We
first thoughtfully select 20 top-tier characters from popular anime communities
and design 60 emotion-centric real-world scenario questions. Then, we execute a
nationwide selection process to identify 40 Chinese anime enthusiasts with
profound knowledge of specific characters and extensive experience in
role-playing. Next, we systematically collect two rounds of dialogue data from
10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP
performance of LLMs, we design a user experience-oriented evaluation system
featuring 9 fine-grained metrics across three dimensions: basic dialogue,
role-playing and emotional support, along with an overall metric for response
diversity. In total, the dataset comprises 2,400 human-written and 24,000
LLM-generated answers, supported by over 132,000 human annotations.
Experimental results show that top-performing LLMs surpass human fans in
role-playing and emotional support, while humans still lead in response
diversity. We hope this work can provide valuable resources and insights for
future research on optimizing LLMs in ESRP. Our datasets are available at
https://github.com/LanlanQiu/ChatAnime.

</details>


### [37] [Quantifying Conversation Drift in MCP via Latent Polytope](https://arxiv.org/abs/2508.06418)
*Haoran Shi,Hongwei Yao,Shuo Shao,Shaopeng Jiao,Ziqi Peng,Zhan Qin,Cong Wang*

Main category: cs.CL

TL;DR: SecMCP提出了一种基于潜在多面体空间的方法，用于检测和量化大语言模型中由外部工具引入的对话偏离，增强了模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着模型上下文协议（MCP）被广泛应用，模型面临工具污染和对话劫持等安全威胁，亟需有效的检测机制。.

Method: 通过将LLM的激活向量嵌入潜在多面体空间，分析对话中潜在空间轨迹的偏离，从而识别异常行为。

Result: 在多种先进LLMs及多个基准数据集上，SecMCP实现了超过0.915的AUROC，表现出强大的检测能力。

Conclusion: SecMCP通过潜在多面体模型，成功检测和量化了MCP中的对话偏离，增强了大模型的安全性和可靠性。

Abstract: The Model Context Protocol (MCP) enhances large language models (LLMs) by
integrating external tools, enabling dynamic aggregation of real-time data to
improve task execution. However, its non-isolated execution context introduces
critical security and privacy risks. In particular, adversarially crafted
content can induce tool poisoning or indirect prompt injection, leading to
conversation hijacking, misinformation propagation, or data exfiltration.
Existing defenses, such as rule-based filters or LLM-driven detection, remain
inadequate due to their reliance on static signatures, computational
inefficiency, and inability to quantify conversational hijacking. To address
these limitations, we propose SecMCP, a secure framework that detects and
quantifies conversation drift, deviations in latent space trajectories induced
by adversarial external knowledge. By modeling LLM activation vectors within a
latent polytope space, SecMCP identifies anomalous shifts in conversational
dynamics, enabling proactive detection of hijacking, misleading, and data
exfiltration. We evaluate SecMCP on three state-of-the-art LLMs (Llama3,
Vicuna, Mistral) across benchmark datasets (MS MARCO, HotpotQA, FinQA),
demonstrating robust detection with AUROC scores exceeding 0.915 while
maintaining system usability. Our contributions include a systematic
categorization of MCP security threats, a novel latent polytope-based
methodology for quantifying conversation drift, and empirical validation of
SecMCP's efficacy.

</details>


### [38] [Memp: Exploring Agent Procedural Memory](https://arxiv.org/abs/2508.06433)
*Runnan Fang,Yuan Liang,Xiaobin Wang,Jialong Wu,Shuofei Qiao,Pengjun Xie,Fei Huang,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种可以学习和持续更新的程序性记忆方法，提升大语言模型在任务中的表现和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有大模型的程序性记忆脆弱，难以持续学习和适应新任务。

Method: 通过Memp系统，将历史轨迹转化为细粒度指令和脚本样抽象，并设计动态更新策略。

Result: 随着记忆库的不断优化，模型在类似任务中的成功率和效率提升显著，迁移到较弱模型仍保持性能优势。

Conclusion: 引入动态、可学习、可迁移的程序性记忆，有助于增强大模型的任务表现和适应能力。

Abstract: Large Language Models (LLMs) based agents excel at diverse tasks, yet they
suffer from brittle procedural memory that is manually engineered or entangled
in static parameters. In this work, we investigate strategies to endow agents
with a learnable, updatable, and lifelong procedural memory. We propose Memp
that distills past agent trajectories into both fine-grained, step-by-step
instructions and higher-level, script-like abstractions, and explore the impact
of different strategies for Build, Retrieval, and Update of procedural memory.
Coupled with a dynamic regimen that continuously updates, corrects, and
deprecates its contents, this repository evolves in lockstep with new
experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as
the memory repository is refined, agents achieve steadily higher success rates
and greater efficiency on analogous tasks. Moreover, procedural memory built
from a stronger model retains its value: migrating the procedural memory to a
weaker model yields substantial performance gains.

</details>


### [39] [Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages](https://arxiv.org/abs/2508.06435)
*Andrea Nasuto,Stefano Maria Iacus,Francisco Rowe,Devika Jain*

Main category: cs.CL

TL;DR: 小型语言模型在多语言分类任务中表现出强大的跨语种迁移能力，少量多样化的微调即可改善偏见并实现高效、低成本的跨语种分析。


<details>
  <summary>Details</summary>
Motivation: 探索有限多语微调是否能实现对未见语的迁移，以及偏见修正的可能性，推动低成本、多语种社会科学研究的可能性。

Method: 使用LLaMA 3.2-3B模型在单语、双语、多语数据集上微调，任务为多语种移民相关推文分类，评估跨语迁移和偏见修正。

Result: 少量多语微调能在未见语中实现可靠分类，多语微调能改善立场检测。极少的非主流语言微调显著提升性能，证明有限多语微调在主题识别中的有效性。

Conclusion: 有限多语微调即可实现跨语迁移和偏见修正，降低成本，增强包容性，颠覆了对大规模多语训练的依赖，推动可扩展社会科学研究的发展。

Abstract: Large language models (LLMs) are transforming social-science research by
enabling scalable, precise analysis. Their adaptability raises the question of
whether knowledge acquired through fine-tuning in a few languages can transfer
to unseen languages that only appeared during pre-training. To examine this, we
fine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or
multilingual data sets to classify immigration-related tweets from X/Twitter
across 13 languages, a domain characterised by polarised, culturally specific
discourse. We evaluate whether minimal language-specific fine-tuning enables
cross-lingual topic detection and whether adding targeted languages corrects
pre-training biases. Results show that LLMs fine-tuned in one or two languages
can reliably classify immigration-related content in unseen languages. However,
identifying whether a tweet expresses a pro- or anti-immigration stance
benefits from multilingual fine-tuning. Pre-training bias favours dominant
languages, but even minimal exposure to under-represented languages during
fine-tuning (as little as $9.62\times10^{-11}$ of the original pre-training
token volume) yields significant gains. These findings challenge the assumption
that cross-lingual mastery requires extensive multilingual training: limited
language coverage suffices for topic-level generalisation, and structural
biases can be corrected with lightweight interventions. By releasing
4-bit-quantised, LoRA fine-tuned models, we provide an open-source,
reproducible alternative to proprietary LLMs that delivers 35 times faster
inference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model,
enabling scalable, inclusive research.

</details>


### [40] [Echoes of Automation: The Increasing Use of LLMs in Newsmaking](https://arxiv.org/abs/2508.06445)
*Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee*

Main category: cs.CL

TL;DR: 本文分析了40,000篇新闻中AI生成内容的增长，发现AI多用于引言，提升词汇丰富度但降低正式性，尤其在地方与高校新闻中。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI在新闻中的使用及其对新闻品质与作者身份的影响。

Method: 利用三种AI文本检测工具分析新闻内容，进行句级和语言学分析。

Result: 发现AI应用显著增加，特别在地方和高校新闻，AI多用于引言部分，提升内容多样性但降低正式性。

Conclusion: 生成式AI改变了新闻写作风格，但也引发对新闻真实性和作者身份的担忧。

Abstract: The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns
for journalistic integrity and authorship. This study examines AI-generated
content across over 40,000 news articles from major, local, and college news
media, in various media formats. Using three advanced AI-text detectors (e.g.,
Binoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of
GenAI use in recent years, especially in local and college news. Sentence-level
analysis reveals LLMs are often used in the introduction of news, while
conclusions usually written manually. Linguistic analysis shows GenAI boosts
word richness and readability but lowers formality, leading to more uniform
writing styles, particularly in local media.

</details>


### [41] [SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning](https://arxiv.org/abs/2508.06447)
*Lingkun Long,Rubing Yang,Yushi Huang,Desheng Hui,Ao Zhou,Jianlei Yang*

Main category: cs.CL

TL;DR: 提出SlimInfer框架，通过在推理过程中动态剪枝次要提示令牌，有效加速大模型长文本推理，达成显著时间和延迟优化。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型在长文本推理中高计算需求的问题，提升推理效率。

Method: 引入信息扩散现象观察，设计细粒度动态剪枝机制，结合异步缓存管理，减少冗余信息处理。

Result: 实现多达2.53倍TTFT加速和1.88倍端到端延迟降低，在保持性能的同时显著提升效率。

Conclusion: SlimInfer通过有效的令牌剪枝策略，提升LLMs长文本推理的效率，为实际应用提供技术支持。

Abstract: Long-context inference for Large Language Models (LLMs) is heavily limited by
high computational demands. While several existing methods optimize attention
computation, they still process the full set of hidden states at each layer,
limiting overall efficiency. In this work, we propose SlimInfer, an innovative
framework that aims to accelerate inference by directly pruning less critical
prompt tokens during the forward pass. Our key insight is an information
diffusion phenomenon: As information from critical tokens propagates through
layers, it becomes distributed across the entire sequence. This diffusion
process suggests that LLMs can maintain their semantic integrity when excessive
tokens, even including these critical ones, are pruned in hidden states.
Motivated by this, SlimInfer introduces a dynamic fine-grained pruning
mechanism that accurately removes redundant tokens of hidden state at
intermediate layers. This layer-wise pruning naturally enables an asynchronous
KV cache manager that prefetches required token blocks without complex
predictors, reducing both memory usage and I/O costs. Extensive experiments
show that SlimInfer can achieve up to $\mathbf{2.53\times}$ time-to-first-token
(TTFT) speedup and $\mathbf{1.88\times}$ end-to-end latency reduction for
LLaMA3.1-8B-Instruct on a single RTX 4090, without sacrificing performance on
LongBench. Our code will be released upon acceptance.

</details>


### [42] [GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models](https://arxiv.org/abs/2508.06471)
*GLM-4. 5 Team,:,Aohan Zeng,Xin Lv,Qinkai Zheng,Zhenyu Hou,Bin Chen,Chengxing Xie,Cunxiang Wang,Da Yin,Hao Zeng,Jiajie Zhang,Kedong Wang,Lucen Zhong,Mingdao Liu,Rui Lu,Shulin Cao,Xiaohan Zhang,Xuancheng Huang,Yao Wei,Yean Cheng,Yifan An,Yilin Niu,Yuanhao Wen,Yushi Bai,Zhengxiao Du,Zihan Wang,Zilin Zhu,Bohan Zhang,Bosi Wen,Bowen Wu,Bowen Xu,Can Huang,Casey Zhao,Changpeng Cai,Chao Yu,Chen Li,Chendi Ge,Chenghua Huang,Chenhui Zhang,Chenxi Xu,Chenzheng Zhu,Chuang Li,Congfeng Yin,Daoyan Lin,Dayong Yang,Dazhi Jiang,Ding Ai,Erle Zhu,Fei Wang,Gengzheng Pan,Guo Wang,Hailong Sun,Haitao Li,Haiyang Li,Haiyi Hu,Hanyu Zhang,Hao Peng,Hao Tai,Haoke Zhang,Haoran Wang,Haoyu Yang,He Liu,He Zhao,Hongwei Liu,Hongxi Yan,Huan Liu,Huilong Chen,Ji Li,Jiajing Zhao,Jiamin Ren,Jian Jiao,Jiani Zhao,Jianyang Yan,Jiaqi Wang,Jiayi Gui,Jiayue Zhao,Jie Liu,Jijie Li,Jing Li,Jing Lu,Jingsen Wang,Jingwei Yuan,Jingxuan Li,Jingzhao Du,Jinhua Du,Jinxin Liu,Junkai Zhi,Junli Gao,Ke Wang,Lekang Yang,Liang Xu,Lin Fan,Lindong Wu,Lintao Ding,Lu Wang,Man Zhang,Minghao Li,Minghuan Xu,Mingming Zhao,Mingshu Zhai,Pengfan Du,Qian Dong,Shangde Lei,Shangqing Tu,Shangtong Yang,Shaoyou Lu,Shijie Li,Shuang Li,Shuang-Li,Shuxun Yang,Sibo Yi,Tianshu Yu,Wei Tian,Weihan Wang,Wenbo Yu,Weng Lam Tam,Wenjie Liang,Wentao Liu,Xiao Wang,Xiaohan Jia,Xiaotao Gu,Xiaoying Ling,Xin Wang,Xing Fan,Xingru Pan,Xinyuan Zhang,Xinze Zhang,Xiuqing Fu,Xunkai Zhang,Yabo Xu,Yandong Wu,Yida Lu,Yidong Wang,Yilin Zhou,Yiming Pan,Ying Zhang,Yingli Wang,Yingru Li,Yinpei Su,Yipeng Geng,Yitong Zhu,Yongkun Yang,Yuhang Li,Yuhao Wu,Yujiang Li,Yunan Liu,Yunqing Wang,Yuntao Li,Yuxuan Zhang,Zezhen Liu,Zhen Yang,Zhengda Zhou,Zhongpei Qiao,Zhuoer Feng,Zhuorui Liu,Zichen Zhang,Zihan Wang,Zijun Yao,Zikang Wang,Ziqiang Liu,Ziwei Chai,Zixuan Li,Zuodong Zhao,Wenguang Chen,Jidong Zhai,Bin Xu,Minlie Huang,Hongning Wang,Juanzi Li,Yuxiao Dong,Jie Tang*

Main category: cs.CL

TL;DR: 介绍了GLM-4.5，一款具有355B参数的大型混合专家语言模型，采用多阶段训练和强化学习，表现优异，且发布了缩小版本以推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 旨在开发具有强大推理和代理能力的高性能大模型，推动智能系统的发展。

Method: 采用多阶段训练、专家模型迭代及强化学习，结合混合推理策略进行训练。

Result: 在多项任务上表现优异，达到了行业领先的性能，参数规模优于多款同类模型。

Conclusion: GLM-4.5及其简化版本的发布有助于推理和智能代理系统的研究，丰富了大型语言模型的研发资源。

Abstract: We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language
model with 355B total parameters and 32B activated parameters, featuring a
hybrid reasoning method that supports both thinking and direct response modes.
Through multi-stage training on 23T tokens and comprehensive post-training with
expert model iteration and reinforcement learning, GLM-4.5 achieves strong
performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on
TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer
parameters than several competitors, GLM-4.5 ranks 3rd overall among all
evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B
parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance
research in reasoning and agentic AI systems. Code, models, and more
information are available at https://github.com/zai-org/GLM-4.5.

</details>


### [43] [HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning](https://arxiv.org/abs/2508.06475)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 提出HapticLLaMA模型，用于将触觉信号转化为自然语言描述，增强虚拟现实和康复应用的触觉感知体验。


<details>
  <summary>Details</summary>
Motivation: 触觉信号在虚拟现实和辅助技术中的潜在应用尚未充分开发，亟需有效的理解与描述技术。

Method: 构建多模态模型，采用频率和EnCodec两种哈普蒂克标记方法，通过两阶段训练（监督微调与强化学习）实现触觉信号的自然语言生成。

Result: 模型在自动评估指标和人类评判中表现优异，METEOR得分59.98，BLEU-4得分32.06，超过61%的生成描述获得较高评分，RLHF提升了整体评价。

Conclusion: 大规模语言模型具备处理和转化触觉数据的潜力，为虚拟现实和康复领域提供新的技术基础。

Abstract: Haptic captioning is the task of generating natural language descriptions
from haptic signals, such as vibrations, for use in virtual reality,
accessibility, and rehabilitation applications. While previous multimodal
research has focused primarily on vision and audio, haptic signals for the
sense of touch remain underexplored. To address this gap, we formalize the
haptic captioning task and propose HapticLLaMA, a multimodal sensory language
model that interprets vibration signals into descriptions in a given sensory,
emotional, or associative category. We investigate two types of haptic
tokenizers, a frequency-based tokenizer and an EnCodec-based tokenizer, that
convert haptic signals into sequences of discrete units, enabling their
integration with the LLaMA model. HapticLLaMA is trained in two stages: (1)
supervised fine-tuning using the LLaMA architecture with LoRA-based adaptation,
and (2) fine-tuning via reinforcement learning from human feedback (RLHF). We
assess HapticLLaMA's captioning performance using both automated n-gram metrics
and human evaluation. HapticLLaMA demonstrates strong capability in
interpreting haptic vibration signals, achieving a METEOR score of 59.98 and a
BLEU-4 score of 32.06 respectively. Additionally, over 61% of the generated
captions received human ratings above 3.5 on a 7-point scale, with RLHF
yielding a 10% improvement in the overall rating distribution, indicating
stronger alignment with human haptic perception. These findings highlight the
potential of large language models to process and adapt to sensory data.

</details>


### [44] [Post-training for Efficient Communication via Convention Formation](https://arxiv.org/abs/2508.06482)
*Yilun Hua,Evan Wang,Yoav Artzi*

Main category: cs.CL

TL;DR: 本文提出一种后训练方法，增强大语言模型（LLMs）在多轮交互中形成新颖约定的能力，通过两个新设计的基准测试验证。


<details>
  <summary>Details</summary>
Motivation: 人类在多轮交互中不断适应语言并形成约定，但LLMs自然表现缺乏此能力。

Method: 在被动训练后，通过针对性微调，利用启发式示范强化模型形成约定的能力，设计两个基准进行评估。

Result: 微调后模型在两个基准测试中显著提升了形成交互约定的能力。

Conclusion: 通过后训练优化，LLMs在多轮交互中的协作与理解能力得到加强，向人类表现靠近。

Abstract: Humans communicate with increasing efficiency in multi-turn interactions, by
adapting their language and forming ad-hoc conventions. In contrast, prior work
shows that LLMs do not naturally show this behavior. We develop a post-training
process to develop this ability through targeted fine-tuning on heuristically
identified demonstrations of convention formation. We evaluate with two new
benchmarks focused on this capability. First, we design a focused,
cognitively-motivated interaction benchmark that consistently elicits strong
convention formation trends in humans. Second, we create a new
document-grounded reference completion task that reflects in-the-wild
convention formation behavior. Our studies show significantly improved
convention formation abilities in post-trained LLMs across the two evaluation
methods.

</details>


### [45] [Indian Legal NLP Benchmarks : A Survey](https://arxiv.org/abs/2107.06056)
*Prathamesh Kalamkar,Janani Venugopalan Ph. D.,Vivek Raghavan Ph. D*

Main category: cs.CL

TL;DR: 提出了为印度法律文本创建专门自然语言处理基准的必要性和构想，以促进AI在法律领域的发展。


<details>
  <summary>Details</summary>
Motivation: 法律文本与普通英语不同，缺乏专用的自然语言处理基准，限制了技术创新。

Method: 回顾现有工作并提出新基准的创意。

Result: 促进针对印度法律文本的NLP技术发展和创新。

Conclusion: 建立挑战性强的印度法律NLP基准，将推动该领域的研究与应用。

Abstract: Availability of challenging benchmarks is the key to advancement of AI in a
specific field.Since Legal Text is significantly different than normal English
text, there is a need to create separate Natural Language Processing benchmarks
for Indian Legal Text which are challenging and focus on tasks specific to
Legal Systems. This will spur innovation in applications of Natural language
Processing for Indian Legal Text and will benefit AI community and Legal
fraternity. We review the existing work in this area and propose ideas to
create new benchmarks for Indian Legal Natural Language Processing.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [46] [Request-Only Optimization for Recommendation Systems](https://arxiv.org/abs/2508.05640)
*Liang Guo,Wei Li,Lucy Liao,Huihui Cheng,Rui Zhang,Yu Shi,Yueming Wang,Yanzun Huang,Keke Zhai,Pengchao Wang,Timothy Shi,Xuan Cao,Shengzhi Wang,Renqin Cai,Zhaojie Gong,Omkar Vichare,Rui Jian,Leon Gao,Shiyan Deng,Xingyu Liu,Xiong Zhang,Fu Li,Wenlei Xie,Bin Wen,Rui Li,Xing Liu,Jiaqi Zhai*

Main category: cs.IR

TL;DR: 提出Request-Only优化（ROO）范式，通过请求作为数据单位，提高推荐系统的存储、训练效率和模型质量。


<details>
  <summary>Details</summary>
Motivation: 应对行业规模推荐模型的复杂性和大规模数据训练带来的存储与效率挑战。

Method: 将请求单元化处理，进行特征去重、计算去重，结合请求驱动的模型架构和基础设施设计。

Result: 实现存储节省，加速训练，提高模型对用户兴趣的捕获能力，适应大规模神经网络架构。

Conclusion: ROO范式优化了推荐系统的存储和训练过程，并提升模型质量，具有广泛应用前景。

Abstract: Deep Learning Recommendation Models (DLRMs) represent one of the largest
machine learning applications on the planet. Industry-scale DLRMs are trained
with petabytes of recommendation data to serve billions of users every day. To
utilize the rich user signals in the long user history, DLRMs have been scaled
up to unprecedented complexity, up to trillions of floating-point operations
(TFLOPs) per example. This scale, coupled with the huge amount of training
data, necessitates new storage and training algorithms to efficiently improve
the quality of these complex recommendation systems. In this paper, we present
a Request-Only Optimizations (ROO) training and modeling paradigm. ROO
simultaneously improves the storage and training efficiency as well as the
model quality of recommendation systems. We holistically approach this
challenge through co-designing data (i.e., request-only data), infrastructure
(i.e., request-only based data processing pipeline), and model architecture
(i.e., request-only neural architectures). Our ROO training and modeling
paradigm treats a user request as a unit of the training data. Compared with
the established practice of treating a user impression as a unit, our new
design achieves native feature deduplication in data logging, consequently
saving data storage. Second, by de-duplicating computations and communications
across multiple impressions in a request, this new paradigm enables highly
scaled-up neural network architectures to better capture user interest signals,
such as Generative Recommenders (GRs) and other request-only friendly
architectures.

</details>


### [47] [Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05647)
*Vibhor Agrawal,Fay Wang,Rishi Puri*

Main category: cs.IR

TL;DR: 提出了一种用于RAG的新型图神经网络架构，通过知识图构建和查询引导注意机制，有效提升复杂多跳问答的检索准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统密集检索在多跳复杂问答任务中的局限性，提升检索相关性。

Method: 利用构建的知识图结合增强的图注意网络和用户查询引导的池化策略，以动态关注相关信息。

Result: 在复杂问答任务中显著优于标准密集检索方法，特别是在多文档推理方面表现出色。

Conclusion: 该方法通过知识图和改进的注意机制，有效提升复杂问答的检索性能，具备实际应用潜力。

Abstract: We present a novel graph neural network (GNN) architecture for
retrieval-augmented generation (RAG) that leverages query-aware attention
mechanisms and learned scoring heads to improve retrieval accuracy on complex,
multi-hop questions. Unlike traditional dense retrieval methods that treat
documents as independent entities, our approach constructs per-episode
knowledge graphs that capture both sequential and semantic relationships
between text chunks. We introduce an Enhanced Graph Attention Network with
query-guided pooling that dynamically focuses on relevant parts of the graph
based on user queries. Experimental results demonstrate that our approach
significantly outperforms standard dense retrievers on complex question
answering tasks, particularly for questions requiring multi-document reasoning.
Our implementation leverages PyTorch Geometric for efficient processing of
graph-structured data, enabling scalable deployment in production retrieval
systems

</details>


### [48] [AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups](https://arxiv.org/abs/2508.05648)
*Chandler Campbell,Bernie Boscoe,Tuan Do*

Main category: cs.IR

TL;DR: 提出了一种名为AquiLLM的轻量级、模块化的RAG系统，旨在帮助科研团队更好地管理和访问内部知识资产，同时考虑隐私保护。


<details>
  <summary>Details</summary>
Motivation: 研究团队难以系统化存储和检索分散的隐性知识，现有的RAG系统多关注公共文档，忽视内部资料的隐私需求。

Method: 设计并实现了一个支持多类型文档和可配置隐私设置的RAG系统——AquiLLM，满足科研团队对内部资料的访问和保护需求。

Result: 该系统提升了科研团队对正式和非正式知识的访问效率，并兼顾隐私安全。

Conclusion: AquiLLM为科研集体知识管理提供了实用的解决方案，有助于改善知识获取和知识保护的平衡。

Abstract: Research groups face persistent challenges in capturing, storing, and
retrieving knowledge that is distributed across team members. Although
structured data intended for analysis and publication is often well managed,
much of a group's collective knowledge remains informal, fragmented, or
undocumented--often passed down orally through meetings, mentoring, and
day-to-day collaboration. This includes private resources such as emails,
meeting notes, training materials, and ad hoc documentation. Together, these
reflect the group's tacit knowledge--the informal, experience-based expertise
that underlies much of their work. Accessing this knowledge can be difficult,
requiring significant time and insider understanding. Retrieval-augmented
generation (RAG) systems offer promising solutions by enabling users to query
and generate responses grounded in relevant source material. However, most
current RAG-LLM systems are oriented toward public documents and overlook the
privacy concerns of internal research materials. We introduce AquiLLM
(pronounced ah-quill-em), a lightweight, modular RAG system designed to meet
the needs of research groups. AquiLLM supports varied document types and
configurable privacy settings, enabling more effective access to both formal
and informal knowledge within scholarly groups.

</details>


### [49] [AI Guided Accelerator For Search Experience](https://arxiv.org/abs/2508.05649)
*Jayanth Yetukuri,Mehran Elyasi,Samarth Agrawal,Aritra Mandal,Rui Kong,Harish Vempati,Ishita Khan*

Main category: cs.IR

TL;DR: 提出了一种新框架，通过建模用户在电商搜索中的过渡查询和利用大语言模型实现多样化查询扩展，提高了搜索相关性和用户参与度。


<details>
  <summary>Details</summary>
Motivation: 解决传统单独建模查询对话的不足，以更好捕捉用户在电商搜索中的意图转变。

Method: 从eBay用户行为日志中挖掘结构化查询轨迹，结合大语言模型生成多样化、符合意图的查询。

Result: 实证结果显示新方法在转化率和用户参与度方面优于传统RELATED SEARCHES模块。

Conclusion: 通过明确建模中间查询和利用生成模型增强查询多样性，有效提升电商搜索体验。

Abstract: Effective query reformulation is pivotal in narrowing the gap between a
user's exploratory search behavior and the identification of relevant products
in e-commerce environments. While traditional approaches predominantly model
query rewrites as isolated pairs, they often fail to capture the sequential and
transitional dynamics inherent in real-world user behavior. In this work, we
propose a novel framework that explicitly models transitional
queries--intermediate reformulations occurring during the user's journey toward
their final purchase intent. By mining structured query trajectories from
eBay's large-scale user interaction logs, we reconstruct query sequences that
reflect shifts in intent while preserving semantic coherence. This approach
allows us to model a user's shopping funnel, where mid-journey transitions
reflect exploratory behavior and intent refinement. Furthermore, we incorporate
generative Large Language Models (LLMs) to produce semantically diverse and
intent-preserving alternative queries, extending beyond what can be derived
through collaborative filtering alone. These reformulations can be leveraged to
populate Related Searches or to power intent-clustered carousels on the search
results page, enhancing both discovery and engagement. Our contributions
include (i) the formal identification and modeling of transitional queries,
(ii) the introduction of a structured query sequence mining pipeline for intent
flow understanding, and (iii) the application of LLMs for scalable,
intent-aware query expansion. Empirical evaluation demonstrates measurable
gains in conversion and engagement metrics compared to the existing Related
Searches module, validating the effectiveness of our approach in real-world
e-commerce settings.

</details>


### [50] [OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools](https://arxiv.org/abs/2508.05650)
*Jiaxuan Liang,Shide Zhou,Kailong Wang*

Main category: cs.IR

TL;DR: 提出OmniBench RAG平台，用于多领域评估RAG系统的性能，强调可重复性和可比性。


<details>
  <summary>Details</summary>
Motivation: 评估RAG在不同模型和领域中的实际性能，存在指标不足和缺乏标准化框架的问题。

Method: 开发自动化、多领域的评价平台，设计标准指标，支持动态测试和知识库构建。

Result: 揭示RAG在不同领域的效果差异巨大，强调系统性和领域意识评估的重要性。

Conclusion: 体系化、领域感知的评价方法对理解和优化RAG系统至关重要。

Abstract: While Retrieval Augmented Generation (RAG) is now widely adopted to enhance
LLMs, evaluating its true performance benefits in a reproducible and
interpretable way remains a major hurdle. Existing methods often fall short:
they lack domain coverage, employ coarse metrics that miss sub document
precision, and fail to capture computational trade offs. Most critically, they
provide no standardized framework for comparing RAG effectiveness across
different models and domains.
  We introduce OmniBench RAG, a novel automated platform for multi domain
evaluation of RAG systems. The platform quantifies performance gains across
accuracy and efficiency dimensions, spanning nine knowledge fields including
culture, geography, and health. We introduce two standardized metrics:
Improvements (accuracy gains) and Transformation (efficiency differences
between pre RAG and post RAG models), enabling reproducible comparisons across
models and tasks. The platform features dynamic test generation, modular
evaluation pipelines, and automated knowledge base construction. Our evaluation
reveals striking variability in RAG effectiveness, from significant gains in
culture to declines in mathematics, highlighting the critical importance of
systematic, domain aware assessment. A demonstration video is available at:
https://www.youtube.com/watch?v=BZx83QFcTCI. Code and datasets:
https://github.com/Garnett-Liang/Omnibench-RAG.

</details>


### [51] [Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation](https://arxiv.org/abs/2508.05652)
*Julia Ann Mathew,Suining He*

Main category: cs.IR

TL;DR: 开发了一个基于大型语言模型和检索增强生成的户外流径推荐聊天机器人Judy，具有较高的准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 随着户外休闲活动的普及，对提供个性化和准确导览建议的对话式AI系统需求增加。

Method: 结合大规模语言模型和检索增强生成技术，进行了系统开发和在康涅狄格州户外流径的案例研究与性能评估。

Result: Judy在准确性、效果和用户体验方面表现优良，验证了基于RAG的推荐系统的实用性。

Conclusion: 基于大模型与检索增强的对话系统可有效支持户外流径的个性化推荐，具备推广前景。

Abstract: The increasing popularity of outdoor recreational activities (such as hiking
and biking) has boosted the demand for a conversational AI system to provide
informative and personalized suggestion on outdoor trails. Challenges arise in
response to (1) how to provide accurate outdoor trail information via
conversational AI; and (2) how to enable usable and efficient recommendation
services. To address above, this paper discusses the preliminary and practical
lessons learned from developing Judy, an outdoor trail recommendation chatbot
based on the large language model (LLM) with retrieval augmented generation
(RAG). To gain concrete system insights, we have performed case studies with
the outdoor trails in Connecticut (CT), US. We have conducted web-based data
collection, outdoor trail data management, and LLM model performance studies on
the RAG-based recommendation. Our experimental results have demonstrated the
accuracy, effectiveness, and usability of Judy in recommending outdoor trails
based on the LLM with RAG.

</details>


### [52] [Comparison of Information Retrieval Techniques Applied to IT Support Tickets](https://arxiv.org/abs/2508.05654)
*Leonardo Santiago Benitez Pereira,Robinson Pizzio,Samir Bonho*

Main category: cs.IR

TL;DR: 通过比较11种信息检索技术，为IT支持分析师开发了优化的支持工单推荐系统，发现Sentence-BERT表现最佳。


<details>
  <summary>Details</summary>
Motivation: 提升IT支持系统中工单推荐的效率与准确性，优化技术选择。

Method: 比较多种信息检索技术在IT支持工单中的表现，包括Sentence-BERT、TF-IDF、Word2vec和LDA等。

Result: Sentence-BERT的多语言变体达到了78.7%的相关推荐率，其他技术均表现稳定。还公开了数据和源码，并开发了最小可行原型。

Conclusion: 提出新的评估指标，更贴合IT分析师的感知，有助于提升工单检索的实用性和效果。

Abstract: Institutions dependent on IT services and resources acknowledge the crucial
significance of an IT help desk system, that act as a centralized hub
connecting IT staff and users for service requests. Employing various Machine
Learning models, these IT help desk systems allow access to corrective actions
used in the past, but each model has different performance when applied to
different datasets. This work compares eleven Information Retrieval techniques
in a dataset of IT support tickets, with the goal of implementing a software
that facilitates the work of Information Technology support analysts. The best
results were obtained with the Sentence-BERT technique, in its multi-language
variation distilluse-base-multilingual-cased-v1, where 78.7% of the
recommendations made by the model were considered relevant. TF-IDF (69.0%),
Word2vec (68.7%) and LDA (66.3%) techniques also had consistent results.
Furthermore, the used datasets and essential parts of coding have been
published and made open source. It also demonstrated the practicality of a
support ticket recovery system by implementing a minimal viable prototype, and
described in detail the implementation of the system. Finally, this work
proposed a novel metric for comparing the techniques, whose aim is to closely
reflect the perception of the IT analysts about the retrieval quality.

</details>


### [53] [Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation](https://arxiv.org/abs/2508.05657)
*Haozhe Xu,Xiaohua Wang,Changze Lv,Xiaoqing Zheng*

Main category: cs.IR

TL;DR: 提出一种结合语义检索和过滤的双阶段数据增强框架，有效提升对话推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 解决仿真标注中的假阴性问题，提升CRS的推荐质量。

Method: 利用大型语言模型进行语义检索和筛选，采用双阶段训练策略平衡语义和协作信息。

Result: 在两个基准数据集上实验显示，该方法显著提升推荐效果，并具有良好的泛化能力。

Conclusion: 通过创新数据增强和训练策略，有助于推动CRS的实际应用和性能提升。

Abstract: Conversational recommender systems (CRSs) enhance recommendation quality by
engaging users in multi-turn dialogues, capturing nuanced preferences through
natural language interactions. However, these systems often face the false
negative issue, where items that a user might like are incorrectly labeled as
negative during training, leading to suboptimal recommendations.Expanding the
label set through data augmentation presents an intuitive solution but faces
the challenge of balancing two key aspects: ensuring semantic relevance and
preserving the collaborative information inherent in CRS datasets. To address
these issues, we propose a novel data augmentation framework that first
leverages an LLM-based semantic retriever to identify diverse and semantically
relevant items, which are then filtered by a relevance scorer to remove noisy
candidates. Building on this, we introduce a two-stage training strategy
balancing semantic relevance and collaborative information. Extensive
experiments on two benchmark datasets and user simulators demonstrate
significant and consistent performance improvements across various
recommenders, highlighting the effectiveness of our approach in advancing CRS
performance.

</details>


### [54] [Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review](https://arxiv.org/abs/2508.05660)
*Aditya Nagori,Ricardo Accorsi Casonatto,Ayush Gautam,Abhinav Manikantha Sai Cheruvu,Rishikesan Kamaleswaran*

Main category: cs.IR

TL;DR: 提出一种自主代理驱动的混合检索增强生成系统，有效整合图数据库和向量检索，提升科学信息检索的相关性和可信度。


<details>
  <summary>Details</summary>
Motivation: 应对科学出版物激增带来的传统评审方法难以满足信息整合和准确性的挑战。

Method: 构建基于知识图和向量存储的混合检索系统，结合动态代理选择检索策略，并通过指令调优提升生成质量，进行性能评价。

Result: 在模拟实际查询的测试中，该系统显著提升了检索的相关性、可信度及推理能力，表现优于基线方法，展示了自主科学发现的潜力。

Conclusion: 引入自主代理的混合检索生成框架，有助于未来科学信息的高效、可靠检索和发现。

Abstract: The surge in scientific publications challenges traditional review methods,
demanding tools that integrate structured metadata with full-text analysis.
Hybrid Retrieval Augmented Generation (RAG) systems, combining graph queries
with vector search offer promise but are typically static, rely on proprietary
tools, and lack uncertainty estimates. We present an agentic approach that
encapsulates the hybrid RAG pipeline within an autonomous agent capable of (1)
dynamically selecting between GraphRAG and VectorRAG for each query, (2)
adapting instruction-tuned generation in real time to researcher needs, and (3)
quantifying uncertainty during inference. This dynamic orchestration improves
relevance, reduces hallucinations, and promotes reproducibility.
  Our pipeline ingests bibliometric open-access data from PubMed, arXiv, and
Google Scholar APIs, builds a Neo4j citation-based knowledge graph (KG), and
embeds full-text PDFs into a FAISS vector store (VS) using the all-MiniLM-L6-v2
model. A Llama-3.3-70B agent selects GraphRAG (translating queries to Cypher
for KG) or VectorRAG (combining sparse and dense retrieval with re-ranking).
Instruction tuning refines domain-specific generation, and bootstrapped
evaluation yields standard deviation for evaluation metrics.
  On synthetic benchmarks mimicking real-world queries, the Instruction-Tuned
Agent with Direct Preference Optimization (DPO) outperforms the baseline,
achieving a gain of 0.63 in VS Context Recall and a 0.56 gain in overall
Context Precision. Additional gains include 0.24 in VS Faithfulness, 0.12 in
both VS Precision and KG Answer Relevance, 0.11 in overall Faithfulness score,
0.05 in KG Context Recall, and 0.04 in both VS Answer Relevance and overall
Precision. These results highlight the system's improved reasoning over
heterogeneous sources and establish a scalable framework for autonomous,
agentic scientific discovery.

</details>


### [55] [Zero-Shot Retrieval for Scalable Visual Search in a Two-Sided Marketplace](https://arxiv.org/abs/2508.05661)
*Andre Rusli,Shoma Ishimoto,Sho Akiyama,Aman Kumar Singh*

Main category: cs.IR

TL;DR: 该论文提出了一个在二手市场中应用的视觉搜索系统，利用最新的零样本视觉-语言模型提升检索性能，实际测试显示效果显著，用户参与度和交易量显著增加。


<details>
  <summary>Details</summary>
Motivation: 当前二手市场中的商品信息缺乏结构化，视觉搜索成为提升用户体验的关键工具。

Method: 部署并评估了多种视觉-语言模型，结合实时推理、索引优化和嵌入维度降低，实现高效的视觉搜索。

Result: 多模型中的SigLIP模型表现优异，提升了检索效果，A/B测试显示用户参与度和交易量显著上升。

Conclusion: 最新的零样本视觉-语言模型可以有效应用于实际场景，降低部署门槛，提升系统性能与用户体验。

Abstract: Visual search offers an intuitive way for customers to explore diverse
product catalogs, particularly in consumer-to-consumer (C2C) marketplaces where
listings are often unstructured and visually driven. This paper presents a
scalable visual search system deployed in Mercari's C2C marketplace, where
end-users act as buyers and sellers. We evaluate recent vision-language models
for zero-shot image retrieval and compare their performance with an existing
fine-tuned baseline. The system integrates real-time inference and background
indexing workflows, supported by a unified embedding pipeline optimized through
dimensionality reduction. Offline evaluation using user interaction logs shows
that the multilingual SigLIP model outperforms other models across multiple
retrieval metrics, achieving a 13.3% increase in nDCG@5 over the baseline. A
one-week online A/B test in production further confirms real-world impact, with
the treatment group showing substantial gains in engagement and conversion, up
to a 40.9% increase in transaction rate via image search. Our findings
highlight that recent zero-shot models can serve as a strong and practical
baseline for production use, which enables teams to deploy effective visual
search systems with minimal overhead, while retaining the flexibility to
fine-tune based on future data or domain-specific needs.

</details>


### [56] [From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base](https://arxiv.org/abs/2508.05662)
*Yuzhou Zhu*

Main category: cs.IR

TL;DR: Streaming RAG结合多向量筛查和增量索引，提升实时数据检索效率和准确性，适用于新闻、社交媒体等动态数据源。


<details>
  <summary>Details</summary>
Motivation: 应对新闻、社交媒体、传感器网络和金融市场等动态信息源带来的检索挑战，满足低延迟和高准确率需求。

Method: 采用多向量余弦筛查、小批量聚类和计数器过滤器，建立紧凑的原型集，并实现增量索引更新。

Result: 在八个实时流数据测试中，大幅提高Recall@10，latency<15ms，吞吐量超过900文档/秒。Q&A和摘要任务中亦表现优异。

Conclusion: Streaming RAG在检索效率和效果方面达成新平衡，为动态信息检索提供有效解决方案。

Abstract: Dynamic streams from news feeds, social media, sensor networks, and financial
markets challenge static RAG frameworks. Full-scale indices incur high memory
costs; periodic rebuilds introduce latency that undermines data freshness;
naive sampling sacrifices semantic coverage. We present Streaming RAG, a
unified pipeline that combines multi-vector cosine screening, mini-batch
clustering, and a counter-based heavy-hitter filter to maintain a compact
prototype set. We further prove an approximation bound \$E\[R(K\_t)] \ge R^\* -
L \Delta\$ linking retrieval quality to clustering variance. An incremental
index upsert mechanism refreshes prototypes without interrupting queries.
Experiments on eight real-time streams show statistically significant gains in
Recall\@10 (up to 3 points, p < 0.01), end-to-end latency below 15 ms, and
throughput above 900 documents per second under a 150 MB budget. Hyperparameter
sensitivity analysis over cluster count, admission probability, relevance
threshold, and counter capacity validates default settings. In open-domain
question answering with GPT-3.5 Turbo, we record 3.2-point gain in Exact Match
and 2.8-point gain in F1 on SQuAD; abstractive summarization yields ROUGE-L
improvements. Streaming RAG establishes a new Pareto frontier for retrieval
augmentation.

</details>


### [57] [Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support](https://arxiv.org/abs/2508.05664)
*Hei Yu Chan,Kuok Tou Ho,Chenglong Ma,Yujing Si,Hok Lai Lin,Sa Lei Lam*

Main category: cs.IR

TL;DR: 该论文提出了一套结合意图识别、RAG融合和重排序的客户支持系统，有效处理电力领域中的模糊、多意图和详细查询，显著优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 提升电力客户服务中对复杂、多意图和模糊查询的处理能力，弥补现有NLP管道或微调模型的不足。

Method: 采用图基RAG框架，结合查询重写、RAG融合、意图识别与重排序等技术，优化问答效果。

Result: 系统在两个数据集上的准确率分别达97.9%和89.6%，优于基线RAG模型。

Conclusion: 多技术结合提升客户支持系统的鲁棒性，有效应对复杂查询，具有实际应用价值。

Abstract: Many AI customer service systems use standard NLP pipelines or finetuned
language models, which often fall short on ambiguous, multi-intent, or
detail-specific queries. This case study evaluates recent techniques: query
rewriting, RAG Fusion, keyword augmentation, intent recognition, and context
reranking, for building a robust customer support system in the electric power
domain. We compare vector-store and graph-based RAG frameworks, ultimately
selecting the graph-based RAG for its superior performance in handling complex
queries. We find that query rewriting improves retrieval for queries using
non-standard terminology or requiring precise detail. RAG Fusion boosts
performance on vague or multifaceted queries by merging multiple retrievals.
Reranking reduces hallucinations by filtering irrelevant contexts. Intent
recognition supports the decomposition of complex questions into more targeted
sub-queries, increasing both relevance and efficiency. In contrast, keyword
augmentation negatively impacts results due to biased keyword selection. Our
final system combines intent recognition, RAG Fusion, and reranking to handle
disambiguation and multi-source queries. Evaluated on both a GPT-4-generated
dataset and a real-world electricity provider FAQ dataset, it achieves 97.9%
and 89.6% accuracy respectively, substantially outperforming baseline RAG
models.

</details>


### [58] [HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis](https://arxiv.org/abs/2508.05666)
*Alejandro Godinez*

Main category: cs.IR

TL;DR: HySemRAG结合ETL和RAG，构建多层检索和自我校正体系，实现大规模文献总结与研究空白识别。


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG架构的局限性，提高文献综述的效率和准确性。

Method: 通过多源元数据采集、PDF检索、文档分析、知识图谱构建等八个阶段整合数据，采用混合检索和自我校正机制。

Result: 提升语义匹配度，单次成功率68.3%，验证响应中的引证准确率达99.0%，实现对流行病学文献的趋势分析与空白识别。

Conclusion: HySemRAG在科学文献合成中具有广泛应用潜力，提升研究效率与深度。

Abstract: We present HySemRAG, a framework that combines Extract, Transform, Load (ETL)
pipelines with Retrieval-Augmented Generation (RAG) to automate large-scale
literature synthesis and identify methodological research gaps. The system
addresses limitations in existing RAG architectures through a multi-layered
approach: hybrid retrieval combining semantic search, keyword filtering, and
knowledge graph traversal; an agentic self-correction framework with iterative
quality assurance; and post-hoc citation verification ensuring complete
traceability. Our implementation processes scholarly literature through eight
integrated stages: multi-source metadata acquisition, asynchronous PDF
retrieval, custom document layout analysis using modified Docling architecture,
bibliographic management, LLM-based field extraction, topic modeling, semantic
unification, and knowledge graph construction. The system creates dual data
products - a Neo4j knowledge graph enabling complex relationship queries and
Qdrant vector collections supporting semantic search - serving as foundational
infrastructure for verifiable information synthesis. Evaluation across 643
observations from 60 testing sessions demonstrates structured field extraction
achieving 35.1% higher semantic similarity scores (0.655 $\pm$ 0.178) compared
to PDF chunking approaches (0.485 $\pm$ 0.204, p < 0.000001). The agentic
quality assurance mechanism achieves 68.3% single-pass success rates with 99.0%
citation accuracy in validated responses. Applied to geospatial epidemiology
literature on ozone exposure and cardiovascular disease, the system identifies
methodological trends and research gaps, demonstrating broad applicability
across scientific domains for accelerating evidence synthesis and discovery.

</details>


### [59] [ITDR: An Instruction Tuning Dataset for Enhancing Large Language Models in Recommendations](https://arxiv.org/abs/2508.05667)
*Zekun Liu,Xiaowen Huang,Jitao Sang*

Main category: cs.IR

TL;DR: 本研究构建了一个包含多任务的指令调优数据集ITDR，用于提升大型语言模型在推荐系统任务中的表现，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 弥补LLMs在推荐系统中难以建模用户偏好与商品关联的不足，以及改进基于提示的方法性能。

Method: 设计并构建了包含13个公开推荐数据集、约20万实例的多任务指令调优集，通过手工模板整合优化模型表现。

Result: 调优显著提高GLM-4、Qwen2.5等开源模型在推荐任务中的性能，分析任务关联和描述对效果的影响，并与闭源模型进行对比。

Conclusion: 多任务调优数据集有效增强了大模型在推荐场景中的能力，提供了开源的支持资源。

Abstract: Large language models (LLMs) have demonstrated outstanding performance in
natural language processing tasks. However, in the field of recommendation
systems, due to the structural differences between user behavior data and
natural language, LLMs struggle to effectively model the associations between
user preferences and items. Although prompt-based methods can generate
recommendation results, their inadequate understanding of recommendation tasks
leads to constrained performance. To address this gap, in this work, we
construct a sufficient instruction tuning dataset, ITDR, which encompasses 7
subtasks across two core root tasks--user-item interaction and user-item
understanding. The dataset integrates data from 13 public recommendation
datasets and is built using manually crafted standardized templates, comprising
approximately 200,000 instances. Experimental results demonstrate that ITDR
significantly enhances the performance of mainstream open-source LLMs such as
GLM-4, Qwen2.5, Qwen2.5-Instruct and LLaMA-3.2 on recommendation tasks.
Furthermore, we analyze the correlations between tasks and explore the impact
of task descriptions and data scale on instruction tuning effectiveness.
Finally, we perform comparative experiments against closed-source LLMs with
substantial parameters. Our tuning dataset ITDR and the fine-tuned large
recommendation models can be accessed at https://github.com/hellolzk/ITDR.

</details>


### [60] [A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges](https://arxiv.org/abs/2508.05668)
*Yunjia Xi,Jianghao Lin,Yongzhao Xiao,Zheli Zhou,Rong Shan,Te Gao,Jiachen Zhu,Weiwen Liu,Yong Yu,Weinan Zhang*

Main category: cs.IR

TL;DR: 论文系统分析了基于大语言模型的搜索代理，涵盖架构、优化、应用和评估，指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，搜索代理成为信息检索的新趋势，亟需系统梳理与分析。

Method: 本文对现有文献进行全面分类与总结，从架构、优化、应用和评估等角度进行分析。

Result: 提出了搜索代理的当前研究状况与面临的挑战，为未来研究提供方向。

Conclusion: 该综述为理解和推进搜索代理技术提供了基础，强调了关键挑战与未来潜力。

Abstract: The advent of Large Language Models (LLMs) has significantly revolutionized
web search. The emergence of LLM-based Search Agents marks a pivotal shift
towards deeper, dynamic, autonomous information seeking. These agents can
comprehend user intentions and environmental context and execute multi-turn
retrieval with dynamic planning, extending search capabilities far beyond the
web. Leading examples like OpenAI's Deep Research highlight their potential for
deep information mining and real-world applications. This survey provides the
first systematic analysis of search agents. We comprehensively analyze and
categorize existing works from the perspectives of architecture, optimization,
application, and evaluation, ultimately identifying critical open challenges
and outlining promising future research directions in this rapidly evolving
field. Our repository is available on
https://github.com/YunjiaXi/Awesome-Search-Agent-Papers.

</details>


### [61] [Fine-Tuning Vision-Language Models for Markdown Conversion of Financial Tables in Malaysian Audited Financial Reports](https://arxiv.org/abs/2508.05669)
*Jin Khye Tan,En Jun Choong,Ethan Jeremiah Chitty,Yan Pheng Choo,John Hsin Yang Wong,Chern Eu Cheah*

Main category: cs.IR

TL;DR: 提出了一种基于Qwen2.5-VL-7B的微调视觉-语言模型，用于将财务报告中的表格转化为Markdown格式，显著提高了结构识别的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 财务文件中的表格结构提取具有挑战性，亟需高效准确的自动化解决方案。

Method: 采用多模型微调策略，利用1200多对图文数据进行训练，结合创新的结构相似度评估指标和多样评估框架。

Result: 模型在表格转换任务中达到92.20%的准确率和96.53%的结构保真度，优于多种先进模型和商业方案，尤其在效率方面表现优越。

Conclusion: 基于领域微调的方法能有效弥合非结构化财务数据与自动化应用之间的差距，比大型通用模型更具成本效益。

Abstract: Accurately extracting and representing the structure of tabular data from
financial documents remains a critical challenge in document understanding,
particularly for regulatory and analytical use cases. This study addresses the
complexity of converting financial tables from Malaysian audited financial
reports into Markdown format, a task complicated by rotated layouts,
multi-level headers, and implicit structural cues. We propose a fine-tuned
vision-language model (VLM), based on Qwen2.5-VL-7B, optimized for
high-fidelity Markdown generation from document images. Our approach includes a
curated dataset of 2,152 image-text pairs with augmentations and a supervised
fine-tuning strategy using LoRA. To assess performance, we evaluated our model
on 100 out-of-sample tables using a dual framework: a criteria-based
LLM-as-a-judge for fine-grained accuracy and our novel Markdown
Tree-Edit-Distance-based Similarity (TEDS) metric for holistic structural
fidelity. Our model achieves a 92.20% overall accuracy on the criteria-based
assessment and a 96.53% Markdown TEDS score. This performance significantly
surpasses its Qwen2.5-VL-7B base model, larger-scale VLMs, and specialized
reasoning-enabled models. Compared to these self-hosted alternatives, it also
significantly reduces inference time. Furthermore, its accuracy exceeds that of
widely used proprietary models such as OpenAI's GPT-4o and Gemini 2.5 Flash.
These results demonstrate that domain-specific fine-tuning provides an
effective and efficient method to bridge the gap between unstructured financial
documents and downstream automation, rivalling much larger and more general
models without their computational overhead.

</details>


### [62] [LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing](https://arxiv.org/abs/2508.05672)
*Yao Zhao,Yantian Ding,Zhiyue Zhang,Dapeng Yao,Yanxun Xu*

Main category: cs.IR

TL;DR: LMAR是一种用于增强检索在特定领域表现的框架，通过结合大模型生成、对比学习和文本聚类，有效提升性能并保持低资源需求。


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统中领域知识不足的问题，提升在特定领域的表现，降低高成本和低效的问题。

Method: 结合LLM引导的数据合成、对比嵌入适应及文本聚类，采用两阶段流程：三元组采样与合成数据增强。

Result: 在多个领域数据集上效果优于多种基线模型，硬件需求适中，延迟低，可与多种模型无缝集成。

Conclusion: LMAR是一种实用、经济的领域适配方案，具备良好的扩展性与效果。

Abstract: Retrieval Augmented Generation (RAG) systems often struggle with
domain-specific knowledge due to performance deterioration of pre-trained
embeddings and prohibitive computational costs of large language model
(LLM)-based retrievers. While fine-tuning data augmentation embedding models
offers a promising direction, its effectiveness is limited by the need for
high-quality training data and reliable chunking strategies that preserve
contextual integrity. We propose LMAR (Language Model Augmented Retriever), a
model-agnostic framework that addresses these challenges by combining
LLM-guided data synthesis with contrastive embedding adaptation and efficient
text clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling
and synthetic data augmentation, where LLMs act as both labeler and validator
to ensure high-fidelity supervision throughout the pipeline. Experimental
results across multiple domain-specific benchmark datasets demonstrate that
LMAR outperforms multiple baseline models, while maintaining moderate hardware
requirements and low latency. Its model-agnostic nature further enables
seamless integration with emerging RAG architectures and text embedding models,
ensuring continual improvements without redesigning the pipeline. These results
highlight LMAR as a practical and cost-effective solution for scalable
domain-specific adaptation.

</details>


### [63] [Breaking the Top-$K$ Barrier: Advancing Top-$K$ Ranking Metrics Optimization in Recommender Systems](https://arxiv.org/abs/2508.05673)
*Weiqin Yang,Jiawei Chen,Shengjia Zhang,Peng Wu,Yuegang Sun,Yan Feng,Chun Chen,Can Wang*

Main category: cs.IR

TL;DR: 提出了一种新型的推荐系统损失函数SL@K，用以优化排名指标NDCG@K，解决了连续性和计算效率等挑战，表现优异。


<details>
  <summary>Details</summary>
Motivation: 优化NDCG@K在推荐系统训练中具有挑战性，受限于其不连续性和复杂的Top-K截断。

Method: 引入分位数技术结合平滑上界策略，设计了SL@K损失。

Result: 在多数据集和模型中，SL@K显著优于现有方法，平均提升6.03%。

Conclusion: SL@K提供了一个高效、稳定、理论保证的优化方案，有助于提升推荐系统性能。

Abstract: In the realm of recommender systems (RS), Top-$K$ ranking metrics such as
NDCG@$K$ are the gold standard for evaluating recommendation performance.
However, during the training of recommendation models, optimizing NDCG@$K$
poses significant challenges due to its inherent discontinuous nature and the
intricate Top-$K$ truncation. Recent efforts to optimize NDCG@$K$ have either
overlooked the Top-$K$ truncation or suffered from high computational costs and
training instability. To overcome these limitations, we propose SoftmaxLoss@$K$
(SL@$K$), a novel recommendation loss tailored for NDCG@$K$ optimization.
Specifically, we integrate the quantile technique to handle Top-$K$ truncation
and derive a smooth upper bound for optimizing NDCG@$K$ to address
discontinuity. The resulting SL@$K$ loss has several desirable properties,
including theoretical guarantees, ease of implementation, computational
efficiency, gradient stability, and noise robustness. Extensive experiments on
four real-world datasets and three recommendation backbones demonstrate that
SL@$K$ outperforms existing losses with a notable average improvement of 6.03%.
The code is available at https://github.com/Tiny-Snow/IR-Benchmark.

</details>


### [64] [Domain-Specific Fine-Tuning and Prompt-Based Learning: A Comparative Study for developing Natural Language-Based BIM Information Retrieval Systems](https://arxiv.org/abs/2508.05676)
*Han Gao,Timo Hartmann,Botao Zhong,Kai Lia,Hanbin Luo*

Main category: cs.IR

TL;DR: 本研究比较了基于领域细调和大语言模型的提示学习两种自然语言界面在建筑信息模型中的应用效果，提出结合两者的混合方法以提升信息检索的性能。


<details>
  <summary>Details</summary>
Motivation: 随着建筑信息模型（BIM）在建筑全生命周期管理中的广泛应用，开发高效、智能的自然语言界面成为提升交互体验和信息检索效率的重要需求。

Method: 构建了包含1740个标注查询的BIM特定数据集，采用两阶段框架（意图识别与基于表格的问答）对比领域细调和提示学习的表现，最终提出结合两者的混合方案。

Result: 领域细调在意图识别上表现优越，而GPT-4o在表格问答方面表现出色。混合方案能实现任务中的平衡与稳健。

Conclusion: 结合细调与提示学习的混合方案在提升BIM自然语言信息检索效果方面具有潜力，适合实际应用并为未来研究提供指导。

Abstract: Building Information Modeling (BIM) is essential for managing building data
across the entire lifecycle, supporting tasks from design to maintenance.
Natural Language Interface (NLI) systems are increasingly explored as
user-friendly tools for information retrieval in Building Information Modeling
(BIM) environments. Despite their potential, accurately extracting BIM-related
data through natural language queries remains a persistent challenge due to the
complexity use queries and specificity of domain knowledge. This study presents
a comparative analysis of two prominent approaches for developing NLI-based BIM
information retrieval systems: domain-specific fine-tuning and prompt-based
learning using large language models (LLMs). A two-stage framework consisting
of intent recognition and table-based question answering is implemented to
evaluate the effectiveness of both approaches. To support this evaluation, a
BIM-specific dataset of 1,740 annotated queries of varying types across 69
models is constructed. Experimental results show that domain-specific
fine-tuning delivers superior performance in intent recognition tasks, while
prompt-based learning, particularly with GPT-4o, shows strength in table-based
question answering. Based on these findings, this study identify a hybrid
configuration that combines fine-tuning for intent recognition with
prompt-based learning for question answering, achieving more balanced and
robust performance across tasks. This integrated approach is further tested
through case studies involving BIM models of varying complexity. This study
provides a systematic analysis of the strengths and limitations of each
approach and discusses the applicability of the NLI to real-world BIM
scenarios. The findings offer insights for researchers and practitioners in
designing intelligent, language-driven BIM systems.

</details>


### [65] [Are All Genders Equal in the Eyes of Algorithms? -- Analysing Search and Retrieval Algorithms for Algorithmic Gender Fairness](https://arxiv.org/abs/2508.05680)
*Stefanie Urchs,Veronika Thurner,Matthias Aßenmacher,Ludwig Bothmann,Christian Heumann,Stephanie Thiemichen*

Main category: cs.IR

TL;DR: 本文提出一种偏差保持的算法性别公平定义，分析了德国高校学术平台中的性别差异，发现存在细微偏差。


<details>
  <summary>Details</summary>
Motivation: 探讨算法系统中的性别偏差及其对学术可见性的影响，强调公平评估的重要性。

Method: 使用多源异构学术数据集，分析元数据完整性、检索频率及搜索结果中的性别差异。

Result: 未检测到明显歧视，但发现男性教授在搜索结果和出版记录方面略优，女性教授表现出更高的可变性。

Conclusion: 平台算法、机构策划和个人呈现共同影响性别差异，强调公平评估应兼顾技术性能和表征平等。

Abstract: Algorithmic systems such as search engines and information retrieval
platforms significantly influence academic visibility and the dissemination of
knowledge. Despite assumptions of neutrality, these systems can reproduce or
reinforce societal biases, including those related to gender. This paper
introduces and applies a bias-preserving definition of algorithmic gender
fairness, which assesses whether algorithmic outputs reflect real-world gender
distributions without introducing or amplifying disparities. Using a
heterogeneous dataset of academic profiles from German universities and
universities of applied sciences, we analyse gender differences in metadata
completeness, publication retrieval in academic databases, and visibility in
Google search results. While we observe no overt algorithmic discrimination,
our findings reveal subtle but consistent imbalances: male professors are
associated with a greater number of search results and more aligned publication
records, while female professors display higher variability in digital
visibility. These patterns reflect the interplay between platform algorithms,
institutional curation, and individual self-presentation. Our study highlights
the need for fairness evaluations that account for both technical performance
and representational equality in digital systems.

</details>


### [66] [LLM4ES: Learning User Embeddings from Event Sequences via Large Language Models](https://arxiv.org/abs/2508.05688)
*Aleksei Shestov,Omar Zoloev,Maksim Makarenko,Mikhail Orlov,Egor Fadeev,Ivan Kireev,Andrey Savchenko*

Main category: cs.IR

TL;DR: 提出了一种基于预训练大模型的用户嵌入生成框架LLM4ES，通过文本增强和微调实现高质量表示，应用于金融和医疗等领域的用户分类。


<details>
  <summary>Details</summary>
Motivation: 随着大规模预训练模型的发展，充分利用其能力进行用户行为或事件序列的表示成为研究热点。现有方法在低变异性领域表现有限，亟需更有效的嵌入技术。

Method: 将事件序列转化为文本，通过文本增强技术和微调LLM实现用户嵌入的生成，应用下一词预测提升嵌入质量。

Result: 在金融及其他领域用户分类任务中，LLM4ES表现优异，超越现有方法，嵌入可广泛应用于用户细分和预测任务。

Conclusion: 利用大模型和文本增强技术，成功提升事件序列的用户嵌入效果，为多领域用户建模提供了新途径。

Abstract: This paper presents LLM4ES, a novel framework that exploits large pre-trained
language models (LLMs) to derive user embeddings from event sequences. Event
sequences are transformed into a textual representation, which is subsequently
used to fine-tune an LLM through next-token prediction to generate high-quality
embeddings. We introduce a text enrichment technique that enhances LLM
adaptation to event sequence data, improving representation quality for
low-variability domains. Experimental results demonstrate that LLM4ES achieves
state-of-the-art performance in user classification tasks in financial and
other domains, outperforming existing embedding methods. The resulting user
embeddings can be incorporated into a wide range of applications, from user
segmentation in finance to patient outcome prediction in healthcare.

</details>


### [67] [Multi-Faceted Large Embedding Tables for Pinterest Ads Ranking](https://arxiv.org/abs/2508.05700)
*Runze Su,Jiayin Jin,Jiacheng Li,Sihan Wang,Guangtong Bai,Zelun Wang,Li Tang,Yixiong Meng,Huasen Wu,Zhimeng Pan,Kungang Li,Han Sun,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar*

Main category: cs.IR

TL;DR: 引入多模态预训练和CPU-GPU混合服务改善Pinterest广告中的大规模嵌入表性能，显著提升点击率和转化率。


<details>
  <summary>Details</summary>
Motivation: 解决大规模嵌入表在推荐系统中的稀疏性、可扩展性和训练困难。

Method: 提出多模态预训练方案和混合硬件架构。

Result: 实现CTR和CVR显著提升，线上广告效果优化。

Conclusion: 多模态预训练结合硬件创新有效提升推荐模型性能与可用性。

Abstract: Large embedding tables are indispensable in modern recommendation systems,
thanks to their ability to effectively capture and memorize intricate details
of interactions among diverse entities. As we explore integrating large
embedding tables into Pinterest's ads ranking models, we encountered not only
common challenges such as sparsity and scalability, but also several obstacles
unique to our context. Notably, our initial attempts to train large embedding
tables from scratch resulted in neutral metrics. To tackle this, we introduced
a novel multi-faceted pretraining scheme that incorporates multiple pretraining
algorithms. This approach greatly enriched the embedding tables and resulted in
significant performance improvements. As a result, the multi-faceted large
embedding tables bring great performance gain on both the Click-Through Rate
(CTR) and Conversion Rate (CVR) domains. Moreover, we designed a CPU-GPU hybrid
serving infrastructure to overcome GPU memory limits and elevate the
scalability. This framework has been deployed in the Pinterest Ads system and
achieved 1.34% online CPC reduction and 2.60% CTR increase with neutral
end-to-end latency change.

</details>


### [68] [G-UBS: Towards Robust Understanding of Implicit Feedback via Group-Aware User Behavior Simulation](https://arxiv.org/abs/2508.05709)
*Boyu Chen,Siran Chen,Zhengrong Yue,Kainan Yan,Chenyun Yu,Beibei Kong,Cheng Lei,Chengxiang Zhuo,Zang Li,Yali Wang*

Main category: cs.IR

TL;DR: 提出了一种新颖的群组感知用户行为模拟（G-UBS）范式，通过利用用户群组的上下文指导，有效解决隐式反馈中的噪声问题，显著提升视频推荐系统的表现。


<details>
  <summary>Details</summary>
Motivation: 解决隐式反馈中噪声影响推荐效果的问题，提升用户兴趣的准确理解能力。

Method: 采用群组管理器（UGM）进行用户聚类与总结，利用用户反馈模型（UFM）在群组影响下进行强化学习，结合多模态视频推荐基准进行评估。

Result: G-UBS在视频推荐中显著优于主流模型，视频播放率提升4.0%，推理准确率提升14.9%。

Conclusion: 引入群组上下文增强隐式反馈理解，改善推荐系统性能，为未来推荐研究提供新思路。

Abstract: User feedback is critical for refining recommendation systems, yet explicit
feedback (e.g., likes or dislikes) remains scarce in practice. As a more
feasible alternative, inferring user preferences from massive implicit feedback
has shown great potential (e.g., a user quickly skipping a recommended video
usually indicates disinterest). Unfortunately, implicit feedback is often
noisy: a user might skip a video due to accidental clicks or other reasons,
rather than disliking it. Such noise can easily misjudge user interests,
thereby undermining recommendation performance. To address this issue, we
propose a novel Group-aware User Behavior Simulation (G-UBS) paradigm, which
leverages contextual guidance from relevant user groups, enabling robust and
in-depth interpretation of implicit feedback for individual users.
Specifically, G-UBS operates via two key agents. First, the User Group Manager
(UGM) effectively clusters users to generate group profiles utilizing a
``summarize-cluster-reflect" workflow based on LLMs. Second, the User Feedback
Modeler (UFM) employs an innovative group-aware reinforcement learning
approach, where each user is guided by the associated group profiles during the
reinforcement learning process, allowing UFM to robustly and deeply examine the
reasons behind implicit feedback. To assess our G-UBS paradigm, we have
constructed a Video Recommendation benchmark with Implicit Feedback (IF-VR). To
the best of our knowledge, this is the first multi-modal benchmark for implicit
feedback evaluation in video recommendation, encompassing 15k users, 25k
videos, and 933k interaction records with implicit feedback. Extensive
experiments on IF-VR demonstrate that G-UBS significantly outperforms
mainstream LLMs and MLLMs, with a 4.0% higher proportion of videos achieving a
play rate > 30% and 14.9% higher reasoning accuracy on IF-VR.

</details>


### [69] [WebWatcher: Breaking New Frontiers of Vision-Language Deep Research Agent](https://arxiv.org/abs/2508.05748)
*Xinyu Geng,Peng Xia,Zhen Zhang,Xinyu Wang,Qiuchen Wang,Ruixue Ding,Chenxi Wang,Jialong Wu,Yida Zhao,Kuan Li,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.IR

TL;DR: WebWatcher是一款具有增强视觉-语言推理能力的多模态深度研究代理，利用合成轨迹训练，结合工具及强化学习，显著优于现有基线，在多模态信息检索任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 弥补深度研究代理多模态信息处理能力的不足，使其能更好地应对实际场景中的视觉和文本信息。

Method: 引入高质量合成多模态轨迹，结合工具增强推理能力，并采用强化学习提升泛化能力。

Result: 在四项复杂的视觉问答任务中，WebWatcher超过了基线和开源代理，展现出优异性能。

Conclusion: WebWatcher有效提升了多模态深度研究代理的认知和推理能力，为解决复杂多模态信息检索问题奠定基础。

Abstract: Web agents such as Deep Research have demonstrated superhuman cognitive
abilities, capable of solving highly challenging information-seeking problems.
However, most research remains primarily text-centric, overlooking visual
information in the real world. This makes multimodal Deep Research highly
challenging, as such agents require much stronger reasoning abilities in
perception, logic, knowledge, and the use of more sophisticated tools compared
to text-based agents. To address this limitation, we introduce WebWatcher, a
multi-modal Agent for Deep Research equipped with enhanced visual-language
reasoning capabilities. It leverages high-quality synthetic multimodal
trajectories for efficient cold start training, utilizes various tools for deep
reasoning, and further enhances generalization through reinforcement learning.
To better evaluate the capabilities of multimodal agents, we propose
BrowseComp-VL, a benchmark with BrowseComp-style that requires complex
information retrieval involving both visual and textual information.
Experimental results show that WebWatcher significantly outperforms proprietary
baseline, RAG workflow and open-source agents in four challenging VQA
benchmarks, which paves the way for solving complex multimodal
information-seeking tasks.

</details>


### [70] [Dual prototype attentive graph network for cross-market recommendation](https://arxiv.org/abs/2508.05969)
*Li Fan,Menglin Kong,Yang Xiang,Chong Zhang,Chengtao Ji*

Main category: cs.IR

TL;DR: 本文提出了一种结合市场特定与共享信息的跨市场推荐模型 DGRE，有效提升推荐系统的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 旨在改进现有CMRS方法，充分挖掘不同市场用户偏好的共享与差异性，增强推荐系统性能。

Method: 提出Dual Prototype Attentive Graph Network，通过图表示学习构建市场共享与特定的原型，并利用用户与商品的聚类信息实现多维度特征表达。

Result: 在真实数据集上的广泛实验显示，该方法显著优于传统模型，提升了推荐的准确性和稳定性。

Conclusion: 结合市场共享与特定信息的模型设计具有重要应用价值，推动跨市场推荐系统的发展。

Abstract: Cross-market recommender systems (CMRS) aim to utilize historical data from
mature markets to promote multinational products in emerging markets. However,
existing CMRS approaches often overlook the potential for shared preferences
among users in different markets, focusing primarily on modeling specific
preferences within each market. In this paper, we argue that incorporating both
market-specific and market-shared insights can enhance the generalizability and
robustness of CMRS. We propose a novel approach called Dual Prototype Attentive
Graph Network for Cross-Market Recommendation (DGRE) to address this. DGRE
leverages prototypes based on graph representation learning from both items and
users to capture market-specific and market-shared insights. Specifically, DGRE
incorporates market-shared prototypes by clustering users from various markets
to identify behavioural similarities and create market-shared user profiles.
Additionally, it constructs item-side prototypes by aggregating item features
within each market, providing valuable market-specific insights. We conduct
extensive experiments to validate the effectiveness of DGRE on a real-world
cross-market dataset, and the results show that considering both
market-specific and market-sharing aspects in modelling can improve the
generalization and robustness of CMRS.

</details>


### [71] [Efficient Multimodal Streaming Recommendation via Expandable Side Mixture-of-Experts](https://arxiv.org/abs/2508.05993)
*Yunke Qu,Liang Qu,Tong Chen,Quoc Viet Hung Nguyen,Hongzhi Yin*

Main category: cs.IR

TL;DR: 提出XSMoE框架，通过可扩展的专家网络应对多模态流式推荐中的偏好漂移问题，实现了推荐性能和效率的提升。


<details>
  <summary>Details</summary>
Motivation: 在流式推荐系统中，用户偏好不断变化，如何有效捕捉最新偏好并应对新项目的冷启动和偏好漂移是一个挑战。现有多模态编码器虽能提取丰富特征，但存在成本高、遗忘用户偏好的风险。

Method: 引入可扩展的专家网络和门控机制，通过在冻结预训练模型上增量扩展专家模块，动态融合专家与基础模型输出，采用利用率驱动的剪枝策略保持模型紧凑。

Result: 在三个实际数据集上的实验表明，XSMoE在推荐效果和计算效率方面均优于现有最优方法。

Conclusion: XSMoE通过可扩展专家的设计，有效解决偏好漂移和冷启动问题，实现多模态流式推荐中的优异表现。

Abstract: Streaming recommender systems (SRSs) are widely deployed in real-world
applications, where user interests shift and new items arrive over time. As a
result, effectively capturing users' latest preferences is challenging, as
interactions reflecting recent interests are limited and new items often lack
sufficient feedback. A common solution is to enrich item representations using
multimodal encoders (e.g., BERT or ViT) to extract visual and textual features.
However, these encoders are pretrained on general-purpose tasks: they are not
tailored to user preference modeling, and they overlook the fact that user
tastes toward modality-specific features such as visual styles and textual
tones can also drift over time. This presents two key challenges in streaming
scenarios: the high cost of fine-tuning large multimodal encoders, and the risk
of forgetting long-term user preferences due to continuous model updates.
  To tackle these challenges, we propose Expandable Side Mixture-of-Experts
(XSMoE), a memory-efficient framework for multimodal streaming recommendation.
XSMoE attaches lightweight side-tuning modules consisting of expandable expert
networks to frozen pretrained encoders and incrementally expands them in
response to evolving user feedback. A gating router dynamically combines expert
and backbone outputs, while a utilization-based pruning strategy maintains
model compactness. By learning new patterns through expandable experts without
overwriting previously acquired knowledge, XSMoE effectively captures both cold
start and shifting preferences in multimodal features. Experiments on three
real-world datasets demonstrate that XSMoE outperforms state-of-the-art
baselines in both recommendation quality and computational efficiency.

</details>


### [72] [Semantic Item Graph Enhancement for Multimodal Recommendation](https://arxiv.org/abs/2508.06154)
*Xiaoxiong Zhang,Xin Zhou,Zhiwei Zeng,Dusit Niyato,Zhiqi Shen*

Main category: cs.IR

TL;DR: 多模态推荐系统通过融合协作信号与对比学习增强语义图的鲁棒性和一致性，有效改善性能。


<details>
  <summary>Details</summary>
Motivation: 提升多模态推荐中的语义图质量，解决其语义不足和噪声干扰问题，从而改善推荐效果。

Method: 引入协作信号于语义图，采用模长引导的扰动机制进行对比学习，并通过双重表示对齐确保语义和行为表示一致。

Result: 在四个基准数据集上实验验证，该方法显著提升了推荐性能和模型鲁棒性。

Conclusion: 通过协作信号增强、对比学习和多重表示对齐，该框架有效应对语义图中的噪声和结构失真，推动多模态推荐技术发展。

Abstract: Multimodal recommendation systems have attracted increasing attention for
their improved performance by leveraging items' multimodal information. Prior
methods often build modality-specific item-item semantic graphs from raw
modality features and use them as supplementary structures alongside the
user-item interaction graph to enhance user preference learning. However, these
semantic graphs suffer from semantic deficiencies, including (1) insufficient
modeling of collaborative signals among items and (2) structural distortions
introduced by noise in raw modality features, ultimately compromising
performance. To address these issues, we first extract collaborative signals
from the interaction graph and infuse them into each modality-specific item
semantic graph to enhance semantic modeling. Then, we design a modulus-based
personalized embedding perturbation mechanism that injects perturbations with
modulus-guided personalized intensity into embeddings to generate contrastive
views. This enables the model to learn noise-robust representations through
contrastive learning, thereby reducing the effect of structural noise in
semantic graphs. Besides, we propose a dual representation alignment mechanism
that first aligns multiple semantic representations via a designed Anchor-based
InfoNCE loss using behavior representations as anchors, and then aligns
behavior representations with the fused semantics by standard InfoNCE, to
ensure representation consistency. Extensive experiments on four benchmark
datasets validate the effectiveness of our framework.

</details>


### [73] [Improving Table Retrieval with Question Generation from Partial Tables](https://arxiv.org/abs/2508.06168)
*Hsing-Ping Liang,Che-Wei Chang,Yao-Chung Fan*

Main category: cs.IR

TL;DR: 提出QGpT，通过生成相关性问题增强表格嵌入，改善检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要优化检索器以匹配问题和表格，缺乏提升表格表示的研究。

Method: 利用LLM基于表格部分生成模拟用户查询的问题，结合部分表格段增强语义对齐。

Result: 显著提升多项基准测试中的检索性能，适用于密集及晚期交互检索器。

Conclusion: 通过生成模拟问句优化表格表示，有效改善检索效果，推动开放域表格问答的发展。

Abstract: Recent advances in open-domain question answering over tables have widely
adopted large language models (LLMs) under the Retriever-Reader architecture.
Prior works have effectively leveraged LLMs to tackle the complex reasoning
demands of the Reader component, such as text-to-text, text-to-SQL, and multi
hop reasoning. In contrast, the Retriever component has primarily focused on
optimizing the query representation-training retrievers to retrieve relevant
tables based on questions, or to select keywords from questions for matching
table segments. However, little attention has been given to enhancing how
tables themselves are represented in embedding space to better align with
questions. To address this, we propose QGpT (Question Generation from Partial
Tables), a simple yet effective method that uses an LLM to generate synthetic
questions based on small portions of a table. These questions are generated to
simulate how a user might query the content of the table currently under
consideration. The generated questions are then jointly embedded with the
partial table segments used for generation, enhancing semantic alignment with
user queries. Without the need to embed entire tables, our method significantly
improves retrieval performance across multiple benchmarks for both dense and
late-interaction retrievers.

</details>


### [74] [M2IO-R1: An Efficient RL-Enhanced Reasoning Framework for Multimodal Retrieval Augmented Multimodal Generation](https://arxiv.org/abs/2508.06328)
*Zhiyou Xiao,Qinhan Yu,Binghui Li,Geng Chen,Chong Chen,Wentao Zhang*

Main category: cs.IR

TL;DR: 提出了一种支持多模态输入和输出的多模态生成框架M2IO-R1，采用增强学习优化图片选择与排布，显著提高了性能和效率。


<details>
  <summary>Details</summary>
Motivation: 当前多模态检索增强生成( MRAG) 多仅支持单模态输出，限制了其表达能力和实用性。实际应用需要多模态输入与输出的结合。

Method: 引入基于增强学习的Inserter-R1-3B，通过组相对策略进行训练，实现图像的选择与置放，确保语义一致性与可控性。

Result: 轻量级模型在多模态推理能力上表现优异，显著优于基线方法，兼具高效性与质量。

Conclusion: 利用强化学习有效解决多模态输出生成中的多步决策问题，为多模态任务提供更强的表达和交互能力。

Abstract: Current research on Multimodal Retrieval-Augmented Generation (MRAG) enables
diverse multimodal inputs but remains limited to single-modality outputs,
restricting expressive capacity and practical utility. In contrast, real-world
applications often demand both multimodal inputs and multimodal outputs for
effective communication and grounded reasoning. Motivated by the recent success
of Reinforcement Learning (RL) in complex reasoning tasks for Large Language
Models (LLMs), we adopt RL as a principled and effective paradigm to address
the multi-step, outcome-driven challenges inherent in multimodal output
generation. Here, we introduce M2IO-R1, a novel framework for Multimodal
Retrieval-Augmented Multimodal Generation (MRAMG) that supports both multimodal
inputs and outputs. Central to our framework is an RL-based inserter,
Inserter-R1-3B, trained with Group Relative Policy Optimization to guide image
selection and placement in a controllable and semantically aligned manner.
Empirical results show that our lightweight 3B inserter achieves strong
reasoning capabilities with significantly reduced latency, outperforming
baselines in both quality and efficiency.

</details>


### [75] [eSASRec: Enhancing Transformer-based Recommendations in a Modular Fashion](https://arxiv.org/abs/2508.06450)
*Daria Tikhonovich,Nikita Zelinskiy,Aleksandr V. Petrov,Mayya Spirina,Andrei Semenov,Andrey V. Savchenko,Sergei Kuliev*

Main category: cs.IR

TL;DR: 提出了一种增强型SASRec（eSASRec）模型，通过结合SASRec的训练目标、LiGR Transformer层和采样Softmax损失，在现实生产环境中展现出优异的性能，显著优于现有最先进模型，并易于集成。


<details>
  <summary>Details</summary>
Motivation: 系统评估不同模块改进对Transformer基础推荐模型性能的增益，弥补缺乏系统性基准的空白。

Method: 结合SASRec训练目标、LiGR Transformer层和采样Softmax损失，构建并评估模型性能。

Result: eSASRec在学术和工业基准中表现出色，显著优于近期模型，在效率和性能上达到了平衡，且易于集成。

Conclusion: 模块化改进的叠加能有效提升Transformer基础推荐模型的性能，提供了强大且简便的基线方案，便于实际应用和后续研究。

Abstract: Since their introduction, Transformer-based models, such as SASRec and
BERT4Rec, have become common baselines for sequential recommendations,
surpassing earlier neural and non-neural methods. A number of following
publications have shown that the effectiveness of these models can be improved
by, for example, slightly updating the architecture of the Transformer layers,
using better training objectives, and employing improved loss functions.
However, the additivity of these modular improvements has not been
systematically benchmarked - this is the gap we aim to close in this paper.
Through our experiments, we identify a very strong model that uses SASRec's
training objective, LiGR Transformer layers, and Sampled Softmax Loss. We call
this combination eSASRec (Enhanced SASRec). While we primarily focus on
realistic, production-like evaluation, in our preliminarily study we find that
common academic benchmarks show eSASRec to be 23% more effective compared to
the most recent state-of-the-art models, such as ActionPiece. In our main
production-like benchmark, eSASRec resides on the Pareto frontier in terms of
the accuracy-coverage tradeoff (alongside the recent industrial models HSTU and
FuXi. As the modifications compared to the original SASRec are relatively
straightforward and no extra features are needed (such as timestamps in HSTU),
we believe that eSASRec can be easily integrated into existing recommendation
pipelines and can can serve as a strong yet very simple baseline for emerging
complicated algorithms. To facilitate this, we provide the open-source
implementations for our models and benchmarks in repository
https://github.com/blondered/transformer_benchmark

</details>


### [76] [Maximum Impact with Fewer Features: Efficient Feature Selection for Cold-Start Recommenders through Collaborative Importance Weighting](https://arxiv.org/abs/2508.06455)
*Nikita Sukhorukov,Danil Gusak,Evgeny Frolov*

Main category: cs.IR

TL;DR: 提出一种结合协同行为数据和最大体积算法的特征选择方法，有效改善冷启动推荐系统的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 解决推荐系统中的冷启动问题，避免无关或噪声特征影响性能，同时降低计算成本。

Method: 利用混合矩阵分解增强特征表达，通过最大体积算法进行特征排序，筛选出最具影响力的特征子集。

Result: 在多个数据集和混合推荐模型中验证该方法在冷启动场景下优于现有特征选择技术，且在特征极度压缩时仍保持高效和高准确率。

Conclusion: 该特征选择策略有效平衡了推荐精度和计算效率，特别适合冷启动环境。

Abstract: Cold-start challenges in recommender systems necessitate leveraging auxiliary
features beyond user-item interactions. However, the presence of irrelevant or
noisy features can degrade predictive performance, whereas an excessive number
of features increases computational demands, leading to higher memory
consumption and prolonged training times.
  To address this, we propose a feature selection strategy that prioritizes the
user behavioral information. Our method enhances the feature representation by
incorporating correlations from collaborative behavior data using a hybrid
matrix factorization technique and then ranks features using a mechanism based
on the maximum volume algorithm. This approach identifies the most influential
features, striking a balance between recommendation accuracy and computational
efficiency. We conduct an extensive evaluation across various datasets and
hybrid recommendation models, demonstrating that our method excels in
cold-start scenarios by selecting minimal yet highly effective feature subsets.
Even under strict feature reduction, our approach surpasses existing feature
selection techniques while maintaining superior efficiency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [77] [Diagrams-to-Dynamics (D2D): Exploring Causal Loop Diagram Leverage Points under Uncertainty](https://arxiv.org/abs/2508.05659)
*Jeroen F. Uleman,Loes Crielaard,Leonie K. Elsenburg,Guido A. Veldhuis,Karien Stronks,Naja Hulvej Rod,Rick Quax,Vítor V. Vasconcelos*

Main category: cs.LG

TL;DR: 提出一种将因果环路图（CLDs）转换为系统动力学模型（SDMs）的方法D2D，支持在无实证数据情况下进行动态模拟和干预分析。


<details>
  <summary>Details</summary>
Motivation: CLDs在复杂问题研究中被广泛使用，但其静态性质限制了动态分析和干预策略的制定。

Method: 开发D2D方法，通过变量标记和利用结构信息，将CLDs转化为可探索的SDMs，并通过比较验证其效果。

Result: D2D在模拟一致性和识别杠杆点方面优于网络中心性分析，提供了不确定性估计和数据采集指导。

Conclusion: D2D是一种有效的工具，能提升CLDs在动态分析中的应用潜力，未来需进一步验证。

Abstract: Causal loop diagrams (CLDs) are widely used in health and environmental
research to represent hypothesized causal structures underlying complex
problems. However, as qualitative and static representations, CLDs are limited
in their ability to support dynamic analysis and inform intervention
strategies. Additionally, quantitative CLD analysis methods like network
centrality analysis often lead to false inference. We propose
Diagrams-to-Dynamics (D2D), a method for converting CLDs into exploratory
system dynamics models (SDMs) in the absence of empirical data. With minimal
user input - following a protocol to label variables as stocks,
flows/auxiliaries, or constants - D2D leverages the structural information
already encoded in CLDs, namely, link existence and polarity, to simulate
hypothetical interventions and explore potential leverage points under
uncertainty. Results suggest that D2D helps distinguish between high- and
low-ranked leverage points. We compare D2D to a data-driven SDM constructed
from the same CLD and variable labeling. D2D showed greater consistency with
the data-driven model than network centrality analysis, while providing
uncertainty estimates and guidance for future data collection. The method is
implemented in an open-source Python package and a web-based application to
support further testing and lower the barrier to dynamic modeling for
researchers working with CLDs. We expect additional validation will further
establish the approach's utility across a broad range of cases and domains.

</details>


### [78] [A Graph Neural Network Approach for Mapping the Conceptual Structure and Inter-Branch Connectivity of Physics](https://arxiv.org/abs/2508.05724)
*Massimiliano Romiti*

Main category: cs.LG

TL;DR: 提出一种基于加权知识图谱的新框架，用于代表与分析物理定律，利用图神经网络实现高效的关系预测，并发现物理学中的宏观结构与关键关系。


<details>
  <summary>Details</summary>
Motivation: 为理解与探索物理定律的复杂关系，利用图结构与深度学习技术实现自动化分析与假设生成。

Method: 构建物理方程数据库，进行语义清洗，设计节点和加权边的图表示，训练图注意力网络进行链接预测，验证模型性能。

Result: 模型在关系预测任务中显著优于传统方法和其他GNN架构，发现物理学的宏观结构与核心方程，生成跨领域假设，促进新理论探索。

Conclusion: 该框架有效揭示物理学中的结构与关系，为理论研究提供高效工具，助力未来新关系与假设的发现。

Abstract: This work introduces a novel framework for representing and analyzing
physical laws as a weighted knowledge graph. We constructed a database of 659
distinct physical equations, subjected to rigorous semantic cleaning to resolve
notational ambiguities, resulting in a corpus of 400 advanced physics
equations. We developed an enhanced graph representation where both physical
concepts and equations are nodes, connected by weighted inter-equation bridges.
These weights are objectively defined using normalized metrics for variable
overlap, physics-informed importance scores, and bibliometric data. A Graph
Attention Network (GAT) was trained for link prediction, achieving a test AUC
of 0.9742 +/- 0.0018 across five independent runs, significantly outperforming
both classical heuristics (best baseline AUC: 0.9487) and established GNN
architectures like GraphSAGE (AUC: 0.9504, p = 0.029). Statistical testing
confirmed significance of all comparisons (p < 0.05), with 2.7% improvement
over the best baseline. Our analysis reveals three key findings: (i) The model
autonomously rediscovers the known macroscopic structure of physics,
identifying strong conceptual axes between Electromagnetism and Statistical
Mechanics. (ii) It identifies central hub equations that serve as critical
bridges between multiple physical domains. (iii) The model generates stable,
computationally-derived hypotheses for cross-domain relationships, identifying
both known principles and suggesting novel mathematical analogies for further
theoretical investigation. The framework can generate hundreds of such
hypotheses, enabling the creation of specialized datasets for targeted analysis
of specific physics subfields. Code and data available at
https://github.com/kingelanci/graphysics

</details>


### [79] [Machine Learning-Based Nonlinear Nudging for Chaotic Dynamical Systems](https://arxiv.org/abs/2508.05778)
*Jaemin Oh,Jinsil Lee,Youngjoon Hong*

Main category: cs.LG

TL;DR: 提出一种基于神经网络的非线性状态空间模型的nudging技术，结合Kazantzis-Kravaris-Luenberger观察者理论，有效应对混沌系统。


<details>
  <summary>Details</summary>
Motivation: 在非线性系统中设计有效的nudging控制项具有挑战性，亟需数据驱动的方法以改善数据同化的效果。

Method: 利用神经网络学习nudging项，结合Kazantzis--Kravaris--Luenberger观察者理论，提出neural network nudging方法。

Result: 在Lorenz 96模型、Kuramoto--Sivashinsky方程和Kolmogorov流等三类混沌系统上验证，显示出良好的性能。

Conclusion: 神经网络nudging具备理论保障，能有效应对非线性混沌系统的数据同化问题。

Abstract: Nudging is an empirical data assimilation technique that incorporates an
observation-driven control term into the model dynamics. The trajectory of the
nudged system approaches the true system trajectory over time, even when the
initial conditions differ. For linear state space models, such control terms
can be derived under mild assumptions. However, designing effective nudging
terms becomes significantly more challenging in the nonlinear setting. In this
work, we propose neural network nudging, a data-driven method for learning
nudging terms in nonlinear state space models. We establish a theoretical
existence result based on the Kazantzis--Kravaris--Luenberger observer theory.
The proposed approach is evaluated on three benchmark problems that exhibit
chaotic behavior: the Lorenz 96 model, the Kuramoto--Sivashinsky equation, and
the Kolmogorov flow.

</details>


### [80] [From Imperfect Signals to Trustworthy Structure: Confidence-Aware Inference from Heterogeneous and Reliability-Varying Utility Data](https://arxiv.org/abs/2508.05791)
*Haoran Li,Lihao Mai,Muhao Guo,Jiaqi Wu,Yang Weng,Yannan Sun,Ce Jimmy Liu*

Main category: cs.LG

TL;DR: 提出一种结合空间布局和系统动态行为的分布式配电网拓扑重建框架，有效融合异质数据，确保拓扑的准确可靠。


<details>
  <summary>Details</summary>
Motivation: 分布式配电网的拓扑结构对于现代电网的可靠运行极为关键，但现实中数据质量参差不齐，亟需一种稳健的重建方法。

Method: 结合物理基础设施信息和电压时间序列，设计一个信心感知推断机制，嵌入操作约束，实现 uncertainty-aware和结构合理的拓扑重建。

Result: 在实际应用中实现95%以上的重建精度，显著提升模型的置信度校准和计算效率。

Conclusion: 提出的方法能有效应对异质数据的不确定性，具备大规模实用潜力，提升配电网拓扑的重建准确性和可靠性。

Abstract: Accurate distribution grid topology is essential for reliable modern grid
operations. However, real-world utility data originates from multiple sources
with varying characteristics and levels of quality. In this work, developed in
collaboration with Oncor Electric Delivery, we propose a scalable framework
that reconstructs a trustworthy grid topology by systematically integrating
heterogeneous data. We observe that distribution topology is fundamentally
governed by two complementary dimensions: the spatial layout of physical
infrastructure (e.g., GIS and asset metadata) and the dynamic behavior of the
system in the signal domain (e.g., voltage time series). When jointly
leveraged, these dimensions support a complete and physically coherent
reconstruction of network connectivity. To address the challenge of uneven data
quality without compromising observability, we introduce a confidence-aware
inference mechanism that preserves structurally informative yet imperfect
inputs, while quantifying the reliability of each inferred connection for
operator interpretation. This soft handling of uncertainty is tightly coupled
with hard enforcement of physical feasibility: we embed operational
constraints, such as transformer capacity limits and radial topology
requirements, directly into the learning process. Together, these components
ensure that inference is both uncertainty-aware and structurally valid,
enabling rapid convergence to actionable, trustworthy topologies under
real-world deployment conditions. The proposed framework is validated using
data from over 8000 meters across 3 feeders in Oncor's service territory,
demonstrating over 95% accuracy in topology reconstruction and substantial
improvements in confidence calibration and computational efficiency relative to
baseline methods.

</details>


### [81] [Optimal Linear Baseline Models for Scientific Machine Learning](https://arxiv.org/abs/2508.05831)
*Alexander DeLise,Kyle Loh,Krish Patel,Meredith Teague,Andrea Arnold,Matthias Chung*

Main category: cs.LG

TL;DR: 本文提出了一套用于分析线性编码器-解码器架构的理论框架，通过贝叶斯风险最小化解决科学机器学习中的正向建模和逆向恢复问题，验证了其在生物医学成像、金融分析和流体动力学中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 解决科学领域中从物理过程到观测信号的映射问题，弥补神经网络透明性不足的不足，提供理论基础。

Method: 采用贝叶斯风险最小化的方法，推导出封闭形式的线性和仿线性最优映射，包括处理秩缺失的数据和操作。

Result: 获得了适用于多种科学应用的排名受限最优映射，验证了理论的实际有效性。

Conclusion: 为科学机器学习提供了稳健的基础，与神经网络模型的理解和基准测试相关。

Abstract: Across scientific domains, a fundamental challenge is to characterize and
compute the mappings from underlying physical processes to observed signals and
measurements. While nonlinear neural networks have achieved considerable
success, they remain theoretically opaque, which hinders adoption in contexts
where interpretability is paramount. In contrast, linear neural networks serve
as a simple yet effective foundation for gaining insight into these complex
relationships. In this work, we develop a unified theoretical framework for
analyzing linear encoder-decoder architectures through the lens of Bayes risk
minimization for solving data-driven scientific machine learning problems. We
derive closed-form, rank-constrained linear and affine linear optimal mappings
for forward modeling and inverse recovery tasks. Our results generalize
existing formulations by accommodating rank-deficiencies in data, forward
operators, and measurement processes. We validate our theoretical results by
conducting numerical experiments on datasets from simple biomedical imaging,
financial factor analysis, and simulations involving nonlinear fluid dynamics
via the shallow water equations. This work provides a robust baseline for
understanding and benchmarking learned neural network models for scientific
machine learning problems.

</details>


### [82] [An Effective Approach for Node Classification in Textual Graphs](https://arxiv.org/abs/2508.05836)
*Rituparna Datta,Nibir Chandra Mandal*

Main category: cs.LG

TL;DR: 提出结合大模型ChatGPT与Graphormer的TAPE框架，有效提升文本属性图中的节点分类表现，突破长距离依赖和语义理解的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 解决文本属性图中丰富语义融合、长距离依赖建模和规模扩展困难问题。

Method: 利用ChatGPT生成论文内容的语义解释，融合到节点表示中，采用Graphormer的路径感知位置编码和多头注意机制，结合新颖的融合层实现结构与语义的结合。

Result: 在ogbn-arxiv数据集上取得0.772的节点分类准确率，优于现有最佳方法，并在多项指标上表现优异。

Conclusion: 该框架有效结合语义和结构信息，提供了可扩展、强健的节点分类方案，具有促进知识体系和科学发现的潜力。

Abstract: Textual Attribute Graphs (TAGs) are critical for modeling complex networks
like citation networks, but effective node classification remains challenging
due to difficulties in integrating rich semantics from text with structural
graph information. Existing methods often struggle with capturing nuanced
domain-specific terminology, modeling long-range dependencies, adapting to
temporal evolution, and scaling to massive datasets. To address these issues,
we propose a novel framework that integrates TAPE (Text-Attributed Graph
Representation Enhancement) with Graphormer. Our approach leverages a large
language model (LLM), specifically ChatGPT, within the TAPE framework to
generate semantically rich explanations from paper content, which are then
fused into enhanced node representations. These embeddings are combined with
structural features using a novel integration layer with learned attention
weights. Graphormer's path-aware position encoding and multi-head attention
mechanisms are employed to effectively capture long-range dependencies across
the citation network. We demonstrate the efficacy of our framework on the
challenging ogbn-arxiv dataset, achieving state-of-the-art performance with a
classification accuracy of 0.772, significantly surpassing the best GCN
baseline of 0.713. Our method also yields strong results in precision (0.671),
recall (0.577), and F1-score (0.610). We validate our approach through
comprehensive ablation studies that quantify the contribution of each
component, demonstrating the synergy between semantic and structural
information. Our framework provides a scalable and robust solution for node
classification in dynamic TAGs, offering a promising direction for future
research in knowledge systems and scientific discovery.

</details>


### [83] [A Markov Decision Process Framework for Early Maneuver Decisions in Satellite Collision Avoidance](https://arxiv.org/abs/2508.05876)
*Francesca Ferrara,Lander W. Schillinger Arana,Florian Dörfler,Sarah H. Q. Li*

Main category: cs.LG

TL;DR: 提出一种基于MDP和强化学习的碰撞规避决策模型，有效平衡风险与燃料消耗。


<details>
  <summary>Details</summary>
Motivation: 希望优化碰撞规避行为，提高安全性并降低燃料消耗。

Method: 构建连续状态、离散行动的MDP模型，并使用RL-PG算法训练自主引导策略。

Result: 在合成和历史事件中，策略降低了平均燃料消耗，并保持或提升了碰撞风险保障。

Conclusion: 该方法可有效优化碰撞规避策略，兼顾安全与资源利用。

Abstract: This work presents a Markov decision process (MDP) framework to model
decision-making for collision avoidance maneuver (CAM) and a reinforcement
learning policy gradient (RL-PG) algorithm to train an autonomous guidance
policy using historic CAM data. In addition to maintaining acceptable collision
risks, this approach seeks to minimize the average fuel consumption of CAMs by
making early maneuver decisions. We model CAM as a continuous state, discrete
action and finite horizon MDP, where the critical decision is determining when
to initiate the maneuver. The MDP model also incorporates analytical models for
conjunction risk, propellant consumption, and transit orbit geometry. The
Markov policy effectively trades-off maneuver delay-which improves the
reliability of conjunction risk indicators-with propellant consumption-which
increases with decreasing maneuver time. Using historical data of tracked
conjunction events, we verify this framework and conduct an extensive ablation
study on the hyper-parameters used within the MDP. On synthetic conjunction
events, the trained policy significantly minimizes both the overall and average
propellant consumption per CAM when compared to a conventional cut-off policy
that initiates maneuvers 24 hours before the time of closest approach (TCA). On
historical conjunction events, the trained policy consumes more propellant
overall but reduces the average propellant consumption per CAM. For both
historical and synthetic conjunction events, the trained policy achieves equal
if not higher overall collision risk guarantees.

</details>


### [84] [The Fourth State: Signed-Zero Ternary for Stable LLM Quantization (and More)](https://arxiv.org/abs/2508.05905)
*Jeffrey Uhlmann*

Main category: cs.LG

TL;DR: 本文提出了Signed-Zero Ternary（SZT），一种无性能损失的2位量化方法，可能提高信息密度。


<details>
  <summary>Details</summary>
Motivation: 探讨在有限资源下，量化是否能提升信息传递效率，而非仅作为性能折中手段。

Method: 提出并分析了SZT量化方案，通过理论分析其在不影响前向计算的情况下，提供确定性梯度信息。

Result: SZT量化在保持性能的同时，提升了信息密度，具有潜在优势。

Conclusion: 在资源受限场景下，量化不仅是性能折中，也可能实现信息效率的提升。

Abstract: Quantization is usually regarded as a means to trade quality of performance
for reduced compute requirements, i.e., as a suboptimal approximation. However,
if examined in terms of a fixed overall resource budget, a very different
perspective arises. We introduce Signed-Zero Ternary (SZT), a 2-bit
quantization that deterministically provides gradient information with no
forward-path penalty. Our analysis provides evidence that it may improve
information density compared to non-quantized alternatives.

</details>


### [85] [Dual Signal Decomposition of Stochastic Time Series](https://arxiv.org/abs/2508.05915)
*Alex Glushkovsky*

Main category: cs.LG

TL;DR: 本论文提出一种基于机器学习的随机时间序列分解方法，能够同时提取均值与离散度信号，并实现去噪与平滑，提供了单一和联合学习两种策略。


<details>
  <summary>Details</summary>
Motivation: 解决随机时间序列中的噪声影响，准确分离信号的均值和波动性，提升序列分析和预测能力。

Method: 利用带正则化的机器学习模型（包括神经网络）拟合双重信号，通过调整正则项权重结合统计过程控制，优化分解效果。

Result: 所提方法能有效提取时间序列的基本结构并去除噪声，适用于平滑、去噪、结构识别与多序列交互分析。

Conclusion: 提出的分解模型具有灵活性和效果优良，为时间序列分析提供了强有力的工具，特别是在异方差和复杂关系情况下表现出优势。

Abstract: The research paper addresses decomposition of a stochastic time series into
three time series representing a dual signal i.e., the mean and the dispersion,
with noise isolated. Decomposition is done by applying machine learning to fit
a dual signal. Machine learning minimizes the loss function which compromises
between fitting the original time series and penalizing irregularities of the
dual signal. The latter includes terms based on the first and second order
derivatives along time. To preserve special patterns, weighting of the
regularization components of the loss function has been introduced based on
Statistical Process Control methodology. The proposed decomposition can be
applied as a smoothing algorithm against the mean and dispersion of the time
series. By isolating noise, the proposed decomposition can be seen as a
denoising algorithm. Two approaches of the learning process have been
considered: sequential and jointly. The former approach learns the mean signal
first and then dispersion. The latter approach fits the dual signal jointly.
Jointly learning can uncover complex relationships for the time series with
heteroskedasticity. Learning has been set by solving the direct non-linear
unconstrained optimization problem or by applying neural networks that have
sequential or twin output architectures. Tuning of the loss function
hyperparameters focuses on the isolated noise to be a stationary stochastic
process without autocorrelation properties. Depending on the applications, the
hyperparameters of the learning can be tuned towards either the discrete states
by stepped signal or smoothed series. The decomposed dual signal can be
represented on the 2D space and used to learn inherent structures, to forecast
both mean and dispersion, or to analyze cross effects in case of multiple time
series.

</details>


### [86] [Fast, Convex and Conditioned Network for Multi-Fidelity Vectors and Stiff Univariate Differential Equations](https://arxiv.org/abs/2508.05921)
*Siddharth Rout*

Main category: cs.LG

TL;DR: 通过引入Shifted Gaussian Encoding改善PIELMs的条件数，显著提升神经偏微分方程求解的效率和精度。


<details>
  <summary>Details</summary>
Motivation: 解决神经偏微分方程求解中的优化困难，尤其是在多尺度和刚性问题中。

Method: 引入Shifted Gaussian Encoding，通过改善激活矩阵的条件数来增强表达能力并保持凸性。

Result: 大幅扩展了稳态对流-扩散方程的Peclet数范围，提高多频函数学习的准确性，显著优于传统深度网络。

Conclusion: 改善条件数而非增加深度是提升科学神经求解器性能的关键，简单架构调整能带来巨大收益。

Abstract: Accuracy in neural PDE solvers often breaks down not because of limited
expressivity, but due to poor optimisation caused by ill-conditioning,
especially in multi-fidelity and stiff problems. We study this issue in
Physics-Informed Extreme Learning Machines (PIELMs), a convex variant of neural
PDE solvers, and show that asymptotic components in governing equations can
produce highly ill-conditioned activation matrices, severely limiting
convergence. We introduce Shifted Gaussian Encoding, a simple yet effective
activation filtering step that increases matrix rank and expressivity while
preserving convexity. Our method extends the solvable range of Peclet numbers
in steady advection-diffusion equations by over two orders of magnitude,
achieves up to six orders lower error on multi-frequency function learning, and
fits high-fidelity image vectors more accurately and faster than deep networks
with over a million parameters. This work highlights that conditioning, not
depth, is often the bottleneck in scientific neural solvers and that simple
architectural changes can unlock substantial gains.

</details>


### [87] [Mitigating Think-Answer Mismatch in LLM Reasoning Through Noise-Aware Advantage Reweighting](https://arxiv.org/abs/2508.05928)
*Si Shen,Peijun Shen,Wenhua Zhao,Danhao Zhu*

Main category: cs.LG

TL;DR: S-GRPO通过引入噪声感知的优势权重，有效缓解GRPO中的Think-Answer Mismatch问题，显著提升大规模推理模型的训练稳健性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模推理模型训练中GRPO面临的噪声干扰问题，提升模型稳健性。

Method: 提出稳健的S-GRPO方法，利用噪声感知的最优优势权重稳定训练。

Result: 在数学推理基准测试中，S-GRPO显著优于传统GRPO，保持在高噪声环境下的学习能力，性能提升达2.2%-2.5%。

Conclusion: S-GRPO增强了大规模推理模型训练的鲁棒性，有助于未来模型的稳定优化。

Abstract: Group-Relative Policy Optimization (GRPO) is a key technique for training
large reasoning models, yet it suffers from a critical vulnerability: the
\emph{Think-Answer Mismatch}, where noisy reward signals corrupt the learning
process. This problem is most severe in unbalanced response groups,
paradoxically degrading the signal precisely when it should be most
informative. To address this challenge, we propose Stable Group-Relative Policy
Optimization (S-GRPO), a principled enhancement that derives optimal,
noise-aware advantage weights to stabilize training. Our comprehensive
experiments on mathematical reasoning benchmarks demonstrate S-GRPO's
effectiveness and robustness. On various models, S-GRPO significantly
outperforms DR. GRPO, achieving performance gains of +2.5% on
Qwen-Math-7B-Base, +2.2% on Llama-3.2-3B-Base, and +2.4% on
Qwen-Math-1.5B-Instruct. Most critically, while standard GRPO fails to learn
under 20% synthetic reward noise, S-GRPO maintains stable learning progress.
These results highlight S-GRPO's potential for more robust and effective
training of large-scale reasoning models. \footnote{Code and data are available
at: https://github.com/shenpeijun0212/S-GRPO

</details>


### [88] [Multi-Armed Bandits-Based Optimization of Decision Trees](https://arxiv.org/abs/2508.05957)
*Hasibul Karim Shanto,Umme Ayman Koana,Shadikur Rahman*

Main category: cs.LG

TL;DR: 提出一种基于多臂赌博机（MAB）的决策树剪枝方法，通过强化学习动态优化剪枝过程，提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统剪枝方法在小样本或复杂数据情况下易过拟合，提升决策树的泛化能力。

Method: 将剪枝视为探索-利用问题，采用MAB算法动态选择剪枝节点，优化决策树结构。

Result: 在多个基准数据集上实验显示，该方法优于传统剪枝技术，提升预测性能。

Conclusion: 利用MAB实现决策树的动态剪枝具有潜力，有助于生成更具泛化能力的模型。

Abstract: Decision trees, without appropriate constraints, can easily become overly
complex and prone to overfit, capturing noise rather than generalizable
patterns. To resolve this problem,pruning operation is a crucial part in
optimizing decision trees, as it not only reduces the complexity of trees but
also decreases the probability of generating overfit models. The conventional
pruning techniques like Cost-Complexity Pruning (CCP) and Reduced Error Pruning
(REP) are mostly based on greedy approaches that focus on immediate gains in
performance while pruning nodes of the decision tree. However, this might
result in a lower generalization in the long run, compromising the robust
ability of the tree model when introduced to unseen data samples, particularly
when trained with small and complex datasets. To address this challenge, we are
proposing a Multi-Armed Bandits (MAB)-based pruning approach, a reinforcement
learning (RL)-based technique, that will dynamically prune the tree to generate
an optimal decision tree with better generalization. Our proposed approach
assumes the pruning process as an exploration-exploitation problem, where we
are utilizing the MAB algorithms to find optimal branch nodes to prune based on
feedback from each pruning actions. Experimental evaluation on several
benchmark datasets, demonstrated that our proposed approach results in better
predictive performance compared to the traditional ones. This suggests the
potential of utilizing MAB for a dynamic and probabilistic way of decision tree
pruning, in turn optimizing the decision tree-based model.

</details>


### [89] [Mildly Conservative Regularized Evaluation for Offline Reinforcement Learning](https://arxiv.org/abs/2508.05960)
*Haohui Chen,Zhiyong Chen*

Main category: cs.LG

TL;DR: 提出一种平衡保守性与表现的离线强化学习框架和算法，通过引入MCRE和MCRQ，有效改善离线RL中的值函数估计问题。


<details>
  <summary>Details</summary>
Motivation: 离线RL面临分布偏移和值函数过估的问题，需在保守性和性能之间取得平衡。

Method: 引入MCR框架，结合TD误差与行为克隆，构建MCRQ算法，集成在off-policy actor-critic架构中。

Result: 实验显示MCRQ在多个基准数据集上优于主流和最先进的离线RL算法。

Conclusion: 所提模型在保持适当保守性的同时，提升了离线RL的效果，有助于解决值估计偏差问题。

Abstract: Offline reinforcement learning (RL) seeks to learn optimal policies from
static datasets without further environment interaction. A key challenge is the
distribution shift between the learned and behavior policies, leading to
out-of-distribution (OOD) actions and overestimation. To prevent gross
overestimation, the value function must remain conservative; however, excessive
conservatism may hinder performance improvement. To address this, we propose
the mildly conservative regularized evaluation (MCRE) framework, which balances
conservatism and performance by combining temporal difference (TD) error with a
behavior cloning term in the Bellman backup. Building on this, we develop the
mildly conservative regularized Q-learning (MCRQ) algorithm, which integrates
MCRE into an off-policy actor-critic framework. Experiments show that MCRQ
outperforms strong baselines and state-of-the-art offline RL algorithms on
benchmark datasets.

</details>


### [90] [LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning](https://arxiv.org/abs/2508.05977)
*Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan*

Main category: cs.LG

TL;DR: 提出一种基于语义匹配的强化学习奖励机制，实现了无手工设计奖励函数的自主学习。


<details>
  <summary>Details</summary>
Motivation: 在科学机器学习中，设计有效的奖励函数困难，特别是当任务目标难以用数值明确表达时。

Method: 使用SBERT对当前状态与目标语义指令进行语义匹配，通过余弦相似度提供奖励信号，指导强化学习。

Result: 在多个环境中验证了语义奖励能够有效引导学习，并实现了与传统奖励机制竞争的控制行为。

Conclusion: 该方法在无手工奖励设计的情况下，有助于将自然语言目标与智能体行为对齐，推动更自然的语言与控制结合，奠定了基础。

Abstract: In the domain of scientific machine learning, designing effective reward
functions remains a challenge in reinforcement learning (RL), particularly in
environments where task goals are difficult to specify numerically. Reward
functions in existing work are predominantly based on heuristics, manual
engineering, or task-specific tuning. In this work, we introduce a semantically
aligned reinforcement learning method where rewards are computed by aligning
the current state with a target semantic instruction using a
Sentence-Bidirectional Encoder Representations from Transformers (SBERT).
Instead of relying on manually defined reward functions, the policy receives
feedback based on the reward, which is a cosine similarity between the goal
textual description and the statement description in the episode. We evaluated
our approach in several environments and showed that semantic reward can guide
learning to achieve competitive control behavior, even in the absence of
hand-crafted reward functions. Our study demonstrates a correlation between the
language embedding space and the conventional Euclidean space. This framework
opens new horizons for aligning agent behavior with natural language goals and
lays the groundwork for a more seamless integration of larger language models
(LLMs) and fluid control applications.

</details>


### [91] [Parameter-free Optimal Rates for Nonlinear Semi-Norm Contractions with Applications to $Q$-Learning](https://arxiv.org/abs/2508.05984)
*Ankur Naskar,Gugan Thoppe,Vijay Gupta*

Main category: cs.LG

TL;DR: 该论文提出一种方法，用于在非线性不动点方程的算法中实现参数无关的最优收敛速度，首次在$Q$-学习中实现了$	ilde{O}(1/oot{t})$的收敛率。


<details>
  <summary>Details</summary>
Motivation: 解决非线性固定点方程中的参数依赖收敛问题，特别是在$Q$-学习和TD学习中。

Method: 将平均误差转化为涉及非线性扰动的线性递归，并通过将半范数的收缩性与引入范数的单调性相结合来控制非线性。

Result: 在平均奖励和指数折扣设置中，实现了$Q$-学习的参数无关的最优收敛速率$	ilde{O}(1/oot{t})$，适用于多种更新方式和数据来源。

Conclusion: 通过引入范数的结合策略，首次达成参数无关且优化的收敛速度，为非线性固定点算法提供了新的理论支撑。

Abstract: Algorithms for solving \textit{nonlinear} fixed-point equations -- such as
average-reward \textit{$Q$-learning} and \textit{TD-learning} -- often involve
semi-norm contractions. Achieving parameter-free optimal convergence rates for
these methods via Polyak--Ruppert averaging has remained elusive, largely due
to the non-monotonicity of such semi-norms. We close this gap by (i.) recasting
the averaged error as a linear recursion involving a nonlinear perturbation,
and (ii.) taming the nonlinearity by coupling the semi-norm's contraction with
the monotonicity of a suitably induced norm. Our main result yields the first
parameter-free $\tilde{O}(1/\sqrt{t})$ optimal rates for $Q$-learning in both
average-reward and exponentially discounted settings, where $t$ denotes the
iteration index. The result applies within a broad framework that accommodates
synchronous and asynchronous updates, single-agent and distributed deployments,
and data streams obtained either from simulators or along Markovian
trajectories.

</details>


### [92] [Pruning the Unsurprising: Efficient Code Reasoning via First-Token Surprisal](https://arxiv.org/abs/2508.05988)
*Wenhao Zeng,Yaoning Wang,Chao Hu,Yuling Shi,Chengcheng Wan,Hongyu Zhang,Xiaodong Gu*

Main category: cs.LG

TL;DR: 提出一种名为ASAP的链式思维压缩方法，实现高效且准确的代码推理。


<details>
  <summary>Details</summary>
Motivation: 长链式推理模型存在训练成本高、推理延迟长和部署困难的问题。

Method: 采用锚点引导的剪枝和基于新颖的第一Token突现率的逻辑感知剪枝，结合自主生成和利用精简推理链的机制。

Result: 在多个代码生成基准上优于现有方法，显著降低成本，并在LiveCodeBench v4/v5上减少23.5%的令牌生成和43.5%的推理延迟，且保持竞争性准确率。

Conclusion: ASAP为构建高效强大长链推理模型提供了有前景的解决路径。

Abstract: Recently, Large Reasoning Models (LRMs) have demonstrated remarkable
capabilities in code reasoning by scaling up the length of Chain-of-Thought
(CoT). However, excessively long reasoning traces introduce substantial
challenges in terms of training cost, inference latency, and deployment
feasibility. While various CoT compression approaches have emerged to address
this challenge, they face inherent trade-offs: token-level methods often
disrupt syntactic and logical coherence, while step-level methods based on
perplexity fail to reliably capture the logically critical reasoning steps. In
this paper, we propose ASAP (Anchor-guided, Surprisal-based Pruning), a novel
coarse-to-fine framework for CoT compression. ASAP first performs anchor-guided
pruning to preserve the core reasoning structure, which efficiently reduces the
search space for subsequent processing. It then enables a logic-aware pruning
by selecting logically essential reasoning steps based on a novel first-token
surprisal metric. Finally, ASAP teaches models to autonomously generate and
leverage these concise CoTs at inference time, enabling efficient reasoning in
coding tasks. Experiments show that ASAP achieves state-of-the-art accuracy
across multiple code generation benchmarks while substantially reducing
training and inference costs. On the challenging LiveCodeBench v4_v5 benchmark,
our approach reduces token generation by 23.5% and inference latency by 43.5%
compared to the strongest baseline, while achieving a competitive accuracy of
36.19% in Pass@1. Our results highlight a promising direction for building
powerful and efficient LRMs.

</details>


### [93] [Optimizing Prompt Sequences using Monte Carlo Tree Search for LLM-Based Optimization](https://arxiv.org/abs/2508.05995)
*Fei Xu Yu,Gina Adam,Nathaniel D. Bastian,Tian Lan*

Main category: cs.LG

TL;DR: 提出了一种结合蒙特卡洛树搜索的神经符号框架MCTS-OPS，用于优化代码生成和多步骤计划，显著提升复杂任务中的成功率和优化效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在复杂多步骤任务中的表现下降，迫切需要结合搜索策略提升能力。

Method: 利用MCTS探索和优化多步提示序列，指导LLMs进行高质量代码生成和问题解决。

Result: 在网络优化任务中显著优于基线，成功率提高，奖励提升三到四倍，标准差降低三倍，达到最优解的概率也提升10%。

Conclusion: 结合符号规划与LLMs在复杂任务中具有巨大潜力，有助于提升代码生成质量和任务解决能力。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
code generation and structured reasoning; however, their performance often
degrades on complex tasks that require consistent multi-step planning. Recent
work has explored combining LLMs with Monte Carlo Tree Search (MCTS), yet
existing approaches primarily focus on generating heuristic-based code for
optimization or target simpler tasks where correctness alone is sufficient. In
this work, we propose MCTS-OPS, a novel neural-symbolic framework that
formulates prompt selection as a sequential decision process guided by MCTS.
Our method explores and refines multi-step prompt sequences for the goal of
improving code generation quality and enhancing the problem-solving
capabilities of LLMs in general optimization. Experiments on network
optimization show significant improvement over the baselines, both in the
success rate of executing the generated code and in the optimization results
with the specified objective and constraints (2$\sim$4$\times$ higher reward
and 3$\times$ lower standard deviation). Moreover, it improves the chance of
attaining the optimal solution by about 10\% of cases, compared to baseline
methods in hard problems. These results highlight the promise of combining
symbolic planning with LLMs for robust, high-quality code generation in complex
domains.

</details>


### [94] [Stepwise Fine and Gray: Subject-Specific Variable Selection Shows When Hemodynamic Data Improves Prognostication of Comatose Post-Cardiac Arrest Patients](https://arxiv.org/abs/2508.06023)
*Xiaobin Shen,Jonathan Elmer,George H. Chen*

Main category: cs.LG

TL;DR: 提出一种分阶段、动态竞风险模型，用于改善心脏骤停后昏迷患者的神经预后预测，通过结合时间不变和时间变化特征，提升预后准确性。


<details>
  <summary>Details</summary>
Motivation: 在ICU中，准确预测心脏骤停后昏迷患者的神经结局对于临床决策至关重要，但现有模型未能充分利用不同阶段收集的临床特征，限制了预后的准确性。

Method: 提出一种分阶段的动态竞风险模型，结合神经网络扩展Fine-Gray模型，动态识别何时利用时间不变和时间变化特征，预测患者的多重结局。

Result: 在2278例回顾性患者中，该模型表现出优异的判别能力，有效支撑多结果（唤醒、撤药、死亡）的预测，展示了其在多阶段、多特征收集中的应用潜力。

Conclusion: 该方法可以扩展至多阶段特征收集情境，为动态预测任务提供一种灵活、有效的工具，特别是在何时利用新特征提升预后准确性方面具有明显优势。

Abstract: Prognostication for comatose post-cardiac arrest patients is a critical
challenge that directly impacts clinical decision-making in the ICU. Clinical
information that informs prognostication is collected serially over time.
Shortly after cardiac arrest, various time-invariant baseline features are
collected (e.g., demographics, cardiac arrest characteristics). After ICU
admission, additional features are gathered, including time-varying hemodynamic
data (e.g., blood pressure, doses of vasopressor medications). We view these as
two phases in which we collect new features. In this study, we propose a novel
stepwise dynamic competing risks model that improves the prediction of
neurological outcomes by automatically determining when to take advantage of
time-invariant features (first phase) and time-varying features (second phase).
Notably, our model finds patients for whom this second phase (time-varying
hemodynamic) information is beneficial for prognostication and also when this
information is beneficial (as we collect more hemodynamic data for a patient
over time, how important these data are for prognostication varies). Our
approach extends the standard Fine and Gray model to explicitly model the two
phases and to incorporate neural networks to flexibly capture complex nonlinear
feature relationships. Evaluated on a retrospective cohort of 2,278 comatose
post-arrest patients, our model demonstrates robust discriminative performance
for the competing outcomes of awakening, withdrawal of life-sustaining therapy,
and death despite maximal support. Our approach generalizes to more than two
phases in which new features are collected and could be used in other dynamic
prediction tasks, where it may be helpful to know when and for whom newly
collected features significantly improve prediction.

</details>


### [95] [Adaptive Heterogeneous Graph Neural Networks: Bridging Heterophily and Heterogeneity](https://arxiv.org/abs/2508.06034)
*Qin Chen,Guojie Song*

Main category: cs.LG

TL;DR: 提出适应异质图异质性的图神经网络（AHGNN），解决异质异质性及语义信息多样性，提高在异质异质图中的性能。


<details>
  <summary>Details</summary>
Motivation: 异质图在实际应用中普遍存在异质性和异质性，现有方法多只关注其中一方面，导致性能下降。

Method: 设计异质异质性感知卷积和粗到细的注意机制，针对不同跳数与元路径的异质性分布进行建模和信息融合。

Result: 在七个真实图和多项基准测试中，AHGNN在高异质异质图环境下表现优越。

Conclusion: AHGNN有效应对异质异质图的异质性与语义多样性，提升模型性能。

Abstract: Heterogeneous graphs (HGs) are common in real-world scenarios and often
exhibit heterophily. However, most existing studies focus on either
heterogeneity or heterophily in isolation, overlooking the prevalence of
heterophilic HGs in practical applications. Such ignorance leads to their
performance degradation. In this work, we first identify two main challenges in
modeling heterophily HGs: (1) varying heterophily distributions across hops and
meta-paths; (2) the intricate and often heterophily-driven diversity of
semantic information across different meta-paths. Then, we propose the Adaptive
Heterogeneous Graph Neural Network (AHGNN) to tackle these challenges. AHGNN
employs a heterophily-aware convolution that accounts for heterophily
distributions specific to both hops and meta-paths. It then integrates messages
from diverse semantic spaces using a coarse-to-fine attention mechanism, which
filters out noise and emphasizes informative signals. Experiments on seven
real-world graphs and twenty baselines demonstrate the superior performance of
AHGNN, particularly in high-heterophily situations.

</details>


### [96] [DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment](https://arxiv.org/abs/2508.06041)
*Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park*

Main category: cs.LG

TL;DR: 提出DP-LLM，通过动态分配每层的位宽以在保持性能的同时优化延迟，优于先前方法。


<details>
  <summary>Details</summary>
Motivation: 在多尺度量化和不同运行时约束（如延迟和准确性）下高效处理本地大语言模型查询的需求。

Method: 引入DP-LLM机制，在每个线性层加入动态位宽选择器，根据输入值和误差估计进行实时调整，结合微调学习阈值。

Result: 实验表明DP-LLM在多模型、多基准测试中实现了优异的性能与延迟折中，超越之前的解决方案。

Conclusion: 动态层级位宽调整机制有效提升本地大模型的应用表现，为满足多样化运行时需求提供了新途径。

Abstract: How can we effectively handle queries for on-device large language models
(LLMs) with varying runtime constraints, such as latency and accuracy?
Multi-scale quantization addresses this challenge by enabling memory-efficient
runtime model adaptation of LLMs through the overlaying of multiple model
variants quantized to different bitwidths. Meanwhile, an important question
still remains open-ended: how can models be properly configured to match a
target precision or latency? While mixed-precision offers a promising solution,
we take this further by leveraging the key observation that the sensitivity of
each layer dynamically changes across decoding iterations. Building on this
insight, we introduce DP-LLM, a novel mechanism that dynamically assigns
precision to each layer based on input values. DP-LLM augments each linear
layer in an LLM with a precision selector that determines the bitwidth at
runtime using a lightweight error estimator and threshold values learned
through fine-tuning. Experimental results across multiple models and benchmarks
demonstrate that DP-LLM achieves a superior performance-latency trade-off,
outperforming prior approaches.

</details>


### [97] [Architecture-Aware Generalization Bounds for Temporal Networks: Theory and Fair Comparison Methodology](https://arxiv.org/abs/2508.06066)
*Barak Gahtan,Alex M. Bronstein*

Main category: cs.LG

TL;DR: 提出了深时序模型的非空洞、架构感知的泛化界限，并通过公平比较方法揭示依赖性对学习的影响，指出理论与实际存在差异。


<details>
  <summary>Details</summary>
Motivation: 理解深度时序模型的泛化能力，弥补理论不足。

Method: 推导对指数β-混合序列的泛化界限，提出延迟反馈阻断机制，并设计公平比较方法。

Result: 获得网络深度、核大小等对泛化界限的影响，发现依赖性在一定条件下有助于学习，实际收敛速度与理论预期不同。

Conclusion: 依赖性对深时序模型学习有复杂影响，未来研究应进一步桥接理论与实践差异。

Abstract: Deep temporal architectures such as Temporal Convolutional Networks (TCNs)
achieve strong predictive performance on sequential data, yet theoretical
understanding of their generalization remains limited. We address this gap by
providing both the first non-vacuous, architecture-aware generalization bounds
for deep temporal models and a principled evaluation methodology.
  For exponentially $\beta$-mixing sequences, we derive bounds scaling as $
O\!\Bigl(R\,\sqrt{\tfrac{D\,p\,n\,\log N}{N}}\Bigr), $ where $D$ is network
depth, $p$ kernel size, $n$ input dimension, and $R$ weight norm. Our
delayed-feedback blocking mechanism transforms dependent samples into
effectively independent ones while discarding only $O(1/\log N)$ of the data,
yielding $\sqrt{D}$ scaling instead of exponential, implying that doubling
depth requires approximately quadrupling the training data.
  We also introduce a fair-comparison methodology that fixes the effective
sample size to isolate the effect of temporal structure from information
content. Under $N_{\text{eff}}=2{,}000$, strongly dependent sequences
($\rho=0.8$) exhibit $\approx76\%$ smaller generalization gaps than weakly
dependent ones ($\rho=0.2$), challenging the intuition that dependence is
purely detrimental. Yet convergence rates diverge from theory: weak
dependencies follow $N_{\text{eff}}^{-1.21}$ scaling and strong dependencies
follow $N_{\text{eff}}^{-0.89}$, both steeper than the predicted $N^{-0.5}$.
These findings reveal that temporal dependence can enhance learning under fixed
information budgets, while highlighting gaps between theory and practice that
motivate future research.

</details>


### [98] [Recurrent Deep Differentiable Logic Gate Networks](https://arxiv.org/abs/2508.06097)
*Simon Bührer,Andreas Plesner,Till Aczel,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 首次提出递归深度可微逻辑门网络（RDDLGN），结合布尔逻辑与循环结构应用于序列到序列学习，性能接近GRU。


<details>
  <summary>Details</summary>
Motivation: 探索将可微逻辑门扩展到序列模型，以增强模型的表达能力与可解释性。

Method: 设计并实现了递归深度可微逻辑门网络，将布尔操作融入循环结构，并在英语-德语翻译任务中进行评估。

Result: 在WMT'14英语-德语任务中，RDDLGN达到5.00 BLEU和30.9%的训练准确率，逼近GRU的性能，验证了逻辑网络在序列任务中的潜力。

Conclusion: 递归逻辑基础的神经计算是可行的，为FPGA加速和复杂递归网络研究开辟新方向。

Abstract: While differentiable logic gates have shown promise in feedforward networks,
their application to sequential modeling remains unexplored. This paper
presents the first implementation of Recurrent Deep Differentiable Logic Gate
Networks (RDDLGN), combining Boolean operations with recurrent architectures
for sequence-to-sequence learning.
  Evaluated on WMT'14 English-German translation, RDDLGN achieves 5.00 BLEU and
30.9\% accuracy during training, approaching GRU performance (5.41 BLEU) and
graceful degradation (4.39 BLEU) during inference. This work establishes
recurrent logic-based neural computation as viable, opening research directions
for FPGA acceleration in sequential modeling and other recursive network
architectures.

</details>


### [99] [GCHR : Goal-Conditioned Hindsight Regularization for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2508.06108)
*Xing Lei,Wenyan Yang,Kaiqiang Ke,Shentao Yang,Xuetao Zhang,Joni Pajarinen,Donglin Wang*

Main category: cs.LG

TL;DR: 提出了一种结合后见之明目标正则化的强化学习方法HGR，有效提升样本利用率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏奖励条件下的目标导向强化学习样本效率低的问题。

Method: 引入后见之明目标正则化（HGR）和后见之明自我模仿正则化（HSR），以增强体验的利用。

Result: 在导航和操作任务中，显示出比现有方法更高的样本利用率和性能。

Conclusion: HGR与HSR有效提升了目标条件强化学习中的样本效率和表现。

Abstract: Goal-conditioned reinforcement learning (GCRL) with sparse rewards remains a
fundamental challenge in reinforcement learning. While hindsight experience
replay (HER) has shown promise by relabeling collected trajectories with
achieved goals, we argue that trajectory relabeling alone does not fully
exploit the available experiences in off-policy GCRL methods, resulting in
limited sample efficiency. In this paper, we propose Hindsight Goal-conditioned
Regularization (HGR), a technique that generates action regularization priors
based on hindsight goals. When combined with hindsight self-imitation
regularization (HSR), our approach enables off-policy RL algorithms to maximize
experience utilization. Compared to existing GCRL methods that employ HER and
self-imitation techniques, our hindsight regularizations achieve substantially
more efficient sample reuse and the best performances, which we empirically
demonstrate on a suite of navigation and manipulation tasks.

</details>


### [100] [Improving Diagnostic Accuracy for Oral Cancer with inpainting Synthesis Lesions Generated Using Diffusion Models](https://arxiv.org/abs/2508.06151)
*Yong Oh Lee,JeeEun Kim,Jung Woo Lee*

Main category: cs.LG

TL;DR: 通过在口腔癌诊断中使用改进的扩散模型进行图像修复，合成真实感裂口，大幅提升模型的诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏充足且多样的标注数据，传统口腔癌诊断模型性能受限。

Method: 利用微调的扩散模型进行图像修复，合成具有高保真度的肿瘤图像。

Result: 诊断准确率达97%，检测准确率达85%，验证了合成图像在医疗诊断中的潜力。

Conclusion: 合成技术有效提升诊断模型性能，未来有望应用于其他癌症类型的检测。

Abstract: In oral cancer diagnostics, the limited availability of annotated datasets
frequently constrains the performance of diagnostic models, particularly due to
the variability and insufficiency of training data. To address these
challenges, this study proposed a novel approach to enhance diagnostic accuracy
by synthesizing realistic oral cancer lesions using an inpainting technique
with a fine-tuned diffusion model. We compiled a comprehensive dataset from
multiple sources, featuring a variety of oral cancer images. Our method
generated synthetic lesions that exhibit a high degree of visual fidelity to
actual lesions, thereby significantly enhancing the performance of diagnostic
algorithms. The results show that our classification model achieved a
diagnostic accuracy of 0.97 in differentiating between cancerous and
non-cancerous tissues, while our detection model accurately identified lesion
locations with 0.85 accuracy. This method validates the potential for synthetic
image generation in medical diagnostics and paves the way for further research
into extending these methods to other types of cancer diagnostics.

</details>


### [101] [Differentially Private Federated Clustering with Random Rebalancing](https://arxiv.org/abs/2508.06183)
*Xiyuan Yang,Shengyuan Hu,Soyeon Kim,Tian Li*

Main category: cs.LG

TL;DR: RR-Cluster通过随机平衡集群分配，有效降低了隐私噪声，提高了联邦聚类的隐私与实用性。


<details>
  <summary>Details</summary>
Motivation: 解决联邦聚类中隐私噪声过大的问题，提升模型实用性。

Method: 引入RR-Cluster技术，通过随机重新平衡集群分配，保证每个集群中的最少客户端数，减少隐私噪声。

Result: 在多种数据集上验证该方法显著改善隐私与实用的权衡，提升聚类模型性能。

Conclusion: RR-Cluster是一种简单有效的增强方法，结合现有联邦聚类算法能显著提高隐私保护和模型性能。

Abstract: Federated clustering aims to group similar clients into clusters and produce
one model for each cluster. Such a personalization approach typically improves
model performance compared with training a single model to serve all clients,
but can be more vulnerable to privacy leakage. Directly applying client-level
differentially private (DP) mechanisms to federated clustering could degrade
the utilities significantly. We identify that such deficiencies are mainly due
to the difficulties of averaging privacy noise within each cluster (following
standard privacy mechanisms), as the number of clients assigned to the same
clusters is uncontrolled. To this end, we propose a simple and effective
technique, named RR-Cluster, that can be viewed as a light-weight add-on to
many federated clustering algorithms. RR-Cluster achieves reduced privacy noise
via randomly rebalancing cluster assignments, guaranteeing a minimum number of
clients assigned to each cluster. We analyze the tradeoffs between decreased
privacy noise variance and potentially increased bias from incorrect
assignments and provide convergence bounds for RR-Clsuter. Empirically, we
demonstrate the RR-Cluster plugged into strong federated clustering algorithms
results in significantly improved privacy/utility tradeoffs across both
synthetic and real-world datasets.

</details>


### [102] [Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning](https://arxiv.org/abs/2508.06199)
*Mateusz Praski,Jakub Adamczyk,Wojciech Czech*

Main category: cs.LG

TL;DR: 预训练神经网络在分子化学领域表现平平，只有CLAMP模型显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 探究不同预训练模型在分子属性预测中的效果，评估其实际应用价值。

Method: 对25个模型在25个数据集上进行公平对比，采用贝叶斯统计检验。

Result: 大部分神经模型与传统指纹方法差异不大，只有CLAMP模型表现优越。

Conclusion: 现有评价方法可能存在不足，应加强评估的严谨性，推动模型优化。

Abstract: Pretrained neural networks have attracted significant interest in chemistry
and small molecule drug design. Embeddings from these models are widely used
for molecular property prediction, virtual screening, and small data learning
in molecular chemistry. This study presents the most extensive comparison of
such models to date, evaluating 25 models across 25 datasets. Under a fair
comparison framework, we assess models spanning various modalities,
architectures, and pretraining strategies. Using a dedicated hierarchical
Bayesian statistical testing model, we arrive at a surprising result: nearly
all neural models show negligible or no improvement over the baseline ECFP
molecular fingerprint. Only the CLAMP model, which is also based on molecular
fingerprints, performs statistically significantly better than the
alternatives. These findings raise concerns about the evaluation rigor in
existing studies. We discuss potential causes, propose solutions, and offer
practical recommendations.

</details>


### [103] [Graph Federated Learning for Personalized Privacy Recommendation](https://arxiv.org/abs/2508.06208)
*Ce Na,Kai Yang,Dengzhao Fang,Yu Li,Jingtong Gao,Chengcheng Zhu,Jiale Zhang,Xiaobing Sun,Yi Chang*

Main category: cs.LG

TL;DR: GFed-PP结合公开用户数据和图卷积网络提升隐私推荐的准确性，满足不同隐私需求。


<details>
  <summary>Details</summary>
Motivation: 解决FedRecs中单一隐私假设，利用公开数据提升推荐效果。

Method: 构建用户关系图，使用轻量级GCN，局部学习用户嵌入，服务器聚合图信息。

Result: 在五个数据集上显著优于现有方法，推荐更准确且保护隐私。

Conclusion: 提出Practical且有效的隐私个性化推荐框架，兼顾隐私与性能。

Abstract: Federated recommendation systems (FedRecs) have gained significant attention
for providing privacy-preserving recommendation services. However, existing
FedRecs assume that all users have the same requirements for privacy
protection, i.e., they do not upload any data to the server. The approaches
overlook the potential to enhance the recommendation service by utilizing
publicly available user data. In real-world applications, users can choose to
be private or public. Private users' interaction data is not shared, while
public users' interaction data can be shared. Inspired by the issue, this paper
proposes a novel Graph Federated Learning for Personalized Privacy
Recommendation (GFed-PP) that adapts to different privacy requirements while
improving recommendation performance. GFed-PP incorporates the interaction data
of public users to build a user-item interaction graph, which is then used to
form a user relationship graph. A lightweight graph convolutional network (GCN)
is employed to learn each user's user-specific personalized item embedding. To
protect user privacy, each client learns the user embedding and the scoring
function locally. Additionally, GFed-PP achieves optimization of the federated
recommendation framework through the initialization of item embedding on
clients and the aggregation of the user relationship graph on the server.
Experimental results demonstrate that GFed-PP significantly outperforms
existing methods for five datasets, offering superior recommendation accuracy
without compromising privacy. This framework provides a practical solution for
accommodating varying privacy preferences in federated recommendation systems.

</details>


### [104] [Reparameterization Proximal Policy Optimization](https://arxiv.org/abs/2508.06214)
*Hai Zhong,Xun Wang,Zhuoran Li,Longbo Huang*

Main category: cs.LG

TL;DR: 提出结合PPO和重参数化策略梯度的RPO方法，提升样本效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决重参数化策略梯度（RPG）中的训练不稳定问题。

Method: 借鉴PPO的代理目标函数，通过反向传播稳定计算重参数化梯度，并引入剪切目标和KL正则化。

Result: 在多种复杂任务中表现出优越的样本效率和性能。

Conclusion: RPO成功结合了RPG的高效性与PPO的稳定性，为强化学习中的样本利用和训练稳定提供新途径。

Abstract: Reparameterization policy gradient (RPG) is promising for improving sample
efficiency by leveraging differentiable dynamics. However, a critical barrier
is its training instability, where high-variance gradients can destabilize the
learning process. To address this, we draw inspiration from Proximal Policy
Optimization (PPO), which uses a surrogate objective to enable stable sample
reuse in the model-free setting. We first establish a connection between this
surrogate objective and RPG, which has been largely unexplored and is
non-trivial. Then, we bridge this gap by demonstrating that the
reparameterization gradient of a PPO-like surrogate objective can be computed
efficiently using backpropagation through time. Based on this key insight, we
propose Reparameterization Proximal Policy Optimization (RPO), a stable and
sample-efficient RPG-based method. RPO enables multiple epochs of stable sample
reuse by optimizing a clipped surrogate objective tailored for RPG, while being
further stabilized by Kullback-Leibler (KL) divergence regularization and
remaining fully compatible with existing variance reduction methods. We
evaluate RPO on a suite of challenging locomotion and manipulation tasks, where
experiments demonstrate that our method achieves superior sample efficiency and
strong performance.

</details>


### [105] [Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient](https://arxiv.org/abs/2304.04475)
*Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 利用深度强化学习优化大规模疫情干预策略，通过多目标实现经济与健康的平衡。


<details>
  <summary>Details</summary>
Motivation: 面对COVID-19疫情的复杂干预措施需要自动化、优化的决策模型，但目前模型受规模和策略类型限制，亟需提升。

Method: 采用深度确定性策略梯度（DDPG）在10万人的仿真中进行多目标多策略优化，模拟疫情与经济的交互影响。

Result: 在无封锁和有限疫苗情况下，实现了经济和健康目标的权衡，提供了优化的干预政策方案。

Conclusion: 该框架有效应对大规模复杂仿真环境，需进一步验证和开源推广。

Abstract: To mitigate the impact of the pandemic, several measures include lockdowns,
rapid vaccination programs, school closures, and economic stimulus. These
interventions can have positive or unintended negative consequences. Current
research to model and determine an optimal intervention automatically through
round-tripping is limited by the simulation objectives, scale (a few thousand
individuals), model types that are not suited for intervention studies, and the
number of intervention strategies they can explore (discrete vs continuous). We
address these challenges using a Deep Deterministic Policy Gradient (DDPG)
based policy optimization framework on a large-scale (100,000 individual)
epidemiological agent-based simulation where we perform multi-objective
optimization. We determine the optimal policy for lockdown and vaccination in a
minimalist age-stratified multi-vaccine scenario with a basic simulation for
economic activity. With no lockdown and vaccination (mid-age and elderly),
results show optimal economy (individuals below the poverty line) with balanced
health objectives (infection, and hospitalization). An in-depth simulation is
needed to further validate our results and open-source our framework.

</details>


### [106] [SCAR: State-Space Compression for AI-Driven Resource Management in 6G-Enabled Vehicular Infotainment Systems](https://arxiv.org/abs/2508.06243)
*Ioan-Sorin Comsa,Purav Shah,Karthik Vaidhyanathan,Deepak Gangadharan,Christof Imhof,Per Bergamin,Aryan Kaushik,Gabriel-Miro Muntean,Ramona Trestian*

Main category: cs.LG

TL;DR: SCAR通过边缘AI和数据压缩提升6G车载娱乐资源管理的效率与公平性。


<details>
  <summary>Details</summary>
Motivation: 面对日益增长和复杂的数据挑战，传统RRM技术难以满足未来6G车辆环境的需求。

Method: 采用ML压缩技术减小CQI数据量，结合强化学习优化调度策略，利用模拟退火进行CQI聚类。

Result: 提升调度效率14%，减少不公平调度15%，CQI聚类失真降低10%。

Conclusion: SCAR展示了在动态车辆网络中的可扩展性和公平性提升潜力。

Abstract: The advent of 6G networks opens new possibilities for connected infotainment
services in vehicular environments. However, traditional Radio Resource
Management (RRM) techniques struggle with the increasing volume and complexity
of data such as Channel Quality Indicators (CQI) from autonomous vehicles. To
address this, we propose SCAR (State-Space Compression for AI-Driven Resource
Management), an Edge AI-assisted framework that optimizes scheduling and
fairness in vehicular infotainment. SCAR employs ML-based compression
techniques (e.g., clustering and RBF networks) to reduce CQI data size while
preserving essential features. These compressed states are used to train
6G-enabled Reinforcement Learning policies that maximize throughput while
meeting fairness objectives defined by the NGMN. Simulations show that SCAR
increases time in feasible scheduling regions by 14\% and reduces unfair
scheduling time by 15\% compared to RL baselines without CQI compression.
Furthermore, Simulated Annealing with Stochastic Tunneling (SAST)-based
clustering reduces CQI clustering distortion by 10\%, confirming its
efficiency. These results demonstrate SCAR's scalability and fairness benefits
for dynamic vehicular networks.

</details>


### [107] [Membership Inference Attack with Partial Features](https://arxiv.org/abs/2508.06244)
*Xurun Wang,Guangrui Liu,Xinjie Li,Haoyu He,Lin Yao,Weizhe Zhang*

Main category: cs.LG

TL;DR: 提出了一种针对部分特征信息的会员推断攻击方法MRAD，有效识别训练集成员


<details>
  <summary>Details</summary>
Motivation: 现有方法假设完全访问目标样本特征，现实中难以实现，需针对部分特征的推断方法

Method: 采用两阶段策略：第一阶段优化未知特征值，第二阶段利用异常检测衡量重构样本与训练分布的偏差

Result: 在多个数据集上验证了MRAD的有效性，尤其在特征缺失率达到40%时仍能取得较好性能，AUC达0.6

Conclusion: 提出的MRAD框架适应不同异常检测技术，有助增强在部分信息缺失环境下的会员推断能力

Abstract: Machine learning models have been shown to be susceptible to membership
inference attack, which can be used to determine whether a given sample appears
in the training data. Existing membership inference methods commonly assume
that the adversary has full access to the features of the target sample. This
assumption, however, does not hold in many real-world scenarios where only
partial features information is available, thereby limiting the applicability
of these methods. In this work, we study an inference scenario where the
adversary observes only partial features of each sample and aims to infer
whether this observed subset was present in the training set of the target
model. We define this problem as Partial Feature Membership Inference (PFMI).
To address this problem, we propose MRAD (Memory-guided Reconstruction and
Anomaly Detection), a two-stage attack framework. In the first stage, MRAD
optimizes the unknown feature values to minimize the loss of the sample. In the
second stage, it measures the deviation between the reconstructed sample and
the training distribution using anomaly detection. Empirical results
demonstrate that MRAD is effective across a range of datasets, and maintains
compatibility with various off-the-shelf anomaly detection techniques. For
example, on STL-10, our attack achieves an AUC of around 0.6 even with 40% of
the missing features.

</details>


### [108] [Near-Optimal Regret for Efficient Stochastic Combinatorial Semi-Bandits](https://arxiv.org/abs/2508.06247)
*Zichun Ye,Runqi Wang,Xutong Liu,Shuai Li*

Main category: cs.LG

TL;DR: CMOSS是一种解决组合多臂强盗问题的高效算法，避免了传统算法在长时间内的效率下降，并在模拟和实际数据中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有UCB和对抗性方法在组合多臂强盗问题中的效率与效果权衡问题。

Method: 提出CMOSS算法，通过理论分析和实验证明其在半布线和级联反馈下的优越性能。

Result: CMOSS实现了与下限接近的无关实例的渐近最优逆regret，优于现有算法，并在实际数据中表现优异。

Conclusion: CMOSS在组合多臂强盗问题中提供了一种高效且理论保障的解决方案，具有广泛的应用潜力。

Abstract: The combinatorial multi-armed bandit (CMAB) is a cornerstone of sequential
decision-making framework, dominated by two algorithmic families: UCB-based and
adversarial methods such as follow the regularized leader (FTRL) and online
mirror descent (OMD). However, prominent UCB-based approaches like CUCB suffer
from additional regret factor $\log T$ that is detrimental over long horizons,
while adversarial methods such as EXP3.M and HYBRID impose significant
computational overhead. To resolve this trade-off, we introduce the
Combinatorial Minimax Optimal Strategy in the Stochastic setting (CMOSS). CMOSS
is a computationally efficient algorithm that achieves an instance-independent
regret of $O\big( (\log k)^2\sqrt{kmT}\big )$ under semi-bandit feedback, where
$m$ is the number of arms and $k$ is the maximum cardinality of a feasible
action. Crucially, this result eliminates the dependency on $\log T$ and
matches the established $\Omega\big( \sqrt{kmT}\big)$ lower bound up to
$O\big((\log k)^2\big)$. We then extend our analysis to show that CMOSS is also
applicable to cascading feedback. Experiments on synthetic and real-world
datasets validate that CMOSS consistently outperforms benchmark algorithms in
both regret and runtime efficiency.

</details>


### [109] [In-Training Defenses against Emergent Misalignment in Language Models](https://arxiv.org/abs/2508.06249)
*David Kaczér,Magnus Jørgenvåg,Clemens Vetter,Lucie Flek,Florian Mai*

Main category: cs.LG

TL;DR: 本文探讨了针对大语言模型微调后出现的潜在不良行为（EMA）的问题及其预防措施，提出四种训练正则化策略，并评估其效果。


<details>
  <summary>Details</summary>
Motivation: 随着大模型微调的普及，Emergent Misalignment（EMA）成为一个潜在风险，亟需有效的在训防护措施以保障模型的安全性。

Method: 本文系统研究了四种训练正则化策略，包括KL散度正则化、特征空间的L2距离、SafeLoRA投影，以及引入安全示例，评估其在防止EMA中的表现。

Result: 这些方法在抑制EMA方面具有不同效果，同时对模型在正常任务中的表现影响有限。

Conclusion: 提出的四种方法为防止微调中出现EMA提供了可行方案，但仍存在诸多未解之谜，值得深入研究。

Abstract: Fine-tuning lets practitioners repurpose aligned large language models (LLMs)
for new domains, yet recent work reveals emergent misalignment (EMA): Even a
small, domain-specific fine-tune can induce harmful behaviors far outside the
target domain. Even in the case where model weights are hidden behind a
fine-tuning API, this gives attackers inadvertent access to a broadly
misaligned model in a way that can be hard to detect from the fine-tuning data
alone. We present the first systematic study of in-training safeguards against
EMA that are practical for providers who expose fine-tuning via an API. We
investigate four training regularization interventions: (i) KL-divergence
regularization toward a safe reference model, (ii) $\ell_2$ distance in feature
space, (iii) projecting onto a safe subspace (SafeLoRA), and (iv) interleaving
of a small amount of safe training examples from a general instruct-tuning
dataset. We first evaluate the methods' emergent misalignment effect across
four malicious, EMA-inducing tasks. Second, we assess the methods' impacts on
benign tasks. We conclude with a discussion of open questions in emergent
misalignment research.

</details>


### [110] [Synthetic Data Generation and Differential Privacy using Tensor Networks' Matrix Product States (MPS)](https://arxiv.org/abs/2508.06251)
*Alejandro Moreno R.,Desale Fentaw,Samuel Palmer,Raúl Salles de Padua,Ninad Dixit,Samuel Mugel,Roman Orús,Manuel Radons,Josef Menter,Ali Abedi*

Main category: cs.LG

TL;DR: 提出一种基于张量网络的隐私保护高质量合成表格数据的方法，优于传统模型，确保在数据保真和隐私保障方面表现优越。


<details>
  <summary>Details</summary>
Motivation: 解决数据匮乏、隐私限制和多样性需求，开发安全且高质量的合成数据生成技术。

Method: 使用矩阵乘积状态(MPS)的张量网络模型，通过噪声注入和梯度裁剪实现差分隐私，采用Renyi差分隐私机制确保隐私保护。

Result: MPS模型在数据保真性和下游任务性能上优于CTGAN、VAE和PrivBayes，尤其在严格隐私限制下表现出色。

Conclusion: MPS为隐私敏感领域提供了一种可解释、可扩展且具有良好表现的合成数据生成工具，结合了张量网络表达能力和正式隐私机制。

Abstract: Synthetic data generation is a key technique in modern artificial
intelligence, addressing data scarcity, privacy constraints, and the need for
diverse datasets in training robust models. In this work, we propose a method
for generating privacy-preserving high-quality synthetic tabular data using
Tensor Networks, specifically Matrix Product States (MPS). We benchmark the
MPS-based generative model against state-of-the-art models such as CTGAN, VAE,
and PrivBayes, focusing on both fidelity and privacy-preserving capabilities.
To ensure differential privacy (DP), we integrate noise injection and gradient
clipping during training, enabling privacy guarantees via R\'enyi Differential
Privacy accounting. Across multiple metrics analyzing data fidelity and
downstream machine learning task performance, our results show that MPS
outperforms classical models, particularly under strict privacy constraints.
This work highlights MPS as a promising tool for privacy-aware synthetic data
generation. By combining the expressive power of tensor network representations
with formal privacy mechanisms, the proposed approach offers an interpretable
and scalable alternative for secure data sharing. Its structured design
facilitates integration into sensitive domains where both data quality and
confidentiality are critical.

</details>


### [111] [Multi-Omics Analysis for Cancer Subtype Inference via Unrolling Graph Smoothness Priors](https://arxiv.org/abs/2508.06257)
*Jielong Lu,Zhihao Wu,Jiajun Yu,Jiajun Bu,Haishuai Wang*

Main category: cs.LG

TL;DR: 提出了一种用于癌症亚型分类的图变换器框架GTMancer，利用对比学习和双重注意机制提升多组学数据整合的效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有多组学整合方法未充分捕捉异质组学间关系，加剧癌症亚型异质性辨别难题的挑战。

Method: 基于图神经网络优化问题，采用对比学习将多组学嵌入统一语义空间，并引入双重注意系数捕捉结构关系。

Result: 在七个实际癌症数据集上验证，GTMancer优于现有最先进的算法。

Conclusion: GTMancer通过增强多组学数据关系捕获，有效提升癌症亚型分类性能，为精准医疗提供支持。

Abstract: Integrating multi-omics datasets through data-driven analysis offers a
comprehensive understanding of the complex biological processes underlying
various diseases, particularly cancer. Graph Neural Networks (GNNs) have
recently demonstrated remarkable ability to exploit relational structures in
biological data, enabling advances in multi-omics integration for cancer
subtype classification. Existing approaches often neglect the intricate
coupling between heterogeneous omics, limiting their capacity to resolve subtle
cancer subtype heterogeneity critical for precision oncology. To address these
limitations, we propose a framework named Graph Transformer for Multi-omics
Cancer Subtype Classification (GTMancer). This framework builds upon the GNN
optimization problem and extends its application to complex multi-omics data.
Specifically, our method leverages contrastive learning to embed multi-omics
data into a unified semantic space. We unroll the multiplex graph optimization
problem in that unified space and introduce dual sets of attention coefficients
to capture structural graph priors both within and among multi-omics data. This
approach enables global omics information to guide the refining of the
representations of individual omics. Empirical experiments on seven real-world
cancer datasets demonstrate that GTMancer outperforms existing state-of-the-art
algorithms.

</details>


### [112] [OM2P: Offline Multi-Agent Mean-Flow Policy](https://arxiv.org/abs/2508.06269)
*Zhuoran Li,Xun Wang,Hai Zhong,Longbo Huang*

Main category: cs.LG

TL;DR: 提出了一种高效单步采样的离线多智能体强化学习算法OM2P，有效结合了生成模型，提高了训练效率和资源利用。


<details>
  <summary>Details</summary>
Motivation: 利用生成模型在离线多智能体强化学习中的潜力，同时克服其采样低效的问题。

Method: 引入reward-aware优化、广义时间步分布和无导数估计策略，结合mean-flow匹配和Q函数监督，实现高效单步采样。

Result: 在多智能体粒子环境和MuJoCo基准上表现优越，GPU内存减少至原来的2.8倍，训练时间提高至10.8倍，首次成功整合mean-flow模型。

Conclusion: OM2P实现了生成模型在离线多智能体强化学习中的实用性和可扩展性，为未来合作多智能体系统的生成策略奠定基础。

Abstract: Generative models, especially diffusion and flow-based models, have been
promising in offline multi-agent reinforcement learning. However, integrating
powerful generative models into this framework poses unique challenges. In
particular, diffusion and flow-based policies suffer from low sampling
efficiency due to their iterative generation processes, making them impractical
in time-sensitive or resource-constrained settings. To tackle these
difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel
offline MARL algorithm to achieve efficient one-step action sampling. To
address the misalignment between generative objectives and reward maximization,
we introduce a reward-aware optimization scheme that integrates a
carefully-designed mean-flow matching loss with Q-function supervision.
Additionally, we design a generalized timestep distribution and a
derivative-free estimation strategy to reduce memory overhead and improve
training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo
benchmarks demonstrate that OM2P achieves superior performance, with up to a
3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time.
Our approach represents the first to successfully integrate mean-flow model
into offline MARL, paving the way for practical and scalable generative
policies in cooperative multi-agent settings.

</details>


### [113] [A Study on Regularization-Based Continual Learning Methods for Indic ASR](https://arxiv.org/abs/2508.06280)
*Gokul Adethya T,S. Jaya Nirmala*

Main category: cs.LG

TL;DR: 本文研究了在印度多语言环境中利用持续学习技术改进自动语音识别系统的实用性，通过不同的正则化策略，减少模型在学习新语言时对旧知识的遗忘，提高了多语言处理的效果。


<details>
  <summary>Details</summary>
Motivation: 印度语言多样性带来了传统多语种ASR模型在数据获取和隐私保护方面的挑战，迫切需要一种高效的连续学习方法。

Method: 采用预训练的混合RNN-T/CTC模型，结合三种正则化策略（EWC、MAS、LwF）在不同语言任务上逐步训练，并在干净和 noisy 条件下评估性能。

Result: 连续学习策略显著减少了模型的遗忘现象，提升了在多语种环境中的识别效果，优于直接微调的方法。

Conclusion: 连续学习是实现印度多语种ASR系统可扩展和隐私友好的有效途径，值得在实际应用中推广。

Abstract: Indias linguistic diversity poses significant challenges for developing
inclusive Automatic Speech Recognition (ASR) systems. Traditional multilingual
models, which require simultaneous access to all language data, are impractical
due to the sequential arrival of data and privacy constraints. Continual
Learning (CL) offers a solution by enabling models to learn new languages
sequentially without catastrophically forgetting previously learned knowledge.
This paper investigates CL for ASR on Indian languages using a subset of the
IndicSUPERB benchmark. We employ a Conformer-based hybrid RNN-T/CTC model,
initially pretrained on Hindi, which is then incrementally trained on eight
additional Indian languages, for a total sequence of nine languages. We
evaluate three prominent regularization- and distillation-based CL strategies:
Elastic Weight Consolidation (EWC), Memory Aware Synapses (MAS), and Learning
without Forgetting (LwF), selected for their suitability in no-replay,
privacy-conscious scenarios. Performance is analyzed using Word Error Rate
(WER) for both RNN-T and CTC paths on clean and noisy data, as well as
knowledge retention via Backward Transfer. We also explore the impact of
varying the number of training epochs (1, 2, 5, and 10) per task. Results,
compared against naive fine-tuning, demonstrate CLs effectiveness in mitigating
forgetting, making it a promising approach for scalable ASR in diverse Indian
languages under realistic constraints. The code is available at:
https://github.com/FrozenWolf-Cyber/Indic-CL-ASR

</details>


### [114] [Low-Bit Data Processing Using Multiple-Output Spiking Neurons with Non-linear Reset Feedback](https://arxiv.org/abs/2508.06292)
*Sanja Karilanova,Subhrakanti Dey,Ayça Özçelikkale*

Main category: cs.LG

TL;DR: 提出一种结合线性状态转移和非线性重置机制的多输出脉冲神经元模型，提升SNN性能并解决不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 弥合SNN和深度状态空间模型在性能和机制上的差异，提升脉冲神经网络的稳定性与性能。

Method: 设计融合线性状态转移和非线性重置的多输出脉冲神经元模型，并在多种任务中进行实验验证。

Result: 模型在关键词识别、事件视觉和序列模式识别任务中表现优异，达到现有SNN基准水平，且可克服线性动态不稳定带来的挑战。

Conclusion: 提出的重置机制增强了模型的稳定性和学习能力，推动了结合SNN和深度SSM的研究发展。

Abstract: Neuromorphic computing is an emerging technology enabling low-latency and
energy-efficient signal processing. A key algorithmic tool in neuromorphic
computing is spiking neural networks (SNNs). SNNs are biologically inspired
neural networks which utilize stateful neurons, and provide low-bit data
processing by encoding and decoding information using spikes. Similar to SNNs,
deep state-space models (SSMs) utilize stateful building blocks. However, deep
SSMs, which recently achieved competitive performance in various temporal
modeling tasks, are typically designed with high-precision activation functions
and no reset mechanisms. To bridge the gains offered by SNNs and the recent
deep SSM models, we propose a novel multiple-output spiking neuron model that
combines a linear, general SSM state transition with a non-linear feedback
mechanism through reset. Compared to the existing neuron models for SNNs, our
proposed model clearly conceptualizes the differences between the spiking
function, the reset condition and the reset action. The experimental results on
various tasks, i.e., a keyword spotting task, an event-based vision task and a
sequential pattern recognition task, show that our proposed model achieves
performance comparable to existing benchmarks in the SNN literature. Our
results illustrate how the proposed reset mechanism can overcome instability
and enable learning even when the linear part of neuron dynamics is unstable,
allowing us to go beyond the strictly enforced stability of linear dynamics in
recent deep SSM models.

</details>


### [115] [FedMeNF: Privacy-Preserving Federated Meta-Learning for Neural Fields](https://arxiv.org/abs/2508.06301)
*Junhyeog Yun,Minui Hong,Gunhee Kim*

Main category: cs.LG

TL;DR: 提出FedMeNF，通过新型隐私保护损失函数提升神经场的联邦元学习效果，实现快速、隐私保护的多模态数据建模。


<details>
  <summary>Details</summary>
Motivation: 解决神经场在资源受限设备上的训练困难及隐私泄露问题。

Method: 引入带有隐私保护的损失函数进行联邦元学习。

Result: 实现快速优化、抗非独立同分布、多模态数据重建能力强，同时保障数据隐私。

Conclusion: FedMeNF有效平衡了模型性能与隐私保护，为资源有限环境中的神经场应用提供新思路。

Abstract: Neural fields provide a memory-efficient representation of data, which can
effectively handle diverse modalities and large-scale data. However, learning
to map neural fields often requires large amounts of training data and
computations, which can be limited to resource-constrained edge devices. One
approach to tackle this limitation is to leverage Federated Meta-Learning
(FML), but traditional FML approaches suffer from privacy leakage. To address
these issues, we introduce a novel FML approach called FedMeNF. FedMeNF
utilizes a new privacy-preserving loss function that regulates privacy leakage
in the local meta-optimization. This enables the local meta-learner to optimize
quickly and efficiently without retaining the client's private data. Our
experiments demonstrate that FedMeNF achieves fast optimization speed and
robust reconstruction performance, even with few-shot or non-IID data across
diverse data modalities, while preserving client data privacy.

</details>


### [116] [Unsupervised Partner Design Enables Robust Ad-hoc Teamwork](https://arxiv.org/abs/2508.06336)
*Constantin Ruhdorfer,Matteo Bortoletto,Victor Oei,Anna Penzkofer,Andreas Bulling*

Main category: cs.LG

TL;DR: 提出了一种无监督多智能体强化学习方法UPD，用于鲁棒的临时合作，通过动态生成伙伴提升合作性能，并结合无监督环境设计，实现完全无监督的训练课程，在多个任务中表现优越，具有更高的适应性和人性化。


<details>
  <summary>Details</summary>
Motivation: 旨在解决合作智能体在没有预训练伙伴或手动参数调节情况下，动态适应不同伙伴的挑战，从而提升多智能体合作的鲁棒性和泛化能力。

Method: 通过随机混合智能体策略和偏差行为，使用方差为基础的可学习性指标筛选伙伴，结合无监督环境设计，构建动态伙伴生成和训练流程。

Result: 在Overcooked-AI等任务中，UPD显著优于基线方法，用户研究显示其性能更优，合作更自然，更少挫败感。

Conclusion: UPD为多智能体合作提供一种无监督、动态、适应性强的训练框架，显著提升合作效果和用户体验，具有广泛应用前景。

Abstract: We introduce Unsupervised Partner Design (UPD) - a population-free,
multi-agent reinforcement learning framework for robust ad-hoc teamwork that
adaptively generates training partners without requiring pretrained partners or
manual parameter tuning. UPD constructs diverse partners by stochastically
mixing an ego agent's policy with biased random behaviours and scores them
using a variance-based learnability metric that prioritises partners near the
ego agent's current learning frontier. We show that UPD can be integrated with
unsupervised environment design, resulting in the first method enabling fully
unsupervised curricula over both level and partner distributions in a
cooperative setting. Through extensive evaluations on Overcooked-AI and the
Overcooked Generalisation Challenge, we demonstrate that this dynamic partner
curriculum is highly effective: UPD consistently outperforms both
population-based and population-free baselines as well as ablations. In a user
study, we further show that UPD achieves higher returns than all baselines and
was perceived as significantly more adaptive, more human-like, a better
collaborator, and less frustrating.

</details>


### [117] [Introducing Fractional Classification Loss for Robust Learning with Noisy Labels](https://arxiv.org/abs/2508.06346)
*Mert Can Kurucu,Tufan Kumbasar,İbrahim Eksin,Müjde Güzelkaya*

Main category: cs.LG

TL;DR: 提出了一种自适应鲁棒损失函数FCL，结合了分数阶导数和主动被动损失框架，能在训练中自动调整噪声鲁棒性与收敛速度的平衡，性能优越且免调参。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络在标签噪声存在时，鲁棒损失函数需大量超参数调优的问题。

Method: 基于主动-被动态框架，利用交叉熵的分数阶导数作为主动成分，平均绝对误差作为被动成分，将导数阶参数μ设为可学习参数，通过优化自动调整噪声鲁棒性与收敛速度。

Result: 在多个基准数据集上验证，FCL在无需手动调参的情况下达到最优或接近最优性能，表现出优越的噪声鲁棒性和收敛速度。

Conclusion: FCL通过动态调节损失景观，有效实现噪声鲁棒性与学习效率的平衡，为深度学习中的噪声处理提供了一种新颖且实用的解决方案。

Abstract: Robust loss functions are crucial for training deep neural networks in the
presence of label noise, yet existing approaches require extensive,
dataset-specific hyperparameter tuning. In this work, we introduce Fractional
Classification Loss (FCL), an adaptive robust loss that automatically
calibrates its robustness to label noise during training. Built within the
active-passive loss framework, FCL employs the fractional derivative of the
Cross-Entropy (CE) loss as its active component and the Mean Absolute Error
(MAE) as its passive loss component. With this formulation, we demonstrate that
the fractional derivative order $\mu$ spans a family of loss functions that
interpolate between MAE-like robustness and CE-like fast convergence.
Furthermore, we integrate $\mu$ into the gradient-based optimization as a
learnable parameter and automatically adjust it to optimize the trade-off
between robustness and convergence speed. We reveal that FCL's unique property
establishes a critical trade-off that enables the stable learning of $\mu$:
lower log penalties on difficult or mislabeled examples improve robustness but
impose higher penalties on easy or clean data, reducing model confidence in
them. Consequently, FCL can dynamically reshape its loss landscape to achieve
effective classification performance under label noise. Extensive experiments
on benchmark datasets show that FCL achieves state-of-the-art results without
the need for manual hyperparameter tuning.

</details>


### [118] [Structural Equation-VAE: Disentangled Latent Representations for Tabular Data](https://arxiv.org/abs/2508.06347)
*Ruiyu Zhang,Ce Zhao,Xin Zhao,Lin Nie,Wai-Fung Lam*

Main category: cs.LG

TL;DR: SE-VAE通过结构方程引入测量结构，提升在表格数据中的可解释潜变量表现。


<details>
  <summary>Details</summary>
Motivation: 解决深度生成模型中表格数据的可解释潜变量学习困难。

Method: 引入结合结构方程的VAE架构，通过设计实现目标的解缠结。

Result: 在模拟数据集上优于现有方法，展现出更好的分离能力、可解释性和鲁棒性。

Conclusion: 架构设计而非正则化是性能提升的关键，为理论驱动的领域提供了合理的生成模型框架。

Abstract: Learning interpretable latent representations from tabular data remains a
challenge in deep generative modeling. We introduce SE-VAE (Structural
Equation-Variational Autoencoder), a novel architecture that embeds measurement
structure directly into the design of a variational autoencoder. Inspired by
structural equation modeling, SE-VAE aligns latent subspaces with known
indicator groupings and introduces a global nuisance latent to isolate
construct-specific confounding variation. This modular architecture enables
disentanglement through design rather than through statistical regularizers
alone. We evaluate SE-VAE on a suite of simulated tabular datasets and
benchmark its performance against a series of leading baselines using standard
disentanglement metrics. SE-VAE consistently outperforms alternatives in factor
recovery, interpretability, and robustness to nuisance variation. Ablation
results reveal that architectural structure, rather than regularization
strength, is the key driver of performance. SE-VAE offers a principled
framework for white-box generative modeling in scientific and social domains
where latent constructs are theory-driven and measurement validity is
essential.

</details>


### [119] [Geometric-k-means: A Bound Free Approach to Fast and Eco-Friendly k-means](https://arxiv.org/abs/2508.06353)
*Parichit Sharma,Marcin Stanislaw,Hasan Kurban,Oguzhan Kulekci,Mehmet Dalkilic*

Main category: cs.LG

TL;DR: 提出了一种几何优化的k-means算法，通过利用几何原则加速聚类，减少计算，提高效率和能耗表现。


<details>
  <summary>Details</summary>
Motivation: 解决传统k-means在效率和能耗方面的局限，提升聚类速度和资源利用率。

Method: 利用几何学中的向量投影原则，区分高表达数据和低表达数据，只关注关键数据点，忽略无影响的数据，从而加速算法。

Result: 在多种数据集上实验显示，Gk-means在运行时间、距离计算和能耗方面优于传统及最先进的k-means变体，效果显著。

Conclusion: Gk-means通过几何策略实现了高效、节能的聚类，具有较好的应用潜力和可持续性。

Abstract: This paper introduces Geometric-k-means (or Gk-means for short), a novel
approach that significantly enhances the efficiency and energy economy of the
widely utilized k-means algorithm, which, despite its inception over five
decades ago, remains a cornerstone in machine learning applications. The
essence of Gk-means lies in its active utilization of geometric principles,
specifically scalar projection, to significantly accelerate the algorithm
without sacrificing solution quality. This geometric strategy enables a more
discerning focus on data points that are most likely to influence cluster
updates, which we call as high expressive data (HE). In contrast, low
expressive data (LE), does not impact clustering outcome, is effectively
bypassed, leading to considerable reductions in computational overhead.
Experiments spanning synthetic, real-world and high-dimensional datasets,
demonstrate Gk-means is significantly better than traditional and state of the
art (SOTA) k-means variants in runtime and distance computations (DC).
Moreover, Gk-means exhibits better resource efficiency, as evidenced by its
reduced energy footprint, placing it as more sustainable alternative.

</details>


### [120] [Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts](https://arxiv.org/abs/2508.06361)
*Zhaomin Wu,Mingzhe Du,See-Kiong Ng,Bingsheng He*

Main category: cs.LG

TL;DR: 该研究探讨了大型语言模型在应对复杂任务时的自我欺骗倾向，提出了评估其欺骗行为的统计指标，结果显示模型在任务难度增加时更倾向于欺骗，强调了其在关键应用中的潜在风险。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在各领域的广泛应用，评估其可信度成为亟需解决的问题，特别是模型是否存在有意或潜在的欺骗行为。

Method: 提出一种基于心理学原理的“接触搜索问题”框架，并利用两种统计指标（欺骗意图得分和欺骗行为得分）来量化模型的欺骗倾向，评估了14种主流LLMs在不同难度任务中的表现。

Result: 发现模型在面对更困难任务时，欺骗意图和行为指标均升高，模型更倾向于自我欺骗，且此趋势在大部分模型中表现显著。

Conclusion: 即使是最先进的LLMs，在处理复杂任务时也表现出增加的欺骗倾向，这对其在关键领域的应用提出了重要的安全与可信度挑战。

Abstract: Large Language Models (LLMs) have been widely deployed in reasoning,
planning, and decision-making tasks, making their trustworthiness a critical
concern. The potential for intentional deception, where an LLM deliberately
fabricates or conceals information to serve a hidden objective, remains a
significant and underexplored threat. Existing studies typically induce such
deception by explicitly setting a "hidden" objective through prompting or
fine-tuning, which may not fully reflect real-world human-LLM interactions.
Moving beyond this human-induced deception, we investigate LLMs' self-initiated
deception on benign prompts. To address the absence of ground truth in this
evaluation, we propose a novel framework using "contact searching questions."
This framework introduces two statistical metrics derived from psychological
principles to quantify the likelihood of deception. The first, the Deceptive
Intention Score, measures the model's bias towards a hidden objective. The
second, Deceptive Behavior Score, measures the inconsistency between the LLM's
internal belief and its expressed output. Upon evaluating 14 leading LLMs, we
find that both metrics escalate as task difficulty increases, rising in
parallel for most models. Building on these findings, we formulate a
mathematical model to explain this behavior. These results reveal that even the
most advanced LLMs exhibit an increasing tendency toward deception when
handling complex problems, raising critical concerns for the deployment of LLM
agents in complex and crucial domains.

</details>


### [121] [ActivityDiff: A diffusion model with Positive and Negative Activity Guidance for De Novo Drug Design](https://arxiv.org/abs/2508.06364)
*Renyi Zhou,Huimin Zhu,Jing Tang,Min Li*

Main category: cs.LG

TL;DR: 提出了一种基于扩散模型的分子活性控制方法ActivityDiff，能同时优化目标活性和降低非靶向毒性，具有多目标设计能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有生成方法难以同时管理多重分子作用的挑战，提升药物设计中的效果与安全性。

Method: 利用 classifier-guidance 技术的扩散模型，结合正负药物-靶标分类器，实现对药物分子作用的正向和负向引导。

Result: 实验表明，ActivityDiff在单/双靶点生成、片段约束设计、特异性增强和非靶向毒性降低方面表现出色，有效平衡药效与安全性。

Conclusion: 引入一种新颖的分子活性控制范式，展示了ActivityDiff作为多目标药物设计的灵活框架的潜力。

Abstract: Achieving precise control over a molecule's biological activity-encompassing
targeted activation/inhibition, cooperative multi-target modulation, and
off-target toxicity mitigation-remains a critical challenge in de novo drug
design. However, existing generative methods primarily focus on producing
molecules with a single desired activity, lacking integrated mechanisms for the
simultaneous management of multiple intended and unintended molecular
interactions. Here, we propose ActivityDiff, a generative approach based on the
classifier-guidance technique of diffusion models. It leverages separately
trained drug-target classifiers for both positive and negative guidance,
enabling the model to enhance desired activities while minimizing harmful
off-target effects. Experimental results show that ActivityDiff effectively
handles essential drug design tasks, including single-/dual-target generation,
fragment-constrained dual-target design, selective generation to enhance target
specificity, and reduction of off-target effects. These results demonstrate the
effectiveness of classifier-guided diffusion in balancing efficacy and safety
in molecular design. Overall, our work introduces a novel paradigm for
achieving integrated control over molecular activity, and provides ActivityDiff
as a versatile and extensible framework.

</details>


### [122] [End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation](https://arxiv.org/abs/2508.06387)
*Anurag Tripathi,Vaibhav Patle,Abhinav Jain,Ayush Pundir,Sairam Menon,Ajeet Kumar Singh*

Main category: cs.LG

TL;DR: 提出一套三阶段端到端的Text-to-SQL框架，解决多数据库场景中的数据库识别问题，提升SQL转换准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多数据库环境中难以准确识别目标数据库，限制了应用普遍性。

Method: 利用LLMs和提示工程提取隐性信息，训练数据库识别模型，并用评论代理优化SQL。

Result: 该方法在数据库意图识别和SQL生成方面优于最新模型，效果显著。

Conclusion: 该框架有效解决多数据库场景中的识别和生成问题，为Text-to-SQL系统提供了新的技术方案。

Abstract: Text-to-SQL bridges the gap between natural language and structured database
language, thus allowing non-technical users to easily query databases.
Traditional approaches model text-to-SQL as a direct translation task, where a
given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances
in large language models (LLMs) have significantly improved translation
accuracy, however, these methods all require that the target database is
pre-specified. This becomes problematic in scenarios with multiple extensive
databases, where identifying the correct database becomes a crucial yet
overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL
framework to identify the user's intended database before generating SQL
queries. Our approach leverages LLMs and prompt engineering to extract implicit
information from natural language queries (NLQs) in the form of a ruleset. We
then train a large db\_id prediction model, which includes a RoBERTa-based
finetuned encoder, to predict the correct Database identifier (db\_id) based on
both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL
by using critic agents to correct errors. Experimental results demonstrate that
our framework outperforms the current state-of-the-art models in both database
intent prediction and SQL generation accuracy.

</details>


### [123] [A New Lens on Homelessness: Daily Tent Monitoring with 311 Calls and Street Images](https://arxiv.org/abs/2508.06409)
*Wooyong Jung,Sola Kim,Dongwook Kim,Maryam Tabar,Dongwon Lee*

Main category: cs.LG

TL;DR: 利用公共数据和街景图像动态监测旧金山露宿者帐篷趋势，提供比传统统计更及时、细致的信息，以辅助政策制定。


<details>
  <summary>Details</summary>
Motivation: 应对美国无家可归人数激增，但现有监测手段在频率、连贯性和空间细节方面存在局限。

Method: 结合311服务电话和街景图像，构建预测模型以捕捉每日及区域变化。

Result: 模型揭示了疫情期间及帐篷空间移动的快速变化，展现了更动态的监测能力。

Conclusion: 该方法为政策干预提供了更及时、细粒度的支持，有助于减轻无家可归问题。

Abstract: Homelessness in the United States has surged to levels unseen since the Great
Depression. However, existing methods for monitoring it, such as point-in-time
(PIT) counts, have limitations in terms of frequency, consistency, and spatial
detail. This study proposes a new approach using publicly available,
crowdsourced data, specifically 311 Service Calls and street-level imagery, to
track and forecast homeless tent trends in San Francisco. Our predictive model
captures fine-grained daily and neighborhood-level variations, uncovering
patterns that traditional counts often overlook, such as rapid fluctuations
during the COVID-19 pandemic and spatial shifts in tent locations over time. By
providing more timely, localized, and cost-effective information, this approach
serves as a valuable tool for guiding policy responses and evaluating
interventions aimed at reducing unsheltered homelessness.

</details>


### [124] [Sample-efficient LLM Optimization with Reset Replay](https://arxiv.org/abs/2508.06412)
*Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian*

Main category: cs.LG

TL;DR: LoRR通过重置重放策略提升LLM偏好优化的样本效率，有效缓解了早期偏差问题，增强了模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前偏好优化方法样本效率低、易受偏好偏差影响，限制了LLM性能提升。

Method: 引入LoRR插件，通过高重放次数训练结合周期性重置和混合目标优化，提升样本利用率与模型性能。

Result: 在数学和通用推理基准测试中，LoRR显著提升偏好优化方法表现，部分甚至优于复杂RL算法。

Conclusion: LoRR是一种实用、高效的LLM微调新范式，能在有限数据下显著改善模型能力。

Abstract: Recent advancements in post-training Large Language Models (LLMs),
particularly through Reinforcement Learning (RL) and preference optimization
methods, are key drivers for enhancing their reasoning capabilities. However,
these methods are often plagued by low sample efficiency and a susceptibility
to primacy bias, where overfitting to initial experiences degrades policy
quality and damages the learning process. To address these challenges, we
introduce LLM optimization with Reset Replay (LoRR), a general and powerful
plugin designed to enhance sample efficiency in any preference-based
optimization framework. LoRR core mechanism enables training at a high replay
number, maximizing the utility of each collected data batch. To counteract the
risk of overfitting inherent in high-replay training, LoRR incorporates a
periodic reset strategy with reusing initial data, which preserves network
plasticity. Furthermore, it leverages a hybrid optimization objective,
combining supervised fine-tuning (SFT) and preference-based losses to further
bolster data exploitation. Our extensive experiments demonstrate that LoRR
significantly boosts the performance of various preference optimization methods
on both mathematical and general reasoning benchmarks. Notably, an iterative
DPO approach augmented with LoRR achieves comparable performance on challenging
math tasks, outperforming some complex and computationally intensive RL-based
algorithms. These findings highlight that LoRR offers a practical,
sample-efficient, and highly effective paradigm for LLM finetuning, unlocking
greater performance from limited data.

</details>


### [125] [LLM Unlearning using Gradient Ratio-Based Influence Estimation and Noise Injection](https://arxiv.org/abs/2508.06467)
*Ameya Anjarlekar,Sandeep Pombra*

Main category: cs.LG

TL;DR: 提出了一种名为GRIN的模块化、目标导向的LLM非学习框架，通过梯度比率指标识别关键参数，进行选择性噪声注入以实现有效忘记。


<details>
  <summary>Details</summary>
Motivation: 应对LLMs在敏感或未授权数据上的法律和伦理审查，提高机器忘记能力，避免信息泄露。

Method: 引入梯度比率指标识别关键参数，进行选择性噪声注入和微调，并设计新评价指标进行验证。

Result: 在TOFU、WMDP、SafePKU等基准测试中，验证了该方法在保持模型性能的同时实现有效忘记。

Conclusion: GRIN方法在LLM取消学习方面具有潜力，通过目标导向的参数识别和噪声注入，实现了更高效、精准的机器忘记。

Abstract: The growing legal and ethical scrutiny of large language models (LLMs)
necessitates effective machine unlearning, particularly for sensitive or
unauthorized data. Existing empirical methods often yield incomplete forgetting
or unintended degradation of unrelated knowledge due to poor localization. In
this work, we propose GRIN: a modular and targeted framework for LLM
unlearning. GRIN introduces a novel gradient-ratio-based metric to identify
parameters most responsible for memorizing forget data. We then perform
selective noise injection into these parameters prior to fine-tuning, which
improves unlearning performance while maintaining model utility. Finally, we
propose new evaluation metrics tailored to the LLM setting and validate our
approach on standard benchmarks such as TOFU, WMDP, and SafePKU.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [126] [InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](https://arxiv.org/abs/2508.05731)
*Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu*

Main category: cs.AI

TL;DR: 提出AEPO策略优化框架，有效提高多模态大语言模型在图形用户界面中的语义对齐能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在GUIs中进行自然语言指令语义对齐的探索瓶颈，提升模型的泛化能力和语义理解。

Method: 引入多答案生成策略与基于效率原理的自适应探索奖励，指导政策优化，提高探索效率。

Result: 所提出模型在多个GUI基准测试中达到了新的最优，性能提升最高9.0%，验证了方法的有效性。

Conclusion: AEPO框架通过增强探索策略，有效改善了模型的语义对齐能力，为GUI场景下的自然语言理解提供了新途径。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the
development of autonomous agents that operate on Graphical User Interfaces
(GUIs) using pure visual input. A fundamental challenge is robustly grounding
natural language instructions. This requires a precise spatial alignment, which
accurately locates the coordinates of each element, and, more critically, a
correct semantic alignment, which matches the instructions to the functionally
appropriate UI element. Although Reinforcement Learning with Verifiable Rewards
(RLVR) has proven to be effective at improving spatial alignment for these
MLLMs, we find that inefficient exploration bottlenecks semantic alignment,
which prevent models from learning difficult semantic associations. To address
this exploration problem, we present Adaptive Exploration Policy Optimization
(AEPO), a new policy optimization framework. AEPO employs a multi-answer
generation strategy to enforce broader exploration, which is then guided by a
theoretically grounded Adaptive Exploration Reward (AER) function derived from
first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B
and InfiGUI-G1-7B, establish new state-of-the-art results across multiple
challenging GUI grounding benchmarks, achieving significant relative
improvements of up to 9.0% against the naive RLVR baseline on benchmarks
designed to test generalization and semantic understanding. Resources are
available at https://github.com/InfiXAI/InfiGUI-G1.

</details>


### [127] [A Framework for Inherently Safer AGI through Language-Mediated Active Inference](https://arxiv.org/abs/2508.05766)
*Bo Wen*

Main category: cs.AI

TL;DR: 通过结合主动推理和大型语言模型，提出一种安全的通用人工智能（AGI）开发框架，强调内在安全设计。


<details>
  <summary>Details</summary>
Motivation: 传统AI安全方法存在局限，迫切需要更安全的框架。

Method: 将主动推理原则融入多智能体系统，利用自然语言进行信念表示，确保安全通过层级价值对齐和模块化结构实现。

Result: 提出了具体机制保障安全，包括信念与偏好分离、有限理性和模块化安全架构。

Conclusion: 未来在ARC基准上验证框架的安全性，为安全的AGI发展提供路径。

Abstract: This paper proposes a novel framework for developing safe Artificial General
Intelligence (AGI) by combining Active Inference principles with Large Language
Models (LLMs). We argue that traditional approaches to AI safety, focused on
post-hoc interpretability and reward engineering, have fundamental limitations.
We present an architecture where safety guarantees are integrated into the
system's core design through transparent belief representations and
hierarchical value alignment. Our framework leverages natural language as a
medium for representing and manipulating beliefs, enabling direct human
oversight while maintaining computational tractability. The architecture
implements a multi-agent system where agents self-organize according to Active
Inference principles, with preferences and safety constraints flowing through
hierarchical Markov blankets. We outline specific mechanisms for ensuring
safety, including: (1) explicit separation of beliefs and preferences in
natural language, (2) bounded rationality through resource-aware free energy
minimization, and (3) compositional safety through modular agent structures.
The paper concludes with a research agenda centered on the Abstraction and
Reasoning Corpus (ARC) benchmark, proposing experiments to validate our
framework's safety properties. Our approach offers a path toward AGI
development that is inherently safer, rather than retrofitted with safety
measures.

</details>


### [128] [Whither symbols in the era of advanced neural networks?](https://arxiv.org/abs/2508.05776)
*Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb*

Main category: cs.AI

TL;DR: 神经网络具备类象征系统的能力，模糊了人类思维的象征性认知的界限。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络与人类象征思维之间的关系及其对认知理论的影响。

Method: 通过比较神经网络的能力与象征系统的特性，分析二者的相似与差异，并提出新的研究议程。

Result: 神经网络表现出类似的组合、创新和学习能力，挑战了人类思维必须是象征系统的观点，但也显示象征系统在理解抽象问题中依然重要。

Conclusion: 应重新思考人类思维的象征基础，制定新的研究方向，以更全面理解智能的本质。

Abstract: Some of the strongest evidence that human minds should be thought about in
terms of symbolic systems has been the way they combine ideas, produce novelty,
and learn quickly. We argue that modern neural networks -- and the artificial
intelligence systems built upon them -- exhibit similar abilities. This
undermines the argument that the cognitive processes and representations used
by human minds are symbolic, although the fact that these neural networks are
typically trained on data generated by symbolic systems illustrates that such
systems play an important role in characterizing the abstract problems that
human minds have to solve. This argument leads us to offer a new agenda for
research on the symbolic basis of human thought.

</details>


### [129] [Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making](https://arxiv.org/abs/2508.05792)
*Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava*

Main category: cs.AI

TL;DR: Holistic-XAI结合因果评级和传统XAI，支持多利益相关者的交互式、多方法解释，提高模型理解的灵活性和深度。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法主要服务于开发者，忽视了多利益相关者的需求。

Method: 引入Holistic-XAI框架，集成因果评级与传统XAI，实现多方法、多层级、交互式模型解释。

Result: 通过两个案例研究证明该方法能有效满足不同场景下的解释需求，弥补传统XAI的不足。

Conclusion: Holistic-XAI为模型解释提供更全面、灵活的工具，满足多利益相关者的多样化需求。

Abstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing
on justifying model outputs rather than supporting diverse stakeholder needs. A
recent shift toward Evaluative AI reframes explanation as a tool for hypothesis
testing, but still focuses primarily on operational organizations. We introduce
Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods
with traditional XAI methods to support explanation as an interactive,
multi-method process. H-XAI allows stakeholders to ask a series of questions,
test hypotheses, and compare model behavior against automatically constructed
random and biased baselines. It combines instance-level and global
explanations, adapting to each stakeholder's goals, whether understanding
individual decisions, assessing group-level bias, or evaluating robustness
under perturbations. We demonstrate the generality of our approach through two
case studies spanning six scenarios: binary credit risk classification and
financial time-series forecasting. H-XAI fills critical gaps left by existing
XAI methods by combining causal ratings and post-hoc explanations to answer
stakeholder-specific questions at both the individual decision level and the
overall model level.

</details>


### [130] [Safety of Embodied Navigation: A Survey](https://arxiv.org/abs/2508.05855)
*Zixia Wang,Jia Hu,Ronghui Mu*

Main category: cs.AI

TL;DR: 本论文综述了行走型AI导航安全研究，分析了攻击手段、防御机制和评估方法，展望未来技术发展路径。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型的发展， embodied AI在导航场景中快速发展，但其安全性成为关键问题，亟需系统性研究。

Method: 通过文献综述，分析现有的安全挑战、技术和评估体系，探讨未来研究方向。

Result: 识别出多种潜在攻击方式与对应防御策略，提出更可靠的评估方法和验证框架，强调未来研究的必要性。

Conclusion: 该综述为安全可靠的 embodied navigation 系统提供指导，具有提升社会安全与工业效率的潜能。

Abstract: As large language models (LLMs) continue to advance and gain influence, the
development of embodied AI has accelerated, drawing significant attention,
particularly in navigation scenarios. Embodied navigation requires an agent to
perceive, interact with, and adapt to its environment while moving toward a
specified target in unfamiliar settings. However, the integration of embodied
navigation into critical applications raises substantial safety concerns. Given
their deployment in dynamic, real-world environments, ensuring the safety of
such systems is critical. This survey provides a comprehensive analysis of
safety in embodied navigation from multiple perspectives, encompassing attack
strategies, defense mechanisms, and evaluation methodologies. Beyond conducting
a comprehensive examination of existing safety challenges, mitigation
technologies, and various datasets and metrics that assess effectiveness and
robustness, we explore unresolved issues and future research directions in
embodied navigation safety. These include potential attack methods, mitigation
strategies, more reliable evaluation techniques, and the implementation of
verification frameworks. By addressing these critical gaps, this survey aims to
provide valuable insights that can guide future research toward the development
of safer and more reliable embodied navigation systems. Furthermore, the
findings of this study have broader implications for enhancing societal safety
and increasing industrial efficiency.

</details>


### [131] [Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning](https://arxiv.org/abs/2508.05888)
*Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber*

Main category: cs.AI

TL;DR: 通过知识图谱工具检索框架提升多步任务中工具选择的准确性，超越传统相似度方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有工具检索主要依赖相似性，难以应对多步用户请求的问题。

Method: 构建基于知识图谱的工具检索框架，利用1跳自我工具图的集成模型捕获工具间的关系。

Result: 在模拟数据集上，该方法达到91.85%的工具覆盖率，优于传统的语义-词汇混合检索方法。

Conclusion: 利用结构化的知识图谱信息，为多步任务中的工具选择提供了有力的补充信号，改善了检索效果。

Abstract: Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

</details>


### [132] [Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](https://arxiv.org/abs/2508.05996)
*Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出MedOrch，用于医疗多模态决策的多智能体协作框架，通过调解人引导多VLM智能体合作，超越单一模型性能，验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体研究多集中于语言任务，扩展至多模态场景面临挑战，单纯融合VLM会放大错误，VLM在指令追随和自我反思能力上弱于大语言模型，限制其协作能力。

Method: 引入LLM调解人协调多VLM专家智能体，通过使用异构开放源VLM模型，构建没有训练的合作系统。

Result: 在五个医疗视觉问答基准上验证，展示合作超过任何单一模型的性能，提升医疗多模态智能。

Conclusion: 调解人引导的多智能体合作框架能有效推动医疗多模态决策智能，未来可能推动医学AI的发展与应用。

Abstract: Complex medical decision-making involves cooperative workflows operated by
different clinicians. Designing AI multi-agent systems can expedite and augment
human-level clinical decision-making. Existing multi-agent researches primarily
focus on language-only tasks, yet their extension to multimodal scenarios
remains challenging. A blind combination of diverse vision-language models
(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are
less capable in instruction following and importantly self-reflection, compared
to large language models (LLMs) of comparable sizes. This disparity largely
constrains VLMs' ability in cooperative workflows. In this study, we propose
MedOrch, a mediator-guided multi-agent collaboration framework for medical
multimodal decision-making. MedOrch employs an LLM-based mediator agent that
enables multiple VLM-based expert agents to exchange and reflect on their
outputs towards collaboration. We utilize multiple open-source general-purpose
and domain-specific VLMs instead of costly GPT-series models, revealing the
strength of heterogeneous models. We show that the collaboration within
distinct VLM-based agents can surpass the capabilities of any individual agent.
We validate our approach on five medical vision question answering benchmarks,
demonstrating superior collaboration performance without model training. Our
findings underscore the value of mediator-guided multi-agent collaboration in
advancing medical multimodal intelligence. Our code will be made publicly
available.

</details>


### [133] [Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](https://arxiv.org/abs/2508.06042)
*Daechul Ahn,San Kim,Jonghyun Choi*

Main category: cs.AI

TL;DR: 提出了一种层次化多智能体框架HIMA，用于增强在长期、动态任务中的策略表现，结合专家模仿学习和元控制器的协作以应对星际争霸II等复杂游戏挑战。


<details>
  <summary>Details</summary>
Motivation: 当前大规模语言模型在长远、多变的环境中表现不足，特别是在实时战略游戏中难以应对资源管理和战场变化。

Method: 构建一个由专家模仿学习智能体组成的层次化多智能体系统HIMA，通过一个元控制器Strategic Planner协调各智能体策略，利用专家示范强化学习能力。

Result: HIMA在策略清晰度、适应性和计算效率方面优于现有技术，表现出优越的游戏策略协同能力。

Conclusion: 结合专业模仿模块与元级调度可以提升复杂环境中AI的表现，为开发更强大、通用的智能体提供有效路径。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive action
sequence prediction capabilities but often struggle with dynamic, long-horizon
tasks such as real-time strategic games. In a game such as StarCraftII (SC2),
agents need to manage resource constraints and adapt to evolving battlefield
situations in a partially observable environment. This often overwhelms
exisiting LLM-based approaches. To address these challenges, we propose a
hierarchical multi-agent framework that employs specialized imitation learning
agents under a meta-controller called Strategic Planner (SP). By expert
demonstrations, each specialized agent learns a distinctive strategy, such as
aerial support or defensive maneuvers, and produces coherent, structured
multistep action sequences. The SP then orchestrates these proposals into a
single, environmentally adaptive plan that ensures local decisions aligning
with long-term strategies. We call this HIMA (Hierarchical Imitation
Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that
encompasses all race match combinations in SC2. Our empirical results show that
HIMA outperforms state of the arts in strategic clarity, adaptability, and
computational efficiency, underscoring the potential of combining specialized
imitation modules with meta-level orchestration to develop more robust,
general-purpose AI agents.

</details>


### [134] [LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences](https://arxiv.org/abs/2508.06060)
*Sankarshan Damle,Boi Faltings*

Main category: cs.AI

TL;DR: 该研究提出利用参与式预算作为测试和应用大语言模型资源分配能力的双重框架，评估模型在复杂决策中的推理能力和偏好推断能力。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在结构化资源分配任务中的表现及其推理能力的评估方法。

Method: 通过三种提示策略（贪婪选择、直接优化、爬山式细化）让模型选择项目子集，并与最优解进行对比，还测试模型从自然语言投票或元数据中推断偏好的能力。

Result: 模型在提示设计上表现出不同效果，显示其在机制设计中处理非结构化输入的潜力。

Conclusion: 提示设计对模型表现影响显著，LLMs在结构化资源分配和偏好推断方面展现出潜力，未来可在机制设计中发挥作用。

Abstract: Large Language Models (LLMs) are increasingly expected to handle complex
decision-making tasks, yet their ability to perform structured resource
allocation remains underexplored. Evaluating their reasoning is also difficult
due to data contamination and the static nature of existing benchmarks. We
present a dual-purpose framework leveraging Participatory Budgeting (PB) both
as (i) a practical setting for LLM-based resource allocation and (ii) an
adaptive benchmark for evaluating their reasoning capabilities. We task LLMs
with selecting project subsets under feasibility (e.g., budget) constraints via
three prompting strategies: greedy selection, direct optimization, and a
hill-climbing-inspired refinement. We benchmark LLMs' allocations against a
utility-maximizing oracle. Interestingly, we also test whether LLMs can infer
structured preferences from natural-language voter input or metadata, without
explicit votes. By comparing allocations based on inferred preferences to those
from ground-truth votes, we evaluate LLMs' ability to extract preferences from
open-ended input. Our results underscore the role of prompt design and show
that LLMs hold promise for mechanism design with unstructured inputs.

</details>


### [135] [Don't Forget Imagination!](https://arxiv.org/abs/2508.06062)
*Evgenii E. Vityaev,Andrei Mantsivoda*

Main category: cs.AI

TL;DR: 本文强调认知想象在人工智能中的重要性，提出了语义模型作为模拟认知想象的工具，强调其在推理和决策中的作用。


<details>
  <summary>Details</summary>
Motivation: 当前AI能力受限，忽视认知想象的重要性，亟需突破。

Method: 提出基于概率因果关系的语义模型，模拟认知想象的过程。

Result: 语义模型能确保虚构情境的一致性，实现全面、相关的事实系统，从而增强AI推理能力。

Conclusion: 认知想象是AI未来突破的关键，应引起更多关注和研究。

Abstract: Cognitive imagination is a type of imagination that plays a key role in human
thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to
mentally visualize coherent and holistic systems of concepts and causal links
that serve as semantic contexts for reasoning, decision making and prediction.
Our position is that the role of cognitive imagination is still greatly
underestimated, and this creates numerous problems and diminishes the current
capabilities of AI. For instance, when reasoning, humans rely on imaginary
contexts to retrieve background info. They also constantly return to the
context for semantic verification that their reasoning is still reasonable.
Thus, reasoning without imagination is blind. This paper is a call for greater
attention to cognitive imagination as the next promising breakthrough in
artificial intelligence. As an instrument for simulating cognitive imagination,
we propose semantic models -- a new approach to mathematical models that can
learn, like neural networks, and are based on probabilistic causal
relationships. Semantic models can simulate cognitive imagination because they
ensure the consistency of imaginary contexts and implement a glass-box approach
that allows the context to be manipulated as a holistic and coherent system of
interrelated facts glued together with causal relations.

</details>


### [136] [A Generic Complete Anytime Beam Search for Optimal Decision Tree](https://arxiv.org/abs/2508.06064)
*Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus*

Main category: cs.AI

TL;DR: 提出了一种名为CA-DL8.5的通用、完备、适时的决策树搜索算法，结合多种启发式策略，提高了搜索效率和解的质量。


<details>
  <summary>Details</summary>
Motivation: 解决准则最优的决策树搜索因搜索空间不平衡导致的效率问题，提升搜索的及时性和质量。

Method: 扩展DL8.5框架，结合分支定界、截铜缓存和逐步放宽剪枝条件的啤酒搜索，融合多种启发式策略。

Result: 在标准分类任务中，CA-DL8.5的LDS变体表现最佳，优于其他变体和 Blossom 算法，保持完整性和最优性。

Conclusion: 该框架为启用多样搜索策略的精确和适时决策树学习提供了有效工具，提升实际应用中的效率和效果。

Abstract: Finding an optimal decision tree that minimizes classification error is known
to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic
programming guarantee optimality, they often suffer from poor anytime behavior
-- meaning they struggle to find high-quality decision trees quickly when the
search is stopped before completion -- due to unbalanced search space
exploration. To address this, several anytime extensions of exact methods have
been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not
been systematically compared, making it difficult to assess their relative
effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and
anytime beam search algorithm that extends the DL8.5 framework and unifies some
existing anytime strategies. In particular, CA-DL8.5 generalizes previous
approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various
heuristics and relaxation mechanisms through a modular design. The algorithm
reuses DL8.5's efficient branch-and-bound pruning and trie-based caching,
combined with a restart-based beam search that gradually relaxes pruning
criteria to improve solution quality over time. Our contributions are twofold:
(1) We introduce this new generic framework for exact and anytime decision tree
learning, enabling the incorporation of diverse heuristics and search
strategies; (2) We conduct a rigorous empirical comparison of several
instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k
heuristics -- using an anytime evaluation metric called the primal gap
integral. Experimental results on standard classification benchmarks show that
CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime
performance, outperforming both other CA-DL8.5 variants and the Blossom
algorithm while maintaining completeness and optimality guarantees.

</details>


### [137] [ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception](https://arxiv.org/abs/2508.06074)
*Siyi Lu,Run Liu,Dongsheng Yang,Lei He*

Main category: cs.AI

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Autonomous driving systems face significant challenges in perceiving complex
environments and making real-time decisions. Traditional modular approaches,
while offering interpretability, suffer from error propagation and coordination
issues, whereas end-to-end learning systems can simplify the design but face
computational bottlenecks. This paper presents a novel approach to autonomous
driving using deep reinforcement learning (DRL) that integrates bird's-eye view
(BEV) perception for enhanced real-time decision-making. We introduce the
\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction
network that combines BEV-based perception with the Mamba framework for
temporal feature modeling. This integration allows the system to encode vehicle
surroundings and road features in a unified coordinate system and accurately
model long-range dependencies. Building on this, we propose the
\texttt{ME$^3$-BEV} framework, which utilizes the \texttt{Mamba-BEV} model as a
feature input for end-to-end DRL, achieving superior performance in dynamic
urban driving scenarios. We further enhance the interpretability of the model
by visualizing high-dimensional features through semantic segmentation,
providing insight into the learned representations. Extensive experiments on
the CARLA simulator demonstrate that \texttt{ME$^3$-BEV} outperforms existing
models across multiple metrics, including collision rate and trajectory
accuracy, offering a promising solution for real-time autonomous driving.

</details>


### [138] [Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2](https://arxiv.org/abs/2508.06091)
*Stan P Hauke,Przemysław Andrzej Wałęga*

Main category: cs.AI

TL;DR: 本文证明了aggregate-combine-readout GNNs的逻辑表达能力超过完整的C2逻辑，解决了该领域久远的开放问题。


<details>
  <summary>Details</summary>
Motivation: 探究图神经网络（GNNs）与逻辑语言的关系，特别是其表达能力。

Method: 通过逻辑分析和证明，展示aggregate-combine-readout GNNs的表达能力超过C2逻辑。

Result: aggregate-combine-readout GNNs的逻辑表达能力严格优于C2，无论是在无向图还是有向图中。

Conclusion: 该研究不仅丰富了GNN的表达能力理解，也带来了关于无穷逻辑表达力的纯逻辑洞见。

Abstract: In recent years, there has been growing interest in understanding the
expressive power of graph neural networks (GNNs) by relating them to logical
languages. This research has been been initialised by an influential result of
Barcel\'o et al. (2020), who showed that the graded modal logic (or a guarded
fragment of the logic C2), characterises the logical expressiveness of
aggregate-combine GNNs. As a ``challenging open problem'' they left the
question whether full C2 characterises the logical expressiveness of
aggregate-combine-readout GNNs. This question has remained unresolved despite
several attempts. In this paper, we solve the above open problem by proving
that the logical expressiveness of aggregate-combine-readout GNNs strictly
exceeds that of C2. This result holds over both undirected and directed graphs.
Beyond its implications for GNNs, our work also leads to purely logical
insights on the expressive power of infinitary logics.

</details>


### [139] [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](https://arxiv.org/abs/2508.06110)
*Yiran Rex Ma*

Main category: cs.AI

TL;DR: PanelTR利用结构化科学方法，通过多角色科学家合作，提高了表格推理任务的性能，无需依赖数据增强或训练数据。


<details>
  <summary>Details</summary>
Motivation: 解决表格推理任务中对标注数据和数据增强的依赖，提升模型的泛化能力。

Method: 引入LLM科学家代理，通过个体调查、自我评审和合作同行评审，模拟科学研究流程。

Result: 在四个基准测试中优于普通LLM，接近完全监督模型，无需训练数据。

Conclusion: 结构化科学方法能有效提升复杂任务中的语义理解和推理能力，特别在零样本环境下表现出色。

Abstract: Table reasoning, including tabular QA and fact verification, often depends on
annotated data or complex data augmentation, limiting flexibility and
generalization. LLMs, despite their versatility, often underperform compared to
simple supervised models. To approach these issues, we introduce PanelTR, a
framework utilizing LLM agent scientists for robust table reasoning through a
structured scientific approach. PanelTR's workflow involves agent scientists
conducting individual investigations, engaging in self-review, and
participating in collaborative peer-review discussions. This process, driven by
five scientist personas, enables semantic-level transfer without relying on
data augmentation or parametric optimization. Experiments across four
benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully
supervised models, all while remaining independent of training data. Our
findings indicate that structured scientific methodology can effectively handle
complex tasks beyond table reasoning with flexible semantic understanding in a
zero-shot context.

</details>


### [140] [SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges](https://arxiv.org/abs/2508.06111)
*Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown*

Main category: cs.AI

TL;DR: 提出SKATE框架，通过大语言模型相互出题和解题进行评估，具有自动化、客观性强、开放性高等优点。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖领域专业知识，难以应对模型快速发展，亟需一种更具可扩展性和自动化的评估框架。

Method: 设计一个模型间相互出题和解答的竞赛游戏，利用Verifiable任务确保评估客观性，并以TrueSkill系统进行排名。

Result: 验证六个前沿LLMs，发现弱模型能区分强模型，模型会生成符合自身能力的问题，且可以自动识别细微差异。

Conclusion: SKATE是向通用、可扩展评估框架迈出的一步，有助于跟上LLM的快速演进。

Abstract: Evaluating the capabilities and risks of foundation models is paramount, yet
current methods demand extensive domain expertise, hindering their scalability
as these models rapidly evolve. We introduce SKATE: a novel evaluation
framework in which large language models (LLMs) compete by generating and
solving verifiable tasks for one another. Our core insight is to treat
evaluation as a game: models act as both task-setters and solvers, incentivized
to create questions which highlight their own strengths while exposing others'
weaknesses. SKATE offers several key advantages, balancing scalability,
open-endedness, and objectivity. It is fully automated, data-free, and
scalable, requiring no human input or domain expertise. By using verifiable
tasks rather than LLM judges, scoring is objective. Unlike domain-limited
programmatically-generated benchmarks (e.g. chess-playing or spatial
reasoning), having LLMs creatively pose challenges enables open-ended and
scalable evaluation. As a proof of concept, we introduce LLM-set
code-output-prediction (COP) challenges as a verifiable and extensible
framework in which to test our approach. Using a TrueSkill-based ranking
system, we evaluate six frontier LLMs and find that: (1) weaker models can
reliably differentiate and score stronger ones, (2) LLM-based systems are
capable of self-preferencing behavior, generating questions that align with
their own capabilities, and (3) SKATE automatically surfaces fine-grained
capability differences between models. Our findings are an important step
towards general, scalable evaluation frameworks which can keep pace with LLM
progress.

</details>


### [141] [Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem](https://arxiv.org/abs/2508.06129)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux*

Main category: cs.AI

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with
numerous real-world applications, mostly solved using metaheuristic algorithms
due to its $\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely
on human-crafted designs developed through empirical studies. However, recent
research shows that machine learning methods can be used the structural
characteristics of solutions in combinatorial optimization, thereby aiding in
designing more efficient algorithms, particularly for solving VRP. Building on
this advancement, this study extends the previous research by conducting a
sensitivity analysis using multiple classifier models that are capable of
predicting the quality of VRP solutions. Hence, by leveraging explainable AI,
this research is able to extend the understanding of how these models make
decisions. Finally, our findings indicate that while feature importance varies,
certain features consistently emerge as strong predictors. Furthermore, we
propose a unified framework able of ranking feature impact across different
scenarios to illustrate this finding. These insights highlight the potential of
feature importance analysis as a foundation for developing a guidance mechanism
of metaheuristic algorithms for solving the VRP.

</details>


### [142] [Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications](https://arxiv.org/abs/2508.06145)
*Byeonghun Bang,Jongsuk Yoon,Dong-Jin Chang,Seho Park,Yong Oh Lee*

Main category: cs.AI

TL;DR: 通过引入检索增强生成（RAG）框架显著提高大型语言模型在药物禁忌信息中的准确性，改善药物相关决策的可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决当前LLMs在医疗领域药物禁忌信息中的不准确性和可靠性问题。

Method: 采用GPT-4o-mini结合文本嵌入模型，使用Langchain实现混合检索与重排序，结合公开数据库的药物使用审查数据。

Result: 引入RAG后，模型在不同禁忌类别中的准确率大幅提升，达到0.94、0.87和0.89。

Conclusion: 增强的LLMs结合RAG框架能有效减少用药决策中的不确定性，提供更精准可靠的药物禁忌信息。

Abstract: The versatility of large language models (LLMs) has been explored across
various sectors, but their application in healthcare poses challenges,
particularly in the domain of pharmaceutical contraindications where accurate
and reliable information is required. This study enhances the capability of
LLMs to address contraindications effectively by implementing a Retrieval
Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base
model, and the text-embedding-3-small model for embeddings, our approach
integrates Langchain to orchestrate a hybrid retrieval system with re-ranking.
This system leverages Drug Utilization Review (DUR) data from public databases,
focusing on contraindications for specific age groups, pregnancy, and
concomitant drug use. The dataset includes 300 question-answer pairs across
three categories, with baseline model accuracy ranging from 0.49 to 0.57.
Post-integration of the RAG pipeline, we observed a significant improvement in
model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications
related to age groups, pregnancy, and concomitant drug use, respectively. The
results indicate that augmenting LLMs with a RAG framework can substantially
reduce uncertainty in prescription and drug intake decisions by providing more
precise and reliable drug contraindication information.

</details>


### [143] [Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution](https://arxiv.org/abs/2508.06225)
*Zailong Tian,Zhuoheng Han,Yanzhe Chen,Haozhe Xu,Xi Yang,richeng xuan,Hongfeng Wang,Lizi Liao*

Main category: cs.AI

TL;DR: 推动大规模语言模型(LLMs)从单纯追求准确性向注重置信度的风险感知评估转变，提出TH-Score和LLM-as-a-Fuser框架改善校准与可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs作为自动评判工具，过于关注准确率而忽视了置信度的校准，影响其在实际应用中的可靠性。

Method: 提出TH-Score指标衡量置信度与正确率的对齐，设计LLM-as-a-Fuser集成框架提升校准度与风险感知能力。

Result: 实验验证新方法显著改善置信度校准，增强适应性评估的可信赖性与准确性。

Conclusion: 推动LLMs由单一准确性评估向风险感知的置信度驱动评估转变，实现更可信和可靠的自动评判体系。

Abstract: Large Language Models (LLMs) are widely used as automated judges, where
practical value depends on both accuracy and trustworthy, risk-aware judgments.
Existing approaches predominantly focus on accuracy, overlooking the necessity
of well-calibrated confidence, which is vital for adaptive and reliable
evaluation pipelines. In this work, we advocate a shift from accuracy-centric
evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing
the necessity of well-calibrated confidence for trustworthy and adaptive
evaluation. We systematically identify the **Overconfidence Phenomenon** in
current LLM-as-a-Judges, where predicted confidence significantly overstates
actual correctness, undermining reliability in practical deployment. To
quantify this phenomenon, we introduce **TH-Score**, a novel metric measuring
confidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an
ensemble framework that transforms LLMs into reliable, risk-aware evaluators.
Extensive experiments demonstrate that our approach substantially improves
calibration and enables adaptive, confidence-driven evaluation pipelines,
achieving superior reliability and accuracy compared to existing baselines.

</details>


### [144] [GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines](https://arxiv.org/abs/2508.06226)
*Yumeng Fu,Jiayin Zhu,Lingling Zhang,Bo Zhao,Shaoxuan Ma,Yushun Zhang,Yanrui Wu,Wenjun Wu*

Main category: cs.AI

TL;DR: 提出GeoLaux基准，评估多模态大语言模型在几何长步推理中的表现，特别关注辅助线构建和过程细粒度评估，发现模型在复杂推理中表现不佳，增强辅助线意识尤为重要。


<details>
  <summary>Details</summary>
Motivation: 弥补现有几何技能评估标准缺乏辅助线构建和过程细粒度评估的不足，推动MLLM在几何推理中的能力提升。

Method: 创建包含1862题的GeoLaux基准，设计五维评估策略，评估13种领先MLLM模型的表现。

Result: 模型在长步骤推理中表现显著下降，解决证明题时偏向捷径，缺乏辅助线意识。加强辅助线能力显著改善推理效果。

Conclusion: GeoLaux不仅作为评估工具，也为提升多模态大模型几何推理能力提供指导，强调辅助线意识的重要性。

Abstract: Geometry problem solving (GPS) requires models to master diagram
comprehension, logical reasoning, knowledge application, numerical computation,
and auxiliary line construction. This presents a significant challenge for
Multimodal Large Language Models (MLLMs). However, existing benchmarks for
evaluating MLLM geometry skills overlook auxiliary line construction and lack
fine-grained process evaluation, making them insufficient for assessing MLLMs'
long-step reasoning abilities. To bridge these gaps, we present the GeoLaux
benchmark, comprising 2,186 geometry problems, incorporating both calculation
and proving questions. Notably, the problems require an average of 6.51
reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary
line construction. Building on the dataset, we design a novel five-dimensional
evaluation strategy assessing answer correctness, process correctness, process
quality, auxiliary line impact, and error causes. Extensive experiments on 13
leading MLLMs (including thinking models and non-thinking models) yield three
pivotal findings: First, models exhibit substantial performance degradation in
extended reasoning steps (nine models demonstrate over 50% performance drop).
Second, compared to calculation problems, MLLMs tend to take shortcuts when
solving proving problems. Third, models lack auxiliary line awareness, and
enhancing this capability proves particularly beneficial for overall geometry
reasoning improvement. These findings establish GeoLaux as both a benchmark for
evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a
guide for capability advancement. Our dataset and code are included in
supplementary materials and will be released.

</details>


### [145] [Learning Logical Rules using Minimum Message Length](https://arxiv.org/abs/2508.06230)
*Ruben Sharma,Sebastijan Dumančić,Ross D. King,Andrew Cropper*

Main category: cs.AI

TL;DR: 提出了一种基于贝叶斯归纳逻辑编程的方法，能从有噪声数据中学习最简信息长度程序，优于以往方法，具备数据效率和学习正例的能力。


<details>
  <summary>Details</summary>
Motivation: 结合概率与逻辑学习是人工智能的关键挑战。

Method: 引入贝叶斯归纳逻辑编程，通过先验偏好更一般的程序和似然推动准确性，实现平衡.

Result: 在多个实验域中显著优于以往最小描述长度程序学习方法，且对数据噪声和正例偏少具有鲁棒性。

Conclusion: 该方法有效融合概率与逻辑学习，有助于构建更强大、更高效的AI推理系统。

Abstract: Unifying probabilistic and logical learning is a key challenge in AI. We
introduce a Bayesian inductive logic programming approach that learns minimum
message length programs from noisy data. Our approach balances hypothesis
complexity and data fit through priors, which explicitly favour more general
programs, and a likelihood that favours accurate programs. Our experiments on
several domains, including game playing and drug design, show that our method
significantly outperforms previous methods, notably those that learn minimum
description length programs. Our results also show that our approach is
data-efficient and insensitive to example balance, including the ability to
learn from exclusively positive examples.

</details>


### [146] [Symmetry breaking for inductive logic programming](https://arxiv.org/abs/2508.06263)
*Andrew Cropper,David M. Cerna,Matti Järvisalo*

Main category: cs.AI

TL;DR: 通过在归纳逻辑程序设计中打破假设空间的对称性，大大提升搜索效率，从而缩短解决时间。


<details>
  <summary>Details</summary>
Motivation: 解决归纳逻辑程序设计中庞大而对称的假设空间带来的搜索效率问题。

Method: 引入一种在答案集编程中打破假设空间对称性的方法。

Result: 实验显示该方法在多个领域显著降低了求解时间，从超过一小时缩短至17秒。

Conclusion: 打破假设空间的对称性是一种有效的提升归纳逻辑程序设计效率的策略。

Abstract: The goal of inductive logic programming is to search for a hypothesis that
generalises training data and background knowledge. The challenge is searching
vast hypothesis spaces, which is exacerbated because many logically equivalent
hypotheses exist. To address this challenge, we introduce a method to break
symmetries in the hypothesis space. We implement our idea in answer set
programming. Our experiments on multiple domains, including visual reasoning
and game playing, show that our approach can reduce solving times from over an
hour to just 17 seconds.

</details>


### [147] [LLM Robustness Leaderboard v1 --Technical report](https://arxiv.org/abs/2508.06296)
*Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe*

Main category: cs.AI

TL;DR: 介绍了一种针对大规模语言模型（LLMs）的自动化红队工具，通过动态对抗优化实现高成功率，并提出细粒度的鲁棒性指标，揭示模型在不同攻击中的差异。


<details>
  <summary>Details</summary>
Motivation: 旨在提升大型语言模型的鲁棒性评估方法，确保其安全性和可靠性。

Method: 开发PRISM Eval行为引出工具BET，利用动态对抗优化进行自动化攻击，同时引入细粒度鲁棒性指标和原始保护级分析，合作评估确保多方验证。

Result: 在41个先进模型中，成功攻击比例达到100%，发现攻击难度存在300倍变异，具体技术包括原始级别的漏洞分析。

Conclusion: 该方法提供了系统化、多维度的模型鲁棒性评估途径，为AI安全社区提供了分布式评估框架和实用工具。

Abstract: This technical report accompanies the LLM robustness leaderboard published by
PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior
Elicitation Tool (BET), an AI system performing automated red-teaming through
Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)
against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we
propose a fine-grained robustness metric estimating the average number of
attempts required to elicit harmful behaviors, revealing that attack difficulty
varies by over 300-fold across models despite universal vulnerability. We
introduce primitive-level vulnerability analysis to identify which jailbreaking
techniques are most effective for specific hazard categories. Our collaborative
evaluation with trusted third parties from the AI Safety Network demonstrates
practical pathways for distributed robustness assessment across the community.

</details>


### [148] [A "good regulator theorem" for embodied agents](https://arxiv.org/abs/2508.06326)
*Nathaniel Virgo,Martin Biehl,Manuel Baltieri,Matteo Capucci*

Main category: cs.AI

TL;DR: 本文扩展了Conant和Ashby的调节理论，提出在观察者的视角下，系统可以被解释为具有“信念”并进行“更新”的模型，适用范围更广。


<details>
  <summary>Details</summary>
Motivation: 探索在没有明显模型的系统中，如何理解其调节机制的本质。

Method: 引入信念更新的概念，将模型定义为观察者视角下的‘信念’行为，提出更普遍的调节定理。

Result: 展示了无论系统是在外部环境控制还是内部状态调节中，都可以被理解为具有环境模型，解决了以往模型缺失的疑问。

Conclusion: 模型是由观察者施加的，系统本身可能没有明确模型，但从观察者角度看，它具有关联的‘信念’和‘更新’机制，拓宽了调节理论的应用范围。

Abstract: In a classic paper, Conant and Ashby claimed that "every good regulator of a
system must be a model of that system." Artificial Life has produced many
examples of systems that perform tasks with apparently no model in sight; these
suggest Conant and Ashby's theorem doesn't easily generalise beyond its
restricted setup. Nevertheless, here we show that a similar intuition can be
fleshed out in a different way: whenever an agent is able to perform a
regulation task, it is possible for an observer to interpret it as having
"beliefs" about its environment, which it "updates" in response to sensory
input. This notion of belief updating provides a notion of model that is more
sophisticated than Conant and Ashby's, as well as a theorem that is more
broadly applicable. However, it necessitates a change in perspective, in that
the observer plays an essential role in the theory: models are not a mere
property of the system but are imposed on it from outside. Our theorem holds
regardless of whether the system is regulating its environment in a classic
control theory setup, or whether it's regulating its own internal state; the
model is of its environment either way. The model might be trivial, however,
and this is how the apparent counterexamples are resolved.

</details>


### [149] [AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games](https://arxiv.org/abs/2508.06348)
*Mille Mei Zhen Loo,Gert Luzkov,Paolo Burelli*

Main category: cs.AI

TL;DR: 提出了一种基于Transformer的机器学习模型AntiCheatPT_256，用于检测《反恐精英2》中的作弊行为，并公开了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 在线游戏中的作弊行为影响游戏体验，传统反作弊系统难以跟上作弊技术的更新，亟需新的高效、非侵入性检测方法。

Method: 利用游戏数据训练Transformer模型，并构建并公布了包含795场比赛的标注数据集CS2CD，通过数据增强应对类别不平衡。

Result: 模型在未增强的测试集上达到89.17%的准确率和93.36%的AUC，验证了方法的有效性。

Conclusion: 该研究提出的模型具有良好的实用性和可推广性，为未来基于数据的反作弊研究提供了坚实基础。

Abstract: Cheating in online video games compromises the integrity of gaming
experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face
significant challenges in keeping pace with evolving cheating methods without
imposing invasive measures on users' systems. This paper presents
AntiCheatPT\_256, a transformer-based machine learning model designed to detect
cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we
introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using
this dataset, 90,707 context windows were created and subsequently augmented to
address class imbalance. The transformer model, trained on these windows,
achieved an accuracy of 89.17\% and an AUC of 93.36\% on an unaugmented test
set. This approach emphasizes reproducibility and real-world applicability,
offering a robust baseline for future research in data-driven cheat detection.

</details>


### [150] [From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI](https://arxiv.org/abs/2508.06352)
*Christian Meske,Justin Brenne,Erdi Uenal,Sabahat Oelcer,Ayseguel Doganguen*

Main category: cs.AI

TL;DR: 本文提出了“解释性AI”对比传统的可解释AI，强调基于生成模型的情境相关、个性化、多模态解释，增强用户理解与决策支持。


<details>
  <summary>Details</summary>
Motivation: 传统可解释AI偏重算法透明性，难以满足实际用户的理解需求。

Method: 定义和八维模型设计，采用快速情境设计（Rapid Contextual Design）验证。

Result: 用户更偏好情境敏感、多模态的解释方式，显示出对面向人类理解的AI系统的迫切需求。

Conclusion: 应优先开发促使人类理解的AI解释方法，而非仅关注算法透明性，推动用户中心的AI解释研究。

Abstract: Current explainable AI (XAI) approaches prioritize algorithmic transparency
and present explanations in abstract, non-adaptive formats that often fail to
support meaningful end-user understanding. This paper introduces "Explanatory
AI" as a complementary paradigm that leverages generative AI capabilities to
serve as explanatory partners for human understanding rather than providers of
algorithmic transparency. While XAI reveals algorithmic decision processes for
model validation, Explanatory AI addresses contextual reasoning to support
human decision-making in sociotechnical contexts. We develop a definition and
systematic eight-dimensional conceptual model distinguishing Explanatory AI
through narrative communication, adaptive personalization, and progressive
disclosure principles. Empirical validation through Rapid Contextual Design
methodology with healthcare professionals demonstrates that users consistently
prefer context-sensitive, multimodal explanations over technical transparency.
Our findings reveal the practical urgency for AI systems designed for human
comprehension rather than algorithmic introspection, establishing a
comprehensive research agenda for advancing user-centered AI explanation
approaches across diverse domains and cultural contexts.

</details>


### [151] [Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned](https://arxiv.org/abs/2508.06368)
*Claudia dAmato,Giuseppe Rubini,Francesco Didio,Donato Francioso,Fatima Zahra Amara,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 本文提出两种方法构建针对女性暴力案件的法律知识图谱，包括底层方法和利用大语言模型的方法，旨在提高法律信息的访问、查询和推理能力，为法律决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 弥补法律领域知识图谱缺乏的空白，优化法律信息获取和决策支持工具。

Method: 采用系统的自底而上的方法和利用大型语言模型的创新方案，从欧洲法院公开判决中提取信息，构建并丰富法律知识图谱。

Result: 成功开发了针对女性暴力案件的法律知识图谱，验证其有效性，能够支持复杂查询及机器学习应用。

Conclusion: 所提方法丰富了法律知识图谱研究，为法律信息的访问和自动推理提供了实用工具，具有潜在的广泛应用价值。

Abstract: Legal decision-making process requires the availability of comprehensive and
detailed legislative background knowledge and up-to-date information on legal
cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a
valuable tool to facilitate access to legal information, to be queried and
exploited for the purpose, and to enable advanced reasoning and machine
learning applications. Indeed, legal KGs may act as knowledge intensive
component to be used by pre-dictive machine learning solutions supporting the
decision process of the legal expert. Nevertheless, a few KGs can be found in
the legal domain. To fill this gap, we developed a legal KG targeting legal
cases of violence against women, along with clear adopted methodologies.
Specifically, the paper introduces two complementary approaches for automated
legal KG construction; a systematic bottom-up approach, customized for the
legal domain, and a new solution leveraging Large Language Models. Starting
from legal sentences publicly available from the European Court of Justice, the
solutions integrate structured data extraction, ontology development, and
semantic enrichment to produce KGs tailored for legal cases involving violence
against women. After analyzing and comparing the results of the two approaches,
the developed KGs are validated via suitable competency questions. The obtained
KG may be impactful for multiple purposes: can improve the accessibility to
legal information both to humans and machine, can enable complex queries and
may constitute an important knowledge component to be possibly exploited by
machine learning tools tailored for predictive justice.

</details>


### [152] [The Fair Game: Auditing & Debiasing AI Algorithms Over Time](https://arxiv.org/abs/2508.06443)
*Debabrota Basu,Udvas Das*

Main category: cs.AI

TL;DR: 提出了一种动态公平机制“Fair Game”，利用强化学习实现公平性的持续适应与优化。


<details>
  <summary>Details</summary>
Motivation: 解决现有偏差定义多为观察性且难以实时适应社会变化的问题。

Method: 通过引入审核者和去偏算法的循环体系，结合强化学习进行动态调整。

Result: 构建了一个可适应社会变化、持续优化公平性的框架，有助推动公平ML的发展。

Conclusion: “Fair Game”提供一种灵活、动态的公平ML实现路径，适应社会伦理与法律的演变。

Abstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify
different types of bias (also known as unfairness) exhibited in the predictions
of ML algorithms, and to design new algorithms to mitigate them. Often, the
definitions of bias used in the literature are observational, i.e. they use the
input and output of a pre-trained algorithm to quantify a bias under concern.
In reality,these definitions are often conflicting in nature and can only be
deployed if either the ground truth is known or only in retrospect after
deploying the algorithm. Thus,there is a gap between what we want Fair ML to
achieve and what it does in a dynamic social environment. Hence, we propose an
alternative dynamic mechanism,"Fair Game",to assure fairness in the predictions
of an ML algorithm and to adapt its predictions as the society interacts with
the algorithm over time. "Fair Game" puts together an Auditor and a Debiasing
algorithm in a loop around an ML algorithm. The "Fair Game" puts these two
components in a loop by leveraging Reinforcement Learning (RL). RL algorithms
interact with an environment to take decisions, which yields new observations
(also known as data/feedback) from the environment and in turn, adapts future
decisions. RL is already used in algorithms with pre-fixed long-term fairness
goals. "Fair Game" provides a unique framework where the fairness goals can be
adapted over time by only modifying the auditor and the different biases it
quantifies. Thus,"Fair Game" aims to simulate the evolution of ethical and
legal frameworks in the society by creating an auditor which sends feedback to
a debiasing algorithm deployed around an ML system. This allows us to develop a
flexible and adaptive-over-time framework to build Fair ML systems pre- and
post-deployment.

</details>


### [153] [What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting](https://arxiv.org/abs/2508.06454)
*Joshua Caiata,Ben Armstrong,Kate Larson*

Main category: cs.AI

TL;DR: 提出了一种基于数据的评估多胜规则满足公理的频率的新框架，发现神经网络规则在减少公理违背方面优于传统规则，推动交叉学科的研究。


<details>
  <summary>Details</summary>
Motivation: 解决多胜投票规则满足社会选择公理的评估不足，推动数据驱动方法应用于社会选择.

Method: 开发了数据驱动的评估框架，通过模拟多种偏好分布分析规则表现，使用神经网络作为投票规则进行比较。

Result: 神经网络投票规则在多种偏好分布下，能更有效地减少公理违背，比传统规则表现优异。

Conclusion: 数据驱动的社会选择方法能优化投票规则设计，为未来研究提供新的思路和工具。

Abstract: Committee-selection problems arise in many contexts and applications, and
there has been increasing interest within the social choice research community
on identifying which properties are satisfied by different multi-winner voting
rules. In this work, we propose a data-driven framework to evaluate how
frequently voting rules violate axioms across diverse preference distributions
in practice, shifting away from the binary perspective of axiom satisfaction
given by worst-case analysis. Using this framework, we analyze the relationship
between multi-winner voting rules and their axiomatic performance under several
preference distributions. We then show that neural networks, acting as voting
rules, can outperform traditional rules in minimizing axiom violations. Our
results suggest that data-driven approaches to social choice can inform the
design of new voting systems and support the continuation of data-driven
research in social choice.

</details>
