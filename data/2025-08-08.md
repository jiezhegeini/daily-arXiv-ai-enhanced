<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 41]
- [cs.AI](#cs.AI) [Total: 33]
- [cs.IR](#cs.IR) [Total: 15]
- [cs.LG](#cs.LG) [Total: 97]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
*Thomas Thebaud,Yen-Ju Lu,Matthew Wiesner,Peter Viechnicki,Najim Dehak*

Main category: cs.CL

TL;DR: 本文提出一种在对话转录后通过结合音频基础模型和语言模型，自动为对话添加说话人特征的工具，无需微调模型即可实现良好性能。


<details>
  <summary>Details</summary>
Motivation: 提升对话转录的丰富性和信息量，通过自动化标注说话人特征以增强理解和分析。

Method: 采用冻结的音频基础模型（如Whisper、WavLM）与冻结的LLAMA模型，结合轻量级连接器，完成说话人特征推断，无需专门微调。

Result: 实现了在说话人特征识别任务中的有竞争力表现，并能直接比较x-vectors，达到8.8%的等错误率。

Conclusion: 利用冻结模型结合轻量连接器可有效增强对话转录的元数据标注，不依赖微调，保持模块性和效率。

Abstract: In dialogue transcription pipelines, Large Language Models (LLMs) are
frequently employed in post-processing to improve grammar, punctuation, and
readability. We explore a complementary post-processing step: enriching
transcribed dialogues by adding metadata tags for speaker characteristics such
as age, gender, and emotion. Some of the tags are global to the entire
dialogue, while some are time-variant. Our approach couples frozen audio
foundation models, such as Whisper or WavLM, with a frozen LLAMA language model
to infer these speaker attributes, without requiring task-specific fine-tuning
of either model. Using lightweight, efficient connectors to bridge audio and
language representations, we achieve competitive performance on speaker
profiling tasks while preserving modularity and speed. Additionally, we
demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving
an Equal Error Rate of 8.8% in some scenarios.

</details>


### [2] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
*Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich*

Main category: cs.CL

TL;DR: 提出了一种平衡不同语言资源的字节对编码变体，通过优化最差压缩语言，实现跨语种公平的分词，对模型性能影响极小。


<details>
  <summary>Details</summary>
Motivation: 解决现有分词算法偏向资源丰富语言，导致低资源语言分词质量差的问题。

Method: 引入Parity-aware BPE，在每次合并中优先考虑最差压缩的语言，以提升低资源语言的分词公平性。

Result: 实验显示该方法实现了跨语言的分词公平性，全球压缩率变化不大，对模型性能几乎无影响。

Conclusion: 该方法有效缓解了低资源语言的分词不公问题，有助于推动公平的多语种自然语言处理发展。

Abstract: Tokenization is the first -- and often least scrutinized -- step of most NLP
pipelines. Standard algorithms for learning tokenizers rely on frequency-based
objectives, which favor languages dominant in the training data and
consequently leave lower-resource languages with tokenizations that are
disproportionately longer, morphologically implausible, or even riddled with
<UNK> placeholders. This phenomenon ultimately amplifies computational and
financial inequalities between users from different language backgrounds. To
remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of
the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes
the compression gain of the currently worst-compressed language, trading a
small amount of global compression for cross-lingual parity. We find
empirically that Parity-aware BPE leads to more equitable token counts across
languages, with negligible impact on global compression rate and no substantial
effect on language-model performance in downstream tasks.

</details>


### [3] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
*David Sasu,Natalie Schluter*

Main category: cs.CL

TL;DR: 结合音调重音检测的半监督ASR模型显著提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 提升自动语音识别系统的性能，通过整合韵律特征，弥补单一模型的不足。

Method: 构建联合ASR与音调重音检测模型，采用半监督学习。

Result: 音调重音检测性能大幅提升，F1-score提升41%；在LibriSpeech数据集上，WER降低28.3%。

Conclusion: 扩展预训练语音模型以保持或再学习重要的韵律特征（如音调重音）是提升ASR性能的关键。

Abstract: We show the performance of Automatic Speech Recognition (ASR) systems that
use semi-supervised speech representations can be boosted by a complimentary
pitch accent detection module, by introducing a joint ASR and pitch accent
detection model. The pitch accent detection component of our model achieves a
significant improvement on the state-of-the-art for the task, closing the gap
in F1-score by 41%. Additionally, the ASR performance in joint training
decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With
these results, we show the importance of extending pretrained speech models to
retain or re-learn important prosodic cues such as pitch accent.

</details>


### [4] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
*Tommaso Tosato,Saskia Helbling,Yorguin-Jose Mantilla-Ramos,Mahmood Hegazy,Alberto Tosato,David John Lemay,Irina Rish,Guillaume Dumas*

Main category: cs.CL

TL;DR: 大型语言模型的行为表现高度不稳定，影响其安全部署。


<details>
  <summary>Details</summary>
Motivation: 理解和评估大规模语言模型的行为一致性，确保其安全性。

Method: 开发PERSIST框架，采用多种测试方法检测25+模型的行为变异性。

Result: 模型表现出显著的响应差异，即使在大规模模型中也存在较大波动，提示架构层面限制无法完全解决稳定性问题。

Conclusion: 当前模型缺乏真正的行为一致性，限制了其在安全关键应用中的使用，单纯的个性化调整不足以解决问题。

Abstract: Large language models require consistent behavioral patterns for safe
deployment, yet their personality-like traits remain poorly understood. We
present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive
evaluation framework testing 25+ open-source models (1B-671B parameters) across
500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted
personality instruments, we systematically vary question order, paraphrasing,
personas, and reasoning modes. Our findings challenge fundamental deployment
assumptions: (1) Even 400B+ models exhibit substantial response variability (SD
> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up
to 20%; (3) Interventions expected to stabilize behavior, such as
chain-of-thought reasoning, detailed personas instruction, inclusion of
conversation history, can paradoxically increase variability; (4) LLM-adapted
instruments show equal instability to human-centric versions, confirming
architectural rather than translational limitations. This persistent
instability across scales and mitigation strategies suggests current LLMs lack
the foundations for genuine behavioral consistency. For safety-critical
applications requiring predictable behavior, these findings indicate that
personality-based alignment strategies may be fundamentally inadequate.

</details>


### [5] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
*Jun Liu,Zhenglun Kong,Changdi Yang,Fan Yang,Tianqi Li,Peiyan Dong,Joannah Nanjekye,Hao Tang,Geng Yuan,Wei Niu,Wenbin Zhang,Pu Zhao,Xue Lin,Dong Huang,Yanzhi Wang*

Main category: cs.CL

TL;DR: 提出一种动态、角色感知的内存路由框架RCR-Router，有效提升多智能体大语言模型的交互效率与回答质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有多智能体LLM系统中静态或全局路由策略导致的Token消耗过多、内存暴露冗余及适应性差的问题。

Method: 设计基于角色和任务阶段的动态内存选择机制，通过轻量级评分策略引导内存筛选，将输出逐步整合到共享内存中，实现上下文的逐步优化。

Result: 在HotPotQA、MuSiQue和2WikiMultihop等三大多跳问答任务上，RCR-Router显著减少Token消耗（最高30%），并在保持或提升答案质量的同时，提高系统的效率。

Conclusion: 结构化的内存路由与输出敏感的评估方式，是提升多智能体大语言模型系统可扩展性和性能的关键措施。

Abstract: Multi-agent large language model (LLM) systems have shown strong potential in
complex reasoning and collaborative decision-making tasks. However, most
existing coordination schemes rely on static or full-context routing
strategies, which lead to excessive token consumption, redundant memory
exposure, and limited adaptability across interaction rounds. We introduce
RCR-Router, a modular and role-aware context routing framework designed to
enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,
this is the first routing approach that dynamically selects semantically
relevant memory subsets for each agent based on its role and task stage, while
adhering to a strict token budget. A lightweight scoring policy guides memory
selection, and agent outputs are iteratively integrated into a shared memory
store to facilitate progressive context refinement. To better evaluate model
behavior, we further propose an Answer Quality Score metric that captures
LLM-generated explanations beyond standard QA accuracy. Experiments on three
multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate
that RCR-Router reduces token usage (up to 30%) while improving or maintaining
answer quality. These results highlight the importance of structured memory
routing and output-aware evaluation in advancing scalable multi-agent LLM
systems.

</details>


### [6] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
*Julia Kharchenko,Tanya Roosta,Aman Chadha,Chirag Shah*

Main category: cs.CL

TL;DR: 提出一个评估大语言模型对微妙的语言标记偏差的基准，可测量模型对不同人口特征的偏见。


<details>
  <summary>Details</summary>
Motivation: 为了识别和衡量AI系统中的语言偏见，确保公平性。

Method: 设计包含100对问答的模拟面试，控制语言变化以测试偏见，分析模型在不同语言表现中的差异。

Result: 发现模型对带有回避语的回答评分较低，验证了基准的有效性，揭示模型存在偏见。

Conclusion: 建立了检测和衡量语言偏见的基础框架，有助于提升AI系统的公平性。

Abstract: This paper introduces a comprehensive benchmark for evaluating how Large
Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic
markers that can inadvertently reveal demographic attributes such as gender,
social class, or regional background. Through carefully constructed interview
simulations using 100 validated question-response pairs, we demonstrate how
LLMs systematically penalize certain linguistic patterns, particularly hedging
language, despite equivalent content quality. Our benchmark generates
controlled linguistic variations that isolate specific phenomena while
maintaining semantic equivalence, which enables the precise measurement of
demographic bias in automated evaluation systems. We validate our approach
along multiple linguistic dimensions, showing that hedged responses receive
25.6% lower ratings on average, and demonstrate the benchmark's effectiveness
in identifying model-specific biases. This work establishes a foundational
framework for detecting and measuring linguistic discrimination in AI systems,
with broad applications to fairness in automated decision-making contexts.

</details>


### [7] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 提出了一种基于视觉-语言聚类的动作识别系统评估方法，弥补传统单一答案评价的不足，更贴近人类判断。


<details>
  <summary>Details</summary>
Motivation: 传统动作识别评估方法无法充分捕捉动词语义多样性和图片多角度理解带来的模糊性，需要更鲁棒的评估标准。

Method: 构建动词意义簇，利用视觉-语言聚类框架对图像中的不同感知角度进行分组，分析模型表现。

Result: 发现每个图像对应平均2.8个意义簇，模型评估显示新方法优于传统标准，且更符合人类判断。

Conclusion: 基于语义簇的评价提供更细腻、更符合人类认知的系统性能评估方案，增强了动作识别模型的可靠性。

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [8] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 多阶段大语言模型框架提高了从非结构化文本中提取与自杀相关的社会决定因素的准确性和透明度，有助于早期干预和预防。


<details>
  <summary>Details</summary>
Motivation: 理解影响自杀的社会因素对于预防自杀至关重要，但现有自动化方法面临数据偏长、关键压力点识别难和模型解释性不足的挑战。

Method: 提出多阶段大语言模型框架，结合多模型比较和用户研究，增强社会决定因素的提取和解释能力。

Result: 框架在提取任务和细粒度检索方面表现优越，微调小模型效果良好，提供中间解释提升透明度。

Conclusion: 该方法提升了SDoH提取的准确性和可解释性，有助早期识别风险个体，指导预防策略。

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [9] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
*Kun Peng,Cong Cao,Hao Peng,Zhifeng Hao,Lei Jiang,Kongjing Gu,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出一种基于结构熵最小化的对话语义子片段划分方法，有效提升多轮、多主体对话的情感四元组提取性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理复杂对话时易引入噪声的问题，提升情感关系提取的准确性。

Method: 利用结构熵最小化算法划分子对话，采用两步框架：先提取单一情感元素，再在子对话层面匹配四元组。

Result: 在多轮多主体对话情感四元组提取任务中，显著优于现有方法，且计算成本较低。

Conclusion: 基于结构熵的划分方式有效提升对话中情感关系的提取效果，具有良好的实用价值。

Abstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to
extract all target-aspect-opinion-sentiment quadruples from a given
multi-round, multi-participant dialogue. Existing methods typically learn word
relations across entire dialogues, assuming a uniform distribution of sentiment
elements. However, we find that dialogues often contain multiple semantically
independent sub-dialogues without clear dependencies between them. Therefore,
learning word relationships across the entire dialogue inevitably introduces
additional noise into the extraction process. To address this, our method
focuses on partitioning dialogues into semantically independent sub-dialogues.
Achieving completeness while minimizing these sub-dialogues presents a
significant challenge. Simply partitioning based on reply relationships is
ineffective. Instead, we propose utilizing a structural entropy minimization
algorithm to partition the dialogues. This approach aims to preserve relevant
utterances while distinguishing irrelevant ones as much as possible.
Furthermore, we introduce a two-step framework for quadruple extraction: first
extracting individual sentiment elements at the utterance level, then matching
quadruples at the sub-dialogue level. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in DiaASQ with much lower
computational costs.

</details>


### [10] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
*Shu Han Ho*

Main category: cs.CL

TL;DR: 通过微调仅解码器的大型语言模型（LLMs）可以在AMR解析中达到与复杂SOTA模型相媲美的性能，LLaMA 3.2表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 探索用微调大型语言模型简化AMR解析，提升性能。

Method: 微调四种不同架构的LLMs（Phi 3.5, Gemma 2, LLaMA 3.2, DeepSeek R1 LLaMA）在AMR3.0数据集上的表现。

Result: 微调解码器型LLMs可达SOTA性能，LLaMA 3.2尤为突出，SMATCH F1达0.804。

Conclusion: 微调解码器型LLMs是AMR解析的有效途径，LLaMA 3.2在语义上表现优越，Phi 3.5在结构验证方面优异。

Abstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence
meaning as rooted, directed, acyclic graphs, where nodes represent concepts and
edges denote semantic relations. Finetuning decoder only Large Language Models
(LLMs) represent a promising novel straightfoward direction for AMR parsing.
This paper presents a comprehensive evaluation of finetuning four distinct LLM
architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled
using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that
straightfoward finetuning of decoder only LLMs can achieve comparable
performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2
demonstrates competitive performance against SOTA AMR parsers given a
straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full
LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching
Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a
consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5
excels in structural validity.

</details>


### [11] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
*Jinda Liu,Bo Cheng,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: 简化的多头结构和单一适配器在多任务学习中的表现优于复杂多组件方法，Align-LoRA通过对齐任务表示进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 提高大语言模型在多任务中的适应能力，同时简化模型结构。

Method: 采用简化的多头架构和调整适配器的rank，提出Align-LoRA通过显式损失对齐任务表示。

Result: 简化模型在多任务学习中表现优越，Align-LoRA显著优于其他基线方法。

Conclusion: 有效的多任务泛化依赖于学习稳健的共享表示，简化结构和对齐策略能更好地适应多任务需求。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large
Language Models (LLMs). In practice, LLMs are often required to handle a
diverse set of tasks from multiple domains, a scenario naturally addressed by
multi-task learning (MTL). Within this MTL context, a prevailing trend involves
LoRA variants with multiple adapters or heads, which advocate for structural
diversity to capture task-specific knowledge. Our findings present a direct
challenge to this paradigm. We first show that a simplified multi-head
architecture with high inter-head similarity substantially outperforms complex
multi-adapter and multi-head systems. This leads us to question the
multi-component paradigm itself, and we further demonstrate that a standard
single-adapter LoRA, with a sufficiently increased rank, also achieves highly
competitive performance. These results lead us to a new hypothesis: effective
MTL generalization hinges on learning robust shared representations, not
isolating task-specific features. To validate this, we propose Align-LoRA,
which incorporates an explicit loss to align task representations within the
shared adapter space. Experiments confirm that Align-LoRA significantly
surpasses all baselines, establishing a simpler yet more effective paradigm for
adapting LLMs to multiple tasks. The code is available at
https://github.com/jinda-liu/Align-LoRA.

</details>


### [12] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
*Aditya Kishore,Gaurav Kumar,Jasabanta Patro*

Main category: cs.CL

TL;DR: 提出了一种多模态事实验证模型MultiCheck，结合文本和图像，利用多模态推理和对比学习有效提升验证性能。


<details>
  <summary>Details</summary>
Motivation: 多模态误导信息增长，传统主要文本验证难以应对多模态证据，亟需更有效的多模态验证方法。

Method: 设计融合文本和图像编码的统一架构，通过交互融合实现跨模态关系建模，结合对比学习对验证对进行语义一致性优化。

Result: 在Factify 2数据集上取得0.84的加权F1分数，显著优于基线，证明多模态推理的有效性。

Conclusion: 该方法有效提升复杂场景中的多模态事实验证能力，为可解释且可扩展的真实性判断提供了新方案。

Abstract: The growing rate of multimodal misinformation, where claims are supported by
both text and images, poses significant challenges to fact-checking systems
that rely primarily on textual evidence. In this work, we have proposed a
unified framework for fine-grained multimodal fact verification called
"MultiCheck", designed to reason over structured textual and visual signals.
Our architecture combines dedicated encoders for text and images with a fusion
module that captures cross-modal relationships using element-wise interactions.
A classification head then predicts the veracity of a claim, supported by a
contrastive learning objective that encourages semantic alignment between
claim-evidence pairs in a shared latent space. We evaluate our approach on the
Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially
outperforming the baseline. These results highlight the effectiveness of
explicit multimodal reasoning and demonstrate the potential of our approach for
scalable and interpretable fact-checking in complex, real-world scenarios.

</details>


### [13] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Jing Liu,Wayne Xin Zhao,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: 提出BEE-RAG框架，通过平衡信息熵提升长文本检索生成的表现稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决RAG因长检索上下文导致的性能下降问题。

Method: 采用熵不变原则，通过调整注意力动态实现上下文敏感性与长度的解耦，结合零样本推断策略与参数高效微调。

Result: 实验证明BEE-RAG在多个RAG任务中表现优越，验证了其在长上下文环境中的适应性。

Conclusion: BEE-RAG通过信息熵平衡显著提升了长文本检索生成的稳定性和效果，具有潜在推广价值。

Abstract: With the rapid advancement of large language models (LLMs),
retrieval-augmented generation (RAG) has emerged as a critical approach to
supplement the inherent knowledge limitations of LLMs. However, due to the
typically large volume of retrieved information, RAG tends to operate with long
context lengths. From the perspective of entropy engineering, we identify
unconstrained entropy growth and attention dilution due to long retrieval
context as significant factors affecting RAG performance. In this paper, we
propose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves
the adaptability of RAG systems to varying context lengths through the
principle of entropy invariance. By leveraging balanced context entropy to
reformulate attention dynamics, BEE-RAG separates attention sensitivity from
context length, ensuring a stable entropy level. Building upon this, we
introduce a zero-shot inference strategy for multi-importance estimation and a
parameter-efficient adaptive fine-tuning mechanism to obtain the optimal
balancing factor for different settings. Extensive experiments across multiple
RAG tasks demonstrate the effectiveness of BEE-RAG.

</details>


### [14] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
*Zihao Yi,Delong Zeng,Zhenqing Ling,Haohao Luo,Zhe Xu,Wei Liu,Jian Luan,Wanxia Cao,Ying Shen*

Main category: cs.CL

TL;DR: 提出AttnRank框架，通过重排输入内容以优化模型关注区域，从而提升不同规模LLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 研究大规模语言模型对输入信息位置敏感的现象，揭示注意力偏向中存在的偏差及其对模型性能的影响。

Method: 设计两阶段方法：先通过校准集估算模型的注意力偏好，再根据偏好重排输入内容，使关键信息位于高注意力位置。

Result: 在多项任务中，AttnRank显著提升了10个不同架构和规模LLMs的性能，无需模型参数调整或训练。

Conclusion: 重排输入内容以对齐模型注意力偏好是一种高效、泛用、不干扰模型的性能提升策略。

Abstract: The performance of Large Language Models (LLMs) is significantly sensitive to
the contextual position of information in the input. To investigate the
mechanism behind this positional bias, our extensive experiments reveal a
consistent phenomenon we term the attention basin: when presented with a
sequence of structured items (e.g., retrieved documents or few-shot examples),
models systematically assign higher attention to the items at the beginning and
end of the sequence, while neglecting those in the middle. Crucially, our
analysis further reveals that allocating higher attention to critical
information is key to enhancing model performance. Based on these insights, we
introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)
estimates a model's intrinsic positional attention preferences using a small
calibration set, and (ii) reorders retrieved documents or few-shot examples to
align the most salient content with these high-attention positions. AttnRank is
a model-agnostic, training-free, and plug-and-play method with minimal
computational overhead. Experiments on multi-hop QA and few-shot in-context
learning tasks demonstrate that AttnRank achieves substantial improvements
across 10 large language models of varying architectures and scales, without
modifying model parameters or training procedures.

</details>


### [15] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
*Chang Hong,Minghao Wu,Qingying Xiao,Yuchi Wang,Xiang Wan,Guangjun Yu,Benyou Wang,Yan Hu*

Main category: cs.CL

TL;DR: 提出PrinciplismQA，用于系统评估大型语言模型在医疗伦理方面的表现，发现模型在实际伦理应用中存在差距。


<details>
  <summary>Details</summary>
Motivation: 确保医疗AI在伦理方面的合规性和可靠性。

Method: 构建由专家验证的多样化伦理问答数据集，评估模型对核心医疗伦理原则的理解与应用。

Result: 模型在伦理知识上存在差距，特别是在处理伦理困境时表现不足，尤其在行善原则方面。高端闭源模型表现较好，医学微调有一定改善。

Conclusion: 提升模型伦理能力需更好地结合医学伦理知识，提供多维度的诊断框架以实现更负责任的医疗AI发展。

Abstract: The integration of large language models into healthcare necessitates a
rigorous evaluation of their ethical reasoning, an area current benchmarks
often overlook. We introduce PrinciplismQA, a comprehensive benchmark with
3,648 questions designed to systematically assess LLMs' alignment with core
medical ethics. Grounded in Principlism, our benchmark features a high-quality
dataset. This includes multiple-choice questions curated from authoritative
textbooks and open-ended questions sourced from authoritative medical ethics
case study literature, all validated by medical experts. Our experiments reveal
a significant gap between models' ethical knowledge and their practical
application, especially in dynamically applying ethical principles to
real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,
often over-emphasizing other principles. Frontier closed-source models, driven
by strong general capabilities, currently lead the benchmark. Notably, medical
domain fine-tuning can enhance models' overall ethical competence, but further
progress requires better alignment with medical ethical knowledge.
PrinciplismQA offers a scalable framework to diagnose these specific ethical
weaknesses, paving the way for more balanced and responsible medical AI.

</details>


### [16] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
*Catherine Kobus,François Lancelot,Marion-Cécile Martin,Nawal Ould Amer*

Main category: cs.CL

TL;DR: 论文介绍ATLANTIS团队在SemEval-2025任务3中的贡献，重点是检测问答系统中的幻觉文本，采用多种方法，包括少样本提示、分词级分类和微调模型，显著提升多语言表现。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型中幻觉内容的问题，提高问答系统的准确性和可信度。

Method: 采用少样本提示、分词级分类和微调模型，结合外部或无外部上下文，检测幻觉文本。

Result: 在西班牙语任务中排名领先，在英语和德语中表现也具有竞争力，强调上下文的重要性和模型微调的潜力。

Conclusion: 整合相关上下文、模型微调和提示工程对于缓解幻觉具有重要意义，未来有望进一步提升多语言问答系统的性能。

Abstract: This paper presents the contributions of the ATLANTIS team to SemEval-2025
Task 3, focusing on detecting hallucinated text spans in question answering
systems. Large Language Models (LLMs) have significantly advanced Natural
Language Generation (NLG) but remain susceptible to hallucinations, generating
incorrect or misleading content. To address this, we explored methods both with
and without external context, utilizing few-shot prompting with a LLM,
token-level classification or LLM fine-tuned on synthetic data. Notably, our
approaches achieved top rankings in Spanish and competitive placements in
English and German. This work highlights the importance of integrating relevant
context to mitigate hallucinations and demonstrate the potential of fine-tuned
models and prompt engineering.

</details>


### [17] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
*Haonan Shangguan,Xiaocui Yang,Shi Feng,Daling Wang,Yifei Zhang,Ge Yu*

Main category: cs.CL

TL;DR: 提出一种适用于资源有限环境的多模态情感推理与分类的轻量级模型MulCoT-RD，通过知识蒸馏实现高效性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态情感分析主要依赖庞大的语言模型，忽视在资源受限环境中的自主推理和生成能力。

Method: 采用“师-助-生”蒸馏策略，从性能强大的多模态大模型中获取推理数据，再训练中等和轻量模型以实现高效推理和分类。

Result: 在四个数据集上，3B参数的MulCoT-RD表现优异，具备良好的泛化能力和可解释性。

Conclusion: 轻量级模型结合知识蒸馏技术，有效实现多模态情感推理与分类，适用于资源受限场景。

Abstract: The surge in rich multimodal content on social media platforms has greatly
advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)
further accelerating progress in this field. Current approaches primarily
leverage the knowledge and reasoning capabilities of parameter-heavy
(Multimodal) LLMs for sentiment classification, overlooking autonomous
multimodal sentiment reasoning generation in resource-constrained environments.
Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment
Reasoning and Classification task, JMSRC, which simultaneously performs
multimodal sentiment reasoning chain generation and sentiment classification
only with a lightweight model. We propose a Multimodal Chain-of-Thought
Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a
"Teacher-Assistant-Student" distillation paradigm to address deployment
constraints in resource-limited environments. We first leverage a
high-performance Multimodal Large Language Model (MLLM) to generate the initial
reasoning dataset and train a medium-sized assistant model with a multi-task
learning mechanism. A lightweight student model is jointly trained to perform
efficient multimodal sentiment reasoning generation and classification.
Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B
parameters achieves strong performance on JMSRC, while exhibiting robust
generalization and enhanced interpretability.

</details>


### [18] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
*Yiheng Liu,Junhao Ning,Sichen Xia,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: 提出一种基于功能网络的结构化裁剪方法，以提高大语言模型的裁剪效果和性能。


<details>
  <summary>Details</summary>
Motivation: 现有裁剪方法忽视神经元间的协作与互动，导致宏观结构受损，影响模型性能。

Method: 将大语言模型比作数字大脑，分解为功能网络，保留关键神经元进行裁剪。

Result: 成功识别并定位了模型中的功能网络和关键神经元，有效提升裁剪效果。

Conclusion: 通过保留功能网络中的关键神经元实现高效裁剪，提升模型性能和应用价值。

Abstract: Structured pruning is one of the representative techniques for compressing
large language models (LLMs) to reduce GPU memory consumption and accelerate
inference speed. It offers significant practical value in improving the
efficiency of LLMs in real-world applications. Current structured pruning
methods typically rely on assessment of the importance of the structure units
and pruning the units with less importance. Most of them overlooks the
interaction and collaboration among artificial neurons that are crucial for the
functionalities of LLMs, leading to a disruption in the macro functional
architecture of LLMs and consequently a pruning performance degradation.
Inspired by the inherent similarities between artificial neural networks and
functional neural networks in the human brain, we alleviate this challenge and
propose to prune LLMs by identifying and preserving functional networks within
LLMs in this study. To achieve this, we treat an LLM as a digital brain and
decompose the LLM into functional networks, analogous to identifying functional
brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving
the key neurons within these functional networks. Experimental results
demonstrate that the proposed method can successfully identify and locate
functional networks and key neurons in LLMs, enabling efficient model pruning.
Our code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [19] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
*Sijie Wang,Quanjiang Guo,Kai Zhao,Yawei Zhang,Xin Li,Xiang Li,Siqi Li,Rui She,Shangshu Yu,Wee Peng Tay*

Main category: cs.CL

TL;DR: CodeBoost通过纯代码片段提升代码大模型，无需人工标注指导，有效提升性能。


<details>
  <summary>Details</summary>
Motivation: 高质量编码指令难以大规模收集，代码片段丰富但缺乏结构化指导。

Method: 引入多种训练策略，包括最大团筛选、多向预测、误差感知、异构增强和奖励机制，从代码中自主学习。

Result: 实验证明该方法在多个模型和基准测试中均显著提升性能，展现出良好的扩展性和效果。

Conclusion: CodeBoost提供了一个无需人工指令的高效训练框架，有助于推动代码大模型的规模化和性能提升。

Abstract: Code large language models (LLMs) have become indispensable tools for
building efficient and automated coding pipelines. Existing models are
typically post-trained using reinforcement learning (RL) from general-purpose
LLMs using "human instruction-final answer" pairs, where the instructions are
usually from manual annotations. However, collecting high-quality coding
instructions is both labor-intensive and difficult to scale. On the other hand,
code snippets are abundantly available from various sources. This imbalance
presents a major bottleneck in instruction-based post-training. We propose
CodeBoost, a post-training framework that enhances code LLMs purely from code
snippets, without relying on human-annotated instructions. CodeBoost introduces
the following key components: (1) maximum-clique curation, which selects a
representative and diverse training corpus from code; (2) bi-directional
prediction, which enables the model to learn from both forward and backward
prediction objectives; (3) error-aware prediction, which incorporates learning
signals from both correct and incorrect outputs; (4) heterogeneous
augmentation, which diversifies the training distribution to enrich code
semantics; and (5) heterogeneous rewarding, which guides model learning through
multiple reward types including format correctness and execution feedback from
both successes and failures. Extensive experiments across several code LLMs and
benchmarks verify that CodeBoost consistently improves performance,
demonstrating its effectiveness as a scalable and effective training pipeline.

</details>


### [20] [ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs](https://arxiv.org/abs/2508.05282)
*Dongxu Zhang,Ning Yang,Jihua Zhu,Jinnan Yang,Miao Xin,Baoliang Tian*

Main category: cs.CL

TL;DR: 本文发现在链式推理中后期错误更具破坏性，提出自适应自我纠正方法（ASCoT）以提升推理的可靠性。


<details>
  <summary>Details</summary>
Motivation: 改善大型语言模型链式推理中的错误影响，尤其是后期错误造成的严重后果。

Method: 引入分阶段验证管理和多角度自我纠正机制，利用位置影响评分优先修正高风险步骤。

Result: 在多个基准测试中，ASCoT显著优于传统方法，提升推理准确性。

Conclusion: 应针对不同错误模式采用有针对性的纠正策略，提升LLMs的推理可靠性。

Abstract: Chain-of-Thought (CoT) prompting has significantly advanced the reasoning
capabilities of Large Language Models (LLMs), yet the reliability of these
reasoning chains remains a critical challenge. A widely held "cascading
failure" hypothesis suggests that errors are most detrimental when they occur
early in the reasoning process. This paper challenges that assumption through
systematic error-injection experiments, revealing a counter-intuitive
phenomenon we term "Late-Stage Fragility": errors introduced in the later
stages of a CoT chain are significantly more likely to corrupt the final answer
than identical errors made at the beginning. To address this specific
vulnerability, we introduce the Adaptive Self-Correction Chain-of-Thought
(ASCoT) method. ASCoT employs a modular pipeline in which an Adaptive
Verification Manager (AVM) operates first, followed by the Multi-Perspective
Self-Correction Engine (MSCE). The AVM leverages a Positional Impact Score
function I(k) that assigns different weights based on the position within the
reasoning chains, addressing the Late-Stage Fragility issue by identifying and
prioritizing high-risk, late-stage steps. Once these critical steps are
identified, the MSCE applies robust, dual-path correction specifically to the
failure parts. Extensive experiments on benchmarks such as GSM8K and MATH
demonstrate that ASCoT achieves outstanding accuracy, outperforming strong
baselines, including standard CoT. Our work underscores the importance of
diagnosing specific failure modes in LLM reasoning and advocates for a shift
from uniform verification strategies to adaptive, vulnerability-aware
correction mechanisms.

</details>


### [21] [Decision-Making with Deliberation: Meta-reviewing as a Document-grounded Dialogue](https://arxiv.org/abs/2508.05283)
*Sukannya Purkayastha,Nils Dycke,Anne Lauscher,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出一种通过大语言模型合成数据训练对话助手以辅助论文评审，验证其在实际中的高效性。


<details>
  <summary>Details</summary>
Motivation: 解决论文评审中元评审阶段对辅助工具的需求，特别是在数据稀缺情况下。

Method: 借助LLMs自我优化生成相关对话数据，训练专门的对话代理，并在实际场景中验证效果。

Result: 所提方法生成高质量合成数据，训练的对话代理优于现成模型，能显著提高元评审的效率。

Conclusion: 利用合成数据训练的对话代理能有效辅助元评审，助力提升审稿流程效率与质量。

Abstract: Meta-reviewing is a pivotal stage in the peer-review process, serving as the
final step in determining whether a paper is recommended for acceptance. Prior
research on meta-reviewing has treated this as a summarization problem over
review reports. However, complementary to this perspective, meta-reviewing is a
decision-making process that requires weighing reviewer arguments and placing
them within a broader context. Prior research has demonstrated that
decision-makers can be effectively assisted in such scenarios via dialogue
agents. In line with this framing, we explore the practical challenges for
realizing dialog agents that can effectively assist meta-reviewers. Concretely,
we first address the issue of data scarcity for training dialogue agents by
generating synthetic data using Large Language Models (LLMs) based on a
self-refinement strategy to improve the relevance of these dialogues to expert
domains. Our experiments demonstrate that this method produces higher-quality
synthetic data and can serve as a valuable resource towards training
meta-reviewing assistants. Subsequently, we utilize this data to train dialogue
agents tailored for meta-reviewing and find that these agents outperform
\emph{off-the-shelf} LLM-based assistants for this task. Finally, we apply our
agents in real-world meta-reviewing scenarios and confirm their effectiveness
in enhancing the efficiency of meta-reviewing.\footnote{Code and Data:
https://github.com/UKPLab/arxiv2025-meta-review-as-dialog

</details>


### [22] [SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens](https://arxiv.org/abs/2508.05305)
*Nikita Dragunov,Temurbek Rahmatullaev,Elizaveta Goncharova,Andrey Kuznetsov,Anton Razzhigaev*

Main category: cs.CL

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: The recently proposed Large Concept Model (LCM) generates text by predicting
a sequence of sentence-level embeddings and training with either mean-squared
error or diffusion objectives. We present SONAR-LLM, a decoder-only transformer
that "thinks" in the same continuous SONAR embedding space, yet is supervised
through token-level cross-entropy propagated via the frozen SONAR decoder. This
hybrid objective retains the semantic abstraction of LCM while eliminating its
diffusion sampler and restoring a likelihood-based training signal. Across
model sizes from 39M to 1.3B parameters, SONAR-LLM attains competitive
generation quality. We report scaling trends, ablations, benchmark results, and
release the complete training code and all pretrained checkpoints to foster
reproducibility and future research.

</details>


### [23] [Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression](https://arxiv.org/abs/2508.05337)
*Jiameng Huang,Baijiong Lin,Guhao Feng,Jierun Chen,Di He,Lu Hou*

Main category: cs.CL

TL;DR: CGRS通过动态抑制高置信度时的反思触发，有效减少LRLMs的冗余推理步骤，节省Token，保持准确性，适用于多模型架构。


<details>
  <summary>Details</summary>
Motivation: 解决Large Reasoning Language Models（LRLMs）中反思行为过多导致的冗余和效率问题。

Method: 提出Certainty-Guided Reflection Suppression（CGRS），在模型自信时抑制反思触发，不需重训练或改架构，易集成。

Result: CGRS在四个推理基准上显著降低Token使用（18.5%-41.9%）同时保持推理准确，且适用于不同模型和参数规模。

Conclusion: CGRS是一种实用的模型无关方法，有效平衡推理长度和性能，提升推理效率。

Abstract: Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought
reasoning with complex reflection behaviors, typically signaled by specific
trigger words (e.g., "Wait" and "Alternatively") to enhance performance.
However, these reflection behaviors can lead to the overthinking problem where
the generation of redundant reasoning steps that unnecessarily increase token
usage, raise inference costs, and reduce practical utility. In this paper, we
propose Certainty-Guided Reflection Suppression (CGRS), a novel method that
mitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS
operates by dynamically suppressing the model's generation of reflection
triggers when it exhibits high confidence in its current response, thereby
preventing redundant reflection cycles without compromising output quality. Our
approach is model-agnostic, requires no retraining or architectural
modifications, and can be integrated seamlessly with existing autoregressive
generation pipelines. Extensive experiments across four reasoning benchmarks
(i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it
reduces token usage by an average of 18.5% to 41.9% while preserving accuracy.
It also achieves the optimal balance between length reduction and performance
compared to state-of-the-art baselines. These results hold consistently across
model architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3
family) and scales (4B to 32B parameters), highlighting CGRS's practical value
for efficient reasoning.

</details>


### [24] [Evaluation of a Sign Language Avatar on Comprehensibility, User Experience \& Acceptability](https://arxiv.org/abs/2508.05358)
*Fenya Wasserroth,Eleftherios Avramidis,Vera Czehmann,Tanja Kojic,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 调整功能未明显改善手语头像的理解度和用户体验，但提升了情感吸引力。改进面部表情、互动界面及采用参与式设计是关键。


<details>
  <summary>Details</summary>
Motivation: 探讨在混合现实平台上，调整功能对手语头像的影响，以提升可理解性和用户体验。

Method: 进行了专家用户与不同头像交互的实验分析，评估理解度、用户体验及接受度。

Result: 调整功能虽受用户偏好但未显著改善体验，存在表达不足与操作困难，用户压力上升。

Conclusion: 个性化不足不应作为唯一目标，应增强头像的默认理解性，优化动画与交互设计。

Abstract: This paper presents an investigation into the impact of adding adjustment
features to an existing sign language (SL) avatar on a Microsoft Hololens 2
device. Through a detailed analysis of interactions of expert German Sign
Language (DGS) users with both adjustable and non-adjustable avatars in a
specific use case, this study identifies the key factors influencing the
comprehensibility, the user experience (UX), and the acceptability of such a
system. Despite user preference for adjustable settings, no significant
improvements in UX or comprehensibility were observed, which remained at low
levels, amid missing SL elements (mouthings and facial expressions) and
implementation issues (indistinct hand shapes, lack of feedback and menu
positioning). Hedonic quality was rated higher than pragmatic quality,
indicating that users found the system more emotionally or aesthetically
pleasing than functionally useful. Stress levels were higher for the adjustable
avatar, reflecting lower performance, greater effort and more frustration.
Additionally, concerns were raised about whether the Hololens adjustment
gestures are intuitive and easy to familiarise oneself with. While
acceptability of the concept of adjustability was generally positive, it was
strongly dependent on usability and animation quality. This study highlights
that personalisation alone is insufficient, and that SL avatars must be
comprehensible by default. Key recommendations include enhancing mouthing and
facial animation, improving interaction interfaces, and applying participatory
design.

</details>


### [25] [Can Language Models Critique Themselves? Investigating Self-Feedback for Retrieval Augmented Generation at BioASQ 2025](https://arxiv.org/abs/2508.05366)
*Samy Ateia,Udo Kruschwitz*

Main category: cs.CL

TL;DR: 本文研究了自主检索增强生成系统在生物医学专业搜索中的应用，特别关注模型的自我反馈机制对提高搜索性能的影响，探索了不同模型和策略的效果。


<details>
  <summary>Details</summary>
Motivation: 解决专业领域搜索中自动系统与专家需求不匹配的问题，增强LLMs在专业搜索中的效果。

Method: 采用自我反馈机制让模型生成、评估和改进输出，比较不同模型和任务中的表现。

Result: 不同模型在自我反馈策略下表现差异显著，初步结果展示了模型自我校正的潜力与局限。

Conclusion: 自我反馈机制有助于提升LLMs的专业搜索能力，但效果受模型和任务影响，未来需进一步探索人机结合优化方案。

Abstract: Agentic Retrieval Augmented Generation (RAG) and 'deep research' systems aim
to enable autonomous search processes where Large Language Models (LLMs)
iteratively refine outputs. However, applying these systems to domain-specific
professional search, such as biomedical research, presents challenges, as
automated systems may reduce user involvement and misalign with expert
information needs. Professional search tasks often demand high levels of user
expertise and transparency. The BioASQ CLEF 2025 challenge, using
expert-formulated questions, can serve as a platform to study these issues. We
explored the performance of current reasoning and nonreasoning LLMs like
Gemini-Flash 2.0, o3-mini, o4-mini and DeepSeek-R1. A key aspect of our
methodology was a self-feedback mechanism where LLMs generated, evaluated, and
then refined their outputs for query expansion and for multiple answer types
(yes/no, factoid, list, ideal). We investigated whether this iterative
self-correction improves performance and if reasoning models are more capable
of generating useful feedback. Preliminary results indicate varied performance
for the self-feedback strategy across models and tasks. This work offers
insights into LLM self-correction and informs future work on comparing the
effectiveness of LLM-generated feedback with direct human expert input in these
search systems.

</details>


### [26] [The TUB Sign Language Corpus Collection](https://arxiv.org/abs/2508.05374)
*Eleftherios Avramidis,Vera Czehmann,Fabian Deckert,Lorenz Hufe,Aljoscha Lipski,Yuni Amaloa Quintero Villalobos,Tae Kwon Rhee,Mengqian Shi,Lennart Stölting,Fabrizio Nunnari,Sebastian Möller*

Main category: cs.CL

TL;DR: 本文介绍了一份包含12种手语平行语料库的庞大视频资料集，涵盖超过1300小时的视频和相关字幕，特别是对拉丁美洲手语的首次统一平行语料库，以及德国手语语料库的大幅扩展。


<details>
  <summary>Details</summary>
Motivation: 旨在为手语自动识别与翻译领域提供丰富、系统的多语言平行语料库，填补现有资料不足。

Method: 通过收集在线视频资料，涉及新闻、政府和教育内容，辅以内容创作者沟通、数据预处理、爬取与裁剪等步骤，构建多语种平行语料。

Result: 成功构建了包括8个拉丁美洲手语在内的多语种平行语料库，德国手语语料库规模显著提升，为研究提供了宝贵资源。

Conclusion: 本研究提供了一个大规模、多语种的手语平行语料库，为手语理解与自动翻译技术的发展奠定基础，并展示了数据收集与处理的具体方法。

Abstract: We present a collection of parallel corpora of 12 sign languages in video
format, together with subtitles in the dominant spoken languages of the
corresponding countries. The entire collection includes more than 1,300 hours
in 4,381 video files, accompanied by 1,3~M subtitles containing 14~M tokens.
Most notably, it includes the first consistent parallel corpora for 8 Latin
American sign languages, whereas the size of the German Sign Language corpora
is ten times the size of the previously available corpora. The collection was
created by collecting and processing videos of multiple sign languages from
various online sources, mainly broadcast material of news shows, governmental
bodies and educational channels. The preparation involved several stages,
including data collection, informing the content creators and seeking usage
approvals, scraping, and cropping. The paper provides statistics on the
collection and an overview of the methods used to collect the data.

</details>


### [27] [MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints](https://arxiv.org/abs/2508.05429)
*Zhong Ken Hew,Jia Xin Low,Sze Jue Yang,Chee Seng chan*

Main category: cs.CL

TL;DR: 提出MyCulture基准，以评估大规模语言模型对马来文化的理解，特别强调无选项开放式问答以减少偏见，并分析模型在结构和语言偏见方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型存在文化偏见，特别是在低资源语言和文化的表现上不足，需开发针对特定文化的评估工具。

Method: 设计了MyCulture基准，采用开放式多项选择问答格式，进行结构和语言偏见分析，测试不同模型的文化理解能力。

Result: 多模型在马来文化理解上存在显著差异，凸显文化和语言偏见，验证了新评估方法的有效性。

Conclusion: 强调构建文化本地化和语言多样性兼容的评估工具的重要性，以促进多元文化的公平代表。

Abstract: Large Language Models (LLMs) often exhibit cultural biases due to training
data dominated by high-resource languages like English and Chinese. This poses
challenges for accurately representing and evaluating diverse cultural
contexts, particularly in low-resource language settings. To address this, we
introduce MyCulture, a benchmark designed to comprehensively evaluate LLMs on
Malaysian culture across six pillars: arts, attire, customs, entertainment,
food, and religion presented in Bahasa Melayu. Unlike conventional benchmarks,
MyCulture employs a novel open-ended multiple-choice question format without
predefined options, thereby reducing guessing and mitigating format bias. We
provide a theoretical justification for the effectiveness of this open-ended
structure in improving both fairness and discriminative power. Furthermore, we
analyze structural bias by comparing model performance on structured versus
free-form outputs, and assess language bias through multilingual prompt
variations. Our evaluation across a range of regional and international LLMs
reveals significant disparities in cultural comprehension, highlighting the
urgent need for culturally grounded and linguistically inclusive benchmarks in
the development and assessment of LLMs.

</details>


### [28] [LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models](https://arxiv.org/abs/2508.05452)
*Ming Zhang,Yujiong Shen,Jingyi Deng,Yuhui Wang,Yue Zhang,Junzhe Wang,Shichun Liu,Shihan Dou,Huayu Sha,Qiyuan Peng,Changhao Jiang,Jingqi Tong,Yilong Wu,Zhihao Zhang,Mingqi Wu,Zhiheng Xi,Mingxu Chai,Tao Liang,Zhihui Fei,Zhen Wang,Mingyang Wan,Guojun Ma,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Existing evaluation of Large Language Models (LLMs) on static benchmarks is
vulnerable to data contamination and leaderboard overfitting, critical issues
that obscure true model capabilities. To address this, we introduce LLMEval-3,
a framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary
bank of 220k graduate-level questions, from which it dynamically samples unseen
test sets for each evaluation run. Its automated pipeline ensures integrity via
contamination-resistant data curation, a novel anti-cheating architecture, and
a calibrated LLM-as-a-judge process achieving 90% agreement with human experts,
complemented by a relative ranking system for fair comparison. An 20-month
longitudinal study of nearly 50 leading models reveals a performance ceiling on
knowledge memorization and exposes data contamination vulnerabilities
undetectable by static benchmarks. The framework demonstrates exceptional
robustness in ranking stability and consistency, providing strong empirical
validation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and
credible methodology for assessing the true capabilities of LLMs beyond
leaderboard scores, promoting the development of more trustworthy evaluation
standards.

</details>


### [29] [TASE: Token Awareness and Structured Evaluation for Multilingual Language Models](https://arxiv.org/abs/2508.05468)
*Chenzhuo Zhao,Xinda Wang,Yue Huang,Junting Lu,Ziqian Liu*

Main category: cs.CL

TL;DR: TASE是一个评估多语言下大模型细粒度和结构理解能力的基准，包括多项任务和跨语言测试，揭示了当前模型的不足。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在高层语义任务表现出色，但在细粒度和结构推理方面存在不足，亟需系统评估和改进。

Method: 设计涵盖10项任务的TASE基准，评估多种模型，并训练定制模型以进行对比测试。

Result: 人类在任务中明显优于模型，展现模型在token级推理上的弱点，为未来改进提供诊断工具。

Conclusion: TASE有助于理解和提升模型的低层次语言理解能力，推动跨语言泛化发展。

Abstract: While large language models (LLMs) have demonstrated remarkable performance
on high-level semantic tasks, they often struggle with fine-grained,
token-level understanding and structural reasoning--capabilities that are
essential for applications requiring precision and control. We introduce TASE,
a comprehensive benchmark designed to evaluate LLMs' ability to perceive and
reason about token-level information across languages. TASE covers 10 tasks
under two core categories: token awareness and structural understanding,
spanning Chinese, English, and Korean, with a 35,927-instance evaluation set
and a scalable synthetic data generation pipeline for training. Tasks include
character counting, token alignment, syntactic structure parsing, and length
constraint satisfaction. We evaluate over 30 leading commercial and open-source
LLMs, including O3, Claude 4, Gemini 2.5 Pro, and DeepSeek-R1, and train a
custom Qwen2.5-14B model using the GRPO training method. Results show that
human performance significantly outpaces current LLMs, revealing persistent
weaknesses in token-level reasoning. TASE sheds light on these limitations and
provides a new diagnostic lens for future improvements in low-level language
understanding and cross-lingual generalization. Our code and dataset are
publicly available at https://github.com/cyzcz/Tase .

</details>


### [30] [Rethinking Creativity Evaluation: A Critical Analysis of Existing Creativity Evaluations](https://arxiv.org/abs/2508.05470)
*Li-Chun Lu,Miri Liu,Pin-Chun Lu,Yufei Tian,Shao-Hua Sun,Nanyun Peng*

Main category: cs.CL

TL;DR: 不同的创造力衡量指标各有局限，表现出有限的一致性，呼吁开发更稳健的评价体系。


<details>
  <summary>Details</summary>
Motivation: 现有创造力衡量方法存在局限性，亟需更可靠的评估框架以更好反映人类创造力认知。

Method: 系统性分析和比较多种代表性创造力指标在不同创造性领域中的表现。

Result: 指标各自捕捉创造力的不同维度，存在适用范围和偏差问题，显示出现有方法的不足。

Conclusion: 需要构建更为稳健和普适的创造力评价体系，以更贴合人类判断。

Abstract: We systematically examine, analyze, and compare representative creativity
measures--creativity index, perplexity, syntactic templates, and
LLM-as-a-Judge--across diverse creative domains, including creative writing,
unconventional problem-solving, and research ideation. Our analyses reveal that
these metrics exhibit limited consistency, capturing different dimensions of
creativity. We highlight key limitations, including the creativity index's
focus on lexical diversity, perplexity's sensitivity to model confidence, and
syntactic templates' inability to capture conceptual creativity. Additionally,
LLM-as-a-Judge shows instability and bias. Our findings underscore the need for
more robust, generalizable evaluation frameworks that better align with human
judgments of creativity.

</details>


### [31] [LAG: Logic-Augmented Generation from a Cartesian Perspective](https://arxiv.org/abs/2508.05509)
*Yilin Xiao,Chuang Zhou,Qinggang Zhang,Su Dong,Shengyuan Chen,Xiao Huang*

Main category: cs.CL

TL;DR: 引入逻辑增强生成（LAG）提升大模型在复杂推理中的表现，减少虚假信息。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在知识密集任务中的虚假生成问题，特别是在复杂推理场景中表现不佳。

Method: 通过问题分解、依赖感知推理、逻辑终止机制和子问题整合，系统性增强模型推理能力。

Result: 在四个基准数据集上，显著提升推理鲁棒性，减少虚假信息，更接近人类推理方式。

Conclusion: LAG为大模型提供了一种系统、逻辑驱动的知识增强新范式，有效改善复杂推理中的表现。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks, yet exhibit critical limitations in knowledge-intensive
tasks, often generating hallucinations when faced with questions requiring
specialized expertise. While retrieval-augmented generation (RAG) mitigates
this by integrating external knowledge, it struggles with complex reasoning
scenarios due to its reliance on direct semantic retrieval and lack of
structured logical organization. Inspired by Cartesian principles from
\textit{Discours de la m\'ethode}, this paper introduces Logic-Augmented
Generation (LAG), a novel paradigm that reframes knowledge augmentation through
systematic question decomposition and dependency-aware reasoning. Specifically,
LAG first decomposes complex questions into atomic sub-questions ordered by
logical dependencies. It then resolves these sequentially, using prior answers
to guide context retrieval for subsequent sub-questions, ensuring stepwise
grounding in logical chain. To prevent error propagation, LAG incorporates a
logical termination mechanism that halts inference upon encountering
unanswerable sub-questions and reduces wasted computation on excessive
reasoning. Finally, it synthesizes all sub-resolutions to generate verified
responses. Experiments on four benchmark datasets demonstrate that LAG
significantly enhances reasoning robustness, reduces hallucination, and aligns
LLM problem-solving with human cognition, offering a principled alternative to
existing RAG systems.

</details>


### [32] [The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities](https://arxiv.org/abs/2508.05525)
*Harsh Nishant Lalai,Raj Sanjay Shah,Jiaxin Pei,Sashank Varma,Yi-Chia Wang,Ali Emami*

Main category: cs.CL

TL;DR: 本文通过“20 Questions”游戏测试，揭示大型语言模型在地理和文化偏见方面存在的差异。


<details>
  <summary>Details</summary>
Motivation: 旨在发现大规模语言模型中潜在的隐性偏见，特别是在未被直接问及时的表现差异。

Method: 采用新的Geo20Q+数据集，通过多轮推理游戏在不同地区、语言中评估模型性能。

Result: 发现模型在全球北方/西方表现优于南方/东方，且不同语言影响有限。性能差异部分与数据频率有关，但无法完全解释偏见。

Conclusion: 创造性评估框架有助于揭示隐藏偏见，强调模型推理过程中的文化与地理偏差。

Abstract: Large Language Models (LLMs) have been extensively tuned to mitigate explicit
biases, yet they often exhibit subtle implicit biases rooted in their
pre-training data. Rather than directly probing LLMs with human-crafted
questions that may trigger guardrails, we propose studying how models behave
when they proactively ask questions themselves. The 20 Questions game, a
multi-turn deduction task, serves as an ideal testbed for this purpose. We
systematically evaluate geographic performance disparities in entity deduction
using a new dataset, Geo20Q+, consisting of both notable people and culturally
significant objects (e.g., foods, landmarks, animals) from diverse regions. We
test popular LLMs across two gameplay configurations (canonical 20-question and
unlimited turns) and in seven languages (English, Hindi, Mandarin, Japanese,
French, Spanish, and Turkish). Our results reveal geographic disparities: LLMs
are substantially more successful at deducing entities from the Global North
than the Global South, and the Global West than the Global East. While
Wikipedia pageviews and pre-training corpus frequency correlate mildly with
performance, they fail to fully explain these disparities. Notably, the
language in which the game is played has minimal impact on performance gaps.
These findings demonstrate the value of creative, free-form evaluation
frameworks for uncovering subtle biases in LLMs that remain hidden in standard
prompting setups. By analyzing how models initiate and pursue reasoning goals
over multiple turns, we find geographic and cultural disparities embedded in
their reasoning processes. We release the dataset (Geo20Q+) and code at
https://sites.google.com/view/llmbias20q/home.

</details>


### [33] [CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation](https://arxiv.org/abs/2508.05534)
*Santosh T. Y. S. S,Youssef Tarek Elkhayat,Oana Ichim,Pranav Shetty,Dongsheng Wang,Zhiqiang Ma,Armineh Nourbakhsh,Xiaomo Liu*

Main category: cs.CL

TL;DR: 提出了一种基于信心引导的复制解码策略CoCoLex，提升法律文本生成的可靠性和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在法律文本生成中可能出现的非真实、缺乏依据或幻觉问题。

Method: 结合模型置信度与复制机制，通过动态插值调整生成内容，增强对上下文的忠实性。

Result: 在五个法律基准测试中，CoCoLex显著优于现有的上下文感知解码策略，特别适用于长文生成任务。

Conclusion: 提出的CoCoLex通过动态置信度引导复制，有效提升法律文本生成的可信度和质量。

Abstract: Due to their ability to process long and complex contexts, LLMs can offer key
benefits to the Legal domain, but their adoption has been hindered by their
tendency to generate unfaithful, ungrounded, or hallucinatory outputs. While
Retrieval-Augmented Generation offers a promising solution by grounding
generations in external knowledge, it offers no guarantee that the provided
context will be effectively integrated. To address this, context-aware decoding
strategies have been proposed to amplify the influence of relevant context, but
they usually do not explicitly enforce faithfulness to the context. In this
work, we introduce Confidence-guided Copy-based Decoding for Legal Text
Generation (CoCoLex)-a decoding strategy that dynamically interpolates the
model produced vocabulary distribution with a distribution derived based on
copying from the context. CoCoLex encourages direct copying based on the
model's confidence, ensuring greater fidelity to the source. Experimental
results on five legal benchmarks demonstrate that CoCoLex outperforms existing
context-aware decoding methods, particularly in long-form generation tasks.

</details>


### [34] [Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees](https://arxiv.org/abs/2508.05544)
*Guang Yang,Xinyang Liu*

Main category: cs.CL

TL;DR: 提出了一种基于采样频率的不确定性量化方法，结合保形预测，提升了大模型在多选题中的问答可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在高风险应用中的不可靠性问题，如幻觉和过度自信。

Method: 利用多次独立采样，通过频率计算预测熵，结合保形预测确保覆盖率。

Result: 在多种模型和数据集上，该方法优于传统的对数几率，能有效控制覆盖率。

Conclusion: 提供了一种无分布、模型无关的可靠不确定性量化框架，增强模型可信度。

Abstract: Large Language Models (LLMs) have shown remarkable progress in
multiple-choice question answering (MCQA), but their inherent unreliability,
such as hallucination and overconfidence, limits their application in high-risk
domains. To address this, we propose a frequency-based uncertainty
quantification method under black-box settings, leveraging conformal prediction
(CP) to ensure provable coverage guarantees. Our approach involves multiple
independent samplings of the model's output distribution for each input, with
the most frequent sample serving as a reference to calculate predictive entropy
(PE). Experimental evaluations across six LLMs and four datasets (MedMCQA,
MedQA, MMLU, MMLU-Pro) demonstrate that frequency-based PE outperforms
logit-based PE in distinguishing between correct and incorrect predictions, as
measured by AUROC. Furthermore, the method effectively controls the empirical
miscoverage rate under user-specified risk levels, validating that sampling
frequency can serve as a viable substitute for logit-based probabilities in
black-box scenarios. This work provides a distribution-free model-agnostic
framework for reliable uncertainty quantification in MCQA with guaranteed
coverage, enhancing the trustworthiness of LLMs in practical applications.

</details>


### [35] [Do Political Opinions Transfer Between Western Languages? An Analysis of Unaligned and Aligned Multilingual LLMs](https://arxiv.org/abs/2508.05553)
*Franziska Weeber,Tanise Ceron,Sebastian Padó*

Main category: cs.CL

TL;DR: 跨文化政治观点在多语言大模型中基本转移，模型中语言间的政治偏好差异较小，偏好调整具有全局影响。


<details>
  <summary>Details</summary>
Motivation: 探究多语言大模型中不同语言间政治观点是否存在差异及其变化机制。

Method: 通过提示模型表达政治观点，比较未对齐与对齐模型的观点差异，涵盖五种西方语言。

Result: 未对齐模型显示很少跨语言差异，偏好对齐后几乎在所有语言中同步变化，显示观点具有跨语言转移性。

Conclusion: 在西方语言背景下，政治观点在多语言模型中实现转移，提示模型的政治偏好调整具有广泛影响，体现了多语言、多文化、多政治背景下模型对齐的复杂性。

Abstract: Public opinion surveys show cross-cultural differences in political opinions
between socio-cultural contexts. However, there is no clear evidence whether
these differences translate to cross-lingual differences in multilingual large
language models (MLLMs). We analyze whether opinions transfer between languages
or whether there are separate opinions for each language in MLLMs of various
sizes across five Western languages. We evaluate MLLMs' opinions by prompting
them to report their (dis)agreement with political statements from voting
advice applications. To better understand the interaction between languages in
the models, we evaluate them both before and after aligning them with more left
or right views using direct preference optimization and English alignment data
only. Our findings reveal that unaligned models show only very few significant
cross-lingual differences in the political opinions they reflect. The political
alignment shifts opinions almost uniformly across all five languages. We
conclude that in Western language contexts, political opinions transfer between
languages, demonstrating the challenges in achieving explicit socio-linguistic,
cultural, and political alignment of MLLMs.

</details>


### [36] [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy](https://arxiv.org/abs/2508.05592)
*Shaoxiong Zhan,Yanlin Lai,Ziyu Lu,Dahua Lin,Ziqing Yang,Fei Tang*

Main category: cs.CL

TL;DR: MathSmith通过从零构建高难度数学题，结合启发式策略和强化学习，显著提升大模型的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 弥补高质量难题数据匮乏，推动大模型数学推理的进步。

Method: 从PlanetMath随机采样概念-解释对，设计九个软约束策略，结合强化学习优化题目结构和推理复杂度。

Result: 在多个基准测试中优于现有方法，特别在长链推理题中表现优异，并能针对性提升特定概念能力。

Conclusion: MathSmith展现出优良的扩展性和适应性，证明高难度合成数据对增强大模型推理的潜力。

Abstract: Large language models have achieved substantial progress in mathematical
reasoning, yet their advancement is limited by the scarcity of high-quality,
high-difficulty training data. Existing synthesis methods largely rely on
transforming human-written templates, limiting both diversity and scalability.
We propose MathSmith, a novel framework for synthesizing challenging
mathematical problems to enhance LLM reasoning. Rather than modifying existing
problems, MathSmith constructs new ones from scratch by randomly sampling
concept-explanation pairs from PlanetMath, ensuring data independence and
avoiding contamination. To increase difficulty, we design nine predefined
strategies as soft constraints during rationales. We further adopts
reinforcement learning to jointly optimize structural validity, reasoning
complexity, and answer consistency. The length of the reasoning trace generated
under autoregressive prompting is used to reflect cognitive complexity,
encouraging the creation of more demanding problems aligned with
long-chain-of-thought reasoning. Experiments across five benchmarks,
categorized as easy & medium (GSM8K, MATH-500) and hard (AIME2024, AIME2025,
OlympiadBench), show that MathSmith consistently outperforms existing baselines
under both short and long CoT settings. Additionally, a weakness-focused
variant generation module enables targeted improvement on specific concepts.
Overall, MathSmith exhibits strong scalability, generalization, and
transferability, highlighting the promise of high-difficulty synthetic data in
advancing LLM reasoning capabilities.

</details>


### [37] [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2508.05613)
*Haitao Hong,Yuchen Yan,Xingyu Wu,Guiyang Hou,Wenqi Zhang,Weiming Lu,Yongliang Shen,Jun Xiao*

Main category: cs.CL

TL;DR: 提出Cooper框架，通过联合优化策略模型和奖励模型，提升RL在大规模语言模型中的效果，解决规则奖励不鲁棒和模型奖励易被操控的问题。


<details>
  <summary>Details</summary>
Motivation: 增强大语言模型推理能力，克服奖励机制的弊端。

Method: 联合优化策略和奖励模型，采用混合标注策略与参考式奖励建模，训练高精度奖励模型VerifyRM，并在训练中动态更新奖励模型。

Result: Cooper减轻奖励操控，提高端到端表现，在Qwen2.5-1.5B-Instruct上提升0.54%的平均准确率。VerifyRM在VerifyBench表现优越。

Conclusion: 动态更新奖励模型有效遏制奖励操控，为RL在大模型中的应用提供参考。

Abstract: Large language models (LLMs) have demonstrated remarkable performance in
reasoning tasks, where reinforcement learning (RL) serves as a key algorithm
for enhancing their reasoning capabilities. Currently, there are two mainstream
reward paradigms: model-based rewards and rule-based rewards. However, both
approaches suffer from limitations: rule-based rewards lack robustness, while
model-based rewards are vulnerable to reward hacking. To address these issues,
we propose Cooper(Co-optimizing Policy Model and Reward Model), a RL framework
that jointly optimizes both the policy model and the reward model. Cooper
leverages the high precision of rule-based rewards when identifying correct
responses, and dynamically constructs and selects positive-negative sample
pairs for continued training the reward model. This design enhances robustness
and mitigates the risk of reward hacking. To further support Cooper, we
introduce a hybrid annotation strategy that efficiently and accurately
generates training data for the reward model. We also propose a reference-based
reward modeling paradigm, where the reward model takes a reference answer as
input. Based on this design, we train a reward model named VerifyRM, which
achieves higher accuracy on VerifyBench compared to other models of the same
size. We conduct reinforcement learning using both VerifyRM and Cooper. Our
experiments show that Cooper not only alleviates reward hacking but also
improves end-to-end RL performance, for instance, achieving a 0.54% gain in
average accuracy on Qwen2.5-1.5B-Instruct. Our findings demonstrate that
dynamically updating reward model is an effective way to combat reward hacking,
providing a reference for better integrating reward models into RL.

</details>


### [38] [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](https://arxiv.org/abs/2508.05614)
*Zixuan Wang,Dingming Li,Hongxing Li,Shuo Chen,Yuchen Yan,Wenqi Zhang,Yongliang Shen,Weiming Lu,Jun Xiao,Yueting Zhuang*

Main category: cs.CL

TL;DR: OmniEAR是一个评估语言模型在实体任务中推理能力的综合框架，揭示模型在实体交互、工具使用和多代理协调面临的挑战，同时展示了模型在复杂环境下的性能限制。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在实体任务中的推理能力，弥补现有基准的不足。

Method: 构建涵盖家庭及工业场景的文本环境模拟，进行系统评估，分析模型在不同任务设置下的表现。

Result: 模型在明确指令下表现良好，但在工具推理和隐性合作中性能明显下降，复杂任务失败率高。环境信息丰富反而影响协调能力，微调提升单代理任务表现有限。

Conclusion: 实体推理能力与现有模型存在根本性差异，OmniEAR为未来实体AI系统的评价提供了严格基准。

Abstract: Large language models excel at abstract reasoning but their capacity for
embodied agent reasoning remains largely unexplored. We present OmniEAR, a
comprehensive framework for evaluating how language models reason about
physical interactions, tool usage, and multi-agent coordination in embodied
tasks. Unlike existing benchmarks that provide predefined tool sets or explicit
collaboration directives, OmniEAR requires agents to dynamically acquire
capabilities and autonomously determine coordination strategies based on task
demands. Through text-based environment representation, we model continuous
physical properties and complex spatial relationships across 1,500 scenarios
spanning household and industrial domains. Our systematic evaluation reveals
severe performance degradation when models must reason from constraints: while
achieving 85-96% success with explicit instructions, performance drops to
56-85% for tool reasoning and 63-85% for implicit collaboration, with compound
tasks showing over 50% failure rates. Surprisingly, complete environmental
information degrades coordination performance, indicating models cannot filter
task-relevant constraints. Fine-tuning improves single-agent tasks dramatically
(0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing
fundamental architectural limitations. These findings demonstrate that embodied
reasoning poses fundamentally different challenges than current models can
address, establishing OmniEAR as a rigorous benchmark for evaluating and
advancing embodied AI systems. Our code and data are included in the
supplementary materials and will be open-sourced upon acceptance.

</details>


### [39] [Learning to Reason for Factuality](https://arxiv.org/abs/2508.05618)
*Xilun Chen,Ilia Kulikov,Vincent-Pierre Berges,Barlas Oğuz,Rulin Shao,Gargi Ghosh,Jason Weston,Wen-tau Yih*

Main category: cs.CL

TL;DR: 提出一种新的奖励函数改善R-LLMs在长篇事实性回答中的表现，有效减少虚假信息，提高回答细节，保持有用性。


<details>
  <summary>Details</summary>
Motivation: 解决R-LLMs在长篇事实性任务中产生虚假信息的问题，以及优化在线强化学习的奖励设计难题。

Method: 设计结合事实精度、细节层级和相关性的新型奖励函数，并应用在线RL训练模型。

Result: 显著降低虚假信息率（减少23.1个百分点）、提高回答细节（增幅23%），且不影响回答的有用性。

Conclusion: 新型奖励函数有效提升R-LLMs的事实性和细节表现，是提升长篇事实性生成的重要方法。

Abstract: Reasoning Large Language Models (R-LLMs) have significantly advanced complex
reasoning tasks but often struggle with factuality, generating substantially
more hallucinations than their non-reasoning counterparts on long-form
factuality benchmarks. However, extending online Reinforcement Learning (RL), a
key component in recent R-LLM advancements, to the long-form factuality setting
poses several unique challenges due to the lack of reliable verification
methods. Previous work has utilized automatic factuality evaluation frameworks
such as FActScore to curate preference data in the offline RL setting, yet we
find that directly leveraging such methods as the reward in online RL leads to
reward hacking in multiple ways, such as producing less detailed or relevant
responses. We propose a novel reward function that simultaneously considers the
factual precision, response detail level, and answer relevance, and applies
online RL to learn high quality factual reasoning. Evaluated on six long-form
factuality benchmarks, our factual reasoning model achieves an average
reduction of 23.1 percentage points in hallucination rate, a 23% increase in
answer detail level, and no degradation in the overall response helpfulness.

</details>


### [40] [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations](https://arxiv.org/abs/2508.05625)
*Brandon Jaipersaud,David Krueger,Ekdeep Singh Lubana*

Main category: cs.CL

TL;DR: 采用线性探针分析大规模语言模型在多轮对话中的劝说行为，探针能有效识别劝说成功点及策略，优于或等同于提示方法。


<details>
  <summary>Details</summary>
Motivation: 理解大模型如何实现劝说，尤其在多轮对话中的动态。

Method: 利用认知科学启发，训练线性探针分析劝说成功、受劝者性格和策略。

Result: 探针能捕捉劝说的多方面特征，识别关键事件点，效率高于提示法，某些任务表现更优。

Conclusion: 线性探针为研究复杂行为（如欺骗、操控）提供有效工具，尤其适合大规模多轮对话场景。

Abstract: Large Language Models (LLMs) have started to demonstrate the ability to
persuade humans, yet our understanding of how this dynamic transpires is
limited. Recent work has used linear probes, lightweight tools for analyzing
model representations, to study various LLM skills such as the ability to model
user sentiment and political perspective. Motivated by this, we apply probes to
study persuasion dynamics in natural, multi-turn conversations. We leverage
insights from cognitive science to train probes on distinct aspects of
persuasion: persuasion success, persuadee personality, and persuasion strategy.
Despite their simplicity, we show that they capture various aspects of
persuasion at both the sample and dataset levels. For instance, probes can
identify the point in a conversation where the persuadee was persuaded or where
persuasive success generally occurs across the entire dataset. We also show
that in addition to being faster than expensive prompting-based approaches,
probes can do just as well and even outperform prompting in some settings, such
as when uncovering persuasion strategy. This suggests probes as a plausible
avenue for studying other complex behaviours such as deception and
manipulation, especially in multi-turn settings and large-scale dataset
analysis where prompting-based methods would be computationally inefficient.

</details>


### [41] [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages](https://arxiv.org/abs/2508.05628)
*Mehrdad Zakershahrak,Samira Ghodratnama*

Main category: cs.CL

TL;DR: H-NET++通过端到端训练的层级动态切分，有效解决了形态丰富语言中的字符处理问题，实现了比传统BPE更优的压缩和识别性能。


<details>
  <summary>Details</summary>
Motivation: 解决形态丰富语言中byte级模型面临的切分与压缩难题，避免依赖脆弱的分词器。

Method: 提出层级动态切分模型H-NET++，集成轻量Transformer、双层潜在超先验以及特殊处理语言特性，通过课程式训练优化序列长度。

Result: 在1.4B Persian语料上实现了压缩性能和分类指标的显著提升，鲁棒性增强，且自动学习的切片符合波斯语形态特征。

Conclusion: 层级动态切分为MRL提供了无依赖分词器的有效方案，兼顾效率与性能，推动byte-level模型在多语言环境下的应用。

Abstract: Byte-level language models eliminate fragile tokenizers but face
computational challenges in morphologically-rich languages (MRLs), where words
span many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that
learns linguistically-informed segmentation through end-to-end training. Key
innovations include: (1) a lightweight Transformer context-mixer (1.9M
parameters) for cross-chunk attention, (2) a two-level latent hyper-prior for
document-level consistency, (3) specialized handling of orthographic artifacts
(e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence
lengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art
results: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better
compression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ
corruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks
align with Persian morphology without explicit supervision, demonstrating that
hierarchical dynamic chunking provides an effective tokenizer-free solution for
MRLs while maintaining computational efficiency.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [42] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 提出了一种基于大语言模型的预诊断维护系统，结合振动分析与多智能体，提供故障检测与具体维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需提前介入以避免灾难性故障，提高效率。传统方法不足以提供行动性建议。

Method: 结合振动信号数据序列化与多智能体处理，利用大语言模型进行 anomaly detection 和维护建议生成。

Result: 系统在振动数据集上验证有效，能准确检测故障并给出详细维护方案。

Conclusion: 该系统弥合了状态监测与维护规划差距，为工业领域提供智能决策支持，推动预诊断维护的发展。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [43] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow是一种自动为地理空间任务生成智能工作流程的方法，显著提高成功率并降低Token消耗。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在地理空间任务中缺乏明确API调用指导的问题，提升任务完成效率。

Method: 通过为每个代理提供详细的工具调用目标，实现Runtime时的API调用指导，增强代理的执行能力。

Result: 在主要的LLM模型中，GeoFlow提高了6.8%的代理成功率，并将Token使用降低至4倍以内。

Conclusion: GeoFlow通过细粒度的API调用指导，有效提升了地理空间任务中代理的表现和效率。

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [44] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 该研究提出一种基于棋盘游戏的对抗性基准框架，利用Qi Town平台评测大规模语言模型（LLMs）在多种游戏中的表现，创新性结合Elo评分和性能循环图，分析模型的技术能力和心理状态。


<details>
  <summary>Details</summary>
Motivation: 弥补传统问答基准依赖数据的不足，利用棋盘游戏评价LLMs的策略推理和抗压能力。

Method: 构建支持五款流行游戏的Qi Town平台，采用Elo评分体系和创新的性能循环图（PLG），通过循环赛形式进行系统评比，结合正面情感分数（PSS）分析模型心理态势。

Result: 多款LLMs表现出较强的适应性，偏向乐观，胜负关系复杂，表明其在压力环境下具有一定弹性，但同时也暴露出技能不稳定的问题。

Conclusion: 该框架有效评估了LLMs在对抗环境中的技术和心理表现，为未来模型优化提供参考。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [45] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: 研究比较了基于云端大型语言模型、半自动离线模型和完全自主离线模型的Web地理信息系统（AWebGIS），发现客户端小模型在准确率和隐私保护方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着Web GIS的发展，如何实现用户自然语言交互的隐私性、独立性和高效性成为研究重点。

Method: 本文比较了三种方法：云端LLMs、离线传统机器学习分类器和基于微调小型语言模型（T5-small）的客户端模型，并在性能和隐私方面进行评估。

Result: 客户端微调的小型模型在准确性方面表现最佳（匹配准确率0.93，Levenshtein相似度0.99，ROUGE-1和ROUGE-L都达0.98），显著减轻了服务器负担，验证了浏览器内运行模型的可行性。

Conclusion: 基于微调的小型模型在隐私保护和性能方面具有巨大潜力，为未来Web GIS中的自然语言交互提供了有效解决方案。

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [46] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 该研究探讨了强化学习在提升大语言模型推理能力中的局限性，特别是在非理想场景下表现不佳，强调了评估模型在现实环境中的重要性，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前大模型推理评估多在理想场景，忽视实际复杂环境中的表现，亟需探索其在非理想条件下的能力。

Method: 采用强化学习微调多种大型模型，评估其在八个公开数据集上的表现，特别是在非理想场景下的性能。

Result: 强化学习虽能改善理想条件下的推理能力，但在 summary inference、噪声抑制和上下文过滤等非理想场景中性能大幅下降，暴露模型推理能力的不足。

Conclusion: 大型模型的推理能力被高估，需重视在现实复杂场景中的表现，未来应开发更鲁棒的训练和评估方法。

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [47] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: 提出了一种自我进化的AI代理HealthFlow，能自主优化其高层策略，通过抽取成功与失败经验，提升复杂医疗任务的处理能力。


<details>
  <summary>Details</summary>
Motivation: 当前AI在医疗研究中受限于静态策略，缺乏学习成为更有效策略规划者的能力。

Method: 引入元级演化机制并建立EHRFlowBench基准测试，通过经验总结不断优化高层策略。

Result: HealthFlow显著优于现有AI框架，表现出更强的自主学习和适应能力。

Conclusion: 从单纯工具使用者向智能自我演化任务管理者转变，推动自主、有效的科学发现AI发展。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [48] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: 提出一种基于博弈论的分子对接新框架与算法，显著提升了对接预测准确率。


<details>
  <summary>Details</summary>
Motivation: 解决多任务学习模型在配体对接表现不佳的问题，特别是对配体的结构复杂性适应不足。

Method: 构建“对接游戏”模型，设计Loop Self-Play算法，交替训练配体和蛋白质两个模块，通过多轮迭代实现结构互补与自我优化。

Result: 在公开数据集上显著优于现有方法，提升约10%的预测准确率，验证了模型的有效性与稳定性。

Conclusion: 该博弈论框架及算法能有效改善分子对接的预测性能，为药物发现中的结构预测提供新思路。

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [49] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLMs）在空间数据整合中的应用潜力，显示其在理解空间关系和纠错方面具有优势，未来可结合多模态和多样化数据形式进一步提升。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法和机器学习方法在空间数据整合中存在局限，需要更灵活、智能的解决方案。

Method: 分析LLMs的空间推理能力，采用review-and-refine方法改进初始结果，关注特征选择和误差修正。

Result: LLMs在简化空间推理任务和提高整合效果方面表现良好，结合 review-and-refine方法增强效果。

Conclusion: LLMs是空间数据整合的有潜力的替代方案，未来应结合多模态和多样化数据支持，推动实际应用发展。

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [50] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: 提出一种基于人类双系统认知模型的网页导航智能体CogniWeb，结合快速反应和深思熟虑，提高效率与表现。


<details>
  <summary>Details</summary>
Motivation: 网页导航对于评估AGI具有挑战性，现有方法缺乏线上线下策略的有效结合。

Method: 借鉴人类双系统认知理论，设计模块化架构CogniWeb，实现快速反应和深度思考的切换。

Result: CogniWeb在WebArena测试中成功率达43.96%，并实现75%的令牌使用降低，表现优异。

Conclusion: 该方法有效融合直觉和深思，提高网页导航的智能性与效率，为AGI研究提供新思路。

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [51] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: 提出MedMKEB作为首个医学多模态知识编辑的综合评测基准，评估模型可靠性、通用性、局部性、迁移性与鲁棒性，推动医学知识编辑技术的发展。


<details>
  <summary>Details</summary>
Motivation: 随着医学知识的不断演进，现有模型难以高效更新知识，因此亟需系统化的评测标准，以改善知识编辑的效果。

Method: 构建以高质量医学视觉问答数据为基础，设计多种编辑任务，并引入专家验证，评估现有多模态大模型的编辑能力。

Result: 验证结果显示目前模型在医学知识编辑方面存在诸多限制，强调开发专业化编辑策略的必要性，提供了评估和改进的基准。

Conclusion: MedMKEB将作为推动可信赖、高效医学知识编辑算法发展的标准平台。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [52] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize是一种基于finetuned Qwen3-8B模型的轻量级模拟电路门控尺寸优化框架，能够跨技术节点和电路拓扑实现高效、通用的性能调优，显著降低资源与专家依赖。


<details>
  <summary>Details</summary>
Motivation: 模拟电路设计耗时且依赖经验，传统优化方法受限于模型大小和兼容性，亟需更高效、通用的自动化工具。

Method: 结合全局差分进化和局部粒子群优化，利用性能指标的易达性动态构建任务特定损失函数，finetune在350nm数据上，具备跨节点能力。

Result: 在不同工艺节点上对实际电路Netlist表现优异，减少资源消耗，优于其他RL方法，降低人力和计算成本。

Conclusion: EasySize显著推动模拟电路自动化设计，将有助于简化流程、缩短开发周期。

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [53] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: 该研究验证了结构化对话式AI教师在高等教育中的潜力，支持批判性和自主性思维，提出多智能体系统的未来教育模式，并探讨其系统级影响。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在高等教育中的普及，探索其在教学中的有效应用成为迫切需求。

Method: 通过在德国预备教师学生中的对照实验，比较Socraic AI Tutor与非指导性聊天机器人对学生思维的影响。

Result: 使用Socraic AI Tutor的学生表现出更高的批判性、独立性和反思性思维，验证了对话式AI的教育潜力。

Conclusion: 提出多智能体系统支持多样化学习路径，强调系统设计的教育协调性，并探讨其制度层面的实施和成本效益，推动混合学习生态的发展。

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [54] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 提出一种基于异构图神经网络的事件日志缺失值补全模型，优于现有的自编码器方法，能重建完整属性集。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，事件日志常存在缺失信息，影响流程分析准确性，需要有效的补全方法。

Method: 开发一种异构图神经网络模型，利用图结构表达复杂多模序列，通过学习补全缺失事件属性。

Result: 在合成与真实日志中验证，模型在重建全部事件属性方面表现优异，优于基于自编码器的最新方法。

Conclusion: 异构图神经网络为事件日志补全提供了更自然、更丰富的表达方式，提高了补全效果，有助于流程挖掘的准确性。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [55] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: 提出了一种支持多模态、多轮、多跳推理的动态检索增强生成系统QA-Dragon，有效提升复杂视觉问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG方法在复杂、多模态、多轮推理中检索能力不足的问题。

Method: 引入领域路由和搜索路由，结合文本和图像搜索代理，实现动态、多策略检索，支持多模态、多轮、多跳推理。

Result: 在KDD Cup 2025挑战中明显优于基线模型，提升答案准确率和知识重叠度，单源、多源、多轮任务分别超越基线5.06%、6.35%、5.03%。

Conclusion: QA-Dragon有效增强了多模态知识密集型VQA任务的推理能力，展示了多策略、多模态检索在复杂任务中的潜力。

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [56] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: 结合RDF图数据库和大型语言模型（LLMs）设计的框架，有效解决大规模维护组织中的信息过载和沟通延误问题，通过自然语言查询实现精准定位和透明推理，提高沟通效率。


<details>
  <summary>Details</summary>
Motivation: 传统沟通方法难以应对大规模维护组织中复杂关系带来的信息过载和响应延迟问题，迫切需要更智能的解决方案。

Method: 将RDF图数据库与LLMs结合，用于处理自然语言查询，支持概念组合并提供透明推理，通过规划协调架构实现解释性结果。

Result: 实现了对设备、制造商、维护工程师和设施等概念的直观查询，提供可解释的结果，增强信任，提高组织内的沟通效率。

Conclusion: 该框架有效应对大规模维护场景中的沟通挑战，提升信息处理的智能化和透明度，具有实际应用潜力。

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [57] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种结合符号推理和大规模语言模型的混合架构，通过多智能体协调实现可解释性和高性能的推理。


<details>
  <summary>Details</summary>
Motivation: 弥补现有神经符号结合方法中符号与神经模块的松散结合，提升推理的 interpretability 和效果。

Method: 将决策树与随机森林作为可调用的预言机融入统一推理系统，配合LLM多智能体处理推理、泛化和互动规划，中央协调者维护一致性。

Result: 在多个推理基准上取得优异性能，提高逻辑一致性、数学推理和抽象能力，应用于临床决策和科学发现。

Conclusion: 该架构提供了一个稳健、可解释、可扩展的通用神经符号推理方案。

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [58] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: 本文提出一种重新定义'agent'的框架，旨在增强人工智能系统的描述和研究一致性，推动术语标准化。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型的发展，'agent'一词的多义性带来了交流和评估的挑战，亟需明确界定。

Method: 通过历史分析和现有用法，设计了多维度的系统描述框架，包括环境互动、学习能力、自治性、目标复杂度和时间连贯性。

Result: 提出了一个定义明确、实用的多维度分类框架，促进术语标准化，改善研究的透明度和可复现性，辅助政策制定。

Conclusion: 建议采用该标准框架，以提升AI研究的清晰度和一致性，推进领域的发展。

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [59] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: 引入NomicLaw模拟多智能体法治协作，探究LLMs在复杂法律和伦理决策中的表现和社交行为。


<details>
  <summary>Details</summary>
Motivation: 目前对LLMs在开放、多智能体法律伦理环境中的行为理解有限。

Method: 构建多智能体模拟平台，通过投票、辩论等互动研究LLMs的合作与策略。

Result: 发现LLMs能形成联盟、背叛和策略性辩论，彰显其社会推理和说服能力。

Conclusion: 研究揭示LLMs的社会行为潜力，为未来自主协商和立法AI系统提供启示。

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [60] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: 本文研究了描述逻辑中的最小模型推理问题，发现概念可满足性在某些情况下尤为复杂，甚至在简单逻辑中也已无解，并提出了在某些限制条件下的可解方案。


<details>
  <summary>Details</summary>
Motivation: 理解描述逻辑中最小模型推理的复杂性，提升知识表示与推理技术的实用性。

Method: 分析不同描述逻辑及其变体中的最小模型问题，结合复杂性分析和限制条件，探索可行性。

Result: 发现概念满足性在部分逻辑中已是不可判定，提出受限条件后复杂性降低，并在DL-Lite家族中取得不同级别的复杂性结论。

Conclusion: 描述逻辑中的最小模型推理具有极高复杂度，部分受限后仍保持较高难度，未来需探索更实用的限制条件和算法。

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [61] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: 提出StructVRM，通过结构化、可验证的奖励模型提升多模态模型在复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型在多步骤、多子问题推理中表现不足，原有奖励机制过于粗糙。

Method: 引入模型验证器，提供细粒度的子题反馈，实现结构化奖励，结合多模态推理。

Result: 在多项基准测试中取得了优异成绩，展现出该方法在复杂推理任务中的优越性。

Conclusion: 结构化、可验证的奖励是提升多模态模型推理能力的重要途径。

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [62] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 提出了一套基于机器学习的铁路交通预测性维护在线解决方案，具有高准确性和良好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 为了提高轨道交通系统的维护效率和安全性，开发一种实时、可解释的预测性维护方法。

Method: 采用样本预处理、增量分类和结果可解释三部分形成的在线数据处理流程，特别引入频率和统计特征的即时构建及自然语言和视觉的解释模块。

Result: 在葡萄牙波尔图地铁数据集上的实验显示，模型达到98%以上的F值和99%的准确率，表现出坚实的性能，尤其在类别不平衡和噪声环境下依然高效，且解释有效。

Conclusion: 该方法验证了其实用性，能够支持铁路系统的主动维护，便于决策制定，提高安全性和可靠性，减少成本。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [63] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: DeepPHY是一个用于评估视觉语言模型在物理推理和复杂互动中的能力的基准框架，显示最先进模型仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 弥补现实任务中复杂互动和物理理解评估的不足，提供模拟环境进行系统测试。

Method: 整合多层次物理环境与细粒度评估指标，构建全面测试平台。

Result: 即使是最先进的VLMs，也难以将描述性物理知识转化为精确的预测控制。

Conclusion: DeepPHY揭示了当前VLMs在物理推理和复杂策略执行方面的局限性，推动未来改进。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [64] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）正逐步转变为有力的化学实验助手，结合图神经网络和其他技术加速绿色化学创新，但仍面临偏差、安全和透明性挑战。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在有机合成中的应用潜力及其实现过程。

Method: 综述现有技术与进展，分析结合多种模型的方法和效果。

Result: LLMs显著提升反应设计和实验自动化能力，推动数据驱动的绿色化学，但存在偏置、解释难和安全隐患。

Conclusion: 未来通过开源基准、联邦学习和可解释界面实现更普惠、安全的分子创新平台。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


### [65] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
*Krzysztof Janowicz,Zilong Liu,Gengchen Mai,Zhangyu Wang,Ivan Majic,Alexandra Fortacz,Grant McKenzie,Song Gao*

Main category: cs.AI

TL;DR: 探讨AI在全球不同地区的文化、法律和政治背景下的地理适应性与对齐问题，强调未来需要空间-时间敏感的对齐方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI在全球范围内应用，加深对不同地域文化和法规影响AI行为的理解变得尤为重要，确保AI符合多元社会的价值观和规范。

Method: 综述现有地理研究问题，提出未来研究方向，以及评估对齐敏感性的方法。

Result: 指出AI的空间-时间敏感对齐需求日益增长，目前缺乏系统的研究和实践指导，强调个性化和上下文感知的重要性。

Conclusion: 未来应发展空间-时间敏感的AI对齐策略，以确保其在全球多样化背景下的适应性和责任性。

Abstract: AI (super) alignment describes the challenge of ensuring (future) AI systems
behave in accordance with societal norms and goals. While a quickly evolving
literature is addressing biases and inequalities, the geographic variability of
alignment remains underexplored. Simply put, what is considered appropriate,
truthful, or legal can differ widely across regions due to cultural norms,
political realities, and legislation. Alignment measures applied to AI/ML
workflows can sometimes produce outcomes that diverge from statistical
realities, such as text-to-image models depicting balanced gender ratios in
company leadership despite existing imbalances. Crucially, some model outputs
are globally acceptable, while others, e.g., questions about Kashmir, depend on
knowing the user's location and their context. This geographic sensitivity is
not new. For instance, Google Maps renders Kashmir's borders differently based
on user location. What is new is the unprecedented scale and automation with
which AI now mediates knowledge, expresses opinions, and represents geographic
reality to millions of users worldwide, often with little transparency about
how context is managed. As we approach Agentic AI, the need for
spatio-temporally aware alignment, rather than one-size-fits-all approaches, is
increasingly urgent. This paper reviews key geographic research problems,
suggests topics for future work, and outlines methods for assessing alignment
sensitivity.

</details>


### [66] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
*Matteo Prandi,Vincenzo Suriani,Federico Pierucci,Marcello Galisai,Daniele Nardi,Piercosma Bisconti*

Main category: cs.AI

TL;DR: 本文提出Bench-2-CoP框架，通过对比评价基准与EU AI法案的能力分类，揭示当今AI评估体系严重忽视关键系统性风险的现状，并为政策制定提供依据。


<details>
  <summary>Details</summary>
Motivation: 随着通用人工智能模型的快速发展及新兴法规的出台，亟需完善的评估框架以衡量系统性风险，但现有基准工具无法满足这一需求。

Method: 引入验证的LLM作为评判者，系统分析了94万多个问答题与欧盟AI法案的能力分类之间的匹配程度，揭示当前评估的不足。

Result: 发现评估体系主要关注狭义的行为倾向，忽视关键的系统性能力，如规避监管、自我复制等；这些能力对应的风险评价几乎为空白。

Conclusion: 提供了关于AI系统性风险评估缺口的首份量化分析，为政策完善和新型评估工具的开发提供理论基础，推动AI的安全合规发展。

Abstract: The rapid advancement of General Purpose AI (GPAI) models necessitates robust
evaluation frameworks, especially with emerging regulations like the EU AI Act
and its associated Code of Practice (CoP). Current AI evaluation practices
depend heavily on established benchmarks, but these tools were not designed to
measure the systemic risks that are the focus of the new regulatory landscape.
This research addresses the urgent need to quantify this "benchmark-regulation
gap." We introduce Bench-2-CoP, a novel, systematic framework that uses
validated LLM-as-judge analysis to map the coverage of 194,955 questions from
widely-used benchmarks against the EU AI Act's taxonomy of model capabilities
and propensities. Our findings reveal a profound misalignment: the evaluation
ecosystem is overwhelmingly focused on a narrow set of behavioral propensities,
such as "Tendency to hallucinate" (53.7% of the corpus) and "Discriminatory
bias" (28.9%), while critical functional capabilities are dangerously
neglected. Crucially, capabilities central to loss-of-control scenarios,
including evading human oversight, self-replication, and autonomous AI
development, receive zero coverage in the entire benchmark corpus. This
translates to a near-total evaluation gap for systemic risks like "Loss of
Control" (0.4% coverage) and "Cyber Offence" (0.8% coverage). This study
provides the first comprehensive, quantitative analysis of this gap, offering
critical insights for policymakers to refine the CoP and for developers to
build the next generation of evaluation tools, ultimately fostering safer and
more compliant AI.

</details>


### [67] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
*Burak Can Kaplan,Hugo Cesar De Castro Carneiro,Stefan Wermter*

Main category: cs.AI

TL;DR: 利用资源有限的大型语言模型合成多样化的ERC数据集，有效提升情感识别的性能和稳健性。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺和偏差影响ERC的发展，同时大型语言模型虽有效但训练成本高，限制其应用。

Method: 使用小型通用LLM生成多样化的ERC数据集，补充主要基准测试。

Result: 在增强数据集后，分类模型表现出较强的鲁棒性和显著的性能提升。

Conclusion: 合成数据集能有效缓解数据不足问题，提高ERC模型的性能和稳健性。

Abstract: Emotion recognition in conversations (ERC) focuses on identifying emotion
shifts within interactions, representing a significant step toward advancing
machine intelligence. However, ERC data remains scarce, and existing datasets
face numerous challenges due to their highly biased sources and the inherent
subjectivity of soft labels. Even though Large Language Models (LLMs) have
demonstrated their quality in many affective tasks, they are typically
expensive to train, and their application to ERC tasks--particularly in data
generation--remains limited. To address these challenges, we employ a small,
resource-efficient, and general-purpose LLM to synthesize ERC datasets with
diverse properties, supplementing the three most widely used ERC benchmarks. We
generate six novel datasets, with two tailored to enhance each benchmark. We
evaluate the utility of these datasets to (1) supplement existing datasets for
ERC classification, and (2) analyze the effects of label imbalance in ERC. Our
experimental results indicate that ERC classifier models trained on the
generated datasets exhibit strong robustness and consistently achieve
statistically significant performance improvements on existing ERC benchmarks.

</details>


### [68] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
*Shuo Cai,Su Lu,Qi Zhou,Kejing Yang,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: 提出InfiAlign框架，通过高质量数据选择和结合监督微调与偏好优化,显著提升大语言模型的推理能力，具有数据和资源效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型后训练过程中高数据和计算成本的问题，提升推理能力。

Method: 集成监督微调（SFT）与偏好优化（DPO），通过多维质量指标自动筛选高质数据。

Result: 在Qwen2.5-Math-7B-Base模型上，数据用量仅为原始的12%，且达到媲美更大模型的性能，在数学推理等任务中平均提升3.89%。

Conclusion: 结合科学数据选择与全阶段后训练的方法有效提升推理模型性能，具有良好的扩展性和实用价值。

Abstract: Large language models (LLMs) have exhibited impressive reasoning abilities on
a wide range of complex tasks. However, enhancing these capabilities through
post-training remains resource intensive, particularly in terms of data and
computational cost. Although recent efforts have sought to improve sample
efficiency through selective data curation, existing methods often rely on
heuristic or task-specific strategies that hinder scalability. In this work, we
introduce InfiAlign, a scalable and sample-efficient post-training framework
that integrates supervised fine-tuning (SFT) with Direct Preference
Optimization (DPO) to align LLMs for enhanced reasoning. At the core of
InfiAlign is a robust data selection pipeline that automatically curates
high-quality alignment data from open-source reasoning datasets using
multidimensional quality metrics. This pipeline enables significant performance
gains while drastically reducing data requirements and remains extensible to
new data sources. When applied to the Qwen2.5-Math-7B-Base model, our SFT model
achieves performance on par with DeepSeek-R1-Distill-Qwen-7B, while using only
approximately 12% of the training data, and demonstrates strong generalization
across diverse reasoning tasks. Additional improvements are obtained through
the application of DPO, with particularly notable gains in mathematical
reasoning tasks. The model achieves an average improvement of 3.89% on AIME
24/25 benchmarks. Our results highlight the effectiveness of combining
principled data selection with full-stage post-training, offering a practical
solution for aligning large reasoning models in a scalable and data-efficient
manner. The model checkpoints are available at
https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT.

</details>


### [69] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.AI

TL;DR: GRAIL通过结合LLMs与图结构探索，提升了知识图问答的准确率，尤其在处理结构化知识方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有RAG方法在结构化知识处理上的局限性，提升图结构推理能力和效果。

Method: 引入GRAIL框架，通过随机探索与路径过滤相结合的交互式学习，采用两阶段训练策略优化图检索策略，平衡检索的广度与精度。

Result: 在三个知识图问答数据集上，GRAIL分别实现了21.01%的准确率提升和22.43%的F1值提升。

Conclusion: GRAIL有效增强了大规模图结构的检索与推理能力，推动了基于知识图的问答技术的发展。

Abstract: Large Language Models (LLMs) integrated with Retrieval-Augmented Generation
(RAG) techniques have exhibited remarkable performance across a wide range of
domains. However, existing RAG approaches primarily operate on unstructured
data and demonstrate limited capability in handling structured knowledge such
as knowledge graphs. Meanwhile, current graph retrieval methods fundamentally
struggle to capture holistic graph structures while simultaneously facing
precision control challenges that manifest as either critical information gaps
or excessive redundant connections, collectively undermining reasoning
performance. To address this challenge, we propose GRAIL: Graph-Retrieval
Augmented Interactive Learning, a framework designed to interact with
large-scale graphs for retrieval-augmented reasoning. Specifically, GRAIL
integrates LLM-guided random exploration with path filtering to establish a
data synthesis pipeline, where a fine-grained reasoning trajectory is
automatically generated for each task. Based on the synthesized data, we then
employ a two-stage training process to learn a policy that dynamically decides
the optimal actions at each reasoning step. The overall objective of
precision-conciseness balance in graph retrieval is decoupled into fine-grained
process-supervised rewards to enhance data efficiency and training stability.
In practical deployment, GRAIL adopts an interactive retrieval paradigm,
enabling the model to autonomously explore graph paths while dynamically
balancing retrieval breadth and precision. Extensive experiments have shown
that GRAIL achieves an average accuracy improvement of 21.01% and F1
improvement of 22.43% on three knowledge graph question-answering datasets. Our
source code and datasets is available at https://github.com/Changgeww/GRAIL.

</details>


### [70] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
*Roshita Bhonsle,Rishav Dutta,Sneha Vavilapalli,Harsh Seth,Abubakarr Jaye,Yapei Chang,Mukund Rungta,Emmanuel Aboah Boateng,Sadid Hasan,Ehi Nosakhare,Soundar Srinivasan*

Main category: cs.AI

TL;DR: 提出一种通用、模块化的评估框架，用于评估智能体任务完成情况，超越现有只关注输出结果的方法。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法难以全面评估智能体的决策过程，缺乏逐步推理验证，且多为领域特定，亟需一种通用的评估框架。

Method: 通过模拟人类评估，分解任务为子任务，逐步验证输出与推理，模块化设计，各模块输出汇聚为最终结论，验证在两个基准上表现优于传统方法。

Result: 在两个测试基准中，该框架的评价与人类更一致，成功预测任务完成情况，提高了4.76%和10.52%的对齐准确度。

Conclusion: 所提出的评估框架具有良好的通用性和效果，有助于提升智能体任务评估的全面性和准确性。

Abstract: The increasing adoption of foundation models as agents across diverse domains
necessitates a robust evaluation framework. Current methods, such as
LLM-as-a-Judge, focus only on final outputs, overlooking the step-by-step
reasoning that drives agentic decision-making. Meanwhile, existing
Agent-as-a-Judge systems, where one agent evaluates another's task completion,
are typically designed for narrow, domain-specific settings. To address this
gap, we propose a generalizable, modular framework for evaluating agent task
completion independent of the task domain. The framework emulates human-like
evaluation by decomposing tasks into sub-tasks and validating each step using
available information, such as the agent's output and reasoning. Each module
contributes to a specific aspect of the evaluation process, and their outputs
are aggregated to produce a final verdict on task completion. We validate our
framework by evaluating the Magentic-One Actor Agent on two benchmarks, GAIA
and BigCodeBench. Our Judge Agent predicts task success with closer agreement
to human evaluations, achieving 4.76% and 10.52% higher alignment accuracy,
respectively, compared to the GPT-4o based LLM-as-a-Judge baseline. This
demonstrates the potential of our proposed general-purpose evaluation
framework.

</details>


### [71] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
*Meryem Yilmaz Soylu,Adrian Gallard,Jeonghyun Lee,Gayane Grigoryan,Rushil Desai,Stephen Harmon*

Main category: cs.AI

TL;DR: 提出LORI，一种利用自然语言处理评估申请者领导能力的AI工具，提升录取流程的效率和评估准确性。


<details>
  <summary>Details</summary>
Motivation: 当前LOR评估耗时且劳动强度大，需要自动化工具以提升效率和客观性。

Method: 采用RoBERTa和LLAMA大规模语言模型进行自然语言处理，识别团队合作、沟通和创新等领导属性。

Result: RoBERTa模型在性能指标上表现优越，F1-score达91.6%，显示模型在评估领导能力方面的高效性。

Conclusion: 引入LORI可优化录取流程，自动化评估申请者领导能力，具有重要应用价值，尤其在STEM领域。

Abstract: Letters of recommendation (LORs) provide valuable insights into candidates'
capabilities and experiences beyond standardized test scores. However,
reviewing these text-heavy materials is time-consuming and labor-intensive. To
address this challenge and support the admission committee in providing
feedback for students' professional growth, our study introduces LORI: LOR
Insights, a novel AI-based detection tool for assessing leadership skills in
LORs submitted by online master's program applicants. By employing natural
language processing and leveraging large language models using RoBERTa and
LLAMA, we seek to identify leadership attributes such as teamwork,
communication, and innovation. Our latest RoBERTa model achieves a weighted F1
score of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong
level of consistency in our test data. With the growing importance of
leadership skills in the STEM sector, integrating LORI into the graduate
admissions process is crucial for accurately assessing applicants' leadership
capabilities. This approach not only streamlines the admissions process but
also automates and ensures a more comprehensive evaluation of candidates'
capabilities.

</details>


### [72] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
*Rui Lu,Jinhe Bi,Yunpu Ma,Feng Xiao,Yuntao Du,Yijun Tian*

Main category: cs.AI

TL;DR: 提出MV-Debate多视角辩论框架，用多智能体分析与反思提升多模态有害内容检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 在复杂的多模态社交媒体内容中，识别隐含的有害意图具有挑战性，亟需更有效的检测方法。

Method: 引入由四个互补辩论代理组成的多视角辩论框架，通过迭代辩论与反思机制提升检测精度，结合动态反思门控优化性能。

Result: 在三个基准数据集上的实验显示，该方法显著优于单模型和现有多智能体辩论方法，验证其有效性。

Conclusion: 多智能体辩论通过多维分析和反思优化，是提升线上内容有害意图检测的有潜力的方法，推动了社会安全领域的研究进展。

Abstract: Social media has evolved into a complex multimodal environment where text,
images, and other signals interact to shape nuanced meanings, often concealing
harmful intent. Identifying such intent, whether sarcasm, hate speech, or
misinformation, remains challenging due to cross-modal contradictions, rapid
cultural shifts, and subtle pragmatic cues. To address these challenges, we
propose MV-Debate, a multi-view agent debate framework with dynamic reflection
gating for unified multimodal harmful content detection. MV-Debate assembles
four complementary debate agents, a surface analyst, a deep reasoner, a
modality contrast, and a social contextualist, to analyze content from diverse
interpretive perspectives. Through iterative debate and reflection, the agents
refine responses under a reflection-gain criterion, ensuring both accuracy and
efficiency. Experiments on three benchmark datasets demonstrate that MV-Debate
significantly outperforms strong single-model and existing multi-agent debate
baselines. This work highlights the promise of multi-agent debate in advancing
reliable social intent detection in safety-critical online contexts.

</details>


### [73] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
*Bo Wen*

Main category: cs.AI

TL;DR: 本文提出以主动推理（AIF）作为基础，实现无需持续人工奖励设计的自主学习AI，试图解决当前AI系统在目标设定上的瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 随着高质量训练数据的枯竭和对大规模人力奖励设计的依赖，这限制了AI的自主性发展，亟需新的理论基础支持自主学习。

Method: 本文结合主动推理（AIF）和大型语言模型作为生成世界模型，提出通过最小化自由能的内在驱动力，使AI能够自主探索与利用并适应变化的目标。

Result: 提出了一种结合AIF和大模型的框架，有助于创造高效自主学习且符合人类价值的AI系统，解决了“grounded-agency gap”。

Conclusion: AIF提供了一条实现自主、符合价值的AI的路径，通过内在动机和贝叶斯目标，实现更自主、更适应变化的智能体。

Abstract: This paper argues that Active Inference (AIF) provides a crucial foundation
for developing autonomous AI agents capable of learning from experience without
continuous human reward engineering. As AI systems begin to exhaust
high-quality training data and rely on increasingly large human workforces for
reward design, the current paradigm faces significant scalability challenges
that could impede progress toward genuinely autonomous intelligence. The
proposal for an ``Era of Experience,'' where agents learn from self-generated
data, is a promising step forward. However, this vision still depends on
extensive human engineering of reward functions, effectively shifting the
bottleneck from data curation to reward curation. This highlights what we
identify as the \textbf{grounded-agency gap}: the inability of contemporary AI
systems to autonomously formulate, adapt, and pursue objectives in response to
changing circumstances. We propose that AIF can bridge this gap by replacing
external reward signals with an intrinsic drive to minimize free energy,
allowing agents to naturally balance exploration and exploitation through a
unified Bayesian objective. By integrating Large Language Models as generative
world models with AIF's principled decision-making framework, we can create
agents that learn efficiently from experience while remaining aligned with
human values. This synthesis offers a compelling path toward AI systems that
can develop autonomously while adhering to both computational and physical
constraints.

</details>


### [74] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
*Yu Yuan,Lili Zhao,Wei Chen,Guangting Zheng,Kai Zhang,Mengdi Zhang,Qi Liu*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型的多主体模拟框架“LearnerAgent”，用以研究人类学习行为的动态特征及其心理特性。


<details>
  <summary>Details</summary>
Motivation: 弥补传统模型在捕捉学习动态、追踪进展及提供可解释性方面的不足。

Method: 构建心理学基础的学习者模型，进行长周期多场景模拟，分析不同类型学习者的行为和认知变化。

Result: 验证不同类型学习者的学习动态，揭示LLM的默认行为偏向表层学习者，同时模型表现与心理特性高度匹配。

Conclusion: LearnerAgent能有效模拟真实学习场景，为理解LLMs的行为提供有价值的洞见，并展示其在心理学与智能系统中的潜力。

Abstract: Capturing human learning behavior based on deep learning methods has become a
major research focus in both psychology and intelligent systems. Recent
approaches rely on controlled experiments or rule-based models to explore
cognitive processes. However, they struggle to capture learning dynamics, track
progress over time, or provide explainability. To address these challenges, we
introduce LearnerAgent, a novel multi-agent framework based on Large Language
Models (LLMs) to simulate a realistic teaching environment. To explore
human-like learning dynamics, we construct learners with psychologically
grounded profiles-such as Deep, Surface, and Lazy-as well as a persona-free
General Learner to inspect the base LLM's default behavior. Through weekly
knowledge acquisition, monthly strategic choices, periodic tests, and peer
interaction, we can track the dynamic learning progress of individual learners
over a full-year journey. Our findings are fourfold: 1) Longitudinal analysis
reveals that only Deep Learner achieves sustained cognitive growth. Our
specially designed "trap questions" effectively diagnose Surface Learner's
shallow knowledge. 2) The behavioral and cognitive patterns of distinct
learners align closely with their psychological profiles. 3) Learners'
self-concept scores evolve realistically, with the General Learner developing
surprisingly high self-efficacy despite its cognitive limitations. 4)
Critically, the default profile of base LLM is a "diligent but brittle Surface
Learner"-an agent that mimics the behaviors of a good student but lacks true,
generalizable understanding. Extensive simulation experiments demonstrate that
LearnerAgent aligns well with real scenarios, yielding more insightful findings
about LLMs' behavior.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [75] [Augmented Question-guided Retrieval (AQgR) of Indian Case Law with LLM, RAG, and Structured Summaries](https://arxiv.org/abs/2508.04710)
*Vishnuprabha V,Daleesha M Viswanathan,Rajesh R,Aneesh V Pillai*

Main category: cs.IR

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Identifying relevant legal precedents remains challenging, as most retrieval
methods emphasize factual similarity over legal issues, and current systems
often lack explanations clarifying case relevance. This paper proposes the use
of Large Language Models (LLMs) to address this gap by facilitating the
retrieval of relevant cases, generating explanations to elucidate relevance,
and identifying core legal issues all autonomously, without requiring legal
expertise. Our approach combines Retrieval Augmented Generation (RAG) with
structured summaries optimized for Indian case law. Leveraging the Augmented
Question-guided Retrieval (AQgR) framework, the system generates targeted legal
questions based on factual scenarios to identify relevant case law more
effectively. The structured summaries were assessed manually by legal experts,
given the absence of a suitable structured summary dataset. Case law retrieval
was evaluated using the FIRE dataset, and explanations were reviewed by legal
experts, as explanation generation alongside case retrieval is an emerging
innovation. Experimental evaluation on a subset of the FIRE 2019 dataset
yielded promising outcomes, achieving a Mean Average Precision (MAP) score of
0.36 and a Mean Average Recall (MAR) of 0.67 across test queries, significantly
surpassing the current MAP benchmark of 0.1573. This work introduces a suite of
novel contributions to advance case law retrieval. By transitioning from
fact-based to legal-issue-based retrieval, the proposed approach delivers more
contextually relevant results that align closely with legal professionals'
needs. Integrating legal questions within the retrieval process through the
AQgR framework ensures more precise and meaningful retrieval by refining the
context of queries.

</details>


### [76] [Scaling Generative Recommendations with Context Parallelism on Hierarchical Sequential Transducers](https://arxiv.org/abs/2508.04711)
*Yue Dong,Han Li,Shen Li,Nikhil Patel,Xing Liu,Xiaodong Wang,Chuanhao Zhuge*

Main category: cs.IR

TL;DR: 提出支持锯齿张量的上下文并行技术，显著提升推荐系统中序列长度的处理能力。


<details>
  <summary>Details</summary>
Motivation: 应对长序列建模时的激活消耗问题，提升模型扩展性。

Method: 引入锯齿张量支持的上下文并行，结合分布式数据并行。

Result: 支持序列长度提升5.3倍，整体扩展性达1.55倍。

Conclusion: 该技术为大规模推荐模型在长序列建模上的扩展提供了基础能力，促进实际部署与性能提升。

Abstract: Large-scale recommendation systems are pivotal to process an immense volume
of daily user interactions, requiring the effective modeling of high
cardinality and heterogeneous features to ensure accurate predictions. In prior
work, we introduced Hierarchical Sequential Transducers (HSTU), an
attention-based architecture for modeling high cardinality, non-stationary
streaming recommendation data, providing good scaling law in the generative
recommender framework (GR). Recent studies and experiments demonstrate that
attending to longer user history sequences yields significant metric
improvements. However, scaling sequence length is activation-heavy,
necessitating parallelism solutions to effectively shard activation memory. In
transformer-based LLMs, context parallelism (CP) is a commonly used technique
that distributes computation along the sequence-length dimension across
multiple GPUs, effectively reducing memory usage from attention activations. In
contrast, production ranking models typically utilize jagged input tensors to
represent user interaction features, introducing unique CP implementation
challenges. In this work, we introduce context parallelism with jagged tensor
support for HSTU attention, establishing foundational capabilities for scaling
up sequence dimensions. Our approach enables a 5.3x increase in supported user
interaction sequence length, while achieving a 1.55x scaling factor when
combined with Distributed Data Parallelism (DDP).

</details>


### [77] [A Metric for MLLM Alignment in Large-scale Recommendation](https://arxiv.org/abs/2508.04963)
*Yubin Zhang,Yanhua Huang,Haiming Xu,Mingliang Qi,Chang Wang,Jiarui Jin,Xiangyuan Ren,Xiaodan Wang,Ruiwen Xu*

Main category: cs.IR

TL;DR: 提出LIS指标以衡量多模态推荐中MLLMs的偏好数据上限，通过线上A/B测试验证其效果，并提升用户停留时间和广告价值。


<details>
  <summary>Details</summary>
Motivation: 多模态推荐系统依赖先进MLLMs的内容表示，但其对推荐效果的评估面临动态性、成本高和指标难用的挑战。

Method: 设计漏洩影响评分（LIS）作为一种高效衡量偏好数据上限的指标，并在实际系统中部署验证。

Result: 在小红书内容推荐和广告中，通过LIS实现用户停留时间和广告价值的显著提升，验证了方法的有效性。

Conclusion: LIS为多模态推荐系统提供一种可行的偏好数据衡量工具，有助于优化MLLMs的应用和性能。

Abstract: Multimodal recommendation has emerged as a critical technique in modern
recommender systems, leveraging content representations from advanced
multimodal large language models (MLLMs). To ensure these representations are
well-adapted, alignment with the recommender system is essential. However,
evaluating the alignment of MLLMs for recommendation presents significant
challenges due to three key issues: (1) static benchmarks are inaccurate
because of the dynamism in real-world applications, (2) evaluations with online
system, while accurate, are prohibitively expensive at scale, and (3)
conventional metrics fail to provide actionable insights when learned
representations underperform. To address these challenges, we propose the
Leakage Impact Score (LIS), a novel metric for multimodal recommendation.
Rather than directly assessing MLLMs, LIS efficiently measures the upper bound
of preference data. We also share practical insights on deploying MLLMs with
LIS in real-world scenarios. Online A/B tests on both Content Feed and Display
Ads of Xiaohongshu's Explore Feed production demonstrate the effectiveness of
our proposed method, showing significant improvements in user spent time and
advertiser value.

</details>


### [78] [Align-for-Fusion: Harmonizing Triple Preferences via Dual-oriented Diffusion for Cross-domain Sequential Recommendation](https://arxiv.org/abs/2508.05074)
*Yongfu Zha,Xinxin Dong,Haokai Ma,Yonghui Yang,Xiaodong Wang*

Main category: cs.IR

TL;DR: 提出HorizonRec框架，通过利用扩散模型进行多领域偏好融合，有效提升跨领域推荐性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有跨领域序列推荐方法在偏好融合上的局限，提升多领域偏好建模的细粒度和鲁棒性。

Method: 引入双向扩散模型，采用混合条件分布检索策略，强调目标相关兴趣，抑制噪声影响。

Result: 在多个真实数据集上验证，HorizonRec显著优于对比模型，展现优异的推荐效果和鲁棒性。

Conclusion: 基于扩散模型的多领域偏好融合框架能有效提升跨域推荐的匹配度和质量，为推荐系统提供新的技术路径。

Abstract: Personalized sequential recommendation aims to predict appropriate items for
users based on their behavioral sequences. To alleviate data sparsity and
interest drift issues, conventional approaches typically incorporate auxiliary
behaviors from other domains via cross-domain transition. However, existing
cross-domain sequential recommendation (CDSR) methods often follow an
align-then-fusion paradigm that performs representation-level alignment across
multiple domains and combines them mechanically for recommendation, overlooking
the fine-grained fusion of domain-specific preferences. Inspired by recent
advances in diffusion models (DMs) for distribution matching, we propose an
align-for-fusion framework for CDSR to harmonize triple preferences via
dual-oriented DMs, termed HorizonRec. Specifically, we investigate the
uncertainty injection of DMs and identify stochastic noise as a key source of
instability in existing DM-based recommenders. To address this, we introduce a
mixed-conditioned distribution retrieval strategy that leverages distributions
retrieved from users' authentic behavioral logic as semantic bridges across
domains, enabling consistent multi-domain preference modeling. Furthermore, we
propose a dual-oriented preference diffusion method to suppress potential noise
and emphasize target-relevant interests during multi-domain user representation
fusion. Extensive experiments on four CDSR datasets from two distinct platforms
demonstrate the effectiveness and robustness of HorizonRec in fine-grained
triple-domain preference fusion.

</details>


### [79] [An End-to-End Multi-objective Ensemble Ranking Framework for Video Recommendation](https://arxiv.org/abs/2508.05093)
*Tiantian He,Minzhi Xie,Runtong Li,Xiaoxiao Xu,Jiaqi Yu,Zixiu Wang,Lantao Hu,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: 提出了一种端到端多目标集成排序方法EMER，提升短视频推荐系统的个性化和效率，效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决多目标集成排序中缺乏有效监督信号的问题，提升短视频推荐的个性化体验。

Method: 引入新的损失函数、样本组织方法、Transformer网络架构，以及离线-在线评估系统。

Result: 在工业数据集和实际平台应用中均取得了明显提升，如用户停留时间和用户生命周期增加。

Conclusion: EMER框架有效改善多目标排序，具有推广价值和实际应用潜力。

Abstract: We propose a novel End-to-end Multi-objective Ensemble Ranking framework
(EMER) for the multi-objective ensemble ranking module, which is the most
critical component of the short video recommendation system. EMER enhances
personalization by replacing manually-designed heuristic formulas with an
end-to-end modeling paradigm. EMER introduces a meticulously designed loss
function to address the fundamental challenge of defining effective supervision
for ensemble ranking, where no single ground-truth signal can fully capture
user satisfaction. Moreover, EMER introduces novel sample organization method
and transformer-based network architecture to capture the comparative
relationships among candidates, which are critical for effective ranking.
Additionally, we have proposed an offline-online consistent evaluation system
to enhance the efficiency of offline model optimization, which is an
established yet persistent challenge within the multi-objective ranking domain
in industry. Abundant empirical tests are conducted on a real industrial
dataset, and the results well demonstrate the effectiveness of our proposed
framework. In addition, our framework has been deployed in the primary
scenarios of Kuaishou, a short video recommendation platform with hundreds of
millions of daily active users, achieving a 1.39% increase in overall App Stay
Time and a 0.196% increase in 7-day user Lifetime(LT7), which are substantial
improvements.

</details>


### [80] [Navigating Through Paper Flood: Advancing LLM-based Paper Evaluation through Domain-Aware Retrieval and Latent Reasoning](https://arxiv.org/abs/2508.05129)
*Wuqiang Zheng,Yiyan Xu,Xinyu Lin,Chongming Gao,Wenjie Wang,Fuli Feng*

Main category: cs.IR

TL;DR: 提出PaperEval框架，结合领域相关性检索和深度推理，提高论文评价的准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 面对学术出版迅速增长，自动高质量论文识别成为紧迫需求，现有方法受限于知识陈旧和推理能力不足。

Method: 引入领域相关性检索模块和潜在推理机制，配合逐步排名优化策略，增强理解和比较能力。

Result: 在两个数据集上优于现有方法，并在实际推荐系统中展现出良好表现，获得较大用户关注。

Conclusion: PaperEval能有效提升论文评估的准确性，并具有实际应用价值。

Abstract: With the rapid and continuous increase in academic publications, identifying
high-quality research has become an increasingly pressing challenge. While
recent methods leveraging Large Language Models (LLMs) for automated paper
evaluation have shown great promise, they are often constrained by outdated
domain knowledge and limited reasoning capabilities. In this work, we present
PaperEval, a novel LLM-based framework for automated paper evaluation that
addresses these limitations through two key components: 1) a domain-aware paper
retrieval module that retrieves relevant concurrent work to support
contextualized assessments of novelty and contributions, and 2) a latent
reasoning mechanism that enables deep understanding of complex motivations and
methodologies, along with comprehensive comparison against concurrently related
work, to support more accurate and reliable evaluation. To guide the reasoning
process, we introduce a progressive ranking optimization strategy that
encourages the LLM to iteratively refine its predictions with an emphasis on
relative comparison. Experiments on two datasets demonstrate that PaperEval
consistently outperforms existing methods in both academic impact and paper
quality evaluation. In addition, we deploy PaperEval in a real-world paper
recommendation system for filtering high-quality papers, which has gained
strong engagement on social media -- amassing over 8,000 subscribers and
attracting over 10,000 views for many filtered high-quality papers --
demonstrating the practical effectiveness of PaperEval.

</details>


### [81] [Tool Graph Retriever: Exploring Dependency Graph-based Tool Retrieval for Large Language Models](https://arxiv.org/abs/2508.05152)
*Linfeng Gao,Yaoxiang Wang,Minlong Peng,Jialong Tang,Yuzhe Shang,Mingming Sun,Jinsong Su*

Main category: cs.IR

TL;DR: 本文提出Tool Graph Retriever (TGR)，通过引入工具依赖图，提高工具检索的准确性，解决了现有方法忽略工具依赖关系的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理工具的增加，如何高效检索相关工具成为挑战，现有方法主要依赖语义相似性，忽略工具之间的依赖关系，导致关键工具可能被遗漏。

Method: 构建TDI300K数据集训练工具依赖判别器，将工具表示为依赖图，通过图卷积融合依赖信息，优化工具检索。

Result: 在多个公开数据集上，TGR显著优于现有方法，达到SOTA，实验证明工具依赖关系的重要性和TGR的有效性。

Conclusion: 引入工具依赖图的方法有效改善工具检索性能，符合实际任务需求，为智能代理工具整合提供新思路。

Abstract: With the remarkable advancement of AI agents, the number of their equipped
tools is increasing rapidly. However, integrating all tool information into the
limited model context becomes impractical, highlighting the need for efficient
tool retrieval methods. In this regard, dominant methods primarily rely on
semantic similarities between tool descriptions and user queries to retrieve
relevant tools. However, they often consider each tool independently,
overlooking dependencies between tools, which may lead to the omission of
prerequisite tools for successful task execution. To deal with this defect, in
this paper, we propose Tool Graph Retriever (TGR), which exploits the
dependencies among tools to learn better tool representations for retrieval.
First, we construct a dataset termed TDI300K to train a discriminator for
identifying tool dependencies. Then, we represent all candidate tools as a tool
dependency graph and use graph convolution to integrate the dependencies into
their representations. Finally, these updated tool representations are employed
for online retrieval. Experimental results on several commonly used datasets
show that our TGR can bring a performance improvement to existing dominant
methods, achieving SOTA performance. Moreover, in-depth analyses also verify
the importance of tool dependencies and the effectiveness of our TGR.

</details>


### [82] [Balancing Accuracy and Novelty with Sub-Item Popularity](https://arxiv.org/abs/2508.05198)
*Chiara Mallamaci,Aleksandr Vladimirovich Petrov,Alberto Carlo Maria Mancino,Vito Walter Anelli,Tommaso Di Noia,Craig Macdonald*

Main category: cs.IR

TL;DR: 通过引入细粒度的个性化流行度（sub-ID-level PPS），解决了传统方法中过度强调已知内容的问题，实现了在推荐准确性与新颖性之间的有效平衡。


<details>
  <summary>Details</summary>
Motivation: 当前的个性化推荐系统在捕获用户重复听歌行为方面表现良好，但过度强调流行内容限制了新颖性，影响用户长期兴趣。

Method: 基于Transformer的RecJPQ框架，通过引入细粒度的sub-ID级别个性化流行度模型，优化推荐的多样性与准确性。

Result: 新方法显著提升了个性化新颖性，同时保持了推荐的准确性，优于传统的item-level PPS。

Conclusion: 细粒度的个性化流行度建模有效增强推荐系统的多样性和用户体验，为大规模推荐提供了新的解决方案。

Abstract: In the realm of music recommendation, sequential recommenders have shown
promise in capturing the dynamic nature of music consumption. A key
characteristic of this domain is repetitive listening, where users frequently
replay familiar tracks. To capture these repetition patterns, recent research
has introduced Personalised Popularity Scores (PPS), which quantify
user-specific preferences based on historical frequency. While PPS enhances
relevance in recommendation, it often reinforces already-known content,
limiting the system's ability to surface novel or serendipitous items - key
elements for fostering long-term user engagement and satisfaction. To address
this limitation, we build upon RecJPQ, a Transformer-based framework initially
developed to improve scalability in large-item catalogues through sub-item
decomposition. We repurpose RecJPQ's sub-item architecture to model
personalised popularity at a finer granularity. This allows us to capture
shared repetition patterns across sub-embeddings - latent structures not
accessible through item-level popularity alone. We propose a novel integration
of sub-ID-level personalised popularity within the RecJPQ framework, enabling
explicit control over the trade-off between accuracy and personalised novelty.
Our sub-ID-level PPS method (sPPS) consistently outperforms item-level PPS by
achieving significantly higher personalised novelty without compromising
recommendation accuracy. Code and experiments are publicly available at
https://github.com/sisinflab/Sub-id-Popularity.

</details>


### [83] [FIRE: Faithful Interpretable Recommendation Explanations](https://arxiv.org/abs/2508.05225)
*S. M. F. Sani,Asal Meskin,Mohammad Amanlou,Hamid R. Rabiee*

Main category: cs.IR

TL;DR: 提出FIRE框架改善推荐系统的解释质量，通过结合SHAP特征归因与结构化生成，提高解释的真实性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有基于用户评论的解释方法难以真实反映模型决策逻辑，导致解释可能既流畅又偏离事实。

Method: 结合SHAP特征归因和结构化提示驱动的语言生成，设计FIRE框架，以提高解释的忠实性、多样性和用户对齐。

Result: FIRE在保持推荐准确的同时，显著改善了解释的对齐度、结构性和忠实性，优于传统方法。

Conclusion: 应超越评论作为解释的范式，发展更具责任感和可解释性的推荐解释方法。

Abstract: Natural language explanations in recommender systems are often framed as a
review generation task, leveraging user reviews as ground-truth supervision.
While convenient, this approach conflates a user's opinion with the system's
reasoning, leading to explanations that may be fluent but fail to reflect the
true logic behind recommendations. In this work, we revisit the core objective
of explainable recommendation: to transparently communicate why an item is
recommended by linking user needs to relevant item features. Through a
comprehensive analysis of existing methods across multiple benchmark datasets,
we identify common limitations-explanations that are weakly aligned with model
predictions, vague or inaccurate in identifying user intents, and overly
repetitive or generic. To overcome these challenges, we propose FIRE, a
lightweight and interpretable framework that combines SHAP-based feature
attribution with structured, prompt-driven language generation. FIRE produces
faithful, diverse, and user-aligned explanations, grounded in the actual
decision-making process of the model. Our results demonstrate that FIRE not
only achieves competitive recommendation accuracy but also significantly
improves explanation quality along critical dimensions such as alignment,
structure, and faithfulness. This work highlights the need to move beyond the
review-as-explanation paradigm and toward explanation methods that are both
accountable and interpretable.

</details>


### [84] [Difference Views for Visual Graph Query Building](https://arxiv.org/abs/2508.05314)
*Benedikt Kantz,Stefan Lengauer,Peter Waldert,Tobias Schreck*

Main category: cs.IR

TL;DR: 开发了一种可视化查询系统，支持用户通过图差异和自然语言表达方式进行迭代式知识图谱查询，促进数据探索和分析。


<details>
  <summary>Details</summary>
Motivation: 解决用户在构建SPARQL查询时的迭代变化难以直观理解和表达的问题。

Method: 设计集成图差异显示与自然语言交互的可视化界面，结合实例验证系统效果。

Result: 系统成功地支持用户在探索过程中方便地观察查询变化，提升了知识图谱的可用性与分析能力。

Conclusion: 通过差异可视化和自然语言接口，增强了非专家用户在知识图谱查询中的交互体验和探索效率。

Abstract: Knowledge Graphs (KGs) contain vast amounts of linked resources that encode
knowledge in various domains, which can be queried and searched for using
specialized languages like SPARQL, a query language developed to query KGs.
Existing visual query builders enable non-expert users to construct SPARQL
queries and utilize the knowledge contained in these graphs. Query building is,
however, an iterative and, often, visual process where the question of the user
can change and differ throughout the process, especially for explorative
search. Our visual querying interface communicates these change between
iterative steps in the query building process using graph differences to
contrast the changes and the evolution in the graph query. We also enable users
to formulate their evolving information needs using a natural language
interface directly integrated into the difference query view. We, furthermore,
communicate the change in results in the result view by contrasting the
differences in both result distribution and individual instances of the
prototype graph and demonstrate the system's applicability through case studies
on different ontologies and usage scenarios, illustrating how our system
fosters, both, data exploration and analysis of domain-specific graphs.

</details>


### [85] [Multi-Modal Multi-Behavior Sequential Recommendation with Conditional Diffusion-Based Feature Denoising](https://arxiv.org/abs/2508.05352)
*Xiaoxi Cui,Weihai Lu,Yu Tong,Yiheng Li,Zhejun Zhao*

Main category: cs.IR

TL;DR: 提出了一种多模态多行为序列推荐模型（M³BSR），通过噪声去除和兴趣抽取，提升多模态行为推荐的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态多行为序列推荐中对用户偏好刻画不足、隐性噪声难以抑制以及模态噪声影响的问题。

Method: 引入条件扩散模型进行多模态噪声去除，利用深层行为信息指导浅层行为噪声抑制，并采用多专家兴趣抽取层来明确不同模态与行为的兴趣关系。

Result: 在多个基准数据集上，该模型显著优于现有最先进方法。

Conclusion: 该模型有效提升了多模态多行为推荐的准确性，为序列推荐研究提供了新思路。

Abstract: The sequential recommendation system utilizes historical user interactions to
predict preferences. Effectively integrating diverse user behavior patterns
with rich multimodal information of items to enhance the accuracy of sequential
recommendations is an emerging and challenging research direction. This paper
focuses on the problem of multi-modal multi-behavior sequential recommendation,
aiming to address the following challenges: (1) the lack of effective
characterization of modal preferences across different behaviors, as user
attention to different item modalities varies depending on the behavior; (2)
the difficulty of effectively mitigating implicit noise in user behavior, such
as unintended actions like accidental clicks; (3) the inability to handle
modality noise in multi-modal representations, which further impacts the
accurate modeling of user preferences. To tackle these issues, we propose a
novel Multi-Modal Multi-Behavior Sequential Recommendation model (M$^3$BSR).
This model first removes noise in multi-modal representations using a
Conditional Diffusion Modality Denoising Layer. Subsequently, it utilizes deep
behavioral information to guide the denoising of shallow behavioral data,
thereby alleviating the impact of noise in implicit feedback through
Conditional Diffusion Behavior Denoising. Finally, by introducing a
Multi-Expert Interest Extraction Layer, M$^3$BSR explicitly models the common
and specific interests across behaviors and modalities to enhance
recommendation performance. Experimental results indicate that M$^3$BSR
significantly outperforms existing state-of-the-art methods on benchmark
datasets.

</details>


### [86] [Does Multimodality Improve Recommender Systems as Expected? A Critical Analysis and Future Directions](https://arxiv.org/abs/2508.05377)
*Hongyu Zhou,Yinan Zhang,Aixin Sun,Zhiqi Shen*

Main category: cs.IR

TL;DR: 本文结构化评估多模态推荐系统，分析其在不同场景下的表现，提出有效的集成策略和设计建议。


<details>
  <summary>Details</summary>
Motivation: 探讨多模态数据在推荐系统中的实际效用及其优化方案。

Method: 提出评估框架，基于多平台、模型对比分析多模态数据的影响。

Result: 多模态数据在稀疏交互和召回阶段效果显著，文本和视觉特征在不同任务中作用不同，集成策略影响模型性能。

Conclusion: 合理选择模态、集成策略和模型规模，有助于构建高效有效的多模态推荐系统。

Abstract: Multimodal recommendation systems are increasingly popular for their
potential to improve performance by integrating diverse data types. However,
the actual benefits of this integration remain unclear, raising questions about
when and how it truly enhances recommendations. In this paper, we propose a
structured evaluation framework to systematically assess multimodal
recommendations across four dimensions: Comparative Efficiency, Recommendation
Tasks, Recommendation Stages, and Multimodal Data Integration. We benchmark a
set of reproducible multimodal models against strong traditional baselines and
evaluate their performance on different platforms. Our findings show that
multimodal data is particularly beneficial in sparse interaction scenarios and
during the recall stage of recommendation pipelines. We also observe that the
importance of each modality is task-specific, where text features are more
useful in e-commerce and visual features are more effective in short-video
recommendations. Additionally, we explore different integration strategies and
model sizes, finding that Ensemble-Based Learning outperforms Fusion-Based
Learning, and that larger models do not necessarily deliver better results. To
deepen our understanding, we include case studies and review findings from
other recommendation domains. Our work provides practical insights for building
efficient and effective multimodal recommendation systems, emphasizing the need
for thoughtful modality selection, integration strategies, and model design.

</details>


### [87] [On the Reliability of Sampling Strategies in Offline Recommender Evaluation](https://arxiv.org/abs/2508.05398)
*Bruno L. Pereira,Alan Said,Rodrygo L. T. Santos*

Main category: cs.IR

TL;DR: 研究了离线评估中的偏差对模型比较的影响，并提供了选择策略的建议。


<details>
  <summary>Details</summary>
Motivation: 离线评估在推荐系统中重要，但受到曝光偏差和采样偏差的影响，影响评估的可靠性。

Method: 采用完全观察数据模拟曝光偏差，系统评估不同采样策略的表现。

Result: 发现采样策略在不同条件下会不同程度扭曲评估结果，提出了实用的策略选择指南。

Conclusion: 合理的采样策略可以提升离线评估的真实性和鲁棒性，改善模型比较的可靠性。

Abstract: Offline evaluation plays a central role in benchmarking recommender systems
when online testing is impractical or risky. However, it is susceptible to two
key sources of bias: exposure bias, where users only interact with items they
are shown, and sampling bias, introduced when evaluation is performed on a
subset of logged items rather than the full catalog. While prior work has
proposed methods to mitigate sampling bias, these are typically assessed on
fixed logged datasets rather than for their ability to support reliable model
comparisons under varying exposure conditions or relative to true user
preferences. In this paper, we investigate how different combinations of
logging and sampling choices affect the reliability of offline evaluation.
Using a fully observed dataset as ground truth, we systematically simulate
diverse exposure biases and assess the reliability of common sampling
strategies along four dimensions: sampling resolution (recommender model
separability), fidelity (agreement with full evaluation), robustness (stability
under exposure bias), and predictive power (alignment with ground truth). Our
findings highlight when and how sampling distorts evaluation outcomes and offer
practical guidance for selecting strategies that yield faithful and robust
offline comparisons.

</details>


### [88] [RankArena: A Unified Platform for Evaluating Retrieval, Reranking and RAG with Human and LLM Feedback](https://arxiv.org/abs/2508.05512)
*Abdelrahman Abdallah,Mahmoud Abdalla,Bhawna Piryani,Jamshid Mozafari,Mohammed Ali,Adam Jatowt*

Main category: cs.IR

TL;DR: 介绍RankArena平台，用于多角度评估和分析检索增强生成系统和文档重排序系统，支持多种评估方式和数据收集，促进模型优化。


<details>
  <summary>Details</summary>
Motivation: 当前评估检索增强生成和重排序系统缺乏高效、用户导向的工具，难以全面衡量系统性能。

Method: 构建一个支持多评估模式、多反馈形式及LLM评判的统一平台，集成数据收集与分析功能，方便模型训练与优化。

Result: 平台实现了多种评估功能，包括可视化、偏好对比、注释和质量评估，支持人类与LLM的比较，数据可用于模型训练。

Conclusion: RankArena为检索系统评价提供了全面、细粒度的工具，提升系统优化效果，已在公开平台提供。

Abstract: Evaluating the quality of retrieval-augmented generation (RAG) and document
reranking systems remains challenging due to the lack of scalable,
user-centric, and multi-perspective evaluation tools. We introduce RankArena, a
unified platform for comparing and analysing the performance of retrieval
pipelines, rerankers, and RAG systems using structured human and LLM-based
feedback as well as for collecting such feedback. RankArena supports multiple
evaluation modes: direct reranking visualisation, blind pairwise comparisons
with human or LLM voting, supervised manual document annotation, and end-to-end
RAG answer quality assessment. It captures fine-grained relevance feedback
through both pairwise preferences and full-list annotations, along with
auxiliary metadata such as movement metrics, annotation time, and quality
ratings. The platform also integrates LLM-as-a-judge evaluation, enabling
comparison between model-generated rankings and human ground truth annotations.
All interactions are stored as structured evaluation datasets that can be used
to train rerankers, reward models, judgment agents, or retrieval strategy
selectors. Our platform is publicly available at https://rankarena.ngrok.io/,
and the Demo video is provided https://youtu.be/jIYAP4PaSSI.

</details>


### [89] [KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation](https://arxiv.org/abs/2508.05633)
*Changle Qu,Sunhao Dai,Ke Guo,Liqin Zhao,Yanan Niu,Xiao Zhang,Jun Xu*

Main category: cs.IR

TL;DR: 介绍了中国快手平台的实时互动数据集KuaiLive，丰富的用户与主播行为数据，为直播推荐系统研究提供了强有力的基准。


<details>
  <summary>Details</summary>
Motivation: 解决直播环境下推荐系统数据缺乏的问题，推动学术研究和算法创新。

Method: 收集并整理了包含多类型行为和丰富特征的直播互动日志数据，进行多角度分析，评估多种推荐算法。

Result: 提供了一个详细的直播推荐数据集和基准，支持多项任务，并促进未来相关研究。

Conclusion: KuaiLive为直播推荐研究提供了珍贵的数据资源，推动行业和学术共同发展。

Abstract: Live streaming platforms have become a dominant form of online content
consumption, offering dynamically evolving content, real-time interactions, and
highly engaging user experiences. These unique characteristics introduce new
challenges that differentiate live streaming recommendation from traditional
recommendation settings and have garnered increasing attention from industry in
recent years. However, research progress in academia has been hindered by the
lack of publicly available datasets that accurately reflect the dynamic nature
of live streaming environments. To address this gap, we introduce KuaiLive, the
first real-time, interactive dataset collected from Kuaishou, a leading live
streaming platform in China with over 400 million daily active users. The
dataset records the interaction logs of 23,772 users and 452,621 streamers over
a 21-day period. Compared to existing datasets, KuaiLive offers several
advantages: it includes precise live room start and end timestamps, multiple
types of real-time user interactions (click, comment, like, gift), and rich
side information features for both users and streamers. These features enable
more realistic simulation of dynamic candidate items and better modeling of
user and streamer behaviors. We conduct a thorough analysis of KuaiLive from
multiple perspectives and evaluate several representative recommendation
methods on it, establishing a strong benchmark for future research. KuaiLive
can support a wide range of tasks in the live streaming domain, such as top-K
recommendation, click-through rate prediction, watch time prediction, and gift
price prediction. Moreover, its fine-grained behavioral data also enables
research on multi-behavior modeling, multi-task learning, and fairness-aware
recommendation. The dataset and related resources are publicly available at
https://imgkkk574.github.io/KuaiLive.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [90] [NAEx: A Plug-and-Play Framework for Explaining Network Alignment](https://arxiv.org/abs/2508.04731)
*Shruti Saxena,Arijit Khan,Joydeep Chandra*

Main category: cs.LG

TL;DR: NAEx是一个用于网络对齐模型的解释框架，通过识别影响预测的关键子图和特征，提升模型的可解释性和信任度。


<details>
  <summary>Details</summary>
Motivation: 现有网络对齐模型缺乏充分的可解释性，限制了其在高风险领域的应用。

Method: 引入可学习的边和特征掩码，优化确保解释的忠实性和可比性，结合结构和特征信息进行解释，支持未知数据的推理。

Result: 在基准数据集上，NAEx展示了其在提升网络对齐模型解释性和效率方面的优越性能，并与多种模型兼容。

Conclusion: NAEx通过结构化和特征掩码技术，有效增强了网络对齐模型的透明性和实用性，为高风险领域的应用提供了可靠的解释工具。

Abstract: Network alignment (NA) identifies corresponding nodes across multiple
networks, with applications in domains like social networks, co-authorship, and
biology. Despite advances in alignment models, their interpretability remains
limited, making it difficult to understand alignment decisions and posing
challenges in building trust, particularly in high-stakes domains. To address
this, we introduce NAEx, a plug-and-play, model-agnostic framework that
explains alignment models by identifying key subgraphs and features influencing
predictions. NAEx addresses the key challenge of preserving the joint
cross-network dependencies on alignment decisions by: (1) jointly
parameterizing graph structures and feature spaces through learnable edge and
feature masks, and (2) introducing an optimization objective that ensures
explanations are both faithful to the original predictions and enable
meaningful comparisons of structural and feature-based similarities between
networks. NAEx is an inductive framework that efficiently generates NA
explanations for previously unseen data. We introduce evaluation metrics
tailored to alignment explainability and demonstrate NAEx's effectiveness and
efficiency on benchmark datasets by integrating it with four representative NA
models.

</details>


### [91] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
*Xiaoqi Dong,Xiangyu Zhou,Nicholas Evans,Yujia Lin*

Main category: cs.LG

TL;DR: LumiGen通过引入LVLM增强的迭代反馈机制，有效提升T2I生成中的细粒度控制和语义一致性，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决T2I模型在复杂指令处理、精细内容控制和深层语义保持方面的不足。

Method: 提出LumiGen框架，结合IPPA模块进行提示增强和IVFR模块作为视觉批评家，通过闭环反馈优化图像。

Result: 在LongBench-T2I基准上获得3.08的平均分，优于现有最先进技术，特别提升了文本渲染和姿态表达。

Conclusion: LVLM的引入提升了T2I生成的控制性和质量，验证了框架的有效性。

Abstract: Text-to-Image (T2I) generation has made significant advancements with
diffusion models, yet challenges persist in handling complex instructions,
ensuring fine-grained content control, and maintaining deep semantic
consistency. Existing T2I models often struggle with tasks like accurate text
rendering, precise pose generation, or intricate compositional coherence.
Concurrently, Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in cross-modal understanding and instruction following. We propose
LumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I
model performance, particularly in areas requiring fine-grained control,
through a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an
Intelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt
enhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which
acts as a "visual critic" to iteratively correct and optimize generated images.
Evaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a
superior average score of 3.08, outperforming state-of-the-art baselines.
Notably, our framework demonstrates significant improvements in critical
dimensions such as text rendering and pose expression, validating the
effectiveness of LVLM integration for more controllable and higher-quality
image generation.

</details>


### [92] [MissMecha: An All-in-One Python Package for Studying Missing Data Mechanisms](https://arxiv.org/abs/2508.04740)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: MissMecha是一个面向缺失数据模拟和评估的开源Python工具包，支持数值和类别特征，帮助用户理解不同缺失机制对数据的影响。


<details>
  <summary>Details</summary>
Motivation: 缺失数据在实际数据集中普遍存在，理解其机制对于数据分析至关重要，但现有工具有限且偏重数值变量，缺乏对异质性数据的支持。

Method: 开发支持多缺失机制（MCAR、MAR、MNAR）的模拟、可视化和评估工具，集成数值和类别特征的支持，实现机制感知的研究功能。

Result: 提供了一个统一的平台，增强了对缺失数据机制的理解和数据质量分析能力，为研究、基准测试和教育提供工具支持。

Conclusion: MissMecha弥补了现有工具的不足，为处理异质性真实世界数据中的缺失问题提供了全面解决方案，促进相关研究和实践的发展。

Abstract: Incomplete data is a persistent challenge in real-world datasets, often
governed by complex and unobservable missing mechanisms. Simulating missingness
has become a standard approach for understanding its impact on learning and
analysis. However, existing tools are fragmented, mechanism-limited, and
typically focus only on numerical variables, overlooking the heterogeneous
nature of real-world tabular data. We present MissMecha, an open-source Python
toolkit for simulating, visualizing, and evaluating missing data under MCAR,
MAR, and MNAR assumptions. MissMecha supports both numerical and categorical
features, enabling mechanism-aware studies across mixed-type tabular datasets.
It includes visual diagnostics, MCAR testing utilities, and type-aware
imputation evaluation metrics. Designed to support data quality research,
benchmarking, and education,MissMecha offers a unified platform for researchers
and practitioners working with incomplete data.

</details>


### [93] [Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)](https://arxiv.org/abs/2508.04745)
*Nan Li,Wanting Yang,Marie Siew,Zehui Xiong,Binbin Chen,Shiwen Mao,Kwok-Yan Lam*

Main category: cs.LG

TL;DR: 提出了一种面向边缘设备的层次化联邦聚合框架，通过参数高效微调和聚类提高个性化和效率，同时保障数据隐私。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备上生成模型的高计算成本、隐私保护和多用户个性化需求。

Method: 采用基于Low-Rank Adaptation的本地微调，利用客户聚类实现个性化增强，并在服务器端进行跨簇知识交互。

Result: 验证了该框架在加快收敛速度和提升多用户个性化AIGC服务方面的有效性，兼顾隐私和资源约束。

Conclusion: 提出的架构有效结合联邦学习与参数高效微调，推动边缘内容生成的实际应用与扩展。

Abstract: Diffusion models (DMs) have emerged as powerful tools for high-quality
content generation, yet their intensive computational requirements for
inference pose challenges for resource-constrained edge devices. Cloud-based
solutions aid in computation but often fall short in addressing privacy risks,
personalization efficiency, and communication costs in multi-user edge-AIGC
scenarios. To bridge this gap, we first analyze existing edge-AIGC applications
in personalized content synthesis, revealing their limitations in efficiency
and scalability. We then propose a novel cluster-aware hierarchical federated
aggregation framework. Based on parameter-efficient local fine-tuning via
Low-Rank Adaptation (LoRA), the framework first clusters clients based on the
similarity of their uploaded task requirements, followed by an intra-cluster
aggregation for enhanced personalization at the server-side. Subsequently, an
inter-cluster knowledge interaction paradigm is implemented to enable
hybrid-style content generation across diverse clusters.Building upon federated
learning (FL) collaboration, our framework simultaneously trains personalized
models for individual users at the devices and a shared global model enhanced
with multiple LoRA adapters on the server,enabling efficient edge inference;
meanwhile, all prompts for clustering and inference are encoded prior to
transmission, thereby further mitigating the risk of plaintext leakage. Our
evaluations demonstrate that the framework achieves accelerated convergence
while maintaining practical viability for scalable multi-user personalized AIGC
services under edge constraints.

</details>


### [94] [A Foundational Multi-Modal Model for Few-Shot Learning](https://arxiv.org/abs/2508.04746)
*Pengtao Dang,Tingbo Guo,Sha Cao,Chi Zhang*

Main category: cs.LG

TL;DR: 提出了一种通过大规模多模态模型（LMMM）增强少样本学习（FSL）性能的方法，包括构建多模态少样本数据集（M3FD）和设计FSL框架（M3F），用于科学数据类型多样的应用，显著优于传统元学习方法。


<details>
  <summary>Details</summary>
Motivation: 解决科学领域少样本数据问题，提升FSL模型的泛化能力，推动LMMM在数据有限环境中的应用。

Method: 训练于多任务、多域、多模态的LMMM，构建多模态少样本数据集，并开发支持多数据类型的FSL框架（M3F），通过微调提升模型性能。

Result: 在多个少样本任务中，所提出的LMMM优于传统元学习模型，实验证明其在科学领域的实用潜力。

Conclusion: 多模态大模型结合定制化FSL框架，可有效突破数据限制，促进科学研究中的少样本学习应用，具有广泛推广价值。

Abstract: Few-shot learning (FSL) is a machine learning paradigm that aims to
generalize models from a small number of labeled examples, typically fewer than
10 per class. FSL is particularly crucial in biomedical, environmental,
materials, and mechanical sciences, where samples are limited and data
collection is often prohibitively costly, time-consuming, or ethically
constrained. In this study, we present an innovative approach to FSL by
demonstrating that a Large Multi-Modal Model (LMMM), trained on a set of
independent tasks spanning diverse domains, task types, and input modalities,
can substantially improve the generalization of FSL models, outperforming
models based on conventional meta-learning on tasks of the same type. To
support this, we first constructed a Multi-Modal Model Few-shot Dataset (M3FD,
over 10K+ few-shot samples), which includes 2D RGB images, 2D/3D medical scans,
tabular and time-course datasets, from which we manually curated FSL tasks such
as classification. We further introduced M3F (Multi-Modal Model for Few-shot
learning framework), a novel Large Multi-Modal Model framework tailored for
data-constrained scientific applications. M3F supports a wide range of
scientific data types through a modular pipeline. By fine-tuning the model on
M3FD, M3F improves model performance, making LMMM feasible for real-world FSL
deployment. The source code is located at https://github.com/ptdang1001/M3F. To
democratize access to complex FSL data and promote reproducibility for public
usage, M3FD is paired with a flexible and user-friendly tool that enables
efficient querying, task-specific sampling, and preprocessing. Together, our
dataset and framework offer a unified, scalable solution that significantly
lowers the barrier to applying LMMMs in data-scarce scientific domains.

</details>


### [95] [AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models](https://arxiv.org/abs/2508.04748)
*Xuan Lin,Long Chen,Yile Wang*

Main category: cs.LG

TL;DR: 提出了一种基于属性引导的强化学习框架AttriLens-Mol，用于通过大语言模型改进分子性质预测。该方法通过奖励机制优化模型推理中的属性相关性，显著提升了模型性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 弥补当前LLMs在分子性质预测中依赖人类设定提示与链式推理模板的不足，提升模型推理的相关性和效率。

Method: 引入奖励机制引导模型生成结构化属性，通过格式、计数、合理性奖励，利用强化学习优化推理过程。

Result: 在多个数据集上，显著提升不同规模LLMs的预测性能，超越部分微调模型和先进模型，同时改善模型的解释能力。

Conclusion: AttriLens-Mol通过引导模型关注相关分子属性，不仅提升预测性能，还增强了模型的可解释性，具有推广价值。

Abstract: Large Language Models (LLMs) have shown promise in assisting molecular
property prediction tasks but often rely on human-crafted prompts and
chain-of-thought templates. While recent advanced large reasoning models like
DeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,
their reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,
an attribute-guided reinforcement learning framework for molecular property
prediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)
a format reward encouraging attribute-based structured output, (2) a count
reward to avoid enumerating irrelevant attributes, and (3) a rationality reward
using advanced LLMs and RDKit to verify the relatedness of the generated
attributes. This approach implicitly elicits the model's inherent knowledge of
relevant molecular attributes during reasoning, enables making predictions for
the molecular property more effectively. Experiments on both in-distribution
and out-of-distribution datasets show that, training both 7B-size
R1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our
proposed AttriLens-Mol method significantly boosts the performance, getting
comparable or better results than supervised fine-tuning models
(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,
DeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the
target property, when used as features for an interpretable decision tree
model, yield superior performance compared to attributes generated by prompting
LLMs. This shows that AttriLens-Mol effectively elicits more relevant and
predictive molecular attributes, leading to enhanced interpretability and
performance for property prediction. We release the code in
https://github.com/szu-tera/AttriLens-Mol.

</details>


### [96] [PA-RNet: Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting](https://arxiv.org/abs/2508.04750)
*Chanjuan Liu,Shengzhi Wang,Enqiang Zhu*

Main category: cs.LG

TL;DR: PA-RNet通过引入扰动感知机制，有效增强多模态时间序列预测模型在噪声扰动下的鲁棒性，特别是在文本模态中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多模态时间序列中文本模态受干扰影响模型性能的问题。

Method: 提出扰动感知投影模块和跨模态注意机制，结合理论分析和文本扰动生成管道，增强模型稳健性。

Result: 在多个领域和时间设置中，PA-RNet优于现有最优方法，展现出强大的鲁棒性与适应性。

Conclusion: 该方法有效应对文本噪声干扰，为多模态预测提供了稳健的解决方案。

Abstract: In real-world applications, multimodal time series data often suffer from
interference, especially in the textual modality. Existing methods for
multimodal time series forecasting often neglect the inherent perturbations
within textual data, where irrelevant, noisy, or ambiguous content can
significantly degrade model performance, particularly when the noise exhibits
varying intensity or stems from structural inconsistencies. To address this
challenge, we propose PA-RNet (Perturbation-Aware Reasoning Network for
Multimodal Time Series Forecasting), a robust multimodal forecasting framework.
PA-RNet features a perturbation-aware projection module and a cross-modal
attention mechanism to effectively separate noise from the textual embeddings
while maintaining semantically meaningful representations, thereby enhancing
the model's generalization ability. Theoretically, we establish the Lipschitz
continuity of PA-RNet with respect to textual inputs and prove that the
proposed perturbation module can reduce expected prediction error, offering
strong guarantees of stability under noisy conditions. Furthermore, we
introduce a textual perturbation pipeline that can be seamlessly incorporated
into existing multimodal time series forecasting tasks, allowing for systematic
evaluation of the model's robustness in the presence of varying levels of
textual noise. Extensive experiments across diverse domains and temporal
settings demonstrate that PA-RNet consistently outperforms state-of-the-art
baselines.

</details>


### [97] [InfoQ: Mixed-Precision Quantization via Global Information Flow](https://arxiv.org/abs/2508.04753)
*Mehmet Emre Akbulut,Hazem Hesham Yousef Shalby,Fabrizio Pittorino,Manuel Roveri*

Main category: cs.LG

TL;DR: 提出InfoQ框架，通过测量量化对信息流的影响，优化多精度量化，减少搜索成本且提升准确率。


<details>
  <summary>Details</summary>
Motivation: 资源受限设备上深度神经网络部署需要高效的多比特宽度优化，现有方法计算成本高或无法全面捕捉量化误差影响。

Method: 使用单次前向传递测量量化对信息流的影响，将比特宽度分配问题转化为整数线性规划，避免重训练。

Result: 实现快速高效的搜索，提升模型压缩比下的准确率，特别在MobileNetV2和ResNet18上获得显著性能提升。

Conclusion: InfoQ通过信息流影响评估，提供一种高效且效果优越的混合精度量化策略，有助于资源有限场景的模型部署。

Abstract: Mixed-precision quantization (MPQ) is crucial for deploying deep neural
networks on resource-constrained devices, but finding the optimal bit-width for
each layer represents a complex combinatorial optimization problem. Current
state-of-the-art methods rely on computationally expensive search algorithms or
local sensitivity heuristic proxies like the Hessian, which fail to capture the
cascading global effects of quantization error. In this work, we argue that the
quantization sensitivity of a layer should not be measured by its local
properties, but by its impact on the information flow throughout the entire
network. We introduce InfoQ, a novel framework for MPQ that is training-free in
the bit-width search phase. InfoQ assesses layer sensitivity by quantizing each
layer at different bit-widths and measuring, through a single forward pass, the
resulting change in mutual information in the subsequent layers. This
quantifies how much each layer quantization impacts the network information
flow. The resulting scores are used to formulate bit-width allocation as an
integer linear programming problem, which is solved efficiently to minimize
total sensitivity under a given budget (e.g., model size or BitOps). Our
retraining-free search phase provides a superior search-time/accuracy trade-off
(using two orders of magnitude less data compared to state-of-the-art methods
such as LIMPQ), while yielding up to a 1% accuracy improvement for MobileNetV2
and ResNet18 on ImageNet at high compression rates (14X and 10.66X).

</details>


### [98] [Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle](https://arxiv.org/abs/2508.04755)
*Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: 本文探讨利用大型语言模型（LLMs）在糖尿病治疗中的应用潜力与挑战，比较其零-shot性能与传统RL方法，并指出模型在临床决策中的局限性，强调谨慎融合的必要性。


<details>
  <summary>Details</summary>
Motivation: 旨在探索无须额外训练、通过提示引入临床知识的LLMs在动态治疗决策中的可能性，以简化复杂的临床决策支持系统开发。

Method: 在糖尿病模拟器中测试不同规模的开源LLMs作为胰岛素剂量调节代理，比较其零-shot推理表现与专门训练的小型神经网络RL代理，分析其临床表现和局限。

Result: 较小的LLMs在稳定患者群中表现媲美甚至优于训练充分的RL代理，但存在过度用药、逻辑不一致等缺陷，加入显式推理信息效果有限。

Conclusion: LLMs在临床决策中具有潜力，但需合理提示设计、严格验证，并结合结构化生理模型实现更安全有效的应用。

Abstract: Reinforcement learning (RL)-based dynamic treatment regimes (DTRs) hold
promise for automating complex clinical decision-making, yet their practical
deployment remains hindered by the intensive engineering required to inject
clinical knowledge and ensure patient safety. Recent advancements in large
language models (LLMs) suggest a complementary approach, where implicit prior
knowledge and clinical heuristics are naturally embedded through linguistic
prompts without requiring environment-specific training. In this study, we
rigorously evaluate open-source LLMs as dynamic insulin dosing agents in an in
silico Type 1 diabetes simulator, comparing their zero-shot inference
performance against small neural network-based RL agents (SRAs) explicitly
trained for the task. Our results indicate that carefully designed zero-shot
prompts enable smaller LLMs (e.g., Qwen2.5-7B) to achieve comparable or
superior clinical performance relative to extensively trained SRAs,
particularly in stable patient cohorts. However, LLMs exhibit notable
limitations, such as overly aggressive insulin dosing when prompted with
chain-of-thought (CoT) reasoning, highlighting critical failure modes including
arithmetic hallucination, temporal misinterpretation, and inconsistent clinical
logic. Incorporating explicit reasoning about latent clinical states (e.g.,
meals) yielded minimal performance gains, underscoring the current model's
limitations in capturing complex, hidden physiological dynamics solely through
textual inference. Our findings advocate for cautious yet optimistic
integration of LLMs into clinical workflows, emphasising the necessity of
targeted prompt engineering, careful validation, and potentially hybrid
approaches that combine linguistic reasoning with structured physiological
modelling to achieve safe, robust, and clinically effective decision-support
systems.

</details>


### [99] [Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration](https://arxiv.org/abs/2508.04780)
*Lin Jiang,Dahai Yu,Rongchao Xu,Tian Tang,Guang Wang*

Main category: cs.LG

TL;DR: 提出一种考虑公平性和效率的电力恢复策略，通过新颖的预测-优化框架，提高恢复速度与公平性。


<details>
  <summary>Details</summary>
Motivation: 应对极端天气频发下的电力系统恢复不公平问题，特别是弱势社区的低请求提交量导致的恢复不公。

Method: 结合公平调节分位数回归与空间-时间注意力强化学习，构建预测-优化框架EPOPR，实现高效且公平的电力恢复决策。

Result: 实验证明EPOPR在缩短平均停电时间和减少社区间不公平方面优于现有方法，分别提高3.60%和减少14.19%的不平等。

Conclusion: 提出的EPOPR框架在应对不确定性和实现公平恢复方面具有显著优势，为极端天气背景下的电力系统恢复提供了有效解决方案。

Abstract: The increasing frequency of extreme weather events, such as hurricanes,
highlights the urgent need for efficient and equitable power system
restoration. Many electricity providers make restoration decisions primarily
based on the volume of power restoration requests from each region. However,
our data-driven analysis reveals significant disparities in request submission
volume, as disadvantaged communities tend to submit fewer restoration requests.
This disparity makes the current restoration solution inequitable, leaving
these communities vulnerable to extended power outages. To address this, we aim
to propose an equity-aware power restoration strategy that balances both
restoration efficiency and equity across communities. However, achieving this
goal is challenging for two reasons: the difficulty of predicting repair
durations under dataset heteroscedasticity, and the tendency of reinforcement
learning agents to favor low-uncertainty actions, which potentially undermine
equity. To overcome these challenges, we design a predict-then-optimize
framework called EPOPR with two key components: (1) Equity-Conformalized
Quantile Regression for uncertainty-aware repair duration prediction, and (2)
Spatial-Temporal Attentional RL that adapts to varying uncertainty levels
across regions for equitable decision-making. Experimental results show that
our EPOPR effectively reduces the average power outage duration by 3.60% and
decreases inequity between different communities by 14.19% compared to
state-of-the-art baselines.

</details>


### [100] [Federated Continual Recommendation](https://arxiv.org/abs/2508.04792)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Seongjin Choi,Dongha Kim,Hwanjo Yu*

Main category: cs.LG

TL;DR: 本文提出了F3CRec，一个结合联邦学习与连续学习的推荐框架，有效应对数据非平稳性与隐私保护的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现有联邦推荐系统在非平稳数据流和动态用户偏好变化中的性能不足，以及连续学习在隐私保护限制下的应用困难。

Method: 引入适应性重放记忆与项级时间均值，设计F3CRec框架，实现知识保留与新知识学习的平衡。

Result: 实验显示F3CRec在多时段环境下优于现有方法，有效提升推荐质量的持续性。

Conclusion: F3CRec成功融合联邦与连续学习，为隐私保护下的动态推荐提供了新的解决方案。

Abstract: The increasing emphasis on privacy in recommendation systems has led to the
adoption of Federated Learning (FL) as a privacy-preserving solution, enabling
collaborative training without sharing user data. While Federated
Recommendation (FedRec) effectively protects privacy, existing methods struggle
with non-stationary data streams, failing to maintain consistent recommendation
quality over time. On the other hand, Continual Learning Recommendation (CLRec)
methods address evolving user preferences but typically assume centralized data
access, making them incompatible with FL constraints. To bridge this gap, we
introduce Federated Continual Recommendation (FCRec), a novel task that
integrates FedRec and CLRec, requiring models to learn from streaming data
while preserving privacy. As a solution, we propose F3CRec, a framework
designed to balance knowledge retention and adaptation under the strict
constraints of FCRec. F3CRec introduces two key components: Adaptive Replay
Memory on the client side, which selectively retains past preferences based on
user-specific shifts, and Item-wise Temporal Mean on the server side, which
integrates new knowledge while preserving prior information. Extensive
experiments demonstrate that F3CRec outperforms existing approaches in
maintaining recommendation quality over time in a federated environment.

</details>


### [101] [HCRide: Harmonizing Passenger Fairness and Driver Preference for Human-Centered Ride-Hailing](https://arxiv.org/abs/2508.04811)
*Lin Jiang,Yu Yang,Guang Wang*

Main category: cs.LG

TL;DR: 设计了HCRide系统，利用多智能体强化学习平衡乘客公平、司机偏好与系统效率，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了在拼车派单系统中兼顾乘客公平、司机偏好与系统效率，解决优化目标间的潜在冲突。

Method: 提出HCRide系统，基于新颖的Habic多智能体强化学习算法，包括竞争机制、动态Actor网络和双Critic网络。

Result: 在深圳和纽约的真实数据集上测试，HCRide在系统效率、乘客公平和司机偏好方面均优于最先进的基线方法。

Conclusion: HCRide有效融合多目标优化，为人性化的拼车调度提供了新思路。

Abstract: Order dispatch systems play a vital role in ride-hailing services, which
directly influence operator revenue, driver profit, and passenger experience.
Most existing work focuses on improving system efficiency in terms of operator
revenue, which may cause a bad experience for both passengers and drivers.
Hence, in this work, we aim to design a human-centered ride-hailing system by
considering both passenger fairness and driver preference without compromising
the overall system efficiency. However, it is nontrivial to achieve this target
due to the potential conflicts between passenger fairness and driver preference
since optimizing one may sacrifice the other. To address this challenge, we
design HCRide, a Human-Centered Ride-hailing system based on a novel
multi-agent reinforcement learning algorithm called Harmonization-oriented
Actor-Bi-Critic (Habic), which includes three major components (i.e., a
multi-agent competition mechanism, a dynamic Actor network, and a Bi-Critic
network) to optimize system efficiency and passenger fairness with driver
preference consideration. We extensively evaluate our HCRide using two
real-world ride-hailing datasets from Shenzhen and New York City. Experimental
results show our HCRide effectively improves system efficiency by 2.02%,
fairness by 5.39%, and driver preference by 10.21% compared to state-of-the-art
baselines.

</details>


### [102] [Unified Flow Matching for Long Horizon Event Forecasting](https://arxiv.org/abs/2508.04843)
*Xiao Shou*

Main category: cs.LG

TL;DR: 提出了一种非自回归的流匹配框架，用于长序列事件预测，在多个实际任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 解决传统自回归神经网络在长时间跨度事件预测中的效率低下和误差累积问题。

Method: 通过连续和离散流匹配，建立统一模型，实现事件时间和类型的联合非自回归建模。

Result: 在六个实际数据集上显著优于传统方法，提升了准确性和生成效率。

Conclusion: 该方法有效突破了长序列事件预测的瓶颈，为相关应用提供了更高效的解决方案。

Abstract: Modeling long horizon marked event sequences is a fundamental challenge in
many real-world applications, including healthcare, finance, and user behavior
modeling. Existing neural temporal point process models are typically
autoregressive, predicting the next event one step at a time, which limits
their efficiency and leads to error accumulation in long-range forecasting. In
this work, we propose a unified flow matching framework for marked temporal
point processes that enables non-autoregressive, joint modeling of inter-event
times and event types, via continuous and discrete flow matching. By learning
continuous-time flows for both components, our method generates coherent long
horizon event trajectories without sequential decoding. We evaluate our model
on six real-world benchmarks and demonstrate significant improvements over
autoregressive and diffusion-based baselines in both accuracy and generation
efficiency.

</details>


### [103] [Multi-Stage Knowledge-Distilled VGAE and GAT for Robust Controller-Area-Network Intrusion Detection](https://arxiv.org/abs/2508.04845)
*Robert Frenken,Sidra Ghayour Bhatti,Hanqin Zhang,Qadeer Ahmed*

Main category: cs.LG

TL;DR: 提出一种结合Variational Graph Autoencoder和知识蒸馏图注意网络的多阶段车载CAN入侵检测框架，有效提升检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有CAN协议缺乏安全性，容易受到网络攻击，需要有效的检测方法。

Method: 采用VGAE进行结构异常检测，再用KD-GAT进行攻击分类，并通过知识蒸馏实现模型压缩。

Result: 在六个公开数据集上实现了96%的参数减少和16.2%的F1-score提升，特别对不平衡数据表现出色。

Conclusion: 结合无监督和监督学习的方法能够显著提升车载CAN网络的入侵检测效果，具有实际应用潜力。

Abstract: The Controller Area Network (CAN) protocol is a standard for in-vehicle
communication but remains susceptible to cyber-attacks due to its lack of
built-in security. This paper presents a multi-stage intrusion detection
framework leveraging unsupervised anomaly detection and supervised graph
learning tailored for automotive CAN traffic. Our architecture combines a
Variational Graph Autoencoder (VGAE) for structural anomaly detection with a
Knowledge-Distilled Graph Attention Network (KD-GAT) for robust attack
classification. CAN bus activity is encoded as graph sequences to model
temporal and relational dependencies. The pipeline applies VGAE-based selective
undersampling to address class imbalance, followed by GAT classification with
optional score-level fusion. The compact student GAT achieves 96% parameter
reduction compared to the teacher model while maintaining strong predictive
performance. Experiments on six public CAN intrusion datasets--Car-Hacking,
Car-Survival, and can-train-and-test--demonstrate competitive accuracy and
efficiency, with average improvements of 16.2% in F1-score over existing
methods, particularly excelling on highly imbalanced datasets with up to 55%
F1-score improvements.

</details>


### [104] [Bidding-Aware Retrieval for Multi-Stage Consistency in Online Advertising](https://arxiv.org/abs/2508.05206)
*Bin Liu,Yunfei Liu,Ziru Xu,Zhaoyu Zhou,Zhi Kou,Yeqiu Yang,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: 提出了一种Bidding-Aware Retrieval (BAR)框架，结合广告竞价信息以提高广告检索的相关性和平台收益。


<details>
  <summary>Details</summary>
Motivation: 因自动出价策略导致的检索阶段与排序阶段不一致，影响平台收益。

Method: 引入单调性约束学习、多任务蒸馏、异步近线推理及任务注意力优化特征交互。

Result: 在阿里巴巴平台实现，平台收入增加4.32%，广告曝光提升22.2%。

Conclusion: BAR通过整合竞价信息解决多阶段不一致问题，有效提升广告效果和平台收益。

Abstract: Online advertising systems typically use a cascaded architecture to manage
massive requests and candidate volumes, where the ranking stages allocate
traffic based on eCPM (predicted CTR $\times$ Bid). With the increasing
popularity of auto-bidding strategies, the inconsistency between the
computationally sensitive retrieval stage and the ranking stages becomes more
pronounced, as the former cannot access precise, real-time bids for the vast ad
corpus. This discrepancy leads to sub-optimal platform revenue and advertiser
outcomes. To tackle this problem, we propose Bidding-Aware Retrieval (BAR), a
model-based retrieval framework that addresses multi-stage inconsistency by
incorporating ad bid value into the retrieval scoring function. The core
innovation is Bidding-Aware Modeling, incorporating bid signals through
monotonicity-constrained learning and multi-task distillation to ensure
economically coherent representations, while Asynchronous Near-Line Inference
enables real-time updates to the embedding for market responsiveness.
Furthermore, the Task-Attentive Refinement module selectively enhances feature
interactions to disentangle user interest and commercial value signals.
Extensive offline experiments and full-scale deployment across Alibaba's
display advertising platform validated BAR's efficacy: 4.32% platform revenue
increase with 22.2% impression lift for positively-operated advertisements.

</details>


### [105] [Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos](https://arxiv.org/abs/2508.04853)
*Haoyu Zhang,Shihao Zhang,Ian Colbert,Rayan Saab*

Main category: cs.LG

TL;DR: 本文提出了关于PTQ算法OPTQ和Qronos的第一个定量误差界，分析了其误差引入机制，提供了实用的设计建议，增强了算法的理论基础。


<details>
  <summary>Details</summary>
Motivation: 弥补OPTQ缺乏严格理论保证的不足，提升PTQ的理论理解。

Method: 推导非渐近2-范数和无穷范数误差界，分析迭代过程对量化误差的影响，并扩展到Qronos算法。

Result: 获得了针对OPTQ及其变体的量化误差界，提高了对其性能的理解，为算法设计提供了理论依据。

Conclusion: 理论分析加强了OPTQ和Qronos的理解，支持其在深度学习模型中的应用。

Abstract: Post-training quantization (PTQ) has become a crucial tool for reducing the
memory and compute costs of modern deep neural networks, including large
language models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as
GPTQ-has emerged as a leading method due to its computational efficiency and
strong empirical performance. Despite its widespread adoption, however, OPTQ
lacks rigorous quantitative theoretical guarantees. This paper presents the
first quantitative error bounds for both deterministic and stochastic variants
of OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ
algorithm. We analyze how OPTQ's iterative procedure induces quantization error
and derive non-asymptotic 2-norm error bounds that depend explicitly on the
calibration data and a regularization parameter that OPTQ uses. Our analysis
provides theoretical justification for several practical design choices,
including the widely used heuristic of ordering features by decreasing norm, as
well as guidance for selecting the regularization parameter. For the stochastic
variant, we establish stronger infinity-norm error bounds, which enable control
over the required quantization alphabet and are particularly useful for
downstream layers and nonlinearities. Finally, we extend our analysis to
Qronos, providing new theoretical bounds, for both its deterministic and
stochastic variants, that help explain its empirical advantages.

</details>


### [106] [Agnostics: Learning to Code in Any Programming Language via Reinforcement with a Universal Learning Environment](https://arxiv.org/abs/2508.04865)
*Aleksander Boruch-Gruszecki,Yangtian Zi,Zixuan Wu,Tejas Oberoi,Carolyn Jane Anderson,Joydeep Biswas,Arjun Guha*

Main category: cs.LG

TL;DR: Agnostics提出了一种语言无关的后训练流程，基于可验证的奖励机制优化低资源语言代码生成，显著提升多语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 低资源编程语言缺乏训练数据和后训练基础设施，限制了大模型的性能。

Method: 利用LLM重写测试数据，配置通用验证器，通过强化学习优化代码行为，适用于任何语言。

Result: 在Lua、Julia、R、OCaml、Fortran等低资源语言上，Agnostics显著提升模型性能，达到或超越大模型，且流程便捷，支持多模型和多任务。

Conclusion: 提出的通用后训练方法有效解决低资源语言的挑战，为多语言模型的发展提供便捷高效的方案。

Abstract: Large language models (LLMs) already excel at writing code in high-resource
languages such as Python and JavaScript, yet stumble on low-resource languages
that remain essential to science and engineering. Besides the obvious shortage
of pre-training data, post-training itself is a bottleneck: every new language
seems to require new datasets, test harnesses, and reinforcement-learning (RL)
infrastructure.
  We introduce Agnostics, a language-agnostic post-training pipeline that
eliminates this per-language engineering. The key idea is to judge code solely
by its externally observable behavior, so a single verifier can test solutions
written in any language. Concretely, we (i) use an LLM to rewrite existing
unit-test datasets into an I/O format, (ii) supply a short configuration that
tells the verifier how to compile and run a target language, and (iii) apply
reinforcement learning with verifiable rewards (RLVR) in a robust code
execution environment.
  Applied to five low-resource languages--Lua, Julia, R, OCaml, and
Fortran--Agnostics (1) improves Qwen-3 4B to performance that rivals other
16B-70B open-weight models; (2) scales cleanly to larger and diverse model
families (Qwen-3 8B, DeepSeek Coder 6.7B Instruct, Phi 4 Mini); and (3) for
${\le} 16$B parameter models, sets new state-of-the-art pass@1 results on
MultiPL-E and a new multi-language version LiveCodeBench that we introduce.
  We will release the language-agnostic training datasets (Ag-MBPP-X,
Ag-Codeforces-X, Ag-LiveCodeBench-X), training code, and ready-to-use
configurations, making RL post-training in any programming language as simple
as editing a short YAML file.

</details>


### [107] [Hilbert Neural Operator: Operator Learning in the Analytic Signal Domain](https://arxiv.org/abs/2508.04882)
*Saman Pordanesh,Pejman Shahsavari,Hossein Ghadjari*

Main category: cs.LG

TL;DR: 引入Hilbert神经算子（HNO），通过分析信号的解析表示，提高偏微分方程解算的效果，克服频域法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的频域神经算子如FNO在处理周期性信号时效果良好，但存在频域假设的限制，且传统方法忽略了信号的相位和幅值之外的特征，亟需引入更丰富的信号特性以提升表现。

Method: 将输入信号通过Hilbert变换映射到解析信号，提取即时振幅与相位信息，并在此基础上进行光谱卷积操作，以增强对非平稳和因果系统的建模能力。

Result: 提出的HNO结构结合信号的解析表示，预期能更有效建模因果、相位敏感和非平稳系统，增强偏微分方程的求解能力。

Conclusion: HNO有效结合信号处理中的解析信号理论，提供了一种新的神经算子架构，具有潜在的优越表现。

Abstract: Neural operators have emerged as a powerful, data-driven paradigm for
learning solution operators of partial differential equations (PDEs).
State-of-the-art architectures, such as the Fourier Neural Operator (FNO), have
achieved remarkable success by performing convolutions in the frequency domain,
making them highly effective for a wide range of problems. However, this method
has some limitations, including the periodicity assumption of the Fourier
transform. In addition, there are other methods of analysing a signal, beyond
phase and amplitude perspective, and provide us with other useful information
to learn an effective network. We introduce the \textbf{Hilbert Neural Operator
(HNO)}, a new neural operator architecture to address some advantages by
incorporating a strong inductive bias from signal processing. HNO operates by
first mapping the input signal to its analytic representation via the Hilbert
transform, thereby making instantaneous amplitude and phase information
explicit features for the learning process. The core learnable operation -- a
spectral convolution -- is then applied to this Hilbert-transformed
representation. We hypothesize that this architecture enables HNO to model
operators more effectively for causal, phase-sensitive, and non-stationary
systems. We formalize the HNO architecture and provide the theoretical
motivation for its design, rooted in analytic signal theory.

</details>


### [108] [Gaussian mixture layers for neural networks](https://arxiv.org/abs/2508.04883)
*Sinho Chewi,Philippe Rigollet,Yuling Yan*

Main category: cs.LG

TL;DR: 本文提出了一种基于Wasserstein梯度流的Gaussian mixture模型，用于神经网络的训练动力学，成功引入了新的GM层，性能与传统网络相当。


<details>
  <summary>Details</summary>
Motivation: 探索能否直接在概率测度上实现训练动力学，以超越传统的参数化方法。

Method: 结合Gaussian mixture模型和Wasserstein梯度流理论，设计了新的GM层。

Result: 在简单分类任务中，GM层达到了与全连接网络类似的性能，表现出不同的动力学行为。

Conclusion: 引入GM层提供了一种新的神经网络建模与训练方式，具有理论和实践意义。

Abstract: The mean-field theory for two-layer neural networks considers infinitely wide
networks that are linearly parameterized by a probability measure over the
parameter space. This nonparametric perspective has significantly advanced both
the theoretical and conceptual understanding of neural networks, with
substantial efforts made to validate its applicability to networks of moderate
width. In this work, we explore the opposite direction, investigating whether
dynamics can be directly implemented over probability measures. Specifically,
we employ Gaussian mixture models as a flexible and expressive parametric
family of distributions together with the theory of Wasserstein gradient flows
to derive training dynamics for such measures. Our approach introduces a new
type of layer -- the Gaussian mixture (GM) layer -- that can be integrated into
neural network architectures. As a proof of concept, we validate our proposal
through experiments on simple classification tasks, where a GM layer achieves
test performance comparable to that of a two-layer fully connected network.
Furthermore, we examine the behavior of these dynamics and demonstrate
numerically that GM layers exhibit markedly different behavior compared to
classical fully connected layers, even when the latter are large enough to be
considered in the mean-field regime.

</details>


### [109] [Uncertainty Quantification for Surface Ozone Emulators using Deep Learning](https://arxiv.org/abs/2508.04885)
*Kelsey Doerksen,Yuliya Marchetti,Steven Lu,Kevin Bowman,James Montgomery,Kazuyuki Miyazaki,Yarin Gal,Freddie Kalaitzis*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的U-Net架构，用于预测表面臭氧偏差，并通过贝叶斯和分位数回归方法实现不确定性量化，以辅助环境政策制定。


<details>
  <summary>Details</summary>
Motivation: 气污染威胁全球健康，传统模型难以精确预测表面臭氧变化，急需具有解释能力的智能模型来支持决策。

Method: 采用不确定性感知的U-Net架构结合贝叶斯和分位数回归，进行多组分化学数据同化，预测臭氧偏差。

Result: 在北美和欧洲的地区数据中验证了模型的有效性，展示了不同不确定性量化方法的表现差异，并分析了土地利用信息在模型中的作用。

Conclusion: 该深度学习模型具备优良的预测能力和不确定性评估能力，有助于改进臭氧偏差校正，为环境监管和政策提供支持。

Abstract: Air pollution is a global hazard, and as of 2023, 94\% of the world's
population is exposed to unsafe pollution levels. Surface Ozone (O3), an
important pollutant, and the drivers of its trends are difficult to model, and
traditional physics-based models fall short in their practical use for scales
relevant to human-health impacts. Deep Learning-based emulators have shown
promise in capturing complex climate patterns, but overall lack the
interpretability necessary to support critical decision making for policy
changes and public health measures. We implement an uncertainty-aware U-Net
architecture to predict the Multi-mOdel Multi-cOnstituent Chemical data
assimilation (MOMO-Chem) model's surface ozone residuals (bias) using Bayesian
and quantile regression methods. We demonstrate the capability of our
techniques in regional estimation of bias in North America and Europe for June
2019. We highlight the uncertainty quantification (UQ) scores between our two
UQ methodologies and discern which ground stations are optimal and sub-optimal
candidates for MOMO-Chem bias correction, and evaluate the impact of land-use
information in surface ozone residual modeling.

</details>


### [110] [Leveraging Deep Learning for Physical Model Bias of Global Air Quality Estimates](https://arxiv.org/abs/2508.04886)
*Kelsey Doerksen,Yuliya Marchetti,Kevin Bowman,Steven Lu,James Montgomery,Yarin Gal,Freddie Kalaitzis,Kazuyuki Miyazaki*

Main category: cs.LG

TL;DR: 本文提出一种基于二维卷积神经网络的方法，用于改善表面臭氧浓度模型偏差，提升其在北美和欧洲的预测能力，助力环境政策优化。


<details>
  <summary>Details</summary>
Motivation: 空气污染，尤其是表面臭氧，是引发全球疾病和早死的重要环境风险因素，现有模型在城市尺度上改善臭氧预估面临挑战，亟需更精准的算法。

Method: 采用基于二维卷积神经网络的架构，估算模型残差，并结合高分辨率卫星土地利用信息，提升模型的预测性能。

Result: 该方法在北美和欧洲地区表现优越，能更好捕捉模型残差，比传统机器学习方法更有效，并有助于理解城市尺度臭氧偏差的影响因素。

Conclusion: 该研究展现了深度学习在环境科学中的潜力，为改善空气质量模型提供了新的技术途径，有助于环境政策制定。

Abstract: Air pollution is the world's largest environmental risk factor for human
disease and premature death, resulting in more than 6 million permature deaths
in 2019. Currently, there is still a challenge to model one of the most
important air pollutants, surface ozone, particularly at scales relevant for
human health impacts, with the drivers of global ozone trends at these scales
largely unknown, limiting the practical use of physics-based models. We employ
a 2D Convolutional Neural Network based architecture that estimate surface
ozone MOMO-Chem model residuals, referred to as model bias. We demonstrate the
potential of this technique in North America and Europe, highlighting its
ability better to capture physical model residuals compared to a traditional
machine learning method. We assess the impact of incorporating land use
information from high-resolution satellite imagery to improve model estimates.
Importantly, we discuss how our results can improve our scientific
understanding of the factors impacting ozone bias at urban scales that can be
used to improve environmental policy.

</details>


### [111] [Retrieval-Augmented Water Level Forecasting for Everglades](https://arxiv.org/abs/2508.04888)
*Rahuul Rangaraj,Jimeng Shi,Rajendra Paudel,Giri Narasimhan,Yanzhao Wu*

Main category: cs.LG

TL;DR: 引入检索增强预测（RAF）框架，通过检索历史相似水文数据提升水位预测准确性。


<details>
  <summary>Details</summary>
Motivation: 水位预测对于生态系统管理至关重要，但深度学习在水文学中的应用和泛化能力有限。

Method: 结合历史相似水文事件检索，增强模型输入，提高预测效果，无需模型微调。

Result: 在Everglades数据上验证了RAF框架显著提升预测精度。

Conclusion: RAF为环境水文学提供了有效的AI增强方法，推动其在生态管理中的应用。

Abstract: Accurate water level forecasting is crucial for managing ecosystems such as
the Everglades, a subtropical wetland vital for flood mitigation, drought
management, water resource planning, and biodiversity conservation. While
recent advances in deep learning, particularly time series foundation models,
have demonstrated success in general-domain forecasting, their application in
hydrology remains underexplored. Furthermore, they often struggle to generalize
across diverse unseen datasets and domains, due to the lack of effective
mechanisms for adaptation. To address this gap, we introduce
Retrieval-Augmented Forecasting (RAF) into the hydrology domain, proposing a
framework that retrieves historically analogous multivariate hydrological
episodes to enrich the model input before forecasting. By maintaining an
external archive of past observations, RAF identifies and incorporates relevant
patterns from historical data, thereby enhancing contextual awareness and
predictive accuracy without requiring the model for task-specific retraining or
fine-tuning. Furthermore, we explore and compare both similarity-based and
mutual information-based RAF methods. We conduct a comprehensive evaluation on
real-world data from the Everglades, demonstrating that the RAF framework
yields substantial improvements in water level forecasting accuracy. This study
highlights the potential of RAF approaches in environmental hydrology and paves
the way for broader adoption of adaptive AI methods by domain experts in
ecosystem management. The code and data are available at
https://github.com/rahuul2992000/WaterRAF.

</details>


### [112] [Honest and Reliable Evaluation and Expert Equivalence Testing of Automated Neonatal Seizure Detection](https://arxiv.org/abs/2508.04899)
*Jovana Kljajic,John M. O'Toole,Robert Hogan,Tamara Skoric*

Main category: cs.LG

TL;DR: 系统评估了新生儿癫痫发作检测中性能指标的有效性，提出了适合临床的评估标准。


<details>
  <summary>Details</summary>
Motivation: 新生儿癫痫检测的AI模型需要可靠评估以促进临床应用，但现有指标存在偏差和不一致的问题。

Method: 通过实际和模拟癫痫数据，评估常用性能指标、共识策略与人类专家等效性检验，分析受类别不平衡、评级一致性和评级数量影响的指标表现。

Result: 发现Matthews和Pearson相关系数优于AUC，建议使用折叠K的Fleiss一致性指标进行专家等效性测试，推荐报告多项性能指标及多评级Turing测试的结果。

Conclusion: 提出一套全面、严谨的评估框架，有助于新生儿癫痫检测AI模型的临床验证和应用推广。

Abstract: Reliable evaluation of machine learning models for neonatal seizure detection
is critical for clinical adoption. Current practices often rely on inconsistent
and biased metrics, hindering model comparability and interpretability.
Expert-level claims about AI performance are frequently made without rigorous
validation, raising concerns about their reliability. This study aims to
systematically evaluate common performance metrics and propose best practices
tailored to the specific challenges of neonatal seizure detection. Using real
and synthetic seizure annotations, we assessed standard performance metrics,
consensus strategies, and human-expert level equivalence tests under varying
class imbalance, inter-rater agreement, and number of raters. Matthews and
Pearson's correlation coefficients outperformed the area under the curve in
reflecting performance under class imbalance. Consensus types are sensitive to
the number of raters and agreement level among them. Among human-expert level
equivalence tests, the multi-rater Turing test using Fleiss k best captured
expert-level AI performance. We recommend reporting: (1) at least one balanced
metric, (2) Sensitivity, specificity, PPV and NPV, (3) Multi-rater Turing test
results using Fleiss k, and (4) All the above on held-out validation set. This
proposed framework provides an important prerequisite to clinical validation by
enabling a thorough and honest appraisal of AI methods for neonatal seizure
detection.

</details>


### [113] [Sensitivity of Stability: Theoretical & Empirical Analysis of Replicability for Adaptive Data Selection in Transfer Learning](https://arxiv.org/abs/2508.04901)
*Prabhav Singh,Jessica Sorrell*

Main category: cs.LG

TL;DR: 本文提出了迁移学习中结果可复现性的理论框架及量化方法，揭示了采用自适应样本选择策略时的性能与稳健性的权衡关系，并通过大量实验验证了理论。


<details>
  <summary>Details</summary>
Motivation: 随着迁移学习广泛应用，自适应数据选择策略引发对结果可复现性的关注，亟需深入理解其影响机制。

Method: 构建数学框架量化选择敏感性，分析复现失败概率与样本选择策略的关系，进行多策略实证验证，并探讨预训练在降低失败率中的作用。

Result: 高敏感性策略虽提升任务性能，但复现失败率亦增加；预训练显著降低失败率，同时保证性能。

Conclusion: 结果表明应在性能和复现性之间权衡，设计中需引入复现性考量，实现稳健迁移学习。

Abstract: The widespread adoption of transfer learning has revolutionized machine
learning by enabling efficient adaptation of pre-trained models to new domains.
However, the reliability of these adaptations remains poorly understood,
particularly when using adaptive data selection strategies that dynamically
prioritize training examples. We present a comprehensive theoretical and
empirical analysis of replicability in transfer learning, introducing a
mathematical framework that quantifies the fundamental trade-off between
adaptation effectiveness and result consistency. Our key contribution is the
formalization of selection sensitivity ($\Delta_Q$), a measure that captures
how adaptive selection strategies respond to perturbations in training data. We
prove that replicability failure probability: the likelihood that two
independent training runs produce models differing in performance by more than
a threshold, increases quadratically with selection sensitivity while
decreasing exponentially with sample size. Through extensive experiments on the
MultiNLI corpus using six adaptive selection strategies - ranging from uniform
sampling to gradient-based selection - we demonstrate that this theoretical
relationship holds precisely in practice. Our results reveal that highly
adaptive strategies like gradient-based and curriculum learning achieve
superior task performance but suffer from high replicability failure rates,
while less adaptive approaches maintain failure rates below 7%. Crucially, we
show that source domain pretraining provides a powerful mitigation mechanism,
reducing failure rates by up to 30% while preserving performance gains. These
findings establish principled guidelines for practitioners to navigate the
performance-replicability trade-off and highlight the need for
replicability-aware design in modern transfer learning systems.

</details>


### [114] [Advancing Hate Speech Detection with Transformers: Insights from the MetaHate](https://arxiv.org/abs/2508.04913)
*Santosh Chapagain,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: 本文探索了基于Transformer的模型在仇恨言论检测中的应用，使用MetaHate数据集，结果显示ELECTRA表现最佳，但仍面临讽刺、隐晦语言和标签噪声等挑战。


<details>
  <summary>Details</summary>
Motivation: 应对网络仇恨言论的广泛传播及其严重社会影响，亟需开发高效自动检测方法。

Method: 采用多种Transformer模型（如BERT、RoBERTa、GPT-2、ELECTRA）进行微调，在MetaHate数据集上进行评估。

Result: ELECTRA模型在F1得分上达到0.8980，是表现最优的模型，并分析了误判中的主要挑战。

Conclusion: Transformer模型在仇恨言论检测中具有优越性，但仍需解决讽刺、隐晦语言及标签噪声带来的挑战。

Abstract: Hate speech is a widespread and harmful form of online discourse,
encompassing slurs and defamatory posts that can have serious social,
psychological, and sometimes physical impacts on targeted individuals and
communities. As social media platforms such as X (formerly Twitter), Facebook,
Instagram, Reddit, and others continue to facilitate widespread communication,
they also become breeding grounds for hate speech, which has increasingly been
linked to real-world hate crimes. Addressing this issue requires the
development of robust automated methods to detect hate speech in diverse social
media environments. Deep learning approaches, such as vanilla recurrent neural
networks (RNNs), long short-term memory (LSTM), and convolutional neural
networks (CNNs), have achieved good results, but are often limited by issues
such as long-term dependencies and inefficient parallelization. This study
represents the comprehensive exploration of transformer-based models for hate
speech detection using the MetaHate dataset--a meta-collection of 36 datasets
with 1.2 million social media samples. We evaluate multiple state-of-the-art
transformer models, including BERT, RoBERTa, GPT-2, and ELECTRA, with
fine-tuned ELECTRA achieving the highest performance (F1 score: 0.8980). We
also analyze classification errors, revealing challenges with sarcasm, coded
language, and label noise.

</details>


### [115] [ALScope: A Unified Toolkit for Deep Active Learning](https://arxiv.org/abs/2508.04937)
*Chenkai Wu,Yuanyuan Qi,Xiaohao Yang,Jueqing Lu,Gang Liu,Wray Buntine,Lan Du*

Main category: cs.LG

TL;DR: 本文提出了一个名为ALScope的深度主动学习平台，集成多数据集和算法，用于在复杂条件下公平评估DAL性能。


<details>
  <summary>Details</summary>
Motivation: 随着应用复杂度增加，现有DAL算法在面对分布偏移和数据不平衡时表现不佳，亟需统一评估平台。

Method: 构建包含多数据集和算法的DAL平台支持灵活配置，并在不同设定下进行广泛实验。

Result: 发现算法在不同任务和条件下表现差异显著，部分算法在特殊场景下仍有提升空间，而一些算法虽性能优异但耗时较长。

Conclusion: 该平台有助于全面评估DAL算法，推动其在复杂环境中的改进与应用。

Abstract: Deep Active Learning (DAL) reduces annotation costs by selecting the most
informative unlabeled samples during training. As real-world applications
become more complex, challenges stemming from distribution shifts (e.g.,
open-set recognition) and data imbalance have gained increasing attention,
prompting the development of numerous DAL algorithms. However, the lack of a
unified platform has hindered fair and systematic evaluation under diverse
conditions. Therefore, we present a new DAL platform ALScope for classification
tasks, integrating 10 datasets from computer vision (CV) and natural language
processing (NLP), and 21 representative DAL algorithms, including both
classical baselines and recent approaches designed to handle challenges such as
distribution shifts and data imbalance. This platform supports flexible
configuration of key experimental factors, ranging from algorithm and dataset
choices to task-specific factors like out-of-distribution (OOD) sample ratio,
and class imbalance ratio, enabling comprehensive and realistic evaluation. We
conduct extensive experiments on this platform under various settings. Our
findings show that: (1) DAL algorithms' performance varies significantly across
domains and task settings; (2) in non-standard scenarios such as imbalanced and
open-set settings, DAL algorithms show room for improvement and require further
investigation; and (3) some algorithms achieve good performance, but require
significantly longer selection time.

</details>


### [116] [REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation](https://arxiv.org/abs/2508.04946)
*Nameer Hirschkind,Joseph Liu,Mahesh Kumar Nandwana,Xiao Yu*

Main category: cs.LG

TL;DR: 提出一种基于信息论的策略优化方法REINA，以增强SimulST系统的延迟与翻译质量的平衡，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 应对同步语音翻译系统中延迟与质量的权衡挑战。

Method: 引入REINA损失，通过信息理论设计，使用非流式模型训练自适应策略，优化翻译时机。

Result: 在法、斯、德语到英语的翻译中实现了最先进的流式翻译效果，延迟/质量权衡改善达21%。

Conclusion: REINA有效提升SimulST系统的性能，为实用化提供新途径。

Abstract: Simultaneous Speech Translation (SimulST) systems stream in audio while
simultaneously emitting translated text or speech. Such systems face the
significant challenge of balancing translation quality and latency. We
introduce a strategy to optimize this tradeoff: wait for more input only if you
gain information by doing so. Based on this strategy, we present Regularized
Entropy INformation Adaptation (REINA), a novel loss to train an adaptive
policy using an existing non-streaming translation model. We derive REINA from
information theory principles and show that REINA helps push the reported
Pareto frontier of the latency/quality tradeoff over prior works. Utilizing
REINA, we train a SimulST model on French, Spanish and German, both from and
into English. Training on only open source or synthetically generated data, we
achieve state-of-the-art (SOTA) streaming results for models of comparable
size. We also introduce a metric for streaming efficiency, quantitatively
showing REINA improves the latency/quality trade-off by as much as 21% compared
to prior approaches, normalized against non-streaming baseline BLEU scores.

</details>


### [117] [Self-Error Adjustment: Theory and Practice of Balancing Individual Performance and Diversity in Ensemble Learning](https://arxiv.org/abs/2508.04948)
*Rui Zou*

Main category: cs.LG

TL;DR: 提出了一种新的集成学习框架SEA，能够通过自我误差调整实现对准确性和多样性的更精细控制，从而超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统集成方法在准确性与多样性调节上的局限，提供更灵活有效的调节机制。

Method: 将集成误差细分为个体性能和多样性两部分，引入可调参数的损失函数实现精确调节。

Result: 在多个数据集上实验显示，SEA优于现有方法，具有更广的调节范围和更优性能。

Conclusion: SEA实现了对集成性能的更细粒度控制，具有理论优势和实证效果，提升了集成学习的调节能力。

Abstract: Ensemble learning boosts performance by aggregating predictions from multiple
base learners. A core challenge is balancing individual learner accuracy with
diversity. Traditional methods like Bagging and Boosting promote diversity
through randomness but lack precise control over the accuracy-diversity
trade-off. Negative Correlation Learning (NCL) introduces a penalty to manage
this trade-off but suffers from loose theoretical bounds and limited adjustment
range. To overcome these limitations, we propose a novel framework called
Self-Error Adjustment (SEA), which decomposes ensemble errors into two distinct
components: individual performance terms, representing the self-error of each
base learner, and diversity terms, reflecting interactions among learners. This
decomposition allows us to introduce an adjustable parameter into the loss
function, offering precise control over the contribution of each component,
thus enabling finer regulation of ensemble performance. Compared to NCL and its
variants, SEA provides a broader range of effective adjustments and more
consistent changes in diversity. Furthermore, we establish tighter theoretical
bounds for adjustable ensemble methods and validate them through empirical
experiments. Experimental results on several public regression and
classification datasets demonstrate that SEA consistently outperforms baseline
methods across all tasks. Ablation studies confirm that SEA offers more
flexible adjustment capabilities and superior performance in fine-tuning
strategies.

</details>


### [118] [Compressed Decentralized Momentum Stochastic Gradient Methods for Nonconvex Optimization](https://arxiv.org/abs/2508.04950)
*Wei Liu,Anweshit Panda,Ujwal Pandey,Christopher Brissette,Yikang Shen,George M. Slota,Naigang Wang,Jie Chen,Yangyang Xu*

Main category: cs.LG

TL;DR: 提出两种用于非凸随机优化的压缩去中心化算法，结合动量和压缩技术，适用于不同场景，均达到最优收敛率并在深度学习中表现优越。


<details>
  <summary>Details</summary>
Motivation: 旨在解决分散式非凸随机优化中通信成本高和收敛速度慢的问题，通过结合动量和压缩技术提升效率。

Method: 设计了两种算法：一种适用于梯度有界的自适应方法，另一种适用于数据异质性的加重球方法，均采用动量和消息压缩策略。

Result: 两种算法均达到了最优收敛速率，支持线性加速，参数与拓扑无关，且在深度学习任务中显著优于现有方法。

Conclusion: 所提出的两种算法有效结合动量和压缩技术，解决了去中心化优化中的关键难题，展现出较强的理论和实践优势。

Abstract: In this paper, we design two compressed decentralized algorithms for solving
nonconvex stochastic optimization under two different scenarios. Both
algorithms adopt a momentum technique to achieve fast convergence and a
message-compression technique to save communication costs. Though momentum
acceleration and compressed communication have been used in literature, it is
highly nontrivial to theoretically prove the effectiveness of their composition
in a decentralized algorithm that can maintain the benefits of both sides,
because of the need to simultaneously control the consensus error, the
compression error, and the bias from the momentum gradient.
  For the scenario where gradients are bounded, our proposal is a compressed
decentralized adaptive method. To the best of our knowledge, this is the first
decentralized adaptive stochastic gradient method with compressed
communication. For the scenario of data heterogeneity without bounded
gradients, our proposal is a compressed decentralized heavy-ball method, which
applies a gradient tracking technique to address the challenge of data
heterogeneity. Notably, both methods achieve an optimal convergence rate, and
they can achieve linear speed up and adopt topology-independent algorithmic
parameters within a certain regime of the user-specified error tolerance.
Superior empirical performance is observed over state-of-the-art methods on
training deep neural networks (DNNs) and Transformers.

</details>


### [119] [MENDR: Manifold Explainable Neural Data Representations](https://arxiv.org/abs/2508.04956)
*Matthew Chen,Micky Nnamdi,Justin Shao,Andrew Hornback,Hongyun Huang,Ben Tamo,Yishan Zhong,Benoit Marteau,Wenqi Shi,May Dongmei Wang*

Main category: cs.LG

TL;DR: 提出了一种基于滤波器组和黎曼流形Transformer的新型EEG基础模型MENDR，具有良好的可解释性和高效性能，适用于临床应用。


<details>
  <summary>Details</summary>
Motivation: 当前EEG基础模型缺乏透明性和可解释性，难以实现临床应用的可靠性。

Method: 引入基于滤波器组的黎曼流形Transformer架构，学习EEG的对称正定矩阵嵌入，并利用小波包变换多分辨率特征。

Result: 模型在多个临床EEG任务中表现优异，参数少，具备良好的可解释性和信号重建能力。

Conclusion: MENDR在保证性能的同时提升了EEG分析的解释性和实用性，有望推动临床EEG的应用与研究。

Abstract: Foundation models for electroencephalography (EEG) signals have recently
demonstrated success in learning generalized representations of EEGs,
outperforming specialized models in various downstream tasks. However, many of
these models lack transparency in their pretraining dynamics and offer limited
insight into how well EEG information is preserved within their embeddings. For
successful clinical integration, EEG foundation models must ensure transparency
in pretraining, downstream fine-tuning, and the interpretability of learned
representations. Current approaches primarily operate in the temporal domain,
overlooking advancements in digital signal processing that enable the
extraction of deterministic and traceable features, such as wavelet-based
representations. We propose MENDR (Manifold Explainable Neural Data
Representations), a filter bank-based EEG foundation model built on a novel
Riemannian Manifold Transformer architecture to resolve these issues. MENDR
learns symmetric positive definite matrix embeddings of EEG signals and is
pretrained on a large corpus comprising over 4,000 hours of EEG data,
decomposed via discrete wavelet packet transforms into multi-resolution
coefficients. MENDR significantly enhances interpretability by visualizing
symmetric positive definite embeddings as geometric ellipsoids and supports
accurate reconstruction of EEG signals from learned embeddings. Evaluations
across multiple clinical EEG tasks demonstrate that MENDR achieves near
state-of-the-art performance with substantially fewer parameters, underscoring
its potential for efficient, interpretable, and clinically applicable EEG
analysis.

</details>


### [120] [RCUKF: Data-Driven Modeling Meets Bayesian Estimation](https://arxiv.org/abs/2508.04985)
*Kumar Anurag,Kasra Azizi,Francesco Sorrentino,Wenbin Wan*

Main category: cs.LG

TL;DR: 提出了一种融合 reservoir computing 和 unscented Kalman filter 的新框架，用于复杂系统的建模与估计，兼具数据驱动与贝叶斯估计优势。


<details>
  <summary>Details</summary>
Motivation: 解决复杂系统建模困难，提升模型的可靠性和估计精度。

Method: 结合reservoir computing学习系统动力学，使用UKF实时融合传感器数据进行校正。

Result: 在基准问题和实时车辆轨迹估计中表现良好，验证了方法的有效性。

Conclusion: RCUKF为复杂系统建模提供了有效的结合数据驱动和贝叶斯估计的框架，有助于改善高维或混沌系统的状态估计。

Abstract: Accurate modeling is crucial in many engineering and scientific applications,
yet obtaining a reliable process model for complex systems is often
challenging. To address this challenge, we propose a novel framework, reservoir
computing with unscented Kalman filtering (RCUKF), which integrates data-driven
modeling via reservoir computing (RC) with Bayesian estimation through the
unscented Kalman filter (UKF). The RC component learns the nonlinear system
dynamics directly from data, serving as a surrogate process model in the UKF
prediction step to generate state estimates in high-dimensional or chaotic
regimes where nominal mathematical models may fail. Meanwhile, the UKF
measurement update integrates real-time sensor data to correct potential drift
in the data-driven model. We demonstrate RCUKF effectiveness on well-known
benchmark problems and a real-time vehicle trajectory estimation task in a
high-fidelity simulation environment.

</details>


### [121] [Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis](https://arxiv.org/abs/2508.04999)
*Menghua Jiang,Yuxia Lin,Baoliang Chen,Haifeng Hu,Yuncheng Jiang,Sijie Mai*

Main category: cs.LG

TL;DR: 该论文提出一种多关系多模态因果干预模型，利用因果推断技术解决多模态情感分析中的偏差问题，提升模型稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感分析方法容易受到内在和跨模态的虚假相关性影响，导致模型依赖统计捷径而非真实因果关系。

Method: 构建多关系图捕捉模态间关系，使用注意力机制估计和解开因果特征与捷径特征，通过背门调整融合二者，提升模型稳健性。

Result: 在多个标准数据集和分布外测试集上验证，该方法有效抑制偏差，提升性能。

Conclusion: 引入因果干预技术的多关系模型改善了多模态情感分析的偏差问题，增强了模型的泛化能力。

Abstract: Multimodal sentiment analysis (MSA) aims to understand human emotions by
integrating information from multiple modalities, such as text, audio, and
visual data. However, existing methods often suffer from spurious correlations
both within and across modalities, leading models to rely on statistical
shortcuts rather than true causal relationships, thereby undermining
generalization. To mitigate this issue, we propose a Multi-relational
Multimodal Causal Intervention (MMCI) model, which leverages the backdoor
adjustment from causal theory to address the confounding effects of such
shortcuts. Specifically, we first model the multimodal inputs as a
multi-relational graph to explicitly capture intra- and inter-modal
dependencies. Then, we apply an attention mechanism to separately estimate and
disentangle the causal features and shortcut features corresponding to these
intra- and inter-modal relations. Finally, by applying the backdoor adjustment,
we stratify the shortcut features and dynamically combine them with the causal
features to encourage MMCI to produce stable predictions under distribution
shifts. Extensive experiments on several standard MSA datasets and
out-of-distribution (OOD) test sets demonstrate that our method effectively
suppresses biases and improves performance.

</details>


### [122] [R-Zero: Self-Evolving Reasoning LLM from Zero Data](https://arxiv.org/abs/2508.05004)
*Chengsong Huang,Wenhao Yu,Xiaoyang Wang,Hongming Zhang,Zongxia Li,Ruosen Li,Jiaxin Huang,Haitao Mi,Dong Yu*

Main category: cs.LG

TL;DR: R-Zero是一种完全自主的训练框架，通过自我对抗和演化机制，生成并优化训练数据，从而提升大规模语言模型的推理能力，无需人类预先设计任务和标签。


<details>
  <summary>Details</summary>
Motivation: 解决现有大模型训练过度依赖人工任务和标签的问题，推进AI向超越人类智能发展。

Method: 引入两种角色的模型（挑战者和解决者）通过相互作用自我演化，生成有针对性的训练任务和挑战，逐步提高模型能力。

Result: 显著提升不同基础模型（如Qwen3-4B-Base）的推理性能，超越传统训练方法的效果。

Conclusion: 提出的自我演化框架R-Zero有效突破了训练数据依赖瓶颈，为未来自主学习系统提供了新思路。

Abstract: Self-evolving Large Language Models (LLMs) offer a scalable path toward
super-intelligence by autonomously generating, refining, and learning from
their own experiences. However, existing methods for training such models still
rely heavily on vast human-curated tasks and labels, typically via fine-tuning
or reinforcement learning, which poses a fundamental bottleneck to advancing AI
systems toward capabilities beyond human intelligence. To overcome this
limitation, we introduce R-Zero, a fully autonomous framework that generates
its own training data from scratch. Starting from a single base LLM, R-Zero
initializes two independent models with distinct roles, a Challenger and a
Solver. These models are optimized separately and co-evolve through
interaction: the Challenger is rewarded for proposing tasks near the edge of
the Solver capability, and the Solver is rewarded for solving increasingly
challenging tasks posed by the Challenger. This process yields a targeted,
self-improving curriculum without any pre-existing tasks and labels.
Empirically, R-Zero substantially improves reasoning capability across
different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on
math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.

</details>


### [123] [SPaRFT: Self-Paced Reinforcement Fine-Tuning for Large Language Models](https://arxiv.org/abs/2508.05015)
*Dai Do,Manh Nguyen,Svetha Venkatesh,Hung Le*

Main category: cs.LG

TL;DR: 提出SPaRFT框架，通过自适应的数据选择和调度显著提升大模型推理能力，减少训练数据需求。


<details>
  <summary>Details</summary>
Motivation: 解决大模型推理能力提升过程中对大量数据和计算资源的依赖问题，提升小模型的效率和效果。

Method: 采用簇划分进行数据降维，利用多臂赌博机优化数据选取，实现自适应训练策略。

Result: 在多个推理任务中达到了与最先进方法相当甚至更优的效果，使用数据量少达100倍。

Conclusion: 通过精心设计的训练课程，可以在资源有限条件下显著提升模型推理性能，具有良好的可扩展性和普适性。

Abstract: Large language models (LLMs) have shown strong reasoning capabilities when
fine-tuned with reinforcement learning (RL). However, such methods require
extensive data and compute, making them impractical for smaller models. Current
approaches to curriculum learning or data selection are largely
heuristic-driven or demand extensive computational resources, limiting their
scalability and generalizability. We propose \textbf{SPaRFT}, a self-paced
learning framework that enables efficient learning based on the capability of
the model being trained through optimizing which data to use and when. First,
we apply \emph{cluster-based data reduction} to partition training data by
semantics and difficulty, extracting a compact yet diverse subset that reduces
redundancy. Then, a \emph{multi-armed bandit} treats data clusters as arms,
optimized to allocate training samples based on model current performance.
Experiments across multiple reasoning benchmarks show that SPaRFT achieves
comparable or better accuracy than state-of-the-art baselines while using up to
\(100\times\) fewer samples. Ablation studies and analyses further highlight
the importance of both data clustering and adaptive selection. Our results
demonstrate that carefully curated, performance-driven training curricula can
unlock strong reasoning abilities in LLMs with minimal resources.

</details>


### [124] [Will You Be Aware? Eye Tracking-Based Modeling of Situational Awareness in Augmented Reality](https://arxiv.org/abs/2508.05025)
*Zhehan Qu,Tianyi Hu,Christian Fronk,Maria Gorlatova*

Main category: cs.LG

TL;DR: 这项研究提出了一种基于眼动追踪的图神经网络模型，用于评估增强现实中心肺复苏操作的情境认知，提高了目前对虚拟内容注意力的理解。


<details>
  <summary>Details</summary>
Motivation: AR系统虽增强任务表现，但存在认知隧道风险，影响关键情境认知，亟需评估和改善用户安全与情境意识。

Method: 开发Magic Leap 2上的AR应用，结合眼动追踪数据，利用图神经网络模型FixGraphPool分析注意力模式，预测SA状态。

Result: 模型达83.0%准确率，优于传统方法，揭示注视特征与认知水平的关系，验证了眼动追踪在AR中SA评估的潜力。

Conclusion: 研究强调眼动追踪在提升AR系统安全性和情境认知评估中的应用价值，为未来AR系统设计提供指导。

Abstract: Augmented Reality (AR) systems, while enhancing task performance through
real-time guidance, pose risks of inducing cognitive tunneling-a hyperfocus on
virtual content that compromises situational awareness (SA) in safety-critical
scenarios. This paper investigates SA in AR-guided cardiopulmonary
resuscitation (CPR), where responders must balance effective compressions with
vigilance to unpredictable hazards (e.g., patient vomiting). We developed an AR
app on a Magic Leap 2 that overlays real-time CPR feedback (compression depth
and rate) and conducted a user study with simulated unexpected incidents (e.g.,
bleeding) to evaluate SA, in which SA metrics were collected via observation
and questionnaires administered during freeze-probe events. Eye tracking
analysis revealed that higher SA levels were associated with greater saccadic
amplitude and velocity, and with reduced proportion and frequency of fixations
on virtual content. To predict SA, we propose FixGraphPool, a graph neural
network that structures gaze events (fixations, saccades) into spatiotemporal
graphs, effectively capturing dynamic attentional patterns. Our model achieved
83.0% accuracy (F1=81.0%), outperforming feature-based machine learning and
state-of-the-art time-series models by leveraging domain knowledge and
spatial-temporal information encoded in ET data. These findings demonstrate the
potential of eye tracking for SA modeling in AR and highlight its utility in
designing AR systems that ensure user safety and situational awareness.

</details>


### [125] [Learning from Oblivion: Predicting Knowledge Overflowed Weights via Retrodiction of Forgetting](https://arxiv.org/abs/2508.05059)
*Jinhyeok Jang,Jaehong Kim,Jung Uk Kim*

Main category: cs.LG

TL;DR: 引入KNOW预测策略，通过逆转结构性遗忘过程，合成知识更丰富的预训练权重，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 提升预训练权重的知识丰富性，超越仅依赖原始数据集的局限。

Method: 利用结构性遗忘和逆转，结合元学习构建KNOW模型，预测增强的权重。

Result: 在多数据集和架构上验证，KNOW预测优于传统微调和简单预测，提升下游任务表现。

Conclusion: 通过重塑遗忘动力学，开拓知识迁移新途径，推动深度学习性能提升。

Abstract: Pre-trained weights have become a cornerstone of modern deep learning,
enabling efficient knowledge transfer and improving downstream task
performance, especially in data-scarce scenarios. However, a fundamental
question remains: how can we obtain better pre-trained weights that encapsulate
more knowledge beyond the given dataset? In this work, we introduce
\textbf{KNowledge Overflowed Weights (KNOW)} prediction, a novel strategy that
leverages structured forgetting and its inversion to synthesize
knowledge-enriched weights. Our key insight is that sequential fine-tuning on
progressively downsized datasets induces a structured forgetting process, which
can be modeled and reversed to recover knowledge as if trained on a larger
dataset. We construct a dataset of weight transitions governed by this
controlled forgetting and employ meta-learning to model weight prediction
effectively. Specifically, our \textbf{KNowledge Overflowed Weights Nowcaster
(KNOWN)} acts as a hyper-model that learns the general evolution of weights and
predicts enhanced weights with improved generalization. Extensive experiments
across diverse datasets and architectures demonstrate that KNOW prediction
consistently outperforms Na\"ive fine-tuning and simple weight prediction,
leading to superior downstream performance. Our work provides a new perspective
on reinterpreting forgetting dynamics to push the limits of knowledge transfer
in deep learning.

</details>


### [126] [TANGO: Graph Neural Dynamics via Learned Energy and Tangential Flows](https://arxiv.org/abs/2508.05070)
*Moshe Eliasof,Eldad Haber,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: TANGO是一种基于动力系统的图表示学习框架，结合能量函数和切向流，提升图神经网络的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决图神经网络在信息传播中面临的能量梯度消失和过度压缩问题。

Method: 引入可学习的李雅普诺夫函数，结合能量梯度下降和切向流两种动力学，进行特征演化。

Result: 在多个节点分类、图分类和回归任务中表现优越，有效缓解了信息过度压缩问题。

Conclusion: TANGO通过能量导向的动力学方法提升了图神经网络的表现，具有良好的适应性和稳定性。

Abstract: We introduce TANGO -- a dynamical systems inspired framework for graph
representation learning that governs node feature evolution through a learned
energy landscape and its associated descent dynamics. At the core of our
approach is a learnable Lyapunov function over node embeddings, whose gradient
defines an energy-reducing direction that guarantees convergence and stability.
To enhance flexibility while preserving the benefits of energy-based dynamics,
we incorporate a novel tangential component, learned via message passing, that
evolves features while maintaining the energy value. This decomposition into
orthogonal flows of energy gradient descent and tangential evolution yields a
flexible form of graph dynamics, and enables effective signal propagation even
in flat or ill-conditioned energy regions, that often appear in graph learning.
Our method mitigates oversquashing and is compatible with different graph
neural network backbones. Empirically, TANGO achieves strong performance across
a diverse set of node and graph classification and regression benchmarks,
demonstrating the effectiveness of jointly learned energy functions and
tangential flows for graph neural networks.

</details>


### [127] [ULU: A Unified Activation Function](https://arxiv.org/abs/2508.05073)
*Simin Huo*

Main category: cs.LG

TL;DR: 提出了一种新型非单调分段激活函数ULU及其变体AULU，在图像分类和目标检测中表现优异，并引入了LIB指标以量化模型的归纳偏差。


<details>
  <summary>Details</summary>
Motivation: 旨在突破现有激活函数的限制，探索更有效的激活机制以提升深度网络性能。

Method: 定义非单调分段激活函数ULU及其可变参数AULU，通过实验验证其优越性，并提出LIB指标衡量归纳偏差。

Result: ULU和AULU在多个任务上显著优于ReLU和Mish，表现出更强的适应性和泛化能力。

Conclusion: ULU及其变体AULU是有效的激活方案，结合LIB指标，对模型归纳偏差的理解具有指导意义。

Abstract: We propose \textbf{ULU}, a novel non-monotonic, piecewise activation function
defined as $\{f(x;\alpha_1),x<0; f(x;\alpha_2),x>=0 \}$, where
$f(x;\alpha)=0.5x(tanh(\alpha x)+1),\alpha >0$. ULU treats positive and
negative inputs differently. Extensive experiments demonstrate ULU
significantly outperforms ReLU and Mish across image classification and object
detection tasks. Its variant Adaptive ULU (\textbf{AULU}) is expressed as
$\{f(x;\beta_1^2),x<0; f(x;\beta_2^2),x>=0 \}$, where $\beta_1$ and $\beta_2$
are learnable parameters, enabling it to adapt its response separately for
positive and negative inputs. Additionally, we introduce the LIB (Like
Inductive Bias) metric from AULU to quantitatively measure the inductive bias
of the model.

</details>


### [128] [Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning](https://arxiv.org/abs/2508.05077)
*Luai Abuelsamen,Temitope Lukman Adebanjo*

Main category: cs.LG

TL;DR: 该论文研究了多模态模仿学习的理论基础，分析了不同模态对样本复杂性和优化的影响，并通过理论框架解释了多模态架构的优越性能。


<details>
  <summary>Details</summary>
Motivation: 理解多模态模仿学习的理论机制，提升其在实际中的效果和理解。

Method: 结合统计学习理论，分析多模态感知对学习样本、优化和泛化的影响，回顾相关理论框架。

Result: 多模态政策可以实现更紧的泛化界和更优的优化景观，明晰了多模态架构如PerAct和CLIPort的优势根源。

Conclusion: 多模态学习具有理论优势，有助于指导未来架构设计及理论研究。

Abstract: This paper examines the theoretical foundations of multimodal imitation
learning through the lens of statistical learning theory. We analyze how
multimodal perception (RGB-D, proprioception, language) affects sample
complexity and optimization landscapes in imitation policies. Building on
recent advances in multimodal learning theory, we show that properly integrated
multimodal policies can achieve tighter generalization bounds and more
favorable optimization landscapes than their unimodal counterparts. We provide
a comprehensive review of theoretical frameworks that explain why multimodal
architectures like PerAct and CLIPort achieve superior performance, connecting
these empirical results to fundamental concepts in Rademacher complexity, PAC
learning, and information theory.

</details>


### [129] [Integrated Influence: Data Attribution with Baseline](https://arxiv.org/abs/2508.05089)
*Linxiao Yang,Xinyu Gu,Liang Sun*

Main category: cs.LG

TL;DR: 提出了一种结合基线的方法——集成影响，用于改进数据归因的准确性和解释性，优于现有的离群点影响方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据归因方法（基于留一法）局限于局部解释和缺乏基线的问题，提升归因的可靠性和解释性。

Method: 定义基线数据集，通过数据退化过程逐步转换当前数据集到基线，并累计每个样本的影响。

Result: 新方法在数据归因和错误标注检测任务中表现优于现有方法，提供更可靠的归因结果。

Conclusion: Integrated Influence是一种结合基线的创新数据归因方法，能更全面且灵活地解释样本影响，有助于提升模型透明度。

Abstract: As an effective approach to quantify how training samples influence test
sample, data attribution is crucial for understanding data and model and
further enhance the transparency of machine learning models. We find that
prevailing data attribution methods based on leave-one-out (LOO) strategy
suffer from the local-based explanation, as these LOO-based methods only
perturb a single training sample, and overlook the collective influence in the
training set. On the other hand, the lack of baseline in many data attribution
methods reduces the flexibility of the explanation, e.g., failing to provide
counterfactual explanations. In this paper, we propose Integrated Influence, a
novel data attribution method that incorporates a baseline approach. Our method
defines a baseline dataset, follows a data degeneration process to transition
the current dataset to the baseline, and accumulates the influence of each
sample throughout this process. We provide a solid theoretical framework for
our method, and further demonstrate that popular methods, such as influence
functions, can be viewed as special cases of our approach. Experimental results
show that Integrated Influence generates more reliable data attributions
compared to existing methods in both data attribution task and mislablled
example identification task.

</details>


### [130] [Cold Start Active Preference Learning in Socio-Economic Domains](https://arxiv.org/abs/2508.05090)
*Mojtaba Fayaz-Bakhsh,Danial Ataee,MohammadAmin Fazli*

Main category: cs.LG

TL;DR: 提出一种基于PCA的冷启动偏好主动学习框架，通过自监督预训练获得初始伪标签，结合主动学习显著提升偏好学习在数据稀缺环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 偏好主动学习在没有初始标注数据时表现较差，亟需解决冷启动问题，特别是在社会和经济系统中。

Method: 先用PCA进行自监督预训练生成伪标签，再通过模拟噪声oracle的主动学习循环优化模型。

Result: 在多个领域的数据集上，该方法优于传统空白起点策略，达到了更高的准确率和更少的标注样本。

Conclusion: 该框架有效缓解冷启动难题，提升偏好学习的样本效率和应用潜力。

Abstract: Active preference learning is a powerful paradigm for efficiently modeling
preferences, yet it suffers from the cold-start problem: a significant drop in
performance when no initial labeled data is available. This challenge is
particularly acute in computational social systems and economic analysis, where
labeled data is often scarce, expensive, and subject to expert noise. To
address this gap, we propose a novel framework for cold-start active preference
learning. Our method initiates the learning process through a self-supervised
pre-training phase, utilizing Principal Component Analysis (PCA) to derive
initial pseudo-labels from the data's inherent structure, thereby creating a
cold-start model without any initial oracle interaction. Subsequently, the
model is refined through an active learning loop that strategically queries a
simulated noisy oracle for labels. We conduct extensive experiments on diverse
datasets from different domains, including financial credibility, career
success rate, and socio-economic status. The results demonstrate that our
cold-start approach outperforms standard active learning strategies that begin
from a blank slate, achieving higher accuracy with substantially fewer labeled
pairs. Our framework offers a practical and effective solution to mitigate the
cold-start problem, enhancing the sample efficiency and applicability of
preference learning in data-constrained environments. We release our code at
https://github.com/Dan-A2/cold-start-preference-learning

</details>


### [131] [Learning from Similarity-Confidence and Confidence-Difference](https://arxiv.org/abs/2508.05108)
*Tomoya Tate,Kosuke Sugiyama,Masato Uchida*

Main category: cs.LG

TL;DR: 该论文提出一种结合多种弱监督信号的创新培训框架，有效提升在标记有限的情况下的分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决在实际应用中，标记数据难以获取且有限的挑战，提升弱监督学习的效果。

Method: 引入SconfConfDiff分类方法，结合相似性置信和置信差两种弱标签，通过两种偏差无关的风险估计器实现分类，采用风险校正减轻过拟合，并分析抗噪声和类别先验偏差的鲁棒性。

Result: 所提出方法在多种实验环境中优于现有方法，验证了其有效性和鲁棒性。

Conclusion: 该研究展现了利用多元弱监督信号提升学习效果的潜力，为弱监督学习提供了新的理论基础和实践指导。

Abstract: In practical machine learning applications, it is often challenging to assign
accurate labels to data, and increasing the number of labeled instances is
often limited. In such cases, Weakly Supervised Learning (WSL), which enables
training with incomplete or imprecise supervision, provides a practical and
effective solution. However, most existing WSL methods focus on leveraging a
single type of weak supervision. In this paper, we propose a novel WSL
framework that leverages complementary weak supervision signals from multiple
relational perspectives, which can be especially valuable when labeled data is
limited. Specifically, we introduce SconfConfDiff Classification, a method that
integrates two distinct forms of weaklabels: similarity-confidence and
confidence-difference, which are assigned to unlabeled data pairs. To implement
this method, we derive two types of unbiased risk estimators for
classification: one based on a convex combination of existing estimators, and
another newly designed by modeling the interaction between two weak labels. We
prove that both estimators achieve optimal convergence rates with respect to
estimation error bounds. Furthermore, we introduce a risk correction approach
to mitigate overfitting caused by negative empirical risk, and provide
theoretical analysis on the robustness of the proposed method against
inaccurate class prior probability and label noise. Experimental results
demonstrate that the proposed method consistently outperforms existing
baselines across a variety of settings.

</details>


### [132] [Exploring Superior Function Calls via Reinforcement Learning](https://arxiv.org/abs/2508.05118)
*Bingguang Hao,Maolin Wang,Zengzhuang Xu,Yicheng Chen,Cunyin Peng,Jinjie GU,Chenyi Zhuang*

Main category: cs.LG

TL;DR: 提出一种基于策略熵探索的强化学习新框架，改善函数调用任务中的探索与推理能力，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前训练方法难以培养模型在实际应用中进行复杂函数调用的稳健推理策略。

Method: 引入改进的强化学习策略，通过两阶段数据准备和结构化推理优化模型表现。

Result: 在伯克利函数调用排行榜中达成86.02%的最高准确率，超越传统方法，尤其在多函数复杂场景中表现优异。

Conclusion: 该新框架有效解决了函数调用中的探索、推理及验证难题，为未来相关模型优化提供了强有力的技术基础。

Abstract: Function calling capabilities are crucial for deploying Large Language Models
in real-world applications, yet current training approaches fail to develop
robust reasoning strategies. Supervised fine-tuning produces models that rely
on superficial pattern matching, while standard reinforcement learning methods
struggle with the complex action space of structured function calls. We present
a novel reinforcement learning framework designed to enhance group relative
policy optimization through strategic entropy based exploration specifically
tailored for function calling tasks. Our approach addresses three critical
challenges in function calling: insufficient exploration during policy
learning, lack of structured reasoning in chain-of-thought generation, and
inadequate verification of parameter extraction. Our two-stage data preparation
pipeline ensures high-quality training samples through iterative LLM evaluation
and abstract syntax tree validation. Extensive experiments on the Berkeley
Function Calling Leaderboard demonstrate that this framework achieves
state-of-the-art performance among open-source models with 86.02\% overall
accuracy, outperforming standard GRPO by up to 6\% on complex multi-function
scenarios. Notably, our method shows particularly strong improvements on
code-pretrained models, suggesting that structured language generation
capabilities provide an advantageous starting point for reinforcement learning
in function calling tasks. We will release all the code, models and dataset to
benefit the community.

</details>


### [133] [HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation](https://arxiv.org/abs/2508.05135)
*Thinh Nguyen,Trung Phan,Binh T. Nguyen,Khoa D Doan,Kok-Seng Wong*

Main category: cs.LG

TL;DR: 提出了一种新的层次联邦域泛化方法HFedATM，有效应对多域数据中的域偏移问题，同时提升模型性能和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决层次联邦学习中面对的域偏移问题，提升模型在不同域中的泛化能力。

Method: 引入基于最优运输的过滤器对齐和收缩正则化平均融合的层次聚合方法HFedATM。

Result: 实验证明HFedATM显著提高几项基准的性能，具有较好的计算和通信效率，并理论证明其收敛性和泛化能力优于传统方法。

Conclusion: HFedATM有效改善了层次联邦学习中的域偏移问题，提供了理论和实证支持，为多域协作学习提供新思路。

Abstract: Federated Learning (FL) is a decentralized approach where multiple clients
collaboratively train a shared global model without sharing their raw data.
Despite its effectiveness, conventional FL faces scalability challenges due to
excessive computational and communication demands placed on a single central
server as the number of participating devices grows. Hierarchical Federated
Learning (HFL) addresses these issues by distributing model aggregation tasks
across intermediate nodes (stations), thereby enhancing system scalability and
robustness against single points of failure. However, HFL still suffers from a
critical yet often overlooked limitation: domain shift, where data
distributions vary significantly across different clients and stations,
reducing model performance on unseen target domains. While Federated Domain
Generalization (FedDG) methods have emerged to improve robustness to domain
shifts, their integration into HFL frameworks remains largely unexplored. In
this paper, we formally introduce Hierarchical Federated Domain Generalization
(HFedDG), a novel scenario designed to investigate domain shift within
hierarchical architectures. Specifically, we propose HFedATM, a hierarchical
aggregation method that first aligns the convolutional filters of models from
different stations through Filter-wise Optimal Transport Alignment and
subsequently merges aligned models using a Shrinkage-aware Regularized Mean
Aggregation. Our extensive experimental evaluations demonstrate that HFedATM
significantly boosts the performance of existing FedDG baselines across
multiple datasets and maintains computational and communication efficiency.
Moreover, theoretical analyses indicate that HFedATM achieves tighter
generalization error bounds compared to standard hierarchical averaging,
resulting in faster convergence and stable training behavior.

</details>


### [134] [Deep Neural Networks with General Activations: Super-Convergence in Sobolev Norms](https://arxiv.org/abs/2508.05141)
*Yahong Yang,Juncai He*

Main category: cs.LG

TL;DR: 深度神经网络在Sobolev空间中的逼近能力超越传统数值方法，实现了超级收敛，为科学计算提供理论基础。


<details>
  <summary>Details</summary>
Motivation: 弥补神经网络逼近PDE解的误差估计理论空白，提升其在科学计算中的应用能力。

Method: 建立深度全连接神经网络在Sobolev空间中的逼近理论，分析误差在不同范数中的表现。

Result: 证明深度网络在Sobolev空间中的逼近率优于传统数值方法，实现超级收敛。

Conclusion: 为神经网络逼近偏微分方程提供统一的理论基础，推动其科学计算应用的发展。

Abstract: This paper establishes a comprehensive approximation result for deep
fully-connected neural networks with commonly-used and general activation
functions in Sobolev spaces $W^{n,\infty}$, with errors measured in the
$W^{m,p}$-norm for $m < n$ and $1\le p \le \infty$. The derived rates surpass
those of classical numerical approximation techniques, such as finite element
and spectral methods, exhibiting a phenomenon we refer to as
\emph{super-convergence}. Our analysis shows that deep networks with general
activations can approximate weak solutions of partial differential equations
(PDEs) with superior accuracy compared to traditional numerical methods at the
approximation level. Furthermore, this work closes a significant gap in the
error-estimation theory for neural-network-based approaches to PDEs, offering a
unified theoretical foundation for their use in scientific computing.

</details>


### [135] [PSEO: Optimizing Post-hoc Stacking Ensemble Through Hyperparameter Tuning](https://arxiv.org/abs/2508.05144)
*Beicheng Xu,Wei Liu,Keyao Ding,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: PSEO提出了一种用于后置堆叠集成优化的框架，有效提升AutoML系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有CASH方法在集成阶段采用固定策略，不能针对不同任务优化集成策略。

Method: 通过二元二次规划进行基础模型选择，引入两种机制完善多层堆叠，实现超参数空间内的最优后置集成策略搜索。

Result: 在80个公开数据集上，PSEO显著优于其他主流方法，获得最佳平均测试排名。

Conclusion: PSEO框架成功提升了AutoML中后置集成的效果，为模型融合提供了更动态和优化的解决方案。

Abstract: The Combined Algorithm Selection and Hyperparameter Optimization (CASH)
problem is fundamental in Automated Machine Learning (AutoML). Inspired by the
success of ensemble learning, recent AutoML systems construct post-hoc
ensembles for final predictions rather than relying on the best single model.
However, while most CASH methods conduct extensive searches for the optimal
single model, they typically employ fixed strategies during the ensemble phase
that fail to adapt to specific task characteristics. To tackle this issue, we
propose PSEO, a framework for post-hoc stacking ensemble optimization. First,
we conduct base model selection through binary quadratic programming, with a
trade-off between diversity and performance. Furthermore, we introduce two
mechanisms to fully realize the potential of multi-layer stacking. Finally,
PSEO builds a hyperparameter space and searches for the optimal post-hoc
ensemble strategy within it. Empirical results on 80 public datasets show that
\sys achieves the best average test rank (2.96) among 16 methods, including
post-hoc designs in recent AutoML systems and state-of-the-art ensemble
learning methods.

</details>


### [136] [Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation](https://arxiv.org/abs/2508.05154)
*Rishabh Gaur,Gaurav Deshkar,Jayanta Kshirsagar,Harshal Hayatnagarkar,Janani Venugopalan*

Main category: cs.LG

TL;DR: 开发面向领域的RL指标以评估代理模型性能，应用于疫情模拟中观察不同策略效果。


<details>
  <summary>Details</summary>
Motivation: 当前RL在ABMs和RABMs中的应用缺乏标准化评估指标，影响模型性能评估。

Method: 构建领域驱动的RL指标，结合传统和前沿指标，在疫情模型中验证。

Result: 领域驱动指标结合传统指标提升评估效果，适应不同模拟场景。

Conclusion: 面向领域的RL指标有助于更准确评估代理模型性能，应对复杂系统的不确定性。

Abstract: For the development and optimization of agent-based models (ABMs) and
rational agent-based models (RABMs), optimization algorithms such as
reinforcement learning are extensively used. However, assessing the performance
of RL-based ABMs and RABMS models is challenging due to the complexity and
stochasticity of the modeled systems, and the lack of well-standardized metrics
for comparing RL algorithms. In this study, we are developing domain-driven
metrics for RL, while building on state-of-the-art metrics. We demonstrate our
``Domain-driven-RL-metrics'' using policy optimization on a rational ABM
disease modeling case study to model masking behavior, vaccination, and
lockdown in a pandemic. Our results show the use of domain-driven rewards in
conjunction with traditional and state-of-the-art metrics for a few different
simulation scenarios such as the differential availability of masks.

</details>


### [137] [pFedDSH: Enabling Knowledge Transfer in Personalized Federated Learning through Data-free Sub-Hypernetwork](https://arxiv.org/abs/2508.05157)
*Thinh Nguyen,Le Huy Khiem,Van-Tuan Tran,Khoa D Doan,Nitesh V Chawla,Kok-Seng Wong*

Main category: cs.LG

TL;DR: 提出一种基于超网络和掩码的个性化联邦学习框架pFedDSH，支持动态客户端加入，保持性能稳定并高效知识迁移。


<details>
  <summary>Details</summary>
Motivation: 解决现有pFL方法假设客户端静态、无法适应动态加入的问题，满足实际应用中的持续客户端加入需求。

Method: 引入中心超网络，通过嵌入向量生成个性化模型，利用批次特定掩码保持知识稳定，并结合无数据重放策略实现知识迁移。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上实验表明，pFedDSH优于现有方法，在性能稳定性和适应新客户端方面表现优越。

Conclusion: 该方法有效应对动态客户端加入场景，维护既有客户端性能，同时实现高效知识迁移，具有较好的实用性和扩展性。

Abstract: Federated Learning (FL) enables collaborative model training across
distributed clients without sharing raw data, offering a significant privacy
benefit. However, most existing Personalized Federated Learning (pFL) methods
assume a static client participation, which does not reflect real-world
scenarios where new clients may continuously join the federated system (i.e.,
dynamic client onboarding). In this paper, we explore a practical scenario in
which a new batch of clients is introduced incrementally while the learning
task remains unchanged. This dynamic environment poses various challenges,
including preserving performance for existing clients without retraining and
enabling efficient knowledge transfer between client batches. To address these
issues, we propose Personalized Federated Data-Free Sub-Hypernetwork (pFedDSH),
a novel framework based on a central hypernetwork that generates personalized
models for each client via embedding vectors. To maintain knowledge stability
for existing clients, pFedDSH incorporates batch-specific masks, which activate
subsets of neurons to preserve knowledge. Furthermore, we introduce a data-free
replay strategy motivated by DeepInversion to facilitate backward transfer,
enhancing existing clients' performance without compromising privacy. Extensive
experiments conducted on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate
that pFedDSH outperforms the state-of-the-art pFL and Federated Continual
Learning baselines in our investigation scenario. Our approach achieves robust
performance stability for existing clients, as well as adaptation for new
clients and efficient utilization of neural resources.

</details>


### [138] [S$^2$M-Former: Spiking Symmetric Mixing Branchformer for Brain Auditory Attention Detection](https://arxiv.org/abs/2508.05164)
*Jiaqi Wang,Zhengyu Ma,Xiongri Shen,Chenlin Zhou,Leilei Zhao,Han Zhang,Yi Zhong,Siqi Cai,Zhenxi Song,Zhiguo Zhang*

Main category: cs.LG

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Auditory attention detection (AAD) aims to decode listeners' focus in complex
auditory environments from electroencephalography (EEG) recordings, which is
crucial for developing neuro-steered hearing devices. Despite recent
advancements, EEG-based AAD remains hindered by the absence of synergistic
frameworks that can fully leverage complementary EEG features under
energy-efficiency constraints. We propose S$^2$M-Former, a novel spiking
symmetric mixing framework to address this limitation through two key
innovations: i) Presenting a spike-driven symmetric architecture composed of
parallel spatial and frequency branches with mirrored modular design,
leveraging biologically plausible token-channel mixers to enhance complementary
learning across branches; ii) Introducing lightweight 1D token sequences to
replace conventional 3D operations, reducing parameters by 14.7$\times$. The
brain-inspired spiking architecture further reduces power consumption,
achieving a 5.8$\times$ energy reduction compared to recent ANN methods, while
also surpassing existing SNN baselines in terms of parameter efficiency and
performance. Comprehensive experiments on three AAD benchmarks (KUL, DTU and
AV-GC-AAD) across three settings (within-trial, cross-trial and cross-subject)
demonstrate that S$^2$M-Former achieves comparable state-of-the-art (SOTA)
decoding accuracy, making it a promising low-power, high-performance solution
for AAD tasks.

</details>


### [139] [Aligning LLMs on a Budget: Inference-Time Alignment with Heuristic Reward Models](https://arxiv.org/abs/2508.05165)
*Mason Nakamura,Saaduddin Mahmud,Kyle H. Wray,Hamed Zamani,Shlomo Zilberstein*

Main category: cs.LG

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Aligning LLMs with user preferences is crucial for real-world use but often
requires costly fine-tuning or expensive inference, forcing trade-offs between
alignment quality and computational cost. Existing inference-time methods
typically ignore this balance, focusing solely on the optimized policy's
performance. We propose HIA (Heuristic-Guided Inference-time Alignment), a
tuning-free, black-box-compatible approach that uses a lightweight prompt
optimizer, heuristic reward models, and two-stage filtering to reduce inference
calls while preserving alignment quality. On real-world prompt datasets,
HelpSteer and ComPRed, HIA outperforms best-of-N sampling, beam search, and
greedy search baselines in multi-objective, goal-conditioned tasks under the
same inference budget. We also find that HIA is effective under low-inference
budgets with as little as one or two response queries, offering a practical
solution for scalable, personalized LLM deployment.

</details>


### [140] [Near Optimal Inference for the Best-Performing Algorithm](https://arxiv.org/abs/2508.05173)
*Amichai Painsky*

Main category: cs.LG

TL;DR: 提出一种新颖的子集选择框架，用于在多项式分布中识别最有可能在未来未见数据中排名最高的算法，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决算法性能在基准测试中差异微小时，如何有效选择最具代表性算法的问题。

Method: 引入新的子集选择框架，提供渐近和有限样本方案，并辅以匹配的下界证明其优越性。

Result: 新方法在准确性和效率方面均优于现有技术，表现出良好的性能。

Conclusion: 本研究提出的框架有效提升了选择最优算法的能力，为多项式分布的子集选择问题提供了理论与实践的支持。

Abstract: Consider a collection of competing machine learning algorithms. Given their
performance on a benchmark of datasets, we would like to identify the best
performing algorithm. Specifically, which algorithm is most likely to rank
highest on a future, unseen dataset. A natural approach is to select the
algorithm that demonstrates the best performance on the benchmark. However, in
many cases the performance differences are marginal and additional candidates
may also be considered. This problem is formulated as subset selection for
multinomial distributions. Formally, given a sample from a countable alphabet,
our goal is to identify a minimal subset of symbols that includes the most
frequent symbol in the population with high confidence. In this work, we
introduce a novel framework for the subset selection problem. We provide both
asymptotic and finite-sample schemes that significantly improve upon currently
known methods. In addition, we provide matching lower bounds, demonstrating the
favorable performance of our proposed schemes.

</details>


### [141] [Human Activity Recognition from Smartphone Sensor Data for Clinical Trials](https://arxiv.org/abs/2508.05175)
*Stefania Russo,Rafał Klimas,Marta Płonka,Hugo Le Gall,Sven Holm,Dimitar Stanev,Florian Lipsmeier,Mattia Zanon,Lito Kriara*

Main category: cs.LG

TL;DR: 本文提出了一种基于ResNet的人体活动识别模型，具备高准确性和多位置适应性，适用于实际应用。


<details>
  <summary>Details</summary>
Motivation: 旨在提升人体活动识别的准确性和实用性，尤其是在多不同佩戴位置下的鲁棒性。

Method: 利用ResNet架构，在智能手机传感器数据上进行训练和评估，结合多个数据集验证模型性能。

Result: 模型在识别步态与非步态以及日常活动方面表现优异，与现有最先进模型相比优势明显，特别是在不同佩戴位置上表现出较强的鲁棒性。

Conclusion: 提出的HAR模型不仅高效准确，还具有良好的实用潜力，适应多样化的佩戴环境。

Abstract: We developed a ResNet-based human activity recognition (HAR) model with
minimal overhead to detect gait versus non-gait activities and everyday
activities (walking, running, stairs, standing, sitting, lying, sit-to-stand
transitions). The model was trained and evaluated using smartphone sensor data
from adult healthy controls (HC) and people with multiple sclerosis (PwMS) with
Expanded Disability Status Scale (EDSS) scores between 0.0-6.5. Datasets
included the GaitLab study (ISRCTN15993728), an internal Roche dataset, and
publicly available data sources (training only). Data from 34 HC and 68 PwMS
(mean [SD] EDSS: 4.7 [1.5]) were included in the evaluation. The HAR model
showed 98.4% and 99.6% accuracy in detecting gait versus non-gait activities in
the GaitLab and Roche datasets, respectively, similar to a comparative
state-of-the-art ResNet model (99.3% and 99.4%). For everyday activities, the
proposed model not only demonstrated higher accuracy than the state-of-the-art
model (96.2% vs 91.9%; internal Roche dataset) but also maintained high
performance across 9 smartphone wear locations (handbag, shopping bag,
crossbody bag, backpack, hoodie pocket, coat/jacket pocket, hand, neck, belt),
outperforming the state-of-the-art model by 2.8% - 9.0%. In conclusion, the
proposed HAR model accurately detects everyday activities and shows high
robustness to various smartphone wear locations, demonstrating its practical
applicability.

</details>


### [142] [Physics-Informed Time-Integrated DeepONet: Temporal Tangent Space Operator Learning for High-Accuracy Inference](https://arxiv.org/abs/2508.05190)
*Luis Mandl,Dibyajyoti Nayak,Tim Ricken,Somdatta Goswami*

Main category: cs.LG

TL;DR: PITI-DeepONet通过物理引导的深度算子网络，实现长时间范围内的时间依赖偏微分方程的准确建模，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统全展开和自回归方法在长时间预测中的准确性和稳定性不足问题。

Method: 引入双输出架构的深度算子网络，结合物理信息训练，通过时间积分方案进行动态预测，同时利用残差监控评估预测质量。

Result: 在多个基准问题上显著降低预测误差，超过传统方法，特别是在延长预测时间方面实现了84%、87%和42%的误差降低。

Conclusion: PITI-DeepONet突破了传统方法的局限，为复杂时间依赖偏微分方程的长时间稳定仿真提供了新途径。

Abstract: Accurately modeling and inferring solutions to time-dependent partial
differential equations (PDEs) over extended horizons remains a core challenge
in scientific machine learning. Traditional full rollout (FR) methods, which
predict entire trajectories in one pass, often fail to capture the causal
dependencies and generalize poorly outside the training time horizon.
Autoregressive (AR) approaches, evolving the system step by step, suffer from
error accumulation, limiting long-term accuracy. These shortcomings limit the
long-term accuracy and reliability of both strategies. To address these issues,
we introduce the Physics-Informed Time-Integrated Deep Operator Network
(PITI-DeepONet), a dual-output architecture trained via fully physics-informed
or hybrid physics- and data-driven objectives to ensure stable, accurate
long-term evolution well beyond the training horizon. Instead of forecasting
future states, the network learns the time-derivative operator from the current
state, integrating it using classical time-stepping schemes to advance the
solution in time. Additionally, the framework can leverage residual monitoring
during inference to estimate prediction quality and detect when the system
transitions outside the training domain. Applied to benchmark problems,
PITI-DeepONet shows improved accuracy over extended inference time horizons
when compared to traditional methods. Mean relative $\mathcal{L}_2$ errors
reduced by 84% (vs. FR) and 79% (vs. AR) for the one-dimensional heat equation;
by 87% (vs. FR) and 98% (vs. AR) for the one-dimensional Burgers equation; and
by 42% (vs. FR) and 89% (vs. AR) for the two-dimensional Allen-Cahn equation.
By moving beyond classic FR and AR schemes, PITI-DeepONet paves the way for
more reliable, long-term integration of complex, time-dependent PDEs.

</details>


### [143] [FAITH: A Framework for Assessing Intrinsic Tabular Hallucinations in finance](https://arxiv.org/abs/2508.05201)
*Mengao Zhang,Jiayu Fu,Tanya Warrier,Yuwen Wang,Tianhui Tan,Ke-wei Huang*

Main category: cs.LG

TL;DR: 提出了一套用于评估金融领域大模型内在幻觉的框架，包括数据集创造和模型评估，提升金融AI的可信度。


<details>
  <summary>Details</summary>
Motivation: 金融应用中大模型的幻觉问题危害决策和合规，亟需专业评估工具。

Method: 设计了基于金融文档的遮蔽预测任务，自动生成检测数据集，并对模型进行相关测试。

Result: 建立了面向金融数据的幻觉评估工具和数据集，揭示了模型中的幻觉模式。

Conclusion: 为金融生成式AI系统的可信性提升提供了系统化评估方法，推动未来发展。

Abstract: Hallucination remains a critical challenge for deploying Large Language
Models (LLMs) in finance. Accurate extraction and precise calculation from
tabular data are essential for reliable financial analysis, since even minor
numerical errors can undermine decision-making and regulatory compliance.
Financial applications have unique requirements, often relying on
context-dependent, numerical, and proprietary tabular data that existing
hallucination benchmarks rarely capture. In this study, we develop a rigorous
and scalable framework for evaluating intrinsic hallucinations in financial
LLMs, conceptualized as a context-aware masked span prediction task over
real-world financial documents. Our main contributions are: (1) a novel,
automated dataset creation paradigm using a masking strategy; (2) a new
hallucination evaluation dataset derived from S&P 500 annual reports; and (3) a
comprehensive evaluation of intrinsic hallucination patterns in
state-of-the-art LLMs on financial tabular data. Our work provides a robust
methodology for in-house LLM evaluation and serves as a critical step toward
building more trustworthy and reliable financial Generative AI systems.

</details>


### [144] [Advanced Hybrid Transformer LSTM Technique with Attention and TS Mixer for Drilling Rate of Penetration Prediction](https://arxiv.org/abs/2508.05210)
*Saddam Hussain Khan*

Main category: cs.LG

TL;DR: 提出了一种结合LSTM、Transformer、TS-Mixer和注意力机制的混合深度学习架构，用于提升钻井钻进速率（ROP）的实时预测准确性。


<details>
  <summary>Details</summary>
Motivation: 由于复杂、动态和高维的钻井数据，传统模型难以准确预测ROP，限制了其实时应用和优化潜力。

Method: 结合LSTM、Transformer、TS-Mixer和注意力机制，设计了一种多尺度、多方面的混合深度学习模型，以捕捉时间依赖关系和特征交互。

Result: 模型在实际钻井数据上表现优异，R方达0.9988，MAPE为1.447%，优于单一模型和其他混合模型，验证了其高准确性和鲁棒性。

Conclusion: 该混合模型实现了高精度、可解释的实时ROP预测，有助于开发智能化的成本效益更高的钻井优化系统。

Abstract: The Rate of Penetration (ROP) is crucial for optimizing drilling operations;
however, accurately predicting it is hindered by the complex, dynamic, and
high-dimensional nature of drilling data. Traditional empirical, physics-based,
and basic machine learning models often fail to capture intricate temporal and
contextual relationships, resulting in suboptimal predictions and limited
real-time utility. To address this gap, we propose a novel hybrid deep learning
architecture integrating Long Short-Term Memory (LSTM) networks, Transformer
encoders, Time-Series Mixer (TS-Mixer) blocks, and attention mechanisms to
synergistically model temporal dependencies, static feature interactions,
global context, and dynamic feature importance. Evaluated on a real-world
drilling dataset, our model outperformed benchmarks (standalone LSTM, TS-Mixer,
and simpler hybrids) with an R-squared score of 0.9988 and a Mean Absolute
Percentage Error of 1.447%, as measured by standard regression metrics
(R-squared, MAE, RMSE, MAPE). Model interpretability was ensured using SHAP and
LIME, while actual vs. predicted curves and bias checks confirmed accuracy and
fairness across scenarios. This advanced hybrid approach enables reliable
real-time ROP prediction, paving the way for intelligent, cost-effective
drilling optimization systems with significant operational impact.

</details>


### [145] [DFW: A Novel Weighting Scheme for Covariate Balancing and Treatment Effect Estimation](https://arxiv.org/abs/2508.05215)
*Ahmad Saeed Khan,Erik Schaffernicht,Johannes Andreas Stork*

Main category: cs.LG

TL;DR: 提出一种新颖的倾向评分加权方法——去混淆因子加权（DFW），通过稳定样本权重改善因果效应估计的性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于观察数据的因果推断中倾向评分法存在的不稳定性和偏差问题。

Method: 引入去混淆因子构建稳健的样本权重，既优先选择低混淆样本，又抑制高度混淆样本的影响，确保权重有界并改善协变量平衡。

Result: 在多个真实和合成数据集上，DFW比IPW和CBPS表现更优，提升协变量平衡和因果效应估计的准确性。

Conclusion: DFW是一个有效的改进方法，能广泛应用于多治疗情境，显著改善观察数据的因果推断质量。

Abstract: Estimating causal effects from observational data is challenging due to
selection bias, which leads to imbalanced covariate distributions across
treatment groups. Propensity score-based weighting methods are widely used to
address this issue by reweighting samples to simulate a randomized controlled
trial (RCT). However, the effectiveness of these methods heavily depends on the
observed data and the accuracy of the propensity score estimator. For example,
inverse propensity weighting (IPW) assigns weights based on the inverse of the
propensity score, which can lead to instable weights when propensity scores
have high variance-either due to data or model misspecification-ultimately
degrading the ability of handling selection bias and treatment effect
estimation. To overcome these limitations, we propose Deconfounding Factor
Weighting (DFW), a novel propensity score-based approach that leverages the
deconfounding factor-to construct stable and effective sample weights. DFW
prioritizes less confounded samples while mitigating the influence of highly
confounded ones, producing a pseudopopulation that better approximates a RCT.
Our approach ensures bounded weights, lower variance, and improved covariate
balance.While DFW is formulated for binary treatments, it naturally extends to
multi-treatment settings, as the deconfounding factor is computed based on the
estimated probability of the treatment actually received by each sample.
Through extensive experiments on real-world benchmark and synthetic datasets,
we demonstrate that DFW outperforms existing methods, including IPW and CBPS,
in both covariate balancing and treatment effect estimation.

</details>


### [146] [ML-based Short Physical Performance Battery future score prediction based on questionnaire data](https://arxiv.org/abs/2508.05222)
*Marcin Kolakowski,Seif Ben Bader*

Main category: cs.LG

TL;DR: 利用问卷数据预测未来四年的短期体能表现，采用多种机器学习算法，XGBoost表现最佳。


<details>
  <summary>Details</summary>
Motivation: 早期干预以减缓老年人身体能力衰退。

Method: 比较多种机器学习算法，包括随机森林、XGBoost、线性回归和神经网络，结合Shapley值进行特征选择。

Result: XGBoost表现优异，平均绝对误差约0.79-0.82分，通过特征选择优化模型。

Conclusion: 问卷数据可用于预测未来体能表现，XGBoost模型具有较高的预测能力，有助于早期干预策略制定。

Abstract: Effective slowing down of older adults\' physical capacity deterioration
requires intervention as soon as the first symptoms surface. In this paper, we
analyze the possibility of predicting the Short Physical Performance Battery
(SPPB) score at a four-year horizon based on questionnaire data. The ML
algorithms tested included Random Forest, XGBoost, Linear Regression, dense and
TabNet neural networks. The best results were achieved for the XGBoost (mean
absolute error of 0.79 points). Based on the Shapley values analysis, we
selected smaller subsets of features (from 10 to 20) and retrained the XGBoost
regressor, achieving a mean absolute error of 0.82.

</details>


### [147] [Fairy$\pm i$: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$](https://arxiv.org/abs/2508.05571)
*Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang*

Main category: cs.LG

TL;DR: 提出了一种面向复杂值大模型的2比特量化框架Fairy±i，突破了现有量化精度的上限，通过在全精度模型提升准确率后再进行量化，实现更高性能和效率。


<details>
  <summary>Details</summary>
Motivation: 当前QAT仅在最小化量化误差方面努力，限制于全精度模型的准确上限，亟需突破量化多比特的性能瓶颈。

Method: 利用复数域表达优势，将权重映射到单位四次根$\\{\\pm1, \pm i\\ight}$，实现对称且信息理论最优的2比特表示，同时支持无乘法推理。

Result: Fairy±i在PPL和下游任务中突破了现有2比特量化的性能上限，兼顾存储和计算效率。

Conclusion: 提出的新范式和方法为极低比特数下构建高精度大模型提供了新思路，开启了量化研究的新方向。

Abstract: Quantization-Aware Training (QAT) integrates quantization into the training
loop, enabling LLMs to learn robust low-bit representations, and is widely
recognized as one of the most promising research directions. All current QAT
research focuses on minimizing quantization error on full-precision models,
where the full-precision accuracy acts as an upper bound (accuracy ceiling). No
existing method has even attempted to surpass this ceiling. To break this
ceiling, we propose a new paradigm: raising the ceiling (full-precision model),
and then still quantizing it efficiently into 2 bits. We propose Fairy$\pm i$,
the first 2-bit quantization framework for complex-valued LLMs. Specifically,
our method leverages the representational advantages of the complex domain to
boost full-precision accuracy. We map weights to the fourth roots of unity
$\{\pm1, \pm i\}$, forming a perfectly symmetric and information-theoretically
optimal 2-bit representation. Importantly, each quantized weight has either a
zero real or imaginary part, enabling multiplication-free inference using only
additions and element swaps. Experimental results show that Fairy$\pm i$
outperforms the ceiling of existing 2-bit quantization approaches in terms of
both PPL and downstream tasks, while maintaining strict storage and compute
efficiency. This work opens a new direction for building highly accurate and
practical LLMs under extremely low-bit constraints.

</details>


### [148] [Don't Reach for the Stars: Rethinking Topology for Resilient Federated Learning](https://arxiv.org/abs/2508.05224)
*Mirko Konstantin,Anirban Mukhopadhyay*

Main category: cs.LG

TL;DR: 提出一种去中心化的点对点联邦学习框架LIGHTYEAR，通过局部一致性评分选择可信更新，提升异质和对抗环境中的模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统中心化FL在端点故障、个性化、分布偏移和数据非独立同分布等方面的局限性，增强系统的鲁棒性和个性化能力。

Method: 引入基于本地验证集的协议评分机制，结合正则化实现个性化更新选择和稳定训练，依托P2P拓扑结构。

Result: 在两个数据集上实验表明，该方法优于现有的中心化及P2P方法，特别在对抗和异质条件下表现更佳。

Conclusion: 通过局部一致性导向的选择与正则化策略，有效提升去中心化联邦学习的性能与鲁棒性，适应异质和复杂环境。

Abstract: Federated learning (FL) enables collaborative model training across
distributed clients while preserving data privacy by keeping data local.
Traditional FL approaches rely on a centralized, star-shaped topology, where a
central server aggregates model updates from clients. However, this
architecture introduces several limitations, including a single point of
failure, limited personalization, and poor robustness to distribution shifts or
vulnerability to malfunctioning clients. Moreover, update selection in
centralized FL often relies on low-level parameter differences, which can be
unreliable when client data is not independent and identically distributed, and
offer clients little control. In this work, we propose a decentralized,
peer-to-peer (P2P) FL framework. It leverages the flexibility of the P2P
topology to enable each client to identify and aggregate a personalized set of
trustworthy and beneficial updates.This framework is the Local Inference Guided
Aggregation for Heterogeneous Training Environments to Yield Enhancement
Through Agreement and Regularization (LIGHTYEAR). Central to our method is an
agreement score, computed on a local validation set, which quantifies the
semantic alignment of incoming updates in the function space with respect to
the clients reference model. Each client uses this score to select a tailored
subset of updates and performs aggregation with a regularization term that
further stabilizes the training. Our empirical evaluation across two datasets
shows that the proposed approach consistently outperforms both centralized
baselines and existing P2P methods in terms of client-level performance,
particularly under adversarial and heterogeneous conditions.

</details>


### [149] [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](https://arxiv.org/abs/2508.05581)
*Guilherme Seidyo Imai Aldeia,Daniel S. Herman,William G. La Cava*

Main category: cs.LG

TL;DR: 大语言模型能有效生成可解释的计算表型，辅助临床决策。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在生成可解释的临床计算表型方面的潜力，以改善高血压患者的医疗服务。

Method: 采用零样本评估和自我迭代优化策略，引导模型生成和完善计算表型。

Result: 模型结合迭代学习，能生成具有良好解释性且性能接近最先进方法的程序，所需训练数据显著较少。

Conclusion: 大语言模型结合迭代优化，有潜力用于临床决策支持，提升医疗效率。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities for
medical question answering and programming, but their potential for generating
interpretable computable phenotypes (CPs) is under-explored. In this work, we
investigate whether LLMs can generate accurate and concise CPs for six clinical
phenotypes of varying complexity, which could be leveraged to enable scalable
clinical decision support to improve care for patients with hypertension. In
addition to evaluating zero-short performance, we propose and test a
synthesize, execute, debug, instruct strategy that uses LLMs to generate and
iteratively refine CPs using data-driven feedback. Our results show that LLMs,
coupled with iterative learning, can generate interpretable and reasonably
accurate programs that approach the performance of state-of-the-art ML methods
while requiring significantly fewer training examples.

</details>


### [150] [Cross-LoRA: A Data-Free LoRA Transfer Framework across Heterogeneous LLMs](https://arxiv.org/abs/2508.05232)
*Feifan Xia,Mingyang Liao,Yuyang Fang,Defang Li,Yantong Xie,Weikang Li,Yang Li,Deguo Xia,Jizhou Huang*

Main category: cs.LG

TL;DR: 提出了一种跨模型迁移的参数高效微调框架Cross-LoRA，无需额外训练数据，可在不同大模型之间迁移LoRA模块，提升性能且快速高效。


<details>
  <summary>Details</summary>
Motivation: 解决现有PEFT方法与基础模型架构紧耦合限制，增强跨模型适用性。

Method: 引入LoRA-Align进行子空间对齐和LoRA-Shift进行权重投影，通过SVD与线性变换实现迁移，全部无训练无需数据，在GPU上快速完成。

Result: 在多个基准测试中，Cross-LoRA提升了模型性能，达到相当于直接训练的LoRA效果，表现优越。

Conclusion: Cross-LoRA为大模型迁移学习提供一种快速、无数据的解决方案，扩大了PEFT的应用范围。

Abstract: Traditional parameter-efficient fine-tuning (PEFT) methods such as LoRA are
tightly coupled with the base model architecture, which constrains their
applicability across heterogeneous pretrained large language models (LLMs). To
address this limitation, we introduce Cross-LoRA, a data-free framework for
transferring LoRA modules between diverse base models without requiring
additional training data. Cross-LoRA consists of two key components: (a)
LoRA-Align, which performs subspace alignment between source and target base
models through rank-truncated singular value decomposition (SVD) and
Frobenius-optimal linear transformation, ensuring compatibility under dimension
mismatch; and (b) LoRA-Shift, which applies the aligned subspaces to project
source LoRA weight updates into the target model parameter space. Both
components are data-free, training-free, and enable lightweight adaptation on a
commodity GPU in 20 minutes. Experiments on ARCs, OBOA and HellaSwag show that
Cross-LoRA achieves relative gains of up to 5.26% over base models. Across
other commonsense reasoning benchmarks, Cross-LoRA maintains performance
comparable to that of directly trained LoRA adapters.

</details>


### [151] [MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs](https://arxiv.org/abs/2508.05257)
*Xiaodong Chen,Mingming Ha,Zhenzhong Lan,Jing Zhang,Jianguo Li*

Main category: cs.LG

TL;DR: 提出一种基于基矩阵分解的模型压缩方法，显著降低模型参数同时保障精度。


<details>
  <summary>Details</summary>
Motivation: 解决大规模Mixture-of-Experts模型在部署时的高内存需求问题，同时减少模型压缩带来的精度损失。

Method: 将每个专家的门控矩阵通过秩分解为两个矩阵，并用一组共享的基础矩阵线性组合重新参数化B矩阵，从而实现参数压缩。

Result: 在多个大模型中应用，参数减少24%-30%，且只产生1%-2%的精度下降，优于现有方法。

Conclusion: 提出的MoBE方法在模型压缩效率和精度保持方面表现优异，为大模型部署提供了有效方案。

Abstract: The Mixture-of-Experts (MoE) architecture has become a predominant paradigm
for scaling large language models (LLMs). Despite offering strong performance
and computational efficiency, large MoE-based LLMs like DeepSeek-V3-0324 and
Kimi-K2-Instruct present serious challenges due to substantial memory
requirements in deployment. While recent works have explored MoE compression to
address this issue, existing methods often suffer from considerable accuracy
drops (e.g., 7-14% relatively) even at modest compression rates. This paper
introduces a novel Mixture-of-Basis-Experts (MoBE) method that achieves model
compression while incurring minimal accuracy drops. Specifically, each up/gate
matrix in an expert is decomposed via a rank decomposition as W = AB, where
matrix A is unique to each expert. The relatively larger matrix B is further
re-parameterized as a linear combination of basis matrices {Bi} shared across
all experts within a given MoE layer. The factorization is learned by
minimizing the reconstruction error relative to the original weight matrices.
Experiments demonstrate that MoBE achieves notably lower accuracy drops
compared to prior works. For instance, MoBE can reduce the parameter counts of
Qwen3-235B-A22B-2507, DeepSeek-V3-0324 (671B) and Kimi-K2-Instruct (1T) by
24%-30% with only 1%-2% accuracy drop (about 2% drops when measured
relatively).

</details>


### [152] [Marine Chlorophyll Prediction and Driver Analysis based on LSTM-RF Hybrid Models](https://arxiv.org/abs/2508.05260)
*Zhouyao Qian,Yang Chen,Baodian Li,Shuyi Zhang,Zhen Tian,Gongsen Wang,Tianyue Gu,Xinyu Zhou,Huilin Chen,Xinyi Li,Hao Zhu,Shuyao Zhang,Zongheng Li,Siyuan Wang*

Main category: cs.LG

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Marine chlorophyll concentration is an important indicator of ecosystem
health and carbon cycle strength, and its accurate prediction is crucial for
red tide warning and ecological response. In this paper, we propose a LSTM-RF
hybrid model that combines the advantages of LSTM and RF, which solves the
deficiencies of a single model in time-series modelling and nonlinear feature
portrayal. Trained with multi-source ocean data(temperature, salinity,
dissolved oxygen, etc.), the experimental results show that the LSTM-RF model
has an R^2 of 0.5386, an MSE of 0.005806, and an MAE of 0.057147 on the test
set, which is significantly better than using LSTM (R^2 = 0.0208) and RF (R^2
=0.4934) alone , respectively. The standardised treatment and sliding window
approach improved the prediction accuracy of the model and provided an
innovative solution for high-frequency prediction of marine ecological
variables.

</details>


### [153] [FlowState: Sampling Rate Invariant Time Series Forecasting](https://arxiv.org/abs/2508.05287)
*Lars Graf,Thomas Ortner,Stanisław Woźniak,Angeliki Pantazi*

Main category: cs.LG

TL;DR: FlowState是一种创新的时间序列预测模型，利用连续时间建模和动态尺度调节，显著提升了模型的泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列基础模型在尺度适应性和泛化能力方面存在不足，亟需更高效、更灵活的模型结构。

Method: 引入基于状态空间模型的编码器和功能基解码器，实现连续时间建模和动态时间尺度调整；采用预训练策略以提升模型鲁棒性和训练效率。

Result: FlowState在多个基准测试中表现优异，优于现有模型，且模型更小、训练更快，可在线适应不同采样率。

Conclusion: FlowState通过创新设计显著提升时间序列预测的泛化、效率和适应性，代表该领域的最新进展。

Abstract: Foundation models (FMs) have transformed natural language processing, but
their success has not yet translated to time series forecasting. Existing time
series foundation models (TSFMs), often based on transformer variants, struggle
with generalization across varying context and target lengths, lack
adaptability to different sampling rates, and are computationally inefficient.
We introduce FlowState, a novel TSFM architecture that addresses these
challenges through two key innovations: a state space model (SSM) based encoder
and a functional basis decoder. This design enables continuous-time modeling
and dynamic time-scale adjustment, allowing FlowState to inherently generalize
across all possible temporal resolutions, and dynamically adjust the
forecasting horizons. In contrast to other state-of-the-art TSFMs, which
require training data across all possible sampling rates to memorize patterns
at each scale, FlowState inherently adapts its internal dynamics to the input
scale, enabling smaller models, reduced data requirements, and improved
efficiency. We further propose an efficient pretraining strategy that improves
robustness and accelerates training. Despite being the smallest model,
FlowState outperforms all other models and is state-of-the-art for the GIFT-ZS
and the Chronos-ZS benchmarks. Ablation studies confirm the effectiveness of
its components, and we demonstrate its unique ability to adapt online to
varying input sampling rates.

</details>


### [154] [RLHF Fine-Tuning of LLMs for Alignment with Implicit User Feedback in Conversational Recommenders](https://arxiv.org/abs/2508.05289)
*Zhongheng Yang,Aijia Sun,Yushang Zhao,Yinuo Yang,Dannier Li,Chengrui Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一种基于人类反馈强化学习的对话推荐系统训练方法，有效提升了推荐的准确性与用户满意度。


<details>
  <summary>Details</summary>
Motivation: 传统监督微调难以捕捉隐性反馈信号，影响系统性能。

Method: 利用人类反馈强化学习（RLHF）通过奖励模型优化基础大型语言模型，结合对话状态转移实现动态推荐。

Result: 模型在合成与真实数据集上优于传统方法，在准确性、连贯性和用户满意度方面表现更佳。

Conclusion: 隐性信号的对齐有助于实现可扩展且用户适应的对话推荐系统。

Abstract: Conversational recommender systems (CRS) based on Large Language Models
(LLMs) need to constantly be aligned to the user preferences to provide
satisfying and context-relevant item recommendations. The traditional
supervised fine-tuning cannot capture the implicit feedback signal, e.g., dwell
time, sentiment polarity, or engagement patterns. In this paper, we share a
fine-tuning solution using human feedback reinforcement learning (RLHF) to
maximize implied user feedback (IUF) in a multi-turn recommendation context. We
specify a reward model $R_{\phi}$ learnt on weakly-labelled engagement
information and maximize user-centric utility by optimizing the foundational
LLM M_{\theta} through a proximal policy optimization (PPO) approach. The
architecture models conversational state transitions $s_t \to a_t \to s_{t
+1}$, where the action $a_t$ is associated with LLM-generated item suggestions
only on condition of conversation history in the past. The evaluation across
synthetic and real-world datasets (e.g.REDIAL, OpenDialKG) demonstrates that
our RLHF-fine-tuned models can perform better in terms of top-$k$
recommendation accuracy, coherence, and user satisfaction compared to
(arrow-zero-cmwrquca-teja-falset ensuite 2Round group-deca States penalty give
up This paper shows that implicit signal alignment can be efficient in
achieving scalable and user-adaptive design of CRS.

</details>


### [155] [ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning](https://arxiv.org/abs/2508.05310)
*Jelle Luijkx,Zlatan Ajanović,Laura Ferranti,Jens Kober*

Main category: cs.LG

TL;DR: 提出一种结合人类教师反馈和新颖机制的主动技能级数据整合框架（ASkDAgger），用于减少人类标注次数，提高学习效率。


<details>
  <summary>Details</summary>
Motivation: 减少交互模仿学习中对人类教师的需求，提升学习效率和泛化能力。

Method: 引入S-Aware Gating、FIER和PIER三大组件，整合人类计划信息，优化样本采样和模仿学习过程。

Result: 在模拟和实际应用中验证了该方法能有效减少标注次数，改善泛化能力，加快适应变化的能力。

Conclusion: 结合人类反馈的主动学习机制能显著提升交互模仿学习的效率和性能。

Abstract: Human teaching effort is a significant bottleneck for the broader
applicability of interactive imitation learning. To reduce the number of
required queries, existing methods employ active learning to query the human
teacher only in uncertain, risky, or novel situations. However, during these
queries, the novice's planned actions are not utilized despite containing
valuable information, such as the novice's capabilities, as well as
corresponding uncertainty levels. To this end, we allow the novice to say: "I
plan to do this, but I am uncertain." We introduce the Active Skill-level Data
Aggregation (ASkDAgger) framework, which leverages teacher feedback on the
novice plan in three key ways: (1) S-Aware Gating (SAG): Adjusts the gating
threshold to track sensitivity, specificity, or a minimum success rate; (2)
Foresight Interactive Experience Replay (FIER), which recasts valid and
relabeled novice action plans into demonstrations; and (3) Prioritized
Interactive Experience Replay (PIER), which prioritizes replay based on
uncertainty, novice success, and demonstration age. Together, these components
balance query frequency with failure incidence, reduce the number of required
demonstration annotations, improve generalization, and speed up adaptation to
changing domains. We validate the effectiveness of ASkDAgger through
language-conditioned manipulation tasks in both simulation and real-world
environments. Code, data, and videos are available at
https://askdagger.github.io.

</details>


### [156] [Optimal Growth Schedules for Batch Size and Learning Rate in SGD that Reduce SFO Complexity](https://arxiv.org/abs/2508.05297)
*Hikaru Umeda,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 本文提出了优化深度学习中批大小和学习率增长计划的方法，以提高训练效率和效果。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型规模不断扩大带来计算瓶颈，需研究批大小和学习率的合理调度以提升训练效率。

Method: 基于随机一阶oracle复杂度，分析并推导出批大小和学习率的最优增长方案，并通过大量实验验证。

Result: 提出的增长方案能有效降低复杂度，提升大批量训练的效率和效果。

Conclusion: 本研究为深度学习中的大批量训练提供了理论基础和实践指南，有助于实现训练的高效与规模扩展。

Abstract: The unprecedented growth of deep learning models has enabled remarkable
advances but introduced substantial computational bottlenecks. A key factor
contributing to training efficiency is batch-size and learning-rate scheduling
in stochastic gradient methods. However, naive scheduling of these
hyperparameters can degrade optimization efficiency and compromise
generalization. Motivated by recent theoretical insights, we investigated how
the batch size and learning rate should be increased during training to balance
efficiency and convergence. We analyzed this problem on the basis of stochastic
first-order oracle (SFO) complexity, defined as the expected number of gradient
evaluations needed to reach an $\epsilon$-approximate stationary point of the
empirical loss. We theoretically derived optimal growth schedules for the batch
size and learning rate that reduce SFO complexity and validated them through
extensive experiments. Our results offer both theoretical insights and
practical guidelines for scalable and efficient large-batch training in deep
learning.

</details>


### [157] [Adaptive Batch Size and Learning Rate Scheduler for Stochastic Gradient Descent Based on Minimization of Stochastic First-order Oracle Complexity](https://arxiv.org/abs/2508.05302)
*Hikaru Umeda,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 提出一种基于理论的自适应调度策略，通过调整批次大小和学习率，加快深度学习中的SGD收敛速度。


<details>
  <summary>Details</summary>
Motivation: 解决SGD在批次大小和学习率设置上的敏感性问题，提升训练效率。

Method: 利用理论分析中的临界批次大小，结合观察到的梯度范数衰减，设计自适应调度策略调整批次大小和学习率。

Result: 实验表明该策略显著提升了训练收敛速度，比现有调度器效果更优。

Conclusion: 基于理论分析实现的自适应调度有助于加快深度学习模型的训练过程。

Abstract: The convergence behavior of mini-batch stochastic gradient descent (SGD) is
highly sensitive to the batch size and learning rate settings. Recent
theoretical studies have identified the existence of a critical batch size that
minimizes stochastic first-order oracle (SFO) complexity, defined as the
expected number of gradient evaluations required to reach a stationary point of
the empirical loss function in a deep neural network. An adaptive scheduling
strategy is introduced to accelerate SGD that leverages theoretical findings on
the critical batch size. The batch size and learning rate are adjusted on the
basis of the observed decay in the full gradient norm during training.
Experiments using an adaptive joint scheduler based on this strategy
demonstrated improved convergence speed compared with that of existing
schedulers.

</details>


### [158] [Optimal Corpus Aware Training for Neural Machine Translation](https://arxiv.org/abs/2508.05364)
*Yi-Hsiu Liao,Cheng Shen,Brenda,Yang*

Main category: cs.LG

TL;DR: 提出一种基于预训练模型微调的方法OCAT，通过冻结大部分参数，仅调整少量语料相关参数，有效提升翻译任务性能，优于传统训练和一些微调技术。


<details>
  <summary>Details</summary>
Motivation: 现有的Corpus Aware Training（CAT）在训练过程中依赖预先定义高质量语料组，存在误差高、效率低的问题。

Method: 在预训练CAT模型基础上，冻结大部分参数，仅微调少量参数，采用轻量化微调策略。

Result: 在中译英和英译德任务中分别实现+3.6和+1.8 chrF的性能提升，优于普通训练，表现接近或优于其他微调技术。

Conclusion: OCAT方法简洁高效，降低超参数敏感性，能有效提升翻译模型性能。

Abstract: Corpus Aware Training (CAT) leverages valuable corpus metadata during
training by injecting corpus information into each training example, and has
been found effective in the literature, commonly known as the "tagging"
approach. Models trained with CAT inherently learn the quality, domain and
nuance between corpora directly from data, and can easily switch to different
inference behavior. To achieve the best evaluation, CAT models pre-define a
group of high quality data before training starts which can be error-prone and
inefficient. In this work, we propose Optimal Corpus Aware Training (OCAT),
which fine-tunes a CAT pre-trained model by freezing most of the model
parameters and only tuning small set of corpus-related parameters. We show that
OCAT is lightweight, resilient to overfitting, and effective in boosting model
accuracy. We use WMT23 English to Chinese and English to German translation
tasks as our test ground and show +3.6 and +1.8 chrF improvement, respectively,
over vanilla training. Furthermore, our approach is on-par or slightly better
than other state-of-the-art fine-tuning techniques while being less sensitive
to hyperparameter settings.

</details>


### [159] [Divide-and-Conquer for Enhancing Unlabeled Learning, Stability, and Plasticity in Semi-supervised Continual Learning](https://arxiv.org/abs/2508.05316)
*Yue Duan,Taicai Chen,Lei Qi,Yinghuan Shi*

Main category: cs.LG

TL;DR: 提出了一种针对半监督连续学习的框架USP，结合特征空间预留、伪标签和类均值蒸馏，有效提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决半监督连续学习中有效未标记学习、记忆稳定性与学习塑性的平衡问题。

Method: 采用特征空间预留、分而治之伪标签策略和类均值蒸馏三大方法。

Result: 在多个评估中优于现有方法，准确率提升最高达5.94%。

Conclusion: USP框架有效整合不同技术，显著提升半监督连续学习性能。

Abstract: Semi-supervised continual learning (SSCL) seeks to leverage both labeled and
unlabeled data in a sequential learning setup, aiming to reduce annotation
costs while managing continual data arrival. SSCL introduces complex
challenges, including ensuring effective unlabeled learning (UL), while
balancing memory stability (MS) and learning plasticity (LP). Previous SSCL
efforts have typically focused on isolated aspects of the three, while this
work presents USP, a divide-and-conquer framework designed to synergistically
enhance these three aspects: (1) Feature Space Reservation (FSR) strategy for
LP, which constructs reserved feature locations for future classes by shaping
old classes into an equiangular tight frame; (2) Divide-and-Conquer
Pseudo-labeling (DCP) approach for UL, which assigns reliable pseudo-labels
across both high- and low-confidence unlabeled data; and (3)
Class-mean-anchored Unlabeled Distillation (CUD) for MS, which reuses DCP's
outputs to anchor unlabeled data to stable class means for distillation to
prevent forgetting. Comprehensive evaluations show USP outperforms prior SSCL
methods, with gains up to 5.94% in the last accuracy, validating its
effectiveness. The code is available at https://github.com/NJUyued/USP4SSCL.

</details>


### [160] [Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms](https://arxiv.org/abs/2508.05387)
*Jie Xiao,Shaoduo Gan,Changyuan Fan,Qingnan Ren,Alfred Long,Yuchen Zhang,Rymon Yu,Eric Yang,Lynn Ai*

Main category: cs.LG

TL;DR: Echo系统通过实现工作流程的解耦，有效提升大规模强化学习在LLMs上的效率，实现资源的去中心化与 heterogeneity，保持收敛速度与奖励水平。


<details>
  <summary>Details</summary>
Motivation: 解决当前RL后训练过程中在GPU集群中切换推理与训练状态带来的性能瓶颈和系统复杂度。

Method: 提出Echo系统，采用轻量级同步协议，分离推理和训练两个阶段，通过异步策略最大化硬件利用率，在分布式环境中进行多任务协作。

Result: 在多地点部署环境中，与完全融合的基线方法相当的收敛速度和最终奖励，同时将轨迹生成任务转移到普通边缘硬件上，验证其高效性。

Conclusion: 大规模RL在大语言模型上的应用可通过去中心化的策略实现接近数据中心级别的性能，为未来多样化硬件资源的利用提供技术路径。

Abstract: Modern RL-based post-training for large language models (LLMs) co-locate
trajectory sampling and policy optimisation on the same GPU cluster, forcing
the system to switch between inference and training workloads. This serial
context switching violates the single-program-multiple-data (SPMD) assumption
underlying today's distributed training systems. We present Echo, the RL system
that cleanly decouples these two phases across heterogeneous "inference" and
"training" swarms while preserving statistical efficiency. Echo introduces two
lightweight synchronization protocols: a sequential pull mode that refreshes
sampler weights on every API call for minimal bias, and an asynchronous
push-pull mode that streams version-tagged rollouts through a replay buffer to
maximise hardware utilisation. Training three representative RL workloads with
Qwen3-4B, Qwen2.5-7B and Qwen3-32B on a geographically distributed cluster,
Echo matches a fully co-located Verl baseline in convergence speed and final
reward while off-loading trajectory generation to commodity edge hardware.
These promising results demonstrate that large-scale RL for LLMs could achieve
datacentre-grade performance using decentralised, heterogeneous resources.

</details>


### [161] [Latent Preference Bandits](https://arxiv.org/abs/2508.05367)
*Newton Mwai,Emil Carlsson,Fredrik D. Johansson*

Main category: cs.LG

TL;DR: 提出了一种放宽潜在臂算法假设的方法，仅需建模偏好排序，从而在个性化决策中提高效率，并用后验抽样算法实现，实验证明优越性。


<details>
  <summary>Details</summary>
Motivation: 现有潜在臂算法在个性化任务中探索成本高，难以准确建模潜在状态导致模型效果受限。

Method: 基于偏好排序模型，设计后验抽样算法，允许不同实例在相同潜在状态下有不同奖励比例。

Result: 算法性能与完全已知奖励分布的潜在臂算法相当，在奖励尺度变化时表现更佳。

Conclusion: 放宽潜在臂模型假设，基于偏好排序的后验采样算法有效优化个性化任务中的决策过程。

Abstract: Bandit algorithms are guaranteed to solve diverse sequential decision-making
problems, provided that a sufficient exploration budget is available. However,
learning from scratch is often too costly for personalization tasks where a
single individual faces only a small number of decision points. Latent bandits
offer substantially reduced exploration times for such problems, given that the
joint distribution of a latent state and the rewards of actions is known and
accurate. In practice, finding such a model is non-trivial, and there may not
exist a small number of latent states that explain the responses of all
individuals. For example, patients with similar latent conditions may have the
same preference in treatments but rate their symptoms on different scales. With
this in mind, we propose relaxing the assumptions of latent bandits to require
only a model of the \emph{preference ordering} of actions in each latent state.
This allows problem instances with the same latent state to vary in their
reward distributions, as long as their preference orderings are equal. We give
a posterior-sampling algorithm for this problem and demonstrate that its
empirical performance is competitive with latent bandits that have full
knowledge of the reward distribution when this is well-specified, and
outperforms them when reward scales differ between instances with the same
latent state.

</details>


### [162] [Tail-Risk-Safe Monte Carlo Tree Search under PAC-Level Guarantees](https://arxiv.org/abs/2508.05441)
*Zuyuan Zhang,Arnob Ghosh,Tian Lan*

Main category: cs.LG

TL;DR: 本文提出两种基于尾风险度量的方法CVaR-MCTS和Wasserstein-MCTS，有效控制决策中的极端风险，提供理论保证并在模拟环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统MCTS只考虑期望收益，无法应对高风险尾部事件，亟需具备极端风险保障的安全决策方法。

Method: 引入CVaR作为尾风险衡量指标，并结合Wasserstein距离构建不确定性模型，提出CVaR-MCTS和W-MCTS两种算法。

Result: 新方法在模拟环境中表现优于基线，提供了明确的尾风险控制保证和较好的奖励及稳定性。

Conclusion: 所提方法有效提升了MCTS在高风险场景下的安全性与鲁棒性，为高风险决策提供了理论与实践支持。

Abstract: Making decisions with respect to just the expected returns in Monte Carlo
Tree Search (MCTS) cannot account for the potential range of high-risk, adverse
outcomes associated with a decision. To this end, safety-aware MCTS often
consider some constrained variants -- by introducing some form of mean risk
measures or hard cost thresholds. These approaches fail to provide rigorous
tail-safety guarantees with respect to extreme or high-risk outcomes (denoted
as tail-risk), potentially resulting in serious consequence in high-stake
scenarios. This paper addresses the problem by developing two novel solutions.
We first propose CVaR-MCTS, which embeds a coherent tail risk measure,
Conditional Value-at-Risk (CVaR), into MCTS. Our CVaR-MCTS with parameter
$\alpha$ achieves explicit tail-risk control over the expected loss in the
"worst $(1-\alpha)\%$ scenarios." Second, we further address the estimation
bias of tail-risk due to limited samples. We propose Wasserstein-MCTS (or
W-MCTS) by introducing a first-order Wasserstein ambiguity set
$\mathcal{P}_{\varepsilon_{s}}(s,a)$ with radius $\varepsilon_{s}$ to
characterize the uncertainty in tail-risk estimates. We prove PAC tail-safety
guarantees for both CVaR-MCTS and W-MCTS and establish their regret.
Evaluations on diverse simulated environments demonstrate that our proposed
methods outperform existing baselines, effectively achieving robust tail-risk
guarantees with improved rewards and stability.

</details>


### [163] [EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty Estimation for Energy Forecasting](https://arxiv.org/abs/2508.05454)
*Wei Li,Zixin Wang,Qizheng Sun,Qixiang Gao,Fenglei Yang*

Main category: cs.LG

TL;DR: EnergyPatchTST是一种针对能源时间序列预测的创新模型，结合多尺度特征提取、概率预测、未来变量整合和预训练技术，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 准确可靠的能源时间序列预测对电力规划和调度意义重大，但现有深度学习方法在多尺度动态和数据不规则性方面存在局限。

Method: 提出能量补丁变换器，采用多尺度特征提取机制、概率预测框架、未来变量整合和预训练加微调技术。

Result: 实验显示EnergyPatchTST在能量数据集上的预测误差降低7-12%，并实现可靠的不确定性估计。

Conclusion: 该方法有效提升能源时间序列预测的准确性和可靠性，为能源领域提供有价值的预测工具。

Abstract: Accurate and reliable energy time series prediction is of great significance
for power generation planning and allocation. At present, deep learning time
series prediction has become the mainstream method. However, the multi-scale
time dynamics and the irregularity of real data lead to the limitations of the
existing methods. Therefore, we propose EnergyPatchTST, which is an extension
of the Patch Time Series Transformer specially designed for energy forecasting.
The main innovations of our method are as follows: (1) multi-scale feature
extraction mechanism to capture patterns with different time resolutions; (2)
probability prediction framework to estimate uncertainty through Monte Carlo
elimination; (3) integration path of future known variables (such as
temperature and wind conditions); And (4) Pre-training and Fine-tuning examples
to enhance the performance of limited energy data sets. A series of experiments
on common energy data sets show that EnergyPatchTST is superior to other
commonly used methods, the prediction error is reduced by 7-12%, and reliable
uncertainty estimation is provided, which provides an important reference for
time series prediction in the energy field.

</details>


### [164] [NT-ML: Backdoor Defense via Non-target Label Training and Mutual Learning](https://arxiv.org/abs/2508.05404)
*Wenjie Huo,Katinka Wolter*

Main category: cs.LG

TL;DR: 提出一种新颖的防御机制NT-ML，有效抵御多种后门攻击。


<details>
  <summary>Details</summary>
Motivation: 应对深度神经网络中后门攻击的威胁，通过提升模型的安全性和鲁棒性。

Method: 结合非目标标签训练和相互学习，利用教师和学生模型的互补优势净化模型。

Result: 在多种后门攻击下验证了NT-ML的有效性，优于现有防御方法。

Conclusion: NT-ML是一种有效的后门防御策略，能在有限干净样本条件下提升模型安全性。

Abstract: Recent studies have shown that deep neural networks (DNNs) are vulnerable to
backdoor attacks, where a designed trigger is injected into the dataset,
causing erroneous predictions when activated. In this paper, we propose a novel
defense mechanism, Non-target label Training and Mutual Learning (NT-ML), which
can successfully restore the poisoned model under advanced backdoor attacks. NT
aims to reduce the harm of poisoned data by retraining the model with the
outputs of the standard training. At this stage, a teacher model with high
accuracy on clean data and a student model with higher confidence in correct
prediction on poisoned data are obtained. Then, the teacher and student can
learn the strengths from each other through ML to obtain a purified student
model. Extensive experiments show that NT-ML can effectively defend against 6
backdoor attacks with a small number of clean samples, and outperforms 5
state-of-the-art backdoor defenses.

</details>


### [165] [Task complexity shapes internal representations and robustness in neural networks](https://arxiv.org/abs/2508.05463)
*Robert Jankowski,Filippo Radicchi,M. Ángeles Serrano,Marián Boguñá,Santo Fortunato*

Main category: cs.LG

TL;DR: 研究通过多种数据无关的探测方法分析任务难度对多层感知机表示的拓扑结构和鲁棒性的影响。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络内部表示如何受任务复杂度影响，从而改善模型性能和可解释性。

Method: 采用五种探测策略将多层感知机表示为有符号的加权二分图，比较不同任务难度下的表现，分析权重二值化、剪枝、噪声注入等对模型性能的影响。

Result: 发现硬任务模型在二值化后准确率降至随机水平，适度噪声可增强准确性，保持符号结构即可维持高性能。这些现象定义了任务复杂度的无偏量度，强调签名二分图拓扑的重要性。

Conclusion: 神经网络的签名二分图拓扑在表示学习中扮演关键角色，为模型压缩和解释提供有益策略。

Abstract: Neural networks excel across a wide range of tasks, yet remain black boxes.
In particular, how their internal representations are shaped by the complexity
of the input data and the problems they solve remains obscure. In this work, we
introduce a suite of five data-agnostic probes-pruning, binarization, noise
injection, sign flipping, and bipartite network randomization-to quantify how
task difficulty influences the topology and robustness of representations in
multilayer perceptrons (MLPs). MLPs are represented as signed, weighted
bipartite graphs from a network science perspective. We contrast easy and hard
classification tasks on the MNIST and Fashion-MNIST datasets. We show that
binarizing weights in hard-task models collapses accuracy to chance, whereas
easy-task models remain robust. We also find that pruning low-magnitude edges
in binarized hard-task models reveals a sharp phase-transition in performance.
Moreover, moderate noise injection can enhance accuracy, resembling a
stochastic-resonance effect linked to optimal sign flips of small-magnitude
weights. Finally, preserving only the sign structure-instead of precise weight
magnitudes-through bipartite network randomizations suffices to maintain high
accuracy. These phenomena define a model- and modality-agnostic measure of task
complexity: the performance gap between full-precision and binarized or
shuffled neural network performance. Our findings highlight the crucial role of
signed bipartite topology in learned representations and suggest practical
strategies for model compression and interpretability that align with task
complexity.

</details>


### [166] [Cumulative Learning Rate Adaptation: Revisiting Path-Based Schedules for SGD and Adam](https://arxiv.org/abs/2508.05408)
*Asma Atamna,Tom Maus,Fabian Kievelitz,Tobias Glasmachers*

Main category: cs.LG

TL;DR: 本文分析了自适应学习率机制尤其是在Adam优化器中的应用与调整，验证其在训练过程中的实际效用和潜在限制。


<details>
  <summary>Details</summary>
Motivation: 探究动态调整学习率对深度学习训练效果的影响，改进现有的适应机制以提升优化性能。

Method: 回顾并修正2017年提出的基于路径的学习率调整方案，比较其与不同优化器（SGD和Adam）在不同设定下的性能表现，并分析其有效性。

Result: 修正后的路径适应机制在某些场景下提升了训练效率，但其效用依赖于优化器的特性和训练动态，提供了对自适应策略实用性的深入理解。

Conclusion: 自适应学习率策略在特定条件下具有实际优势，但需要根据优化器的内部机制进行调整，未来研究应关注其在不同模型和数据集中的适用性。

Abstract: The learning rate is a crucial hyperparameter in deep learning, with its
ideal value depending on the problem and potentially changing during training.
In this paper, we investigate the practical utility of adaptive learning rate
mechanisms that adjust step sizes dynamically in response to the loss
landscape. We revisit a cumulative path-based adaptation scheme proposed in
2017, which adjusts the learning rate based on the discrepancy between the
observed path length, computed as a time-discounted sum of normalized gradient
steps, and the expected length of a random walk. While the original approach
offers a compelling intuition, we show that its adaptation mechanism for Adam
is conceptually inconsistent due to the optimizer's internal preconditioning.
We propose a corrected variant that better reflects Adam's update dynamics. To
assess the practical value of online learning rate adaptation, we benchmark SGD
and Adam, with and without cumulative adaptation, and compare them to a recent
alternative method. Our results aim to clarify when and why such adaptive
strategies offer practical benefits.

</details>


### [167] [MoMA: A Mixture-of-Multimodal-Agents Architecture for Enhancing Clinical Prediction Modelling](https://arxiv.org/abs/2508.05492)
*Jifan Gao,Mahmudur Rahman,John Caskey,Madeline Oguss,Ann O'Rourke,Randy Brown,Anne Stey,Anoop Mayampurath,Matthew M. Churpek,Guanhua Chen,Majid Afshar*

Main category: cs.LG

TL;DR: 提出了一种多模态电子健康记录的深度学习架构MoMA，通过多个大型语言模型进行不同模态信息整合，显著提升临床预测性能。


<details>
  <summary>Details</summary>
Motivation: 融合多模态EHR数据以提升临床预测的准确性，但现有方法面临数据整合复杂和模型效果有限的问题。

Method: 设计了多代理(MoMA)架构，包括转换非文本模态为结构化文本的专家代理、汇聚信息的聚合代理和最终预测的预测代理，通过整合多模态信息实现统一预测。

Result: 在三项真实世界数据集上进行评估，MoMA在各种任务中均优于现有最先进方法，展示了其优越的准确性和适应性。

Conclusion: MoMA有效整合多模态EHR信息，为临床预测提供了高效、灵活的解决方案，具有推广应用潜力。

Abstract: Multimodal electronic health record (EHR) data provide richer, complementary
insights into patient health compared to single-modality data. However,
effectively integrating diverse data modalities for clinical prediction
modeling remains challenging due to the substantial data requirements. We
introduce a novel architecture, Mixture-of-Multimodal-Agents (MoMA), designed
to leverage multiple large language model (LLM) agents for clinical prediction
tasks using multimodal EHR data. MoMA employs specialized LLM agents
("specialist agents") to convert non-textual modalities, such as medical images
and laboratory results, into structured textual summaries. These summaries,
together with clinical notes, are combined by another LLM ("aggregator agent")
to generate a unified multimodal summary, which is then used by a third LLM
("predictor agent") to produce clinical predictions. Evaluating MoMA on three
prediction tasks using real-world datasets with different modality combinations
and prediction settings, MoMA outperforms current state-of-the-art methods,
highlighting its enhanced accuracy and flexibility across various tasks.

</details>


### [168] [MolSnap: Snap-Fast Molecular Generation with Latent Variational Mean Flow](https://arxiv.org/abs/2508.05411)
*Md Atik Ahamed,Qiang Ye,Qiang Cheng*

Main category: cs.LG

TL;DR: 提出了一种新颖的因果感知分子生成框架，结合CAT和VMF技术，显著提升分子生成的质量、多样性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有条件下分子生成在质量、多样性和推理速度上的不足。

Method: 引入因果感知Transformer和变分平均流框架，通过联合编码和混合高斯潜空间增强生成能力。

Result: 模型在多个分子基准测试中优于现有方法，具有更高的新颖性、多样性和有效性，同时计算效率显著提升。

Conclusion: 提出的框架有效改善了分子生成的质量与效率，为药物设计提供了强大工具。

Abstract: Molecular generation conditioned on textual descriptions is a fundamental
task in computational chemistry and drug discovery. Existing methods often
struggle to simultaneously ensure high-quality, diverse generation and fast
inference. In this work, we propose a novel causality-aware framework that
addresses these challenges through two key innovations. First, we introduce a
Causality-Aware Transformer (CAT) that jointly encodes molecular graph tokens
and text instructions while enforcing causal dependencies during generation.
Second, we develop a Variational Mean Flow (VMF) framework that generalizes
existing flow-based methods by modeling the latent space as a mixture of
Gaussians, enhancing expressiveness beyond unimodal priors. VMF enables
efficient one-step inference while maintaining strong generation quality and
diversity. Extensive experiments on four standard molecular benchmarks
demonstrate that our model outperforms state-of-the-art baselines, achieving
higher novelty (up to 74.5\%), diversity (up to 70.3\%), and 100\% validity
across all datasets. Moreover, VMF requires only one number of function
evaluation (NFE) during conditional generation and up to five NFEs for
unconditional generation, offering substantial computational efficiency over
diffusion-based methods.

</details>


### [169] [Echo State Networks for Bitcoin Time Series Prediction](https://arxiv.org/abs/2508.05416)
*Mansi Sharma,Enrico Sartor,Marc Cavazza,Helmut Prendinger*

Main category: cs.LG

TL;DR: 本文提出使用回声状态网络（ESNs）预测加密货币价格，尤其在极端波动期表现优异，优于其他机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 解决加密货币市场中的高波动性和非平稳性带来的预测困难。

Method: 采用ESNs进行价格预测，并通过Lyapunov指数进行混沌分析，评估模型在极端波动时期的鲁棒性。

Result: ESNs在极端波动期表现优于Boosting和Naive方法，展示出强大的预测能力和在混沌环境中的稳定性。

Conclusion: ESNs是分析和预测高波动、混沌的加密货币市场的有效工具，优于传统机器学习方法。

Abstract: Forecasting stock and cryptocurrency prices is challenging due to high
volatility and non-stationarity, influenced by factors like economic changes
and market sentiment. Previous research shows that Echo State Networks (ESNs)
can effectively model short-term stock market movements, capturing nonlinear
patterns in dynamic data. To the best of our knowledge, this work is among the
first to explore ESNs for cryptocurrency forecasting, especially during extreme
volatility. We also conduct chaos analysis through the Lyapunov exponent in
chaotic periods and show that our approach outperforms existing machine
learning methods by a significant margin. Our findings are consistent with the
Lyapunov exponent analysis, showing that ESNs are robust during chaotic periods
and excel under high chaos compared to Boosting and Na\"ive methods.

</details>


### [170] [Negative Binomial Variational Autoencoders for Overdispersed Latent Modeling](https://arxiv.org/abs/2508.05423)
*Yixuan Zhang,Wenxin Zhang,Hua Jiang,Quyu Kong,Feng Zhou*

Main category: cs.LG

TL;DR: NegBio-VAE通过引入负二项分布，更灵活地建模神经突触点数，优于传统的Poisson模型。


<details>
  <summary>Details</summary>
Motivation: 现有模型无法准确反映神经突触点数的变异性，特别是过度离散化的问题。

Method: 提出NegBio-VAE，利用负二项分布取代Poisson分布，开发多种ELBO优化和可微参数化策略。

Result: 在多个实验中，NegBio-VAE在重建精度方面优于Poisson-VAE，验证了明确建模过度离散的重要性。

Conclusion: 引入负二项分布扩展VAE框架，有助于更真实地捕捉神经活动的变异性，提升建模性能。

Abstract: Biological neurons communicate through spike trains, discrete, irregular
bursts of activity that exhibit variability far beyond the modeling capacity of
conventional variational autoencoders (VAEs). Recent work, such as the
Poisson-VAE, makes a biologically inspired move by modeling spike counts using
the Poisson distribution. However, they impose a rigid constraint: equal mean
and variance, which fails to reflect the true stochastic nature of neural
activity. In this work, we challenge this constraint and introduce NegBio-VAE,
a principled extension of the VAE framework that models spike counts using the
negative binomial distribution. This shift grants explicit control over
dispersion, unlocking a broader and more accurate family of neural
representations. We further develop two ELBO optimization schemes and two
differentiable reparameterization strategies tailored to the negative binomial
setting. By introducing one additional dispersion parameter, NegBio-VAE
generalizes the Poisson latent model to a negative binomial formulation.
Empirical results demonstrate this minor yet impactful change leads to
significant gains in reconstruction fidelity, highlighting the importance of
explicitly modeling overdispersion in spike-like activations.

</details>


### [171] [Tractable Sharpness-Aware Learning of Probabilistic Circuits](https://arxiv.org/abs/2508.05537)
*Hrithik Suresh,Sahil Sidheekh,Vishnu Shreeram M. P,Sriraam Natarajan,Narayanan C. Krishnan*

Main category: cs.LG

TL;DR: 提出一种基于Hessian的正则化方法，减轻概率电路模型的过拟合问题，提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着深度概率电路模型能力增强，过拟合成为关键问题，亟需有效的正则化技术。

Method: 引入Hessian的迹作为平滑程度指标，设计与EM算法兼容的正则化策略，促进模型收敛至平滑极小值。

Result: 实验表明新方法有效引导概率电路模型找到更平坦的极小点，从而改善泛化性能。

Conclusion: 利用Hessian迹的高效计算实现了深度概率电路的正则化，有助于解决过拟合，提高模型泛化能力。

Abstract: Probabilistic Circuits (PCs) are a class of generative models that allow
exact and tractable inference for a wide range of queries. While recent
developments have enabled the learning of deep and expressive PCs, this
increased capacity can often lead to overfitting, especially when data is
limited. We analyze PC overfitting from a log-likelihood-landscape perspective
and show that it is often caused by convergence to sharp optima that generalize
poorly. Inspired by sharpness aware minimization in neural networks, we propose
a Hessian-based regularizer for training PCs. As a key contribution, we show
that the trace of the Hessian of the log-likelihood-a sharpness proxy that is
typically intractable in deep neural networks-can be computed efficiently for
PCs. Minimizing this Hessian trace induces a gradient-norm-based regularizer
that yields simple closed-form parameter updates for EM, and integrates
seamlessly with gradient based learning methods. Experiments on synthetic and
real-world datasets demonstrate that our method consistently guides PCs toward
flatter minima, improves generalization performance.

</details>


### [172] [Federated Multi-Objective Learning with Controlled Pareto Frontiers](https://arxiv.org/abs/2508.05424)
*Jiansheng Rao,Jiayi Li,Zhizhi Gong,Soummya Kar,Haoxuan Li*

Main category: cs.LG

TL;DR: 提出了一种新型的联邦多目标优化框架CR-FMOL，通过偏好锥约束确保每个客户端的帕累托最优，提高了客户端的公平性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如FedAvg偏向多数客户端，导致少数客户端受益不足，需改善公平性。

Method: 引入偏好锥约束，结合局部多梯度平均和服务器优化，确保每个客户端的帕累托最优。

Result: CR-FMOL在非IID场景下提升了客户端公平性，尽管早期性能略低于FedAvg，但随着训练轮次增加，精度有望媲美。

Conclusion: CR-FMOL通过偏好锥约束实现公平性，为联邦多目标优化提供新思路。

Abstract: Federated learning (FL) is a widely adopted paradigm for privacy-preserving
model training, but FedAvg optimise for the majority while under-serving
minority clients. Existing methods such as federated multi-objective learning
(FMOL) attempts to import multi-objective optimisation (MOO) into FL. However,
it merely delivers task-wise Pareto-stationary points, leaving client fairness
to chance. In this paper, we introduce Conically-Regularised FMOL (CR-FMOL),
the first federated MOO framework that enforces client-wise Pareto optimality
through a novel preference-cone constraint. After local federated
multi-gradient descent averaging (FMGDA) / federated stochastic multi-gradient
descent averaging (FSMGDA) steps, each client transmits its aggregated
task-loss vector as an implicit preference; the server then solves a
cone-constrained Pareto-MTL sub-problem centred at the uniform vector,
producing a descent direction that is Pareto-stationary for every client within
its cone. Experiments on non-IID benchmarks show that CR-FMOL enhances client
fairness, and although the early-stage performance is slightly inferior to
FedAvg, it is expected to achieve comparable accuracy given sufficient training
rounds.

</details>


### [173] [Group Causal Policy Optimization for Post-Training Large Language Models](https://arxiv.org/abs/2508.05428)
*Ziyin Gu,Jingyao Wang,Ran Zuo,Chuxiong Sun,Zeen Song,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: 提出了一种结合因果结构的优化方法GCPO，有效提升多轮推理任务表现，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法忽视候选响应中语义交互（如互补和矛盾）的问题。

Method: 引入结构因果模型（SCM）揭示响应间隐藏依赖，设计因果信息引导的奖励调整和KL正则化，构建GCPO。

Result: 实验显示GCPO在多个推理基准测试中显著优于GRPO等现有方法。

Conclusion: 结合因果结构的策略优化能有效增强多轮推理任务中的响应质量和模型表现。

Abstract: Recent advances in large language models (LLMs) have broadened their
applicability across diverse tasks, yet specialized domains still require
targeted post training. Among existing methods, Group Relative Policy
Optimization (GRPO) stands out for its efficiency, leveraging groupwise
relative rewards while avoiding costly value function learning. However, GRPO
treats candidate responses as independent, overlooking semantic interactions
such as complementarity and contradiction. To address this challenge, we first
introduce a Structural Causal Model (SCM) that reveals hidden dependencies
among candidate responses induced by conditioning on a final integrated output
forming a collider structure. Then, our causal analysis leads to two insights:
(1) projecting responses onto a causally informed subspace improves prediction
quality, and (2) this projection yields a better baseline than query only
conditioning. Building on these insights, we propose Group Causal Policy
Optimization (GCPO), which integrates causal structure into optimization
through two key components: a causally informed reward adjustment and a novel
KL regularization term that aligns the policy with a causally projected
reference distribution. Comprehensive experimental evaluations demonstrate that
GCPO consistently surpasses existing methods, including GRPO across multiple
reasoning benchmarks.

</details>


### [174] [Adapting Vision-Language Models Without Labels: A Comprehensive Survey](https://arxiv.org/abs/2508.05547)
*Hao Dong,Lijun Sheng,Jian Liang,Ran He,Eleni Chatzi,Olga Fink*

Main category: cs.LG

TL;DR: 本文综述了视觉-语言模型（VLMs）在无监督自适应中的研究现状，提出四类主要范畴，分析核心方法和未来挑战。


<details>
  <summary>Details</summary>
Motivation: 随着VLMs在多任务中的表现提升，针对其在特定场景中的适应能力不足，研究者关注无监督自适应技术以提升实用性。

Method: 提出基于未标注视觉数据可用性和性质的分类体系，系统梳理不同范畴的适应方法，并分析主流基准与未来方向。

Result: 构建了完整的理论框架，涵盖数据自由、无监督领域转移、逐例测试时适应与在线测试时适应四大范畴，梳理核心技术与挑战。

Conclusion: 通过统一分类与分析，促进未来无监督VLMs适应技术的发展与应用，提高其实际性能与效率。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable generalization
capabilities across a wide range of tasks. However, their performance often
remains suboptimal when directly applied to specific downstream scenarios
without task-specific adaptation. To enhance their utility while preserving
data efficiency, recent research has increasingly focused on unsupervised
adaptation methods that do not rely on labeled data. Despite the growing
interest in this area, there remains a lack of a unified, task-oriented survey
dedicated to unsupervised VLM adaptation. To bridge this gap, we present a
comprehensive and structured overview of the field. We propose a taxonomy based
on the availability and nature of unlabeled visual data, categorizing existing
approaches into four key paradigms: Data-Free Transfer (no data), Unsupervised
Domain Transfer (abundant data), Episodic Test-Time Adaptation (batch data),
and Online Test-Time Adaptation (streaming data). Within this framework, we
analyze core methodologies and adaptation strategies associated with each
paradigm, aiming to establish a systematic understanding of the field.
Additionally, we review representative benchmarks across diverse applications
and highlight open challenges and promising directions for future research. An
actively maintained repository of relevant literature is available at
https://github.com/tim-learn/Awesome-LabelFree-VLMs.

</details>


### [175] [Discovering Interpretable Programmatic Policies via Multimodal LLM-assisted Evolutionary Search](https://arxiv.org/abs/2508.05433)
*Qinglong Hu,Xialiang Tong,Mingxuan Yuan,Fei Liu,Zhichao Lu,Qingfu Zhang*

Main category: cs.LG

TL;DR: 提出一种结合多模态大语言模型和进化搜索的可解释控制策略发现新方法，兼顾性能和透明度。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习在控制策略中的可解释性不足和高性能需求。

Method: 利用多模态大语言模型作为策略生成器，结合演化机制，融合视觉反馈进行行为分析以优化策略。

Result: 在两个控制任务中，与PPO性能相当，同时实现可解释性和追溯性，优于预设领域专用语言。

Conclusion: MLES展示了成为未来可解释控制策略发现的有力候选，具有广泛的应用潜力。

Abstract: Interpretability and high performance are essential goals in designing
control policies, particularly for safety-critical tasks. Deep reinforcement
learning has greatly enhanced performance, yet its inherent lack of
interpretability often undermines trust and hinders real-world deployment. This
work addresses these dual challenges by introducing a novel approach for
programmatic policy discovery, called Multimodal Large Language Model-assisted
Evolutionary Search (MLES). MLES utilizes multimodal large language models as
policy generators, combining them with evolutionary mechanisms for automatic
policy optimization. It integrates visual feedback-driven behavior analysis
within the policy generation process to identify failure patterns and
facilitate targeted improvements, enhancing the efficiency of policy discovery
and producing adaptable, human-aligned policies. Experimental results show that
MLES achieves policy discovery capabilities and efficiency comparable to
Proximal Policy Optimization (PPO) across two control tasks, while offering
transparent control logic and traceable design processes. This paradigm
overcomes the limitations of predefined domain-specific languages, facilitates
knowledge transfer and reuse, and is scalable across various control tasks.
MLES shows promise as a leading approach for the next generation of
interpretable control policy discovery.

</details>


### [176] [Competing Risks: Impact on Risk Estimation and Algorithmic Fairness](https://arxiv.org/abs/2508.05435)
*Vincent Jeanselme,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: 忽视竞争风险在生存分析中的偏差和公平性问题，影响风险估计和公平性。


<details>
  <summary>Details</summary>
Motivation: 提升生存分析的准确性和公平性，避免因错误处理竞争风险而导致的偏差和不公。

Method: 建立理论框架量化竞争风险作为删失的误差，分析其对预测性能和公平性的影响，结合心血管管理的实证分析。

Result: 忽视竞争风险导致风险高估和公平性下降，尤其影响高风险群体，加剧不平等。

Conclusion: 建议在生存模型中考虑竞争风险，以提高预测的准确性和公平性，避免系统性偏差。

Abstract: Accurate time-to-event prediction is integral to decision-making, informing
medical guidelines, hiring decisions, and resource allocation. Survival
analysis, the quantitative framework used to model time-to-event data, accounts
for patients who do not experience the event of interest during the study
period, known as censored patients. However, many patients experience events
that prevent the observation of the outcome of interest. These competing risks
are often treated as censoring, a practice frequently overlooked due to a
limited understanding of its consequences. Our work theoretically demonstrates
why treating competing risks as censoring introduces substantial bias in
survival estimates, leading to systematic overestimation of risk and,
critically, amplifying disparities. First, we formalize the problem of
misclassifying competing risks as censoring and quantify the resulting error in
survival estimates. Specifically, we develop a framework to estimate this error
and demonstrate the associated implications for predictive performance and
algorithmic fairness. Furthermore, we examine how differing risk profiles
across demographic groups lead to group-specific errors, potentially
exacerbating existing disparities. Our findings, supported by an empirical
analysis of cardiovascular management, demonstrate that ignoring competing
risks disproportionately impacts the individuals most at risk of these events,
potentially accentuating inequity. By quantifying the error and highlighting
the fairness implications of the common practice of considering competing risks
as censoring, our work provides a critical insight into the development of
survival models: practitioners must account for competing risks to improve
accuracy, reduce disparities in risk assessment, and better inform downstream
decisions.

</details>


### [177] [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](https://arxiv.org/abs/2508.05612)
*Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai*

Main category: cs.LG

TL;DR: 提出Shuffle-R1框架，通过动态重组轨迹采样和批次组成，解决RL微调中的优势塌缩和回滚沉默问题，提升多模态大语言模型的推理能力训练效率。


<details>
  <summary>Details</summary>
Motivation: 提高多模态大语言模型在强化学习微调中的训练效率，解决优势塌缩和回滚沉默问题，增强模型推理能力。

Method: 引入成对轨迹采样和优势驱动的轨迹洗牌策略，改善梯度信号质量和增大有效回滚的曝光度，优化采样与批次重组方式。

Result: 在多个推理基准测试中，方法显著优于强基线，且开销有限，验证了数据驱动的改进对RL训练效率的促进作用。

Conclusion: 数据驱动的轨迹采样与重组策略在RL微调中有效缓解优势塌缩和回滚沉默，推动多模态大语言模型的高效推理能力发展。

Abstract: Reinforcement learning (RL) has emerged as an effective post-training
paradigm for enhancing the reasoning capabilities of multimodal large language
model (MLLM). However, current RL pipelines often suffer from training
inefficiencies caused by two underexplored issues: Advantage Collapsing, where
most advantages in a batch concentrate near zero, and Rollout Silencing, where
the proportion of rollouts contributing non-zero gradients diminishes over
time. These issues lead to suboptimal gradient updates and hinder long-term
learning efficiency. To address these issues, we propose Shuffle-R1, a simple
yet principled framework that improves RL fine-tuning efficiency by dynamically
restructuring trajectory sampling and batch composition. It introduces (1)
Pairwise Trajectory Sampling, which selects high-contrast trajectories with
large advantages to improve gradient signal quality, and (2) Advantage-based
Trajectory Shuffle, which increases exposure of valuable rollouts through
informed batch reshuffling. Experiments across multiple reasoning benchmarks
show that our framework consistently outperforms strong RL baselines with
minimal overhead. These results highlight the importance of data-centric
adaptations for more efficient RL training in MLLM.

</details>


### [178] [TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution](https://arxiv.org/abs/2508.05616)
*Zhikai Zhao,Chuanbo Hua,Federico Berto,Kanghoon Lee,Zihan Ma,Jiachen Li,Jinkyoo Park*

Main category: cs.LG

TL;DR: TrajEvo通过进化算法和大语言模型自动设计轨迹预测启发式方法，提升了预测准确性和OOD泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统规则和深度学习方法在轨迹预测中存在准确性不足、泛化差和可解释性差的问题。

Method: 引入进化算法结合大语言模型，利用交叉生成精英采样和统计反馈循环优化预测启发式。

Result: TrajEvo在多个实际数据集上优于现有方法，尤其在未见的OOD场景中表现优越。

Conclusion: TrajEvo实现了自动化、快速、可解释且具有良好泛化能力的轨迹预测启发式设计，推动了相关领域的发展。

Abstract: Trajectory prediction is a critical task in modeling human behavior,
especially in safety-critical domains such as social robotics and autonomous
vehicle navigation. Traditional heuristics based on handcrafted rules often
lack accuracy and generalizability. Although deep learning approaches offer
improved performance, they typically suffer from high computational cost,
limited explainability, and, importantly, poor generalization to
out-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a
framework that leverages Large Language Models (LLMs) to automatically design
trajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to
generate and refine prediction heuristics from past trajectory data. We propose
two key innovations: Cross-Generation Elite Sampling to encourage population
diversity, and a Statistics Feedback Loop that enables the LLM to analyze and
improve alternative predictions. Our evaluations demonstrate that TrajEvo
outperforms existing heuristic methods across multiple real-world datasets, and
notably surpasses both heuristic and deep learning methods in generalizing to
an unseen OOD real-world dataset. TrajEvo marks a promising step toward the
automated design of fast, explainable, and generalizable trajectory prediction
heuristics. We release our source code to facilitate future research at
https://github.com/ai4co/trajevo.

</details>


### [179] [Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](https://arxiv.org/abs/2508.05469)
*Zachary Robertson,Sanmi Koyejo*

Main category: cs.LG

TL;DR: 提出一种基于信息理论的无真值评估机制，用于检测AI系统的真伪性，提高抗操纵性。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统评估缺乏可靠的无真值标准，容易被操控或误导。

Method: 通过研究信息测度的游戏抗性，特别是f-互信息，结合数据处理不等式，设计稳定的评估机制，同时在不同信息测度下进行实证验证。

Result: 机制在多领域表现出优异的区分能力，比传统方法抗操纵性强10-100倍，且在最优压缩比下表现最佳。

Conclusion: 基于信息理论的评估机制能有效提升AI系统评估的稳定性和抗操纵能力，为无真值评估提供了理论基础和实证支持。

Abstract: We develop mechanisms for evaluating AI systems without ground truth by
exploiting a connection between gaming resistance and output quality. The data
processing inequality ensures post-hoc attempts to game a metric degrades both
information content and task performance. We prove that f-mutual information
measures are the unique gaming resistant mechanisms under natural conditions,
with the overseer acting as an agent. While Shannon mutual information faces
exponential sample complexity, bounded measures like total variation distance
remain tractable. Empirically, across ten domains from translation to peer
review, all information-theoretic mechanisms achieve perfect discrimination (d
> 0.5) between faithful and strategic agents. In contrast, LLM judges exhibit
systematic evaluation inversion, preferring fabricated content over accurate
summaries. Our mechanisms show 10-100x better robustness to adversarial
manipulation than current practices. We also find performance follows an
inverted-U curve with compression ratio, peaking at 10:1 where agent responses
exhibit optimal information diversity (3 effective dimensions), giving a
bias-variance perspective on when our approach is expected to be most
effective.

</details>


### [180] [Prediction of Survival Outcomes under Clinical Presence Shift: A Joint Neural Network Architecture](https://arxiv.org/abs/2508.05472)
*Vincent Jeanselme,Glen Martin,Matthew Sperrin,Niels Peek,Brian Tom,Jessica Barrett*

Main category: cs.LG

TL;DR: 提出一种多任务循环神经网络模型，联合建模观察时间和缺失过程，提高电子健康记录中临床存在感变化对预测模型的影响，应对不同环境中的模型迁移问题。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中的临床存在感变化影响模型性能和迁移性，亟需有效模型应对环境变化。

Method: 采用多任务循环神经网络同时建模观察时间和缺失过程，以提升预测模型的稳健性和迁移性。

Result: 在MIMIC-III数据集的死亡率预测任务中，该方法优于传统模型，展现出更强的性能和迁移能力。

Conclusion: 联合建模观察时间和缺失过程有助于提升电子健康记录预测模型的性能与迁移性，应被广泛采用。

Abstract: Electronic health records arise from the complex interaction between patients
and the healthcare system. This observation process of interactions, referred
to as clinical presence, often impacts observed outcomes. When using electronic
health records to develop clinical prediction models, it is standard practice
to overlook clinical presence, impacting performance and limiting the
transportability of models when this interaction evolves. We propose a
multi-task recurrent neural network that jointly models the inter-observation
time and the missingness processes characterising this interaction in parallel
to the survival outcome of interest. Our work formalises the concept of
clinical presence shift when the prediction model is deployed in new settings
(e.g. different hospitals, regions or countries), and we theoretically justify
why the proposed joint modelling can improve transportability under changes in
clinical presence. We demonstrate, in a real-world mortality prediction task in
the MIMIC-III dataset, how the proposed strategy improves performance and
transportability compared to state-of-the-art prediction models that do not
incorporate the observation process. These results emphasise the importance of
leveraging clinical presence to improve performance and create more
transportable clinical prediction models.

</details>


### [181] [Parameter-free entropy-regularized multi-view clustering with hierarchical feature selection](https://arxiv.org/abs/2508.05504)
*Kristina P. Sinaga,Sara Colantonio,Miin-Shen Yang*

Main category: cs.LG

TL;DR: 提出两种基于信噪比正则化的多视图聚类算法，实现无需参数调节的自适应视图和特征融合，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多视图聚类中高维特征处理和视图信息融合的自动化与效率问题。

Method: 引入信噪比正则化和层次降维技术，设计参数全自动调节的聚类算法AMVFCM-U和AAMVFCM-U。

Result: 在五个基准数据集上优于15种最新方法，AAMVFCM-U提升计算效率97%，极大减少特征维度。

Conclusion: 提出的算法通过信噪比正则化实现自动调节视图与特征贡献，验证其优越性与实用性。

Abstract: Multi-view clustering faces critical challenges in automatically discovering
patterns across heterogeneous data while managing high-dimensional features and
eliminating irrelevant information. Traditional approaches suffer from manual
parameter tuning and lack principled cross-view integration mechanisms. This
work introduces two complementary algorithms: AMVFCM-U and AAMVFCM-U, providing
a unified parameter-free framework. Our approach replaces fuzzification
parameters with entropy regularization terms that enforce adaptive cross-view
consensus. The core innovation employs signal-to-noise ratio based
regularization ($\delta_j^h = \frac{\bar{x}_j^h}{(\sigma_j^h)^2}$) for
principled feature weighting with convergence guarantees, coupled with
dual-level entropy terms that automatically balance view and feature
contributions. AAMVFCM-U extends this with hierarchical dimensionality
reduction operating at feature and view levels through adaptive thresholding
($\theta^{h^{(t)}} = \frac{d_h^{(t)}}{n}$). Evaluation across five diverse
benchmarks demonstrates superiority over 15 state-of-the-art methods. AAMVFCM-U
achieves up to 97% computational efficiency gains, reduces dimensionality to
0.45% of original size, and automatically identifies critical view combinations
for optimal pattern discovery.

</details>


### [182] [X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment](https://arxiv.org/abs/2508.05568)
*Qinghua Yao,Xiangrui Xu,Zhize Li*

Main category: cs.LG

TL;DR: 提出一种面向非对齐数据样本和本地独立推理的垂直联邦学习框架X-VFL，通过特征补全和决策子空间对齐显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决垂直联邦学习中数据样本对齐困难和限制本地推理的挑战。

Method: 设计XCom和DS-Align两个模块，结合不同算法的收敛性分析。

Result: 在真实数据集上实现了显著性能提升，例如CIFAR-10提高15%，MIMIC-III提高43%。

Conclusion: X-VFL有效解决非对齐特征和本地推理问题，具有实际应用优势。

Abstract: Vertical Federated Learning (VFL) enables collaborative learning by
integrating disjoint feature subsets from multiple clients/parties. However,
VFL typically faces two key challenges: i) the requirement for perfectly
aligned data samples across all clients (missing features are not allowed); ii)
the requirement for joint collaborative inference/prediction involving all
clients (it does not support locally independent inference on a single client).
To address these challenges, we propose X-VFL, a new VFL framework designed to
deal with the non-aligned data samples with (partially) missing features and to
support locally independent inference of new data samples for each client. In
particular, we design two novel modules in X-VFL: Cross Completion (XCom) and
Decision Subspace Alignment (DS-Align). XCom can complete/reconstruct missing
features for non-aligned data samples by leveraging information from other
clients. DS-Align aligns local features with completed and global features
across all clients within the decision subspace, thus enabling locally
independent inference at each client. Moreover, we provide convergence theorems
for different algorithms used in training X-VFL, showing an $O(1/\sqrt{T})$
convergence rate for SGD-type algorithms and an $O(1/T)$ rate for PAGE-type
algorithms, where $T$ denotes the number of training update steps. Extensive
experiments on real-world datasets demonstrate that X-VFL significantly
outperforms existing methods, e.g., achieving a 15% improvement in accuracy on
the image CIFAR-10 dataset and a 43% improvement on the medical MIMIC-III
dataset. These results validate the practical effectiveness and superiority of
X-VFL, particularly in scenarios involving partially missing features and
locally independent inference.

</details>


### [183] [Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge Graph Embedding Models](https://arxiv.org/abs/2508.05587)
*Claudia d'Amato,Ivan Diliso,Nicola Fanizzi,Zafar Saeed*

Main category: cs.LG

TL;DR: 本论文提出了一个扩展工具，增强了PyKEEN框架中的负采样策略，提升知识图谱嵌入模型的性能和开发灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前知识图谱嵌入模型在负样本采样策略上支持有限，亟需更先进且灵活的解决方案以提升模型性能。

Method: 在PyKEEN框架中集成多种静态和动态负采样策略，构建模块化架构，验证其在链接预测任务中的效果。

Result: 扩展显著提升了负采样的质量和模型性能，为未来的嵌入方法开发提供了便利。

Conclusion: 该扩展充分满足了对高效、灵活负采样策略的需求，推动了知识图谱嵌入技术的发展。

Abstract: Embedding methods have become popular due to their scalability on link
prediction and/or triple classification tasks on Knowledge Graphs. Embedding
models are trained relying on both positive and negative samples of triples.
However, in the absence of negative assertions, these must be usually
artificially generated using various negative sampling strategies, ranging from
random corruption to more sophisticated techniques which have an impact on the
overall performance. Most of the popular libraries for knowledge graph
embedding, support only basic such strategies and lack advanced solutions. To
address this gap, we deliver an extension for the popular KGE framework PyKEEN
that integrates a suite of several advanced negative samplers (including both
static and dynamic corruption strategies), within a consistent modular
architecture, to generate meaningful negative samples, while remaining
compatible with existing PyKEEN -based workflows and pipelines. The developed
extension not only enhancesPyKEEN itself but also allows for easier and
comprehensive development of embedding methods and/or for their customization.
As a proof of concept, we present a comprehensive empirical study of the
developed extensions and their impact on the performance (link prediction
tasks) of different embedding methods, which also provides useful insights for
the design of more effective strategies

</details>


### [184] [Optimizing IoT Threat Detection with Kolmogorov-Arnold Networks (KANs)](https://arxiv.org/abs/2508.05591)
*Natalia Emelianova,Carlos Kamienski,Ronaldo C. Prati*

Main category: cs.LG

TL;DR: Kolmogorov-Arnold Networks (KANs)在物联网入侵检测中表现出优越的性能和解释性，优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 随着物联网规模的扩大，网络安全威胁增加，迫切需要更有效的入侵检测模型。

Method: 本文探讨了Kolmogorov-Arnold Networks（KANs）作为检测工具，比较其与传统MLP、随机森林和XGBoost的性能。

Result: KANs在准确率和可解释性方面优于传统MLPs，并与最新模型相当，展现出良好的应用前景。

Conclusion: KANs提供了一种具有潜力的、具有优异性能和可解释性的入侵检测方法，适合物联网安全防护。

Abstract: The exponential growth of the Internet of Things (IoT) has led to the
emergence of substantial security concerns, with IoT networks becoming the
primary target for cyberattacks. This study examines the potential of
Kolmogorov-Arnold Networks (KANs) as an alternative to conventional machine
learning models for intrusion detection in IoT networks. The study demonstrates
that KANs, which employ learnable activation functions, outperform traditional
MLPs and achieve competitive accuracy compared to state-of-the-art models such
as Random Forest and XGBoost, while offering superior interpretability for
intrusion detection in IoT networks.

</details>


### [185] [Non-omniscient backdoor injection with a single poison sample: Proving the one-poison hypothesis for linear regression and linear classification](https://arxiv.org/abs/2508.05600)
*Thorsten Peinemann,Paula Arnold,Sebastian Berndt,Thomas Eisenbarth,Esfandiar Mohammadi*

Main category: cs.LG

TL;DR: 研究展示了单样本中毒攻击（只需一个污染样本）即可成功植入后门，并且影响有限。


<details>
  <summary>Details</summary>
Motivation: 探讨在极少中毒样本条件下后门攻击的可行性和影响，为模型安全提供新视角。

Method: 提建立一/线性回归和分类的数学模型，分析单样本中毒对模型的影响，并通过实验证明其效果。

Result: 证明单样本中毒可实现零误差后门植入，影响有限，部分情况下毒样本对模型无影响。

Conclusion: 单样本中毒攻击具有潜在威胁，但在某些方向或条件下影响可被规避，为模型防御提供启示。

Abstract: Backdoor injection attacks are a threat to machine learning models that are
trained on large data collected from untrusted sources; these attacks enable
attackers to inject malicious behavior into the model that can be triggered by
specially crafted inputs. Prior work has established bounds on the success of
backdoor attacks and their impact on the benign learning task, however, an open
question is what amount of poison data is needed for a successful backdoor
attack. Typical attacks either use few samples, but need much information about
the data points or need to poison many data points.
  In this paper, we formulate the one-poison hypothesis: An adversary with one
poison sample and limited background knowledge can inject a backdoor with zero
backdooring-error and without significantly impacting the benign learning task
performance. Moreover, we prove the one-poison hypothesis for linear regression
and linear classification. For adversaries that utilize a direction that is
unused by the benign data distribution for the poison sample, we show that the
resulting model is functionally equivalent to a model where the poison was
excluded from training. We build on prior work on statistical backdoor learning
to show that in all other cases, the impact on the benign learning task is
still limited. We also validate our theoretical results experimentally with
realistic benchmark data sets.

</details>


### [186] [On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification](https://arxiv.org/abs/2508.05629)
*Yongliang Wu,Yizhou Zhou,Zhou Ziheng,Yingzhe Peng,Xinyu Ye,Xinting Hu,Wenbo Zhu,Lu Qi,Ming-Hsuan Yang,Xu Yang*

Main category: cs.LG

TL;DR: 提出动态微调（DFT）以改善大型语言模型的微调效果，显著优于标准微调并在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决标准微调在泛化能力上的局限性，使模型表现更接近强化学习的方法。

Method: 通过数学分析，发现标准微调的梯度隐含不合理的奖励结构，提出动态调节梯度的DFT方法以增强泛化性。

Result: DFT在多个基准测试中优于标准微调，在离线强化学习中也显示出竞争力，提升模型的泛化能力。

Conclusion: 该方法结合理论洞察与实践应用，有效提升了微调的性能，简洁且实用。

Abstract: We present a simple yet theoretically motivated improvement to Supervised
Fine-Tuning (SFT) for the Large Language Model (LLM), addressing its limited
generalization compared to reinforcement learning (RL). Through mathematical
analysis, we reveal that standard SFT gradients implicitly encode a problematic
reward structure that may severely restrict the generalization capabilities of
model. To rectify this, we propose Dynamic Fine-Tuning (DFT), stabilizing
gradient updates for each token by dynamically rescaling the objective function
with the probability of this token. Remarkably, this single-line code change
significantly outperforms standard SFT across multiple challenging benchmarks
and base models, demonstrating greatly improved generalization. Additionally,
our approach shows competitive results in offline RL settings, offering an
effective yet simpler alternative. This work bridges theoretical insight and
practical solutions, substantially advancing SFT performance. The code will be
available at https://github.com/yongliang-wu/DFT.

</details>
