<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 21]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks](https://arxiv.org/abs/2510.19829)
*Meghna Roy Chowdhury,Yi Ding,Shreyas Sen*

Main category: eess.SP

TL;DR: SSL-SE-EEG框架结合自监督学习和SE-Nets，通过将EEG信号转化为2D图像，提高了特征提取、噪声鲁棒性和对标记数据的依赖性，在多个数据集上取得了最先进的准确率，适用于实时BCI应用。


<details>
  <summary>Details</summary>
Motivation: EEG在脑机接口和神经诊断中至关重要，但面临噪声、数据缺失和高昂标注成本的挑战。

Method: SSL-SE-EEG框架将EEG信号转化为结构化2D图像，并利用自监督学习和Squeeze-Excitation Networks进行特征提取。

Result: 在MindBigData、TUH-AB、SEED-IV和BCI-IV数据集上进行了实验验证，在MindBigData上达到91%的准确率，在TUH-AB上达到85%的准确率，优于现有技术。

Conclusion: SSL-SE-EEG通过实现低功耗、可扩展的EEG处理，为生物医学信号分析、神经工程和下一代BCI提供了有前景的解决方案。

Abstract: Electroencephalography (EEG) plays a crucial role in brain-computer
interfaces (BCIs) and neurological diagnostics, but its real-world deployment
faces challenges due to noise artifacts, missing data, and high annotation
costs. We introduce SSL-SE-EEG, a framework that integrates Self-Supervised
Learning (SSL) with Squeeze-and-Excitation Networks (SE-Nets) to enhance
feature extraction, improve noise robustness, and reduce reliance on labeled
data. Unlike conventional EEG processing techniques, SSL-SE-EEG} transforms EEG
signals into structured 2D image representations, suitable for deep learning.
Experimental validation on MindBigData, TUH-AB, SEED-IV and BCI-IV datasets
demonstrates state-of-the-art accuracy (91% in MindBigData, 85% in TUH-AB),
making it well-suited for real-time BCI applications. By enabling low-power,
scalable EEG processing, SSL-SE-EEG presents a promising solution for
biomedical signal analysis, neural engineering, and next-generation BCIs.

</details>


### [2] [Low-Latency Neural Inference on an Edge Device for Real-Time Handwriting Recognition from EEG Signals](https://arxiv.org/abs/2510.19832)
*Ovishake Sen,Raghav Soni,Darpan Virmani,Akshar Parekh,Patrick Lehman,Sarthak Jena,Adithi Katikhaneni,Adam Khalifa,Baibhab Chatterjee*

Main category: eess.SP

TL;DR: 通过结合先进的机器学习和信息丰富的脑电图(EEG)特征提取，我们开发了一种能够实现实时、高精度神经解码的便携式边缘设备脑机接口(BCI)，大大提高了无创BCI在支持实时通信方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在克服非侵入性脑电图(EEG)在信号信噪比和空间分辨率方面的局限性，以实现高精度的意念手写神经解码，并将其应用于便携式边缘设备，为严重运动或言语障碍者提供交流途径。

Method: 收集了15名参与者进行意念手写任务的32通道EEG数据集。对信号进行带通滤波和伪迹子空间重建预处理，并提取了85个时域、频域和图域特征。将时间卷积网络与多层感知器相结合，构建了EEdGeNet混合架构。

Result: 在NVIDIA Jetson TX2上部署时，EEdGeNet系统实现了89.83%的准确率，每字符延迟为914.18毫秒。通过仅选择10个关键特征，延迟减少了4.5倍（达到202.6毫秒），准确率仅损失不到1%。

Conclusion: 本研究证明了先进的机器学习和信息丰富的EEG特征提取可以克服无创BCI的现有瓶颈，为实现高精度、低延迟、全便携的非侵入性BCI提供了可行途径，支持实时通信。

Abstract: Brain-computer interfaces (BCIs) offer a pathway to restore communication for
individuals with severe motor or speech impairments. Imagined handwriting
provides an intuitive paradigm for character-level neural decoding, bridging
the gap between human intention and digital communication. While invasive
approaches such as electrocorticography (ECoG) achieve high accuracy, their
surgical risks limit widespread adoption. Non-invasive electroencephalography
(EEG) offers safer and more scalable alternatives but suffers from low
signal-to-noise ratio and spatial resolution, constraining its decoding
precision. This work demonstrates that advanced machine learning combined with
informative EEG feature extraction can overcome these barriers, enabling
real-time, high-accuracy neural decoding on portable edge devices. A 32-channel
EEG dataset was collected from fifteen participants performing imagined
handwriting. Signals were preprocessed with bandpass filtering and artifact
subspace reconstruction, followed by extraction of 85 time-, frequency-, and
graphical-domain features. A hybrid architecture, EEdGeNet, integrates a
Temporal Convolutional Network with a multilayer perceptron trained on the
extracted features. When deployed on an NVIDIA Jetson TX2, the system achieved
89.83 percent accuracy with 914.18 ms per-character latency. Selecting only ten
key features reduced latency by 4.5 times to 202.6 ms with less than 1 percent
loss in accuracy. These results establish a pathway for accurate, low-latency,
and fully portable non-invasive BCIs supporting real-time communication.

</details>


### [3] [MATLAB-Simulated Dataset for Automatic Modulation Classification in Wireless Fading Channels](https://arxiv.org/abs/2510.19985)
*M. M. Sadman Shafi,Tasnia Siddiqua Ahona,Ashraful Islam Mridha*

Main category: eess.SP

TL;DR: 本文构建了一个用于无线调制分类的合成数据集，包含五种数字调制方案（BPSK、QPSK、16-QAM、64-QAM、256-QAM），在瑞利和莱斯衰落信道下，并考虑了多种信号损伤，以支持机器学习模型的研究与评估。


<details>
  <summary>Details</summary>
Motivation: 认知无线电、自适应通信、频谱分析等领域在未知发射机和动态信道下进行精确调制分类是一个核心挑战。

Method: 通过MATLAB生成了包含五种数字调制方案（BPSK、QPSK、16-QAM、64-QAM、256-QAM）的合成数据集，并在瑞利和莱斯衰落信道下进行了传输，同时加入信号损伤以提高真实性。提取了包括统计、时域、频域、频谱图、频谱相关和图像处理（BRISK、MSER、GLCM）在内的多种特征。数据集包含10个CSV文件，涵盖两种信道类型和五种采样频率。此外，还提供了生成和特征提取的MATLAB脚本。

Result: 构建了一个包含五种数字调制方案、在两种衰落信道下、并经过多种信号损伤处理的合成数据集，并提取了全面的特征集。数据集以CSV文件形式组织，并附带MATLAB脚本，支持不同采样频率下的研究。

Conclusion: 本数据集为调制分类、信号识别和无线通信研究领域内的机器学习模型的开发与评估提供了一个有价值的基准。

Abstract: Accurate modulation classification is a core challenge in cognitive radio,
adaptive communications, spectrum analysis, and related domains, especially
under dynamic channels without transmitter knowledge. To address this need,
this article presents a labeled synthetic dataset designed for wireless
modulation classification under realistic propagation scenarios. The signals
were generated in MATLAB by modulating randomly generated bitstreams using five
digital modulation schemes: BPSK, QPSK, 16-QAM, 64-QAM, and 256-QAM. These
signals were then transmitted through Rayleigh and Rician fading channels with
standardized parameters, along with additional impairments to enhance realism
and diversity. Each modulated signal contains 1000 symbols. A comprehensive set
of features was extracted from the signals, encompassing statistical,
time-domain, frequency-domain, spectrogram-based, spectral correlation-based,
and image-processing-based descriptors such as BRISK, MSER, and GLCM. The
dataset is organized into 10 CSV files covering two channel types (Rayleigh and
Rician) across five sampling frequencies: 1 MHz, 10 MHz, 100 MHz, 500 MHz, and
1 GHz. To facilitate reproducibility and encourage further experimentation, the
MATLAB scripts used for signal generation and feature extraction are also
provided. This dataset serves as a valuable benchmark for developing and
evaluating machine learning models in modulation classification, signal
identification, and wireless communication research.

</details>


### [4] [NanoHydra: Energy-Efficient Time-Series Classification at the Edge](https://arxiv.org/abs/2510.20038)
*Cristian Cioflan,Jose Fonseca,Xiaying Wang,Luca Benini*

Main category: eess.SP

TL;DR: NanoHydra是一个用于极端边缘设备的时间序列分类（TSC）方法，使用轻量级二元随机卷积核提取特征，在GAP9微控制器上实现了高达94.47%的准确率，能耗仅为7.69 uJ，比现有技术效率高18倍，适用于智能可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的设备上实现高效的TinyML时间序列分类，以延长电池寿命并保持用户隐私和实时预测能力。

Method: 提出NanoHydra方法，利用轻量级二元随机卷积核提取特征，并在GAP9微控制器的八核集群上并行执行计算密集型任务。

Result: 在ECG5000数据集上实现了高达94.47%的分类准确率，分类1秒长的ECG信号仅需0.33毫秒，能耗为7.69 uJ，比现有技术效率高18倍。

Conclusion: NanoHydra方法在能效和分类准确性方面表现出色，非常适合需要长电池寿命的智能可穿戴设备，可实现超过四年的设备使用寿命。

Abstract: Time series classification (TSC) on extreme edge devices represents a
stepping stone towards intelligent sensor nodes that preserve user privacy and
offer real-time predictions. Resource-constrained devices require efficient
TinyML algorithms that prolong the device lifetime of battery-operated devices
without compromising the classification accuracy. We introduce NanoHydra, a
TinyML TSC methodology relying on lightweight binary random convolutional
kernels to extract meaningful features from data streams. We demonstrate our
system on the ultra-low-power GAP9 microcontroller, exploiting its eight-core
cluster for the parallel execution of computationally intensive tasks. We
achieve a classification accuracy of up to 94.47% on ECG5000 dataset,
comparable with state-of-the-art works. Our efficient NanoHydra requires only
0.33 ms to accurately classify a 1-second long ECG signal. With a modest energy
consumption of 7.69 uJ per inference, 18x more efficient than the
state-of-the-art, NanoHydra is suitable for smart wearable devices, enabling a
device lifetime of over four years.

</details>


### [5] [Semantic Communication for Task Execution and Data Reconstruction in Multi-User Scenarios](https://arxiv.org/abs/2510.20067)
*Maximilian H. V. Tillmann,Avinash Kankari,Carsten Bockelmann,Armin Dekorsy*

Main category: eess.SP

TL;DR: 该论文提出了一种用于多用户场景的并发任务执行和数据重建的语义通信系统，并通过最大化互信息来解决。


<details>
  <summary>Details</summary>
Motivation: 现有的语义通信工作大多只关注任务执行或数据重建，或两者的结合。而本工作旨在解决多用户场景下的并发任务执行和数据重建问题。

Method: 提出了一种语义通信系统，将并发任务执行和数据重建的问题建模为最大化互信息的问题。通过将任务执行和数据重建结合为一个联合目标（作为任务执行和数据重建的凸组合）来研究这两个目标之间的权衡。

Result: 在特定假设下，证明了结构相似性度量（SSIM）损失可以从用于数据重建的互信息最大化目标中获得，并考虑了人类视觉感知。此外，在资源恒定的情况下，通过将重建目标的权重增加到某一点，可以使任务执行性能几乎保持不变，同时显著提高数据重建质量。

Conclusion: 研究表明，该语义通信系统能够有效处理多用户场景下的并发任务执行和数据重建，并且可以通过调整重建目标的权重来在任务执行和数据重建之间进行权衡，以优化系统性能。

Abstract: Semantic communication has gained significant attention with the advances in
machine learning. Most semantic communication works focus on either task
execution or data reconstruction, with some recent works combining the two. In
this work, we propose a semantic communication system for concurrent task
execution and data reconstruction for a multi-user scenario, which we formulate
as the maximization of mutual information. To investigate the trade-off between
the two objectives, we formulate a joint objective as a convex combination of
task execution and data reconstruction. We show that under specific
assumptions, the \ac{SSIM} loss can be obtained from the mutual information
maximization objective for data reconstruction, which takes human visual
perception into account. Furthermore, for constant resource use, we show that
by increasing the weight of the reconstruction objective up to a certain point,
the task execution performance can be kept nearly constant, while the data
reconstruction can be significantly improved.

</details>


### [6] [RIS-Aided mmWave O-RAN: Coverage Extension and User Mobility Handling](https://arxiv.org/abs/2510.20088)
*Tawfik Osman,Aditya S. Shekhawat,Abhradeep Roy,Georgios C. Trichopoulos,Ahmed Alkhateeb*

Main category: eess.SP

TL;DR: 通过O-RAN E2接口动态控制RIS配置，在FR2毫米波频段，实现RIS辅助的5G系统，提升信号覆盖和UE移动性。


<details>
  <summary>Details</summary>
Motivation: RISs能够重定向电磁波以增强信号覆盖和/或提高UE的信噪比。本文旨在设计、实现和评估一个RIS辅助的O-RAN 5G系统。

Method: 设计一个1024单元（32x32）的1位RIS（工作在28 GHz频段），采用模块化、可扩展的瓷砖架构。利用O-RAN E2接口动态控制RIS配置。开发了两种UE移动性管理算法，利用UE接收到的信号功率来联合实时跟踪和调整RIS和UE波束。

Result: 在室内和室外环境中进行了现场试验，结果显示RIS提供了显著的接收信号功率增益（室内9-20 dB，室外6-18 dB）。开发的算法在RIS O-RAN测试台中进行了实时评估。

Conclusion: 将RIS集成到O-RAN系统中，能够增强下一代蜂窝网络的覆盖、移动性支持和链路可靠性，并具有实际可行性。

Abstract: Reconfigurable Intelligent Surfaces (RISs) can redirect electromagnetic waves
to desired directions to enhance signal coverage and/or improve signal-to-noise
ratio (SNR) at the user equipment (UE). We present the design, implementation,
and evaluation of an RIS-assisted O-RAN 5G system operating in the FR2
millimeter wave (mmWave) frequency band. We first introduce the design of 1,024
element (32 $\times$ 32) 1-bit RIS operating at the 28 GHz band, utilizing a
modular and scalable tiled architecture. Then we demonstrate how the O-RAN E2
interface can be leveraged to dynamically control RIS configurations without
modifying standard 5G signaling procedures. To evaluate the RIS-assisted 5G
system, we conducted extensive field trials in both indoor and outdoor
environments. The results of the O-RAN link coverage trials show that the
deployed RIS provides substantial received signal power gains, ranging from 9
to 20 dB and 6 to 18 dB in indoor and outdoors scenarios, respectively.
Handling UE mobility in RIS-assisted systems is challenging due to the need for
joint RIS and UE beam management. For that, we develop two UE mobility
management algorithms and evaluate them in real-time operation using the RIS
O-RAN testbed. These algorithms leverage the received signal power at the UE to
jointly track and adapt the RIS and UE beams in real time as the UE moves. The
findings draw important insights into the practical feasibility of integrating
RIS into O-RAN systems to enhance coverage, mobility support, and link
reliability in next-generation cellular networks.

</details>


### [7] [Signal Design for OTFS Dual-Functional Radar and Communications with Imperfect CSI](https://arxiv.org/abs/2510.20112)
*Borui Du,Yumeng Zhang,Christos Masouros,Bruno Clerckx*

Main category: eess.SP

TL;DR: 本文提出了一种用于双功能雷达通信（DFRC）的OTFS信号设计方法，通过联合优化导频符号和数据功率分配，以最大化感应和通信性能的加权和，仿真结果表明该方法在ISL抑制和SINR方面相较于传统方案有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有DFRC-OTFS信号设计未充分挖掘OTFS在高速移动场景下的潜力，尤其是在信道估计和功率分配方面。

Method: 提出了一种联合优化导频符号设计和数据功率分配的信号设计方法。利用模糊函数的综合旁瓣电平（ISL）作为雷达性能指标，并考虑数据符号的随机性；利用通信信道容量下界作为通信性能指标，并计入信道估计误差。采用交替优化框架求解优化问题。

Result: 所提出的信号设计在ISL抑制方面至少有9.44 dB的增益，在通信SINR方面至少有4.82 dB的增益，显著改善了感应-通信性能区域。

Conclusion: 所提出的信号设计方案能够有效提升DFRC-OTFS系统的感应和通信性能，充分发挥OTFS在高速移动场景下的优势。

Abstract: Orthogonal time frequency space (OTFS) offers significant advantages in
managing mobility for both wireless sensing and communication systems, making
it a promising candidate for dual-functional radar-communication (DFRC).
However, the optimal signal design that fully exploits OTFS's potential in DFRC
has not been sufficiently explored. This paper addresses this gap by
formulating an optimization problem for signal design in DFRC-OTFS,
incorporating both pilot-symbol design for channel estimation and data-power
allocation. Specifically, we employ the integrated sidelobe level (ISL) of the
ambiguity function as a radar metric, accounting for the randomness of the data
symbols alongside the deterministic pilot symbols. For communication, we derive
a channel capacity lower bound metric that considers channel estimation errors
in OTFS. We maximize the weighted sum of sensing and communication metrics and
solve the optimization problem via an alternating optimization framework.
Simulations indicate that the proposed signal significantly improves the
sensing-communication performance region compared with conventional signal
schemes, achieving at least a 9.44 dB gain in ISL suppression for sensing, and
a 4.82 dB gain in the signal-to-interference-plus-noise ratio (SINR) for
communication.

</details>


### [8] [Active Localization of Close-range Adversarial Acoustic Sources for Underwater Data Center Surveillance](https://arxiv.org/abs/2510.20122)
*Adnan Abdullah,David Blow,Sara Rampazzi,Md Jahidul Islam*

Main category: eess.SP

TL;DR: 提出了一种用于定位和跟踪水下数据中心声学注入攻击的框架，使用异构声纳接收器和LC-MAP-UKF算法，实现了高精度和高成功率的实时威胁定位。


<details>
  <summary>Details</summary>
Motivation: 水下数据基础设施虽然具有自然冷却和物理安全优势，但容易遭受声学注入攻击，威胁数据完整性和可用性。

Method: 提出了一种异构接收器配置（固定和移动声纳），并开发了LC-MAP（Locus-Conditioned Maximum A-Posteriori）方案，为联合TDOA/FDOA滤波生成先验信息，并将其集成到UKF（Unscented Kalman Filtering）流程中。

Result: 该框架能够实时估计攻击源的三维位置和速度，具有优于亚米级的定位精度和超过90%的成功率，并且收敛时间比基线方法缩短近一半。

Conclusion: 这项研究提出了一种几何感知、实时的声学威胁定位方法，提高了水下基础设施的自主监控能力。

Abstract: Underwater data infrastructures offer natural cooling and enhanced physical
security compared to terrestrial facilities, but are susceptible to acoustic
injection attacks that can disrupt data integrity and availability. This work
presents a comprehensive surveillance framework for localizing and tracking
close-range adversarial acoustic sources targeting offshore infrastructures,
particularly underwater data centers (UDCs). We propose a heterogeneous
receiver configuration comprising a fixed hydrophone mounted on the facility
and a mobile hydrophone deployed on a dedicated surveillance robot. While using
enough arrays of static hydrophones covering large infrastructures is not
feasible in practice, off-the-shelf approaches based on time difference of
arrival (TDOA) and frequency difference of arrival (FDOA) filtering fail to
generalize for this dynamic configuration. To address this, we formulate a
Locus-Conditioned Maximum A-Posteriori (LC-MAP) scheme to generate acoustically
informed and geometrically consistent priors, ensuring a physically plausible
initial state for a joint TDOA-FDOA filtering. We integrate this into an
unscented Kalman filtering (UKF) pipeline, which provides reliable convergence
under nonlinearity and measurement noise. Extensive Monte Carlo analyses,
Gazebo-based physics simulations, and field trials demonstrate that the
proposed framework can reliably estimate the 3D position and velocity of an
adversarial acoustic attack source in real time. It achieves sub-meter
localization accuracy and over 90% success rates, with convergence times nearly
halved compared to baseline methods. Overall, this study establishes a
geometry-aware, real-time approach for acoustic threat localization, advancing
autonomous surveillance capabilities of underwater infrastructures.

</details>


### [9] [Sensing Security in Near-Field ISAC: Exploiting Scatterers for Eavesdropper Deception](https://arxiv.org/abs/2510.20140)
*Jiangong Chen,Xia Lei,Kaitao Meng,Kawon Han,Yuchen Zhang,Christos Masouros,Athina P. Petropulu*

Main category: eess.SP

TL;DR: 本研究提出了一种在近场集成感知与通信（ISAC）场景下，利用已知散射体进行感知安全定位欺骗（LD）的方案，以对抗具有感知能力的小偷。该方案通过向已知散射体注入高于目标探测功率的探测功率，诱使小偷将散射体误认为目标，从而实现安全目标。该方案在无需了解小偷信息的情况下，即可有效欺骗小偷，并且可以通过调整波束形成策略，灵活地在通信、感知和感知安全性能之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 在近场集成感知与通信（ISAC）场景下，保护感知信息的安全，防止具有感知能力的小偷（Eve）获取敏感目标信息，是一个重要的研究问题。本研究旨在提出一种新的感知安全方案，以应对这一挑战。

Method: 提出了一种定位欺骗（LD）方案，通过向已知散射体注入高于目标探测功率的探测功率，诱导小偷将散射体误认为目标。利用分数规划（FP）和半定规划松弛（SDR）来求解在通信、感知和感知安全性能之间进行权衡的优化问题。使用Cramer-Rao Bound（CRB）和均方误差（MSE）评估LD方案的安全性。引入目标和散射体在小偷处之间的Kullback-Leibler Divergence（KLD）差距来量化LD框架对小偷感知性能的影响。

Result: 仿真结果表明，所提出的LD方案能够根据性能要求灵活调整波束形成策略，实现通信、感知和感知安全性能的三方权衡。具体来说，在感知安全方面，该方案显著增强了小偷端 the clutter signal strength，导致实际目标的混淆甚至漏检。

Conclusion: 提出的LD方案能够有效地在近场ISAC场景下实现感知安全，通过定位欺骗手段，在通信、感知和感知安全性能之间取得灵活的权衡，并显著提升了感知安全性能。

Abstract: In this paper, we explore sensing security in near-field (NF) integrated
sensing and communication (ISAC) scenarios by exploiting known scatterers in
the sensing scene. We propose a location deception (LD) scheme where scatterers
are deliberately illuminated with probing power that is higher than that
directed toward targets of interest, with the goal of deceiving potential
eavesdroppers (Eves) with sensing capability into misidentifying scatterers as
targets. While the known scatterers can be removed at the legitimate sensing
receiver, our LD approach causes Eves to misdetect targets. Notably, this
deception is achieved without requiring any prior information about the Eves'
characteristics or locations. To strike a flexible three-way tradeoff among
communication, sensing, and sensing-security performance, the sum rate and
power allocated to scatterers are weighted and maximized under a legitimate
radar signal-to-interference-plus-noise ratio (SINR) constraint. We employ the
fractional programming (FP) framework and semidefinite relaxation (SDR) to
solve this problem. To evaluate the security of the proposed LD scheme, the
Cramer-Rao Bound (CRB) and mean squared error (MSE) metrics are employed.
Additionally, we introduce the Kullback-Leibler Divergence (KLD) gap between
targets and scatterers at Eve to quantify the impact of the proposed LD
framework on Eve's sensing performance from an information-theoretical
perspective. Simulation results demonstrate that the proposed LD scheme can
flexibly adjust the beamforming strategy according to performance requirements,
thereby achieving the desired three-way tradeoff. In particular, in terms of
sensing security, the proposed scheme significantly enhances the clutter signal
strength at Eve's side, leading to confusion or even missed detection of the
actual target.

</details>


### [10] [Deep Learning Based Joint Space-Time-Frequency Domain Channel Prediction for Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2510.20146)
*Yongning Qi,Tao Zhou,Zuowei Xiang,Liu Liu,Bo Ai*

Main category: eess.SP

TL;DR: 该论文提出了一种基于深度学习的空-时-频联合信道预测模型，用于解决6G通信中的CF-mMIMO信道预测问题，并验证了其在仿真和真实数据集上的优越性。


<details>
  <summary>Details</summary>
Motivation: 为了提升6G通信系统中CF-mMIMO性能，需要准确的信道状态信息（CSI），而信道预测是获取CSI的关键。

Method: 提出了一种在Transformer编码器中加入频域卷积（FreqConv）和空域卷积（SpaceConv）层的深度学习模型，以联合利用空-时-频域相关性，并能并行输出多步预测结果，解决误差传播问题。通过仿真数据集优化超参数，并评估预测精度和计算复杂度。最后，使用真实数据集进行验证。

Result: 仿真结果表明，所提出的模型预测精度高于传统模型，计算复杂度低于传统Transformer模型。研究表明空-时-频域相关性对预测精度有显著影响。在真实高速列车LTE网络数据集中，所提出的模型同样实现了更高的预测精度。

Conclusion: 该深度学习模型能够有效地进行CF-mMIMO信道预测，在预测精度和计算复杂度方面优于现有传统模型，并能处理不规则的AP部署，为6G通信系统的性能提升提供了有力支持。

Abstract: The cell-free massive multi-input multi-output (CF-mMIMO) is a promising
technology for the six generation (6G) communication systems. Channel
prediction will play an important role in obtaining the accurate CSI to improve
the performance of CF-mMIMO systems. This paper studies a deep learning (DL)
based joint space-time-frequency domain channel prediction for CF-mMIMO.
Firstly, the prediction problems are formulated, which can output the
multi-step prediction results in parallel without error propagation. Then, a
novel channel prediction model is proposed, which adds frequency convolution
(FreqConv) and space convolution (SpaceConv) layers to Transformer-encoder. It
is able to utilize the space-time-frequency correlations and extract the space
correlation in the irregular AP deployment. Next, simulated datasets with
different sizes of service areas, UE velocities and scenarios are generated,
and correlation analysis and cross-validation are used to determine the optimal
hyper-parameters. According to the optimized hyper-parameters, the prediction
accuracy and computational complexity are evaluated based on simulated
datasets. It is indicated that the prediction accuracy of the proposed model is
higher than traditional model, and its computational complexity is lower than
traditional Transformer model. After that, the impacts of space-time-frequency
correlations on prediction accuracy are studied. Finally, realistic datasets in
a high-speed train (HST) long-term evolution (LTE) network are collected to
verify the prediction accuracy. The verification results demonstrate that it
also achieves higher prediction accuracy compared with traditional models in
the HST LTE network.

</details>


### [11] [NOMA for Visible Light Communications: Recent Advances and Future Directions](https://arxiv.org/abs/2510.20215)
*Xuesong Wang*

Main category: eess.SP

TL;DR: VLC是6G的重要补充，但现有标准未充分利用其光学特性。本文提出了一种面向VLC的MAC层新设计，并探讨了NOMA在VLC中的应用前景。


<details>
  <summary>Details</summary>
Motivation: 现有VLC标准未充分利用光学特性，且TDMA和CSMA/CA等协议在VLC环境中效率不高，尤其是在处理突发和非对称流量时。因此，需要一种针对VLC的、尤其是在MAC层进行优化的新设计。

Method: 本文回顾了VLC和基于NOMA的VLC的研究进展，分析了关键的优化约束和目标，并调研了适用于NOMA in VLC的场景。

Result: 文中讨论了NOMA在VLC中的应用潜力，并指出了未来研究方向。

Conclusion: NOMA是一种有前景的6G VLC技术，但需要进一步的研究和优化。

Abstract: Rapidly increasing demand for high speed data is pushing 6G wireless networks
to support larger link scales, lower latency, and higher spectral efficiency.
Visible light communications (VLC) is a strong complement to radio frequency
(RF) systems within 6G. The latest ITU G.9991 and IEEE 802.11bb standards are
adapted from cable and RF wireless technologies for use in VLC, so they do not
fully exploit the optical nature of light links. VLC links are often asymmetric
between uplink and downlink, which makes TDMA style protocols inefficient when
many users generate bursty and asymmetric traffic. Compared with RF, the strong
directionality and frequent line of sight in VLC can mitigate hidden and
exposed terminals, yet these effects can still appear under limited field of
view, blockage, or reflections. CSMA/CA and related methods remain usable in
VLC and in RF plus VLC networks, but they usually need design tweaks such as
RTS/CTS or directional sensing to perform well. Although the optical spectrum
is vast, the bandwidth of practical LEDs and of common PIN or APD receivers is
limited, so efficient multiple access can yield large gains. This motivates a
clean slate design for VLC, especially at the MAC layer. NOMA, first explored
in 5G RF systems, is also promising for 6G VLC. It lets multiple users share
the same time and frequency resources while tolerating controlled interference.
This paper reviews progress in VLC and in NOMA based VLC, outlines key
optimization constraints and objectives, surveys scenarios that fit NOMA in
VLC, and points to several directions for future work.

</details>


### [12] [A Survey of OTFS-Based Index Modulation Techniques: Challenges, Benefits, and Future Directions for 6G and Beyond](https://arxiv.org/abs/2510.20265)
*Burak Ahmet Ozden,Erdogan Aydin,Emir Aslandogan,Haci Ilhan,Ertugrul Basar,Miaowen Wen,Marco Di Renzo,Vincent Poor*

Main category: eess.SP

TL;DR: OTFS-IM技术结合了OTFS的鲁棒性和IM的效率，为6G无线通信提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: OTFS在6G通信中具有潜力，IM技术可以提高通信性能，因此结合两者具有研究价值。

Method: 对现有的OTFS-IM方案进行了全面的综述，并根据系统架构、检测方法和性能进行了分类。此外，还描述了OTFS-IM的变体，并进行了性能比较分析。

Result: 对OTFS-IM系统在容量、峰均功率比、多样性、复杂度、信道状态信息不完美、频谱效率和中断概率等方面的现有研究进行了分类和分析，并对OTFS-IM变体的性能进行了比较。

Conclusion: 讨论了OTFS-IM系统的挑战、优势和未来方向，包括复杂度、效率、延迟、信道估计、硬件限制、同步、安全以及与其他先进无线通信技术的集成。

Abstract: Orthogonal time frequency space (OTFS) is a two-dimensional modulation
technique that uses the delay-Doppler (DD) domain and is a candidate for
providing robust, high-capacity wireless communications for envisioned 6G and
beyond networks. The OTFS technique maps data to the DD domain instead of the
traditional time-frequency domain, enabling it to fully utilize channel
diversity and transform fast time-varying channels into nearly static channels.
Index modulation (IM) is a communication paradigm that conveys information not
only through conventional modulation symbols but also by encoding data bits in
the indices of the selected communication resources to improve error
performance, spectral efficiency, and energy efficiency. In this survey, a
comprehensive review of work on OTFS-based wireless communication systems is
presented. In particular, the existing OTFS-IM schemes are reviewed and
systematically categorized according to their system architectures, detection
methods, and performance aspects such as capacity, peak-to-average power ratio,
diversity, complexity, imperfect channel state information, spectral
efficiency, and outage probability. Furthermore, the operating principles and
system models of OTFS-IM variants-including OTFS-based space shift keying,
OTFS-based spatial modulation, OTFS-based quadrature spatial modulation,
OTFS-based media-based modulation, and OTFS-based code index modulation-are
described, followed by a comparative performance analysis in terms of
computational complexity, error performance, capacity, energy saving, spectral
efficiency, and throughput. Finally, the challenges, benefits, and future
directions for OTFS-IM systems are discussed, covering key aspects such as
complexity, efficiency, latency, channel estimation, hardware constraints,
synchronization, security, and potential integration with other advanced
wireless communication techniques.

</details>


### [13] [Near-Field 3D Localization and MIMO Channel Estimation with Sub-Connected Planar Arrays](https://arxiv.org/abs/2510.20274)
*Kangda Zhi,Tianyu Yang,Songyan Xue,Giuseppe Caire*

Main category: eess.SP

TL;DR: 提出了一种用于超大尺度MIMO通信中子阵列信道估计和三维定位问题的新算法。


<details>
  <summary>Details</summary>
Motivation: 现有的码本设计无法有效估计全列秩的超大尺度MIMO近场上行链路信道，尤其是在用户为多天线的情况下。

Method: 提出了一种三阶段算法：1. 使用基于DFT的字典矩阵和OMP算法进行子阵列信道估计。 2. 利用估计的子阵列信道和一维MUSIC算法，在最小二乘法标准下估计用户阵列的中心位置。 3. 利用估计的中心位置构建精炼的、aided的字典矩阵，并使用SBL获得MIMO信道估计。

Result: 提出的算法在导频开销和估计精度方面均优于现有基准算法。

Conclusion: 所提出的算法能够有效解决子连接平面超大尺度MIMO近场通信中的信道估计和三维定位问题。

Abstract: This paper investigates the design of channel estimation and 3D localization
algorithms in a challenging scenario, where a sub-connected planar extremely
large-scale multiple-input multiple-output (XL-MIMO) communicates with
multi-antenna users. In the near field, the uplink MIMO channel is of full
column rank and therefore can not be estimated effectively by applying existing
codebooks that are designed for the far-field case or for the near-field case
but limited to single antenna users. To solve this problem, we propose a
three-stage algorithm aided by orthogonal matching pursuit (OMP) and sparse
Bayesian learning (SBL). Specifically, we firstly partition the XL-MIMO into
subarrays and use OMP to solve the compressed sensing (CS) problem about
subarray channel estimation with the Discrete Fourier Transform (DFT)-based
dictionary matrix. Secondly, exploiting the estimated subarray channels and
employing one-dimensional multiple signal classification (MUSIC), we estimate
the central location of the user array under the Least Squares (LS) criterion.
Finally, we utilize the estimated central location to construct a refined
location-aided dictionary matrix and obtain the MIMO channel estimation using
SBL. Results exhibit the significant superiority of the proposed algorithm
compared with several benchmarks, in terms of both the pilot overhead and
estimation accuracy.

</details>


### [14] [Channel Estimation and Passive Beamforming for Pixel-based Reconfigurable Intelligent Surfaces with Non-Separable State Response](https://arxiv.org/abs/2510.20354)
*Huayan Guo,Junhui Rao,Alex M. H. Wong,Ross Murch,Vincent K. N. Lau*

Main category: eess.SP

TL;DR: 像素级可重构智能表面（RIS）通过消除移相器来实现高反射增益和低硬件成本，但面临信道估计和无源波束成形挑战。本文提出一种基于核方法和深度神经网络的近似方法来解决非可分离的RIS响应问题，并提出一种简化的级联信道模型和定制算法来分别估计短期和长期参数。最后，提出一种低复杂度无源波束成形算法来优化离散RIS状态向量，以最大化可实现速率。仿真结果表明，该方法在广泛的信噪比范围内显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统RIS的移相器设计增加了硬件成本，并且像素级RIS的设计面临信道估计和无源波束成形方面的挑战，现有解决方案无效。

Method: 1. 使用核方法和深度神经网络近似像素级RIS的非可分离响应函数。 2. 提出简化的级联信道模型，并设计定制算法分别估计短期和长期参数。 3. 提出低复杂度无源波束成形算法配置离散RIS状态向量。

Result: 所提出的解决方案在广泛的信噪比范围内显著优于各种基线方法。

Conclusion: 该方法能够有效解决像素级RIS的信道估计和无源波束成形问题，并能通过优化RIS状态向量来最大化可实现速率。

Abstract: Pixel-based reconfigurable intelligent surfaces (RISs) employ a novel design
to achieve high reflection gain at a lower hardware cost by eliminating the
phase shifters used in traditional RIS. However, this design presents
challenges for channel estimation and passive beamforming due to its
non-separable state response, rendering existing solutions ineffective. To
address this, we first approximate the non-separable RIS response functions
using a kernel-based method and a deep neural network, achieving high accuracy
while reducing computational and memory complexity. Next, we propose a
simplified cascaded channel model that focuses on dominated scattering paths
with limited unknown parameters, along with customized algorithms to estimate
short-term and long-term parameters separately. Finally, we introduce a
low-complexity passive beamforming algorithm to configure the discrete RIS
state vector, maximizing the achievable rate. Our simulation results
demonstrate that the proposed solution significantly outperforms various
baselines across a wide SNR range.

</details>


### [15] [A Transformer Inspired AI-based MIMO receiver](https://arxiv.org/abs/2510.20363)
*András Rácz,Tamás Borsos,András Veres,Benedek Csala*

Main category: eess.SP

TL;DR: AttDet是一种受Transformer启发的MIMO检测方法，通过自注意力机制学习层间干扰，在接近最优的BER/BLER性能下具有可预测的多项式复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有的MIMO检测方法在接近最优性能时，计算复杂度较高，或者在低复杂度下性能较差。本研究旨在提出一种兼顾性能和复杂度的MIMO检测方法。

Method: AttDet将每个发射层视为一个token，并利用轻量级自注意力机制来学习层间干扰。信道矩阵的估计值被用来直接导出查询（queries）和键（keys），从而使得注意力分数能够量化信道相关性。值（values）则由匹配滤波器输出来初始化，并进行迭代优化。

Result: 通过在真实的5G信道模型下进行链路级仿真，并采用高阶、混合QAM调制和编码方案，结果表明AttDet的BER/BLER性能接近最优值。

Conclusion: AttDet通过结合基于模型的解释性和数据驱动的灵活性，在保持可预测的多项式复杂度的同时，实现了接近最优的BER/BLER性能，是一种有效的MIMO检测方法。

Abstract: We present AttDet, a Transformer-inspired MIMO (Multiple Input Multiple
Output) detection method that treats each transmit layer as a token and learns
inter-stream interference via a lightweight self-attention mechanism. Queries
and keys are derived directly from the estimated channel matrix, so attention
scores quantify channel correlation. Values are initialized by matched-filter
outputs and iteratively refined. The AttDet design combines model-based
interpretability with data-driven flexibility. We demonstrate through
link-level simulations under realistic 5G channel models and high-order, mixed
QAM modulation and coding schemes, that AttDet can approach near-optimal
BER/BLER (Bit Error Rate/Block Error Rate) performance while maintaining
predictable, polynomial complexity.

</details>


### [16] [Efficient Medium Access Control for Low-Latency Industrial M2M Communications](https://arxiv.org/abs/2510.20380)
*Anwar Ahmed Khan,Indrakshi Dey*

Main category: eess.SP

TL;DR: FROG-MAC在工业M2M网络的多优先级数据传输中，在延迟和吞吐量方面优于BoP-MAC。


<details>
  <summary>Details</summary>
Motivation: 工业M2M网络对低延迟和高可靠性通信有较高要求，多优先级数据增加了通信复杂性。现有MAC方案众多，缺乏全面的比较，难以选择最优方案。

Method: 通过在Contiki仿真环境中，针对两种流量优先级和不同节点数量，比较了基于竞争窗口的MAC方案BoP-MAC和基于分片机制的MAC方案FROG-MAC。

Result: 仿真结果表明，在处理工业环境中的多优先级异构数据时，FROG-MAC在延迟和吞吐量方面均优于BoP-MAC。

Conclusion: FROG-MAC通过分片机制优先传输高优先级数据包，在多优先级异构数据传输场景下，能够提供更好的延迟和吞吐量性能。

Abstract: Efficient medium access control (MAC) is critical for enabling low-latency
and reliable communication in industrial Machine-to-Machine (M2M) net-works,
where timely data delivery is essential for seamless operation. The presence of
multi-priority data in high-risk industrial environments further adds to the
challenges. The development of tens of MAC schemes over the past decade often
makes it a tough choice to deploy the most efficient solu-tion. Therefore, a
comprehensive cross-comparison of major MAC protocols across a range of
performance parameters appears necessary to gain deeper insights into their
relative strengths and limitations. This paper presents a comparison of
Contention window-based MAC scheme BoP-MAC with a fragmentation based,
FROG-MAC; both protocols focus on reducing the delay for higher priority
traffic, while taking a diverse approach. BoP-MAC assigns a differentiated
back-off value to the multi-priority traffic, whereas FROG-MAC enables early
transmission of higher-priority packets by fragmenting lower-priority traffic.
Simulations were performed on Contiki by varying the number of nodes for two
traffic priorities. It has been shown that when work-ing with multi-priority
heterogenous data in the industrial environment, FROG-MAC results better both
in terms of delay and throughput.

</details>


### [17] [Inference-Optimal ISAC via Task-Oriented Feature Transmission and Power Allocation](https://arxiv.org/abs/2510.20429)
*Biao Dong,Bin Cao,Qinyu Zhang*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: This work is concerned with the coordination gain in integrated sensing and
communication (ISAC) systems under a compress-and-estimate (CE) framework,
wherein inference performance is leveraged as the key metric. To enable
tractable transceiver design and resource optimization, we characterize
inference performance via an error probability bound as a monotonic function of
the discriminant gain (DG). This raises the natural question of whether
maximizing DG, rather than minimizing mean squared error (MSE), can yield
better inference performance. Closed-form solutions for DG-optimal and
MSE-optimal transceiver designs are derived, revealing water-filling-type
structures and explicit sensing and communication (S\&C) tradeoff. Numerical
experiments confirm that DG-optimal design achieves more power-efficient
transmission, especially in the low signal-to-noise ratio (SNR) regime, by
selectively allocating power to informative features and thus saving transmit
power for sensing.

</details>


### [18] [Analysis of Frequency-Diverse and Dispersion Effects in Dynamic Metasurface Antenna for Holographic Sensing and Imaging](https://arxiv.org/abs/2510.20447)
*Abdul Jabbar,Aakash Bansal,William Whittow*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Dynamic metasurface antennas (DMAs) represent a novel approach to
programmable and affordable electromagnetic wave manipulation for enhanced
wireless communications, sensing, and imaging applications. Nevertheless,
current DMA designs and models are usually quasi-narrowband, neglecting the
versatile frequency-diverse manifestation and its utilization. This work
demonstrates the frequency-diversity and dispersion operations of a
representative DMA structure at the millimeter-wave band. We demonstrate
flexible dispersion manipulation through dynamic holographic reconfigurability
of the meta-atoms in a DMA. This effect can create distinct radiation patterns
across the operating frequency band, achieving flexible frequency diversity
with enhanced scanning range within a compact, reconfigurable platform. It
eliminates the need for wideband systems or complex phase-shifting networks
while offering an alternative to frequency-scanned static beams of traditional
leaky-wave antennas. The results establish fundamental insights into modelling
and utilization of dispersive effects of DMAs in next-generation near-field and
far-field holographic sensing and computational holographic imaging
applications.

</details>


### [19] [An Accelerated Mixed Weighted-Unweighted MMSE Approach for MU-MIMO Beamforming](https://arxiv.org/abs/2510.20507)
*Xi Gao,Akang Wang,Junkai Zhang,Qihong Duan,Jiang Xue*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Precoding design based on weighted sum-rate (WSR) maximization is a
fundamental problem in downlink multi-user multiple-input multiple-output
(MU-MIMO) systems. While the weighted minimum mean-square error (WMMSE)
algorithm is a standard solution, its high computational complexity--cubic in
the number of base station antennas due to matrix inversions--hinders its
application in latency-sensitive scenarios. To address this limitation, we
propose a highly parallel algorithm based on a block coordinate descent
framework. Our key innovation lies in updating the precoding matrix via block
coordinate gradient descent, which avoids matrix inversions and relies solely
on matrix multiplications, making it exceptionally amenable to GPU
acceleration. We prove that the proposed algorithm converges to a stationary
point of the WSR maximization problem. Furthermore, we introduce a two-stage
warm-start strategy grounded in the sum mean-square error (MSE) minimization
problem to accelerate convergence. We refer to our method as the Accelerated
Mixed weighted-unweighted sum-MSE minimization (A-MMMSE) algorithm. Simulation
results demonstrate that A-MMMSE matches the WSR performance of both
conventional WMMSE and its enhanced variant, reduced-WMMSE, while achieving a
substantial reduction in computational time across diverse system
configurations.

</details>


### [20] [Performance Analysis of End-to-End LEO Satellite-Aided Shore-to-Ship Communications: A Stochastic Geometry Approach](https://arxiv.org/abs/2510.20515)
*Xu Hu,Bin Lin,Xiao Lu,Ping Wang,Nan Cheng,Zhisheng Yin,Weihua Zhuang*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Low Earth orbit (LEO) satellite networks have shown strategic superiority in
maritime communications, assisting in establishing signal transmissions from
shore to ship through space-based links. Traditional performance modeling based
on multiple circular orbits is challenging to characterize large-scale LEO
satellite constellations, thus requiring a tractable approach to accurately
evaluate the network performance. In this paper, we propose a theoretical
framework for an LEO satellite-aided shore-to-ship communication network
(LEO-SSCN), where LEO satellites are distributed as a binomial point process
(BPP) on a specific spherical surface. The framework aims to obtain the
end-to-end transmission performance by considering signal transmissions through
either a marine link or a space link subject to Rician or Shadowed Rician
fading, respectively. Due to the indeterminate position of the serving
satellite, accurately modeling the distance from the serving satellite to the
destination ship becomes intractable. To address this issue, we propose a
distance approximation approach. Then, by approximation and incorporating a
threshold-based communication scheme, we leverage stochastic geometry to derive
analytical expressions of end-to-end transmission success probability and
average transmission rate capacity. Extensive numerical results verify the
accuracy of the analysis and demonstrate the effect of key parameters on the
performance of LEO-SSCN.

</details>


### [21] [Time-series Random Process Complexity Ranking Using a Bound on Conditional Differential Entropy](https://arxiv.org/abs/2510.20551)
*Jacob Ayers,Richard Hahnloser,Julia Ulrich,Lothar Sebastian Krapp,Remo Nitschke,Sabine Stoll,Balthasar Bickel,Reinhard Furrer*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Conditional differential entropy provides an intuitive measure for relatively
ranking time-series complexity by quantifying uncertainty in future
observations given past context. However, its direct computation for
high-dimensional processes from unknown distributions is often intractable.
This paper builds on the information theoretic prediction error bounds
established by Fang et al. \cite{fang2019generic}, which demonstrate that the
conditional differential entropy \textbf{$h(X_k \mid X_{k-1},...,X_{k-m})$} is
upper bounded by a function of the determinant of the covariance matrix of
next-step prediction errors for any next step prediction model. We add to this
theoretical framework by further increasing this bound by leveraging Hadamard's
inequality and the positive semi-definite property of covariance matrices.
  To see if these bounds can be used to rank the complexity of time series, we
conducted two synthetic experiments: (1) controlled linear autoregressive
processes with additive Gaussian noise, where we compare ordinary least squares
prediction error entropy proxies to the true entropies of various additive
noises, and (2) a complexity ranking task of bio-inspired synthetic audio data
with unknown entropy, where neural network prediction errors are used to
recover the known complexity ordering.
  This framework provides a computationally tractable method for time-series
complexity ranking using prediction errors from next-step prediction models,
that maintains a theoretical foundation in information theory.

</details>
