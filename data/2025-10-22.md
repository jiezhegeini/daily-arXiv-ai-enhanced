<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 22]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Machine Learning-Based Performance Evaluation of a Solar-Powered Hydrogen Fuel Cell Hybrid in a Radio-Controlled Electric Vehicle](https://arxiv.org/abs/2510.17808)
*Amirhesam Aghanouri,Mohamed Sabry,Joshua Cherian Varughese,Cristina Olaverri-Monreal*

Main category: eess.SP

TL;DR: 本研究提出了一种混合动力电动遥控赛车，结合了镍氢电池和质子交换膜燃料电池系统，并通过数据驱动的方法进行了性能评估和建模。


<details>
  <summary>Details</summary>
Motivation: 为了提高混合动力电动汽车的性能和可靠性，并为未来设计和规划提供参考。

Method: 研究采用了信号处理和机器学习技术，包括用于区分油门水平、检测异常和变化点以及预测电压行为的时间卷积网络。此外，还集成了太阳能电解槽以实现离网运行。

Result: 该混合系统显著提高了电气性能和可靠性，减少了关键故障。时间卷积网络能够精确预测电压行为。集成的太阳能电解槽证实了离网使用可再生氢的潜力。

Conclusion: 将质子交换膜燃料电池与镍氢电池集成可以显著提高小型电动汽车的电气性能和可靠性，并且这些发现可以为扩大到大型车辆提供基线。

Abstract: This paper presents an experimental investigation and performance evaluation
of a hybrid electric radio-controlled car powered by a Nickel-Metal Hydride
battery combined with a renewable Proton Exchange Membrane Fuel Cell system.
The study evaluates the performance of the system under various load-carrying
scenarios and varying environmental conditions, simulating real-world operating
conditions including throttle operation. In order to build a predictive model,
gather operational insights, and detect anomalies, data-driven analyses using
signal processing and modern machine learning techniques were employed.
Specifically, machine learning techniques were used to distinguish throttle
levels with high precision based on the operational data. Anomaly and change
point detection methods enhanced voltage stability, resulting in fewer critical
faults in the hybrid system compared to battery-only operation. Temporal
Convolutional Networks were effectively employed to predict voltage behavior,
demonstrating potential for use in planning the locations of fueling or
charging stations. Moreover, integration with a solar-powered electrolyzer
confirmed the system's potential for off-grid, renewable hydrogen use. The
results indicate that integrating a Proton Exchange Membrane Fuel Cell with
Nickel-Metal Hydride batteries significantly improves electrical performance
and reliability for small electric vehicles, and these findings can be a
potential baseline for scaling up to larger vehicles.

</details>


### [2] [In-Process Monitoring of Gear Power Honing Using Vibration Signal Analysis and Machine Learning](https://arxiv.org/abs/2510.17809)
*Massimo Capurso,Luciano Afferrante*

Main category: eess.SP

TL;DR: 提出了一种基于振动信号分析和机器学习的齿轮珩磨过程实时监测新框架。


<details>
  <summary>Details</summary>
Motivation: 传统的齿轮加工质量控制方法（如SPC）无法实时检测瞬态加工异常，无法满足现代齿轮加工对NVH性能的严格要求。

Method: 使用加速度计采集振动信号，通过时频分析提取特征，并比较了PCA、PCA+LDA和R-UMLDA三种子空间学习方法。提取的特征随后被输入到SVM分类器中，以预测齿轮质量类别。模型在工业环境下采集的实验数据上进行训练和验证。

Result: 该框架在工业环境中实现了高达100%的齿轮质量分类准确率，并能提取与加工动态相关的可解释频谱特征。

Conclusion: 所提出的数据驱动框架能够实现齿轮珩磨过程的实时监测，并有望集成到实时监控和预测性维护系统中。

Abstract: In modern gear manufacturing, stringent Noise, Vibration, and Harshness (NVH)
requirements demand high-precision finishing operations such as power honing.
Conventional quality control strategies rely on post-process inspections and
Statistical Process Control (SPC), which fail to capture transient machining
anomalies and cannot ensure real-time defect detection. This study proposes a
novel, data-driven framework for in-process monitoring of gear power honing
using vibration signal analysis and machine learning. Our proposed methodology
involves continuous data acquisition via accelerometers, followed by
time-frequency signal analysis. We investigate and compare the efficacy of
three subspace learning methods for features extraction: (1) Principal
Component Analysis (PCA) for dimensionality reduction; (2) a two-stage
framework combining PCA with Linear Discriminant Analysis (LDA) for enhanced
class separation; and (3) Uncorrelated Multilinear Discriminant Analysis with
Regularization (R-UMLDA), adapted for tensor data, which enforces feature
decorrelation and includes regularization for small sample sizes. These
extracted features are then fed into a Support Vector Machine (SVM) classifier
to predict four distinct gear quality categories, established through rigorous
geometrical inspections and test bench results of assembled gearboxes. The
models are trained and validated on an experimental dataset collected in an
industrial context during gear power-honing operations, with gears classified
into four different quality categories. The proposed framework achieves high
classification accuracy (up to 100%) in an industrial setting. The approach
offers interpretable spectral features that correlate with process dynamics,
enabling practical integration into real-time monitoring and predictive
maintenance systems.

</details>


### [3] [Exploring Complexity Changes in Diseased ECG Signals for Enhanced Classification](https://arxiv.org/abs/2510.17810)
*Camilo Quiceno Quintero,Sandip Varkey George*

Main category: eess.SP

TL;DR: 本研究利用非线性时间序列分析方法，结合PTB-XL数据集，提取心电图（ECG）的非线性特征和跨导联特征，并将其应用于机器学习模型，以区分心脏病患者和健康个体，结果显示这些特征能显著提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 心电图（ECG）的复杂动态变化与其电气活动相关，本研究旨在利用非线性时间序列分析方法，理解ECG的复杂性如何随心脏病理发生变化。

Method: 研究使用PTB-XL数据集，提取了导联II的ECG非线性度量和跨导联（导联II, V2, AVL）的度量，并使用了Spearman相关和互信息方法。

Result: 在健康与患病类别之间，以及5个诊断超类别之间，几乎所有的度量都存在显著差异 (p<.001)。将这些复杂性量化指标纳入机器学习模型后，ROC曲线下面积（AUC）从基线的0.86提升至0.87（仅包含非线性度量），再到0.90（包含跨时间序列度量），分类准确性显著提高。

Conclusion: 本研究表明，ECG的非线性特征和跨导联特征能够显著区分心脏病患者和健康个体，并且能有效提升机器学习模型的分类性能。

Abstract: The complex dynamics of the heart are reflected in its electrical activity,
captured through electrocardiograms (ECGs). In this study we use nonlinear time
series analysis to understand how ECG complexity varies with cardiac pathology.
Using the large PTB-XL dataset, we extracted nonlinear measures from lead II
ECGs, and cross-channel metrics (leads II, V2, AVL) using Spearman correlations
and mutual information. Significant differences between diseased and healthy
individuals were found in almost all measures between healthy and diseased
classes, and between 5 diagnostic superclasses ($p<.001$). Moreover,
incorporating these complexity quantifiers into machine learning models
substantially improved classification accuracy measured using area under the
ROC curve (AUC) from 0.86 (baseline) to 0.87 (nonlinear measures) and 0.90
(including cross-time series metrics).

</details>


### [4] [Channel Modeling of Satellite-to-Underwater Laser Communication Links: An Analytical-Monte Carlo Hybrid Approach](https://arxiv.org/abs/2510.17811)
*Zhixing Wang,Renzhi Yuan,Haifeng Yao,Chuang Yang,Mugen Peng*

Main category: eess.SP

TL;DR: 该论文建立了一个综合的卫星-水下激光通信（StULC）信道模型，并分析了其性能。


<details>
  <summary>Details</summary>
Motivation: 之前的StULC信道模型要么只关注单个信道，要么忽略了粒子和湍流对激光传播的综合影响。本研究旨在建立一个考虑粒子和湍流综合影响的StULC信道模型。

Method: 采用分析-蒙特卡洛混合方法。首先，基于扩展的惠更斯-菲涅尔原理得到激光束穿过湍流大气后的强度分布。然后，推导出光子穿过空气-水界面后的传播方向的闭式概率密度函数。最后，使用蒙特卡洛方法对水下链路进行建模，得到接收平面的功率分布。

Result: 基于所提出的StULC信道模型，分析了不同环境条件下的误比特率和中断概率。数值结果表明，水下粒子浓度对通信性能的影响远大于大气湍流和水下湍流的影响。值得注意的是，增加空气-水界面的风速并不会显著恶化StULC链路的通信性能。

Conclusion: 该研究提出的综合StULC信道模型能够准确评估不同环境因素对通信性能的影响，并揭示了水下粒子浓度是影响StULC链路性能的关键因素。

Abstract: Channel modeling for satellite-to-underwater laser communication (StULC)
links remains challenging due to long distances and the diversity of the
channel constituents. The StULC channel is typically segmented into three
isolated channels: the atmospheric channel, the air-water interface channel,
and the underwater channel. Previous studies involving StULC channel modeling
either focused on separated channels or neglected the combined effects of
particles and turbulence on laser propagation. In this paper, we established a
comprehensive StULC channel model by an analytical-Monte Carlo hybrid approach,
taking into account the effects of both particles and turbulence. We first
obtained the intensity distribution of the transmitted laser beam after passing
through the turbulent atmosphere based on the extended Huygens-Fresnel
principle. Then we derived a closed-form probability density function of the
photon propagating direction after passing through the air-water interface,
which greatly simplified the modeling of StULC links. At last, we employed a
Monte Carlo method to model the underwater links and obtained the power
distribution at the receiving plane. Based on the proposed StULC channel model,
we analyzed the bit error rate and the outage probability under different
environmental conditions. Numerical results demonstrated that, the influence of
underwater particle concentration on the communication performance is much
pronounced than those of both the atmospheric turbulence and the underwater
turbulence. Notably, increasing the wind speed at the air-water interface does
not significantly worsen the communication performance of the StULC links.

</details>


### [5] [Cross-Domain Multi-Person Human Activity Recognition via Near-Field Wi-Fi Sensing](https://arxiv.org/abs/2510.17816)
*Xin Li,Jingzhi Hu,Yinghui He,Hongbo Wang,Jin Gan,Jun Luo*

Main category: eess.SP

TL;DR: WiAnchor是一个用于处理不完整活动类别下的Wi-Fi设备间交叉域适应的训练框架。


<details>
  <summary>Details</summary>
Motivation: 现有的Wi-Fi设备用于人体活动识别（HAR）的研究很多，但是Wi-Fi设备的空间分辨率较低，这在区分多个人体活动时存在很大的局限性。通过利用近场主导效应，为每个受试者建立一个专用的传感链路，可以为在原生流量下进行多受试者HAR提供一种解决方案。然而，由于受试者特定的特征和近场信号的不规则模式，HAR神经网络模型需要进行微调（FT）以进行交叉域适应，当某些类别不可用时，这尤其具有挑战性。

Method: WiAnchor训练框架通过三个步骤来处理嵌入了不规则时间信息的Wi-Fi信号：在预训练阶段，通过扩大类间特征边界来增强活动的可分离性；在FT阶段，通过创新的锚点匹配机制来实现交叉域适应，并根据不完整的活动类别过滤受试者特定的干扰，而不是试图从中提取完整的特征；最后，基于输入样本与其锚点的特征级相似性来进一步提高识别精度。

Result: 使用构建的综合数据集对WiAnchor进行评估，在活动类别缺失的情况下，跨域准确率超过90%。

Conclusion: WiAnchor能够有效地处理不完整活动类别下的Wi-Fi设备间交叉域适应问题，并在多受试者HAR任务中取得优异的性能。

Abstract: Wi-Fi-based human activity recognition (HAR) provides substantial convenience
and has emerged as a thriving research field, yet the coarse spatial resolution
inherent to Wi-Fi significantly hinders its ability to distinguish multiple
subjects. By exploiting the near-field domination effect, establishing a
dedicated sensing link for each subject through their personal Wi-Fi device
offers a promising solution for multi-person HAR under native traffic. However,
due to the subject-specific characteristics and irregular patterns of
near-field signals, HAR neural network models require fine-tuning (FT) for
cross-domain adaptation, which becomes particularly challenging with certain
categories unavailable. In this paper, we propose WiAnchor, a novel training
framework for efficient cross-domain adaptation in the presence of incomplete
activity categories. This framework processes Wi-Fi signals embedded with
irregular time information in three steps: during pre-training, we enlarge
inter-class feature margins to enhance the separability of activities; in the
FT stage, we innovate an anchor matching mechanism for cross-domain adaptation,
filtering subject-specific interference informed by incomplete activity
categories, rather than attempting to extract complete features from them;
finally, the recognition of input samples is further improved based on their
feature-level similarity with anchors. We construct a comprehensive dataset to
thoroughly evaluate WiAnchor, achieving over 90% cross-domain accuracy with
absent activity categories.

</details>


### [6] [Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach](https://arxiv.org/abs/2510.17818)
*Salar Nouri*

Main category: eess.SP

TL;DR: 提出一种新颖的框架，通过联合估计流形变换矩阵和源方位角-仰角对，在单个快照数据下解决均匀圆阵（UCA）的无网格二维（2D)到达角（DOA）估计问题。


<details>
  <summary>Details</summary>
Motivation: 现有无网格方法在单快照情况下由于计算成本高或鲁棒性不足而失败。

Method: 提出一个新颖的框架，使用非精确增广拉格朗日方法（iALM）联合优化数据保真度和变换鲁棒性，以解决单快照二维DOA估计问题，无需半定规划。

Result: 仿真结果表明，所提出的iALM框架提供了鲁棒且高分辨率的无网格2D-DOA估计。

Conclusion: 所提出的iALM框架在具有挑战性的阵列信号处理应用中，能够有效地进行单快照无网格二维DOA估计。

Abstract: This paper tackles the challenging problem of gridless two-dimensional (2D)
direction-of-arrival (DOA) estimation for a uniform circular array (UCA) from a
single snapshot of data. Conventional gridless methods often fail in this
scenario due to prohibitive computational costs or a lack of robustness. We
propose a novel framework that overcomes these limitations by jointly
estimating a manifold transformation matrix and the source azimuth-elevation
pairs within a single, unified optimization problem. This problem is solved
efficiently using an inexact Augmented Lagrangian Method (iALM), which
completely circumvents the need for semidefinite programming. By unifying the
objectives of data fidelity and transformation robustness, our approach is
uniquely suited for the demanding single-snapshot case. Simulation results
confirm that the proposed iALM framework provides robust and high-resolution,
gridless 2D-DOA estimates, establishing its efficacy for challenging array
signal processing applications.

</details>


### [7] [CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms](https://arxiv.org/abs/2510.17821)
*Long Lin,Pablo Peiro-Corbacho,Pablo Ávila,Alejandro Carta-Bergaz,Ángel Arenal,Gonzalo R. Ríos-Muñoz,Carlos Sevilla-Salcedo*

Main category: eess.SP

TL;DR: CLARAE是一种创新的1D自编码器，可用于心脏电生理信号降噪和降维，并在各种节律类型中实现了高精度的节律分类，同时提供可解释的嵌入和实时分析的Web应用。


<details>
  <summary>Details</summary>
Motivation: 传统的心脏腔内心房电图（EGMs）虽然能提供高分辨率的心脏电生理信息，但常被噪声干扰且维度较高，限制了其在实时分析中的应用。因此，需要一种能够有效处理噪声、降低维度同时保持信号保真度和可解释性的方法。

Method: 提出了一种名为CLARAE（CLArity-preserving Reconstruction AutoEncoder）的一维自编码器模型。该模型采用下采样（池化）、混合插值-卷积上采样路径以及有界潜在空间等三项原则，旨在实现高保真重建、抑制重建伪影，并产生可解释的嵌入。CLARAE将高维信号压缩成一个紧凑的64维潜在表示。

Result: 在495,731个心房电信号片段（单极和双极）上对CLARAE进行了评估，涵盖了3种节律类型（房颤、SR300、SR600）。与其他六种先进自编码器相比，CLARAE在重建指标、节律分类和不同信噪比（-5至15 dB）下的鲁棒性方面表现优异。在下游节律分类任务中，CLARAE在所有节律类型中均达到了高于0.97的F1分数，并且其潜在空间显示出明显的按节律分类的聚类。在去噪任务中，CLARAE在单极和双极信号上均表现出色的性能。

Conclusion: CLARAE结合了强大的去噪能力和紧凑、具区分性的表示，为临床工作流程（如节律辨别、信号质量评估和实时标测）奠定了坚实的基础。此外，还提供了一个基于Web的交互式应用程序，以促进研究的可复现性和提高可及性，允许用户探索预训练模型、可视化重建并实时计算指标。

Abstract: Intracavitary atrial electrograms (EGMs) provide high-resolution insights
into cardiac electrophysiology but are often contaminated by noise and remain
high-dimensional, limiting real-time analysis. We introduce CLARAE
(CLArity-preserving Reconstruction AutoEncoder), a one-dimensional
encoder--decoder designed for atrial EGMs, which achieves both high-fidelity
reconstruction and a compact 64-dimensional latent representation. CLARAE is
designed to preserve waveform morphology, mitigate reconstruction artifacts,
and produce interpretable embeddings through three principles: downsampling
with pooling, a hybrid interpolation--convolution upsampling path, and a
bounded latent space.
  We evaluated CLARAE on 495,731 EGM segments (unipolar and bipolar) from 29
patients across three rhythm types (AF, SR300, SR600). Performance was
benchmarked against six state-of-the-art autoencoders using reconstruction
metrics, rhythm classification, and robustness across signal-to-noise ratios
from -5 to 15 dB. In downstream rhythm classification, CLARAE achieved
F1-scores above 0.97 for all rhythm types, and its latent space showed clear
clustering by rhythm. In denoising tasks, it consistently ranked among the top
performers for both unipolar and bipolar signals.
  In order to promote reproducibility and enhance accessibility, we offer an
interactive web-based application. This platform enables users to explore
pre-trained CLARAE models, visualize the reconstructions, and compute metrics
in real time. Overall, CLARAE combines robust denoising with compact,
discriminative representations, offering a practical foundation for clinical
workflows such as rhythm discrimination, signal quality assessment, and
real-time mapping.

</details>


### [8] [Covariance Matrix Construction with Preprocessing-Based Spatial Sampling for Robust Adaptive Beamforming](https://arxiv.org/abs/2510.17823)
*Saeed Mohammadzadeh,Rodrigo C. de Lamare,Yuriy Zakharov*

Main category: eess.SP

TL;DR: 提出一种高效鲁棒的自适应波束形成技术，用于处理导向矢量估计失配和数据协方差矩阵重构问题。


<details>
  <summary>Details</summary>
Motivation: 解决导向矢量估计失配和数据协方差矩阵重构问题，提出一种高效鲁棒的自适应波束形成技术。

Method: 通过自适应估计干扰信号的角度扇区，利用广义线性组合算法和预处理空间采样（PPBSS）重构干扰加噪声协方差矩阵。提出一种基于预处理矩阵的功率谱采样策略，并利用功率法计算信号的导向矢量。

Result: 仿真结果表明，该方法在阵列波束图分析和计算成本方面优于现有方法。

Conclusion: 所提出的PPBSS技术通过自适应估计角度信息，能够有效解决导向矢量估计失配和数据协方差矩阵重构问题，并在仿真中验证了其有效性。

Abstract: This work proposes an efficient, robust adaptive beamforming technique to
deal with steering vector (SV) estimation mismatches and data covariance matrix
reconstruction problems. In particular, the direction-of-arrival(DoA) of
interfering sources is estimated with available snapshots in which the angular
sectors of the interfering signals are computed adaptively. Then, we utilize
the well-known general linear combination algorithm to reconstruct the
interference-plus-noise covariance (IPNC) matrix using preprocessing-based
spatial sampling (PPBSS). We demonstrate that the preprocessing matrix can be
replaced by the sample covariance matrix (SCM) in the shrinkage method. A power
spectrum sampling strategy is then devised based on a preprocessing matrix
computed with the estimated angular sectors' information. Moreover, the
covariance matrix for the signal is formed for the angular sector of the
signal-of-interest (SOI), which allows for calculating an SV for the SOI using
the power method. An analysis of the array beampattern in the proposed PPBSS
technique is carried out, and a study of the computational cost of competing
approaches is conducted. Simulation results show the proposed method's
effectiveness compared to existing approaches.

</details>


### [9] [Carbon-Aware Orchestration of Integrated Satellite Aerial Terrestrial Networks via Digital Twin](https://arxiv.org/abs/2510.17825)
*Shumaila Javaid,Nasir Saeed*

Main category: eess.SP

TL;DR: ISATNs面临能源消耗和碳排放挑战，提出基于数字孪生（DT）的碳感知编排框架，采用gCO2/bit作为指标，结合长期预测和实时优化，利用碳感知切换、无人机周期工作和可再生能源感知边缘部署等手段减少排放，仿真结果显示gCO2/bit降低29%，并提高可再生能源利用率和弹性。


<details>
  <summary>Details</summary>
Motivation: 为了解决集成卫星航空地面网络（ISATN）大规模部署带来的不可持续的能源消耗和碳排放问题。

Method: 提出一个利用数字孪生（DT）技术的碳感知编排框架，采用公克二氧化碳当量每比特（gCO2/bit）作为主要的衡量指标，并实现了一个结合超前预测和实时自适应优化的多时间尺度计划-执行-检查-行动（PDCA）循环。利用碳感知切换、无人机工作周期管理和可再生能源感知边缘部署等ISATN特定控制手段来减少排放。

Result: 仿真结果显示，与仅考虑服务质量（QoS）的编排相比，本框架的gCO2/bit降低了29%，同时提高了可再生能源的利用率，并在不利事件下增强了网络的弹性。

Conclusion: 基于数字孪生的碳感知编排框架能够有效减少ISATN的碳排放，同时提高可再生能源利用率和网络弹性。

Abstract: Integrated Satellite Aerial Terrestrial Networks (ISATNs) are envisioned as
key enablers of 6G, providing global connectivity for applications such as
autonomous transportation, Industrial IoT, and disaster response. Their
large-scale deployment, however, risks unsustainable energy use and carbon
emissions. This work advances prior energy-aware studies by proposing a
carbon-aware orchestration framework for ISATNs that leverages Digital Twin
(DT) technology. The framework adopts grams of CO$_2$-equivalent per bit
(gCO$_2$/bit) as a primary sustainability metric and implements a multi
timescale Plan Do Check Act (PDCA) loop that combines day-ahead forecasting
with real-time adaptive optimization. ISATN-specific control knobs, including
carbon-aware handovers, UAV duty cycling, and renewable-aware edge placement,
are exploited to reduce emissions. Simulation results with real carbon
intensity data show up to 29\% lower gCO$_2$/bit than QoS-only orchestration,
while improving renewable utilization and resilience under adverse events.

</details>


### [10] [Synthetic EEG Generation using Diffusion Models for Motor Imagery Tasks](https://arxiv.org/abs/2510.17832)
*Henrique de Lima Alexandre,Clodoaldo Aparecido de Moraes Lima*

Main category: eess.SP

TL;DR: 该研究使用扩散概率模型（DDPM）生成合成的脑电图（EEG）信号，以解决脑机接口（BCI）中数据采集的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决脑电图（EEG）数据采集中的挑战，如传感器成本、采集时间和受试者间的变异性，该研究提出了一种生成合成EEG信号的方法。

Method: 该研究使用扩散概率模型（DDPM）生成与运动想象任务相关的合成EEG信号，通过预处理真实EEG数据、训练扩散模型从噪声中重建EEG通道，并使用信号和任务级别的指标进行评估。

Result: 生成的合成EEG信号在分类任务中达到了95%以上的准确率，均方误差低，与真实信号相关性高。

Conclusion: 研究结果表明，扩散模型生成的合成EEG信号可以有效补充数据集，提高基于EEG的BCI的分类性能，并解决数据稀缺性问题。

Abstract: Electroencephalography (EEG) is a widely used, non-invasive method for
capturing brain activity, and is particularly relevant for applications in
Brain-Computer Interfaces (BCI). However, collecting high-quality EEG data
remains a major challenge due to sensor costs, acquisition time, and
inter-subject variability. To address these limitations, this study proposes a
methodology for generating synthetic EEG signals associated with motor imagery
brain tasks using Diffusion Probabilistic Models (DDPM). The approach involves
preprocessing real EEG data, training a diffusion model to reconstruct EEG
channels from noise, and evaluating the quality of the generated signals
through both signal-level and task-level metrics. For validation, we employed
classifiers such as K-Nearest Neighbors (KNN), Convolutional Neural Networks
(CNN), and U-Net to compare the performance of synthetic data against real data
in classification tasks. The generated data achieved classification accuracies
above 95%, with low mean squared error and high correlation with real signals.
  Our results demonstrate that synthetic EEG signals produced by diffusion
models can effectively complement datasets, improving classification
performance in EEG-based BCIs and addressing data scarcity.

</details>


### [11] [Two Phases Leakage Detection Strategy Supported by DMAs](https://arxiv.org/abs/2510.17836)
*G. Messa,G. Acconciaioco,S. Ripani,L. Bozzelli,A. Simone,O. Giustolisi*

Main category: eess.SP

TL;DR: 该研究提出了一种新颖的两阶段模型驱动策略，用于检测和预定位供水管网中的泄漏点。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一种具有成本效益的泄漏检测方法，通过识别区域计量单元（DMA）并随后在确定的DMA中预定位管道泄漏，从而最大限度地减少检查成本。

Method: 该策略通过将泄漏点视为与正常工作条件异常来识别DMA和预定位管道。它还引入了一种设计压力仪表位置的新颖方法，并使用资产管理支持指标（AMSI）来减少DMA识别阶段的误报。

Result: 研究使用两个真实的Apulian供水网络（WDNs）对该策略进行了测试和讨论，证明了其有效性。

Conclusion: 该模型驱动策略为供水管网中的泄漏检测和预定位提供了一种有前景的方法，具有减少检查成本和提高检测精度的潜力。

Abstract: The present work proposes a novel two phases model-based strategy for leakage
detection. The two phases are: the identification of the district metering area
(DMA) and the pipe pre-localization into the identified DMA. The strategy is
based on detecting and pre-localizing the punctual leakage as anomaly with
respect to the normal working conditions. A further novelty is the fact that
the pre-localization phase returns the sequence of pipes to inspect, which
makes the strategy attractive for water utilities, whose aim is to identify the
anomaly at DMA level and, successively, to localize it with the minimum
inspection cost. Furthermore, a random database is useful to test the
performance of the strategy with respect to the configuration of DMAs and the
pressure metering system. Consequently, a novel strategy to design the location
of pressure meters is also proposed. It is demonstrated that the entire
strategy limits false positives during the DMA identification phase by using
the recently proposed index named Asset Management Support Indicator (AMSI).
AMSI is invariant with respect to the deterioration, i.e., it is sensitive to
its increase causing punctual leakage. The strategy is studied and discussed
using two real Apulian WDNs managed by Acquedotto Pugliese.

</details>


### [12] [Majority Vote Compressed Sensing](https://arxiv.org/abs/2510.18008)
*Henrik Hellström,Jiwon Jeong,Ayfer Özgür,Viktoria Fodor,Carlo Fischione*

Main category: eess.SP

TL;DR: 该研究提出了一种利用稀疏性和随机变换的非相干空中计算（AirComp）方法，称为MVCS，以降低通信成本，并能从聚合投影中恢复原始数据。


<details>
  <summary>Details</summary>
Motivation: 之前的非相干AirComp方法在通信时需要超过d次信道使用，以解决信道非相干性问题。然而，当数据向量具有稀疏性时，可以利用稀疏性来显著降低通信成本。

Method: 提出使用随机变换来传输数据的低维投影（s_i），然后使用多数表决（MV）-AirComp方案通信这些投影，以获得聚合投影的符号向量（y）。最后，结合1比特压缩感知（1bCS）技术，从y中恢复出聚合数据向量（sum(x_i)）。

Result: MVCS方案可以在T=O(kn log(d)/ε^2)次信道使用中，以ε的l2范数误差估计聚合数据向量。此外，还提出了利用MVCS进行直方图估计和分布式机器学习的具体算法，并通过数值结果验证了其优于现有技术。

Conclusion: MVCS方案通过结合随机变换、多数表决AirComp和1比特压缩感知，有效利用了数据稀疏性，降低了非相干AirComp的通信成本，并在理论和数值上证明了其有效性。

Abstract: We consider the problem of non-coherent over-the-air computation (AirComp),
where $n$ devices carry high-dimensional data vectors
$\mathbf{x}_i\in\mathbb{R}^d$ of sparsity $\lVert\mathbf{x}_i\rVert_0\leq k$
whose sum has to be computed at a receiver. Previous results on non-coherent
AirComp require more than $d$ channel uses to compute functions of
$\mathbf{x}_i$, where the extra redundancy is used to combat non-coherent
signal aggregation. However, if the data vectors are sparse, sparsity can be
exploited to offer significantly cheaper communication. In this paper, we
propose to use random transforms to transmit lower-dimensional projections
$\mathbf{s}_i\in\mathbb{R}^T$ of the data vectors. These projected vectors are
communicated to the receiver using a majority vote (MV)-AirComp scheme, which
estimates the bit-vector corresponding to the signs of the aggregated
projections, i.e., $\mathbf{y} = \text{sign}(\sum_i\mathbf{s}_i)$. By
leveraging 1-bit compressed sensing (1bCS) at the receiver, the real-valued and
high-dimensional aggregate $\sum_i\mathbf{x}_i$ can be recovered from
$\mathbf{y}$. We prove analytically that the proposed MVCS scheme estimates the
aggregated data vector $\sum_i \mathbf{x}_i$ with $\ell_2$-norm error
$\epsilon$ in $T=\mathcal{O}(kn\log(d)/\epsilon^2)$ channel uses. Moreover, we
specify algorithms that leverage MVCS for histogram estimation and distributed
machine learning. Finally, we provide numerical evaluations that reveal the
advantage of MVCS compared to the state-of-the-art.

</details>


### [13] [MCANet: A Coherent Multimodal Collaborative Attention Network for Advanced Modulation Recognition in Adverse Noisy Environments](https://arxiv.org/abs/2510.18336)
*Wangye Jiang,Haoming Yang,Xinyu Lu,Mingyuan Wang,Huimei Sun,Jingya Zhang*

Main category: eess.SP

TL;DR: MCANet是一个多模态深度学习框架，在低信噪比条件下比传统自动调制识别模型更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 提高无线通信系统的频谱效率，特别是在认知无线电系统中，自动调制识别（AMR）至关重要，但传统方法在复杂、嘈杂和低信噪比环境下存在挑战。

Method: MCANet（多模态协作注意力网络）是一种多模态深度学习框架，采用精细的特征提取和全局建模来实现其融合策略。

Result: 实验结果表明，MCANet在多个基准数据集上的表现优于主流AMR模型，在低信噪比条件下具有更好的鲁棒性。

Conclusion: MCANet通过其多模态融合策略，在复杂和低信噪比的无线通信环境中实现了先进的自动调制识别性能。

Abstract: As wireless communication systems evolve, automatic modulation recognition
(AMR) plays a key role in improving spectrum efficiency, especially in
cognitive radio systems. Traditional AMR methods face challenges in complex,
noisy environments, particularly in low signal-to-noise ratio (SNR) conditions.
This paper introduces MCANet (Multimodal Collaborative Attention Network), a
multimodal deep learning framework designed to address these challenges. MCANet
employs refined feature extraction and global modeling to support its fusion
strategy.Experimental results across multiple benchmark datasets show that
MCANet outperforms mainstream AMR models, offering better robustness in low-SNR
conditions.

</details>


### [14] [AWSPNet: Attention-based Dual-Tree Wavelet Scattering Prototypical Network for MIMO Radar Target Recognition and Jamming Suppression](https://arxiv.org/abs/2510.18422)
*Yizhen Jia,Siyao Xiao,Wenkai Jia,Hui Chen,Wen-Qin Wang*

Main category: eess.SP

TL;DR: AWSPNet是一种深度学习框架，用于雷达目标识别和干扰抑制，在低信噪比下准确率达90.45%。


<details>
  <summary>Details</summary>
Motivation: 数字射频记忆电子对抗对雷达系统的生存能力构成威胁，需要有效区分真实目标和复杂干扰信号，尤其是在低信噪比环境下。

Method: 提出了一种基于注意力机制的、双树复小波变换的散布式原型网络（AWSPNet）。该网络利用双树复小波变换提取对噪声和信号平移具有鲁棒性的特征，并通过注意力机制和预训练骨干网络进行优化。为解决标记数据有限的问题，采用了监督对比学习策略。利用原型网络进行分类，以适应少样本学习场景。

Result: AWSPNet在-6 dB信噪比下实现了90.45%的准确率。通过t-SNE可视化分析了模型不同阶段的特征可分离性。将AWSPNet与时域滑动窗口方法相结合，提出了一种能够识别和抑制干扰的完整算法。

Conclusion: AWSPNet在复杂电磁环境下具有实际应用潜力，能够有效识别雷达目标并抑制干扰。

Abstract: The increasing of digital radio frequency memory based electronic
countermeasures poses a significant threat to the survivability and
effectiveness of radar systems. These jammers can generate a multitude of
deceptive false targets, overwhelming the radar's processing capabilities and
masking targets. Consequently, the ability to robustly discriminate between
true targets and complex jamming signals, especially in low signal-to-noise
ratio (SNR) environments, is of importance. This paper introduces the
attention-based dual-tree wavelet scattering prototypical network (AWSPNet), a
deep learning framework designed for simultaneous radar target recognition and
jamming suppression. The core of AWSPNet is the encoder that leverages the
dual-tree complex wavelet transform to extract features that are inherently
robust to noise and signal translations. These features are further refined by
an attention mechanism and a pre-trained backbone network. To address the
challenge of limited labeled data and enhance generalization, we employ a
supervised contrastive learning strategy during the training phase. The
classification is performed by a prototypical network, which is particularly
effective in few-shot learning scenarios, enabling rapid adaptation to new
signal types. We demonstrate the efficacy of our approach through extensive
experiments. The results show that AWSPNet achieves 90.45\% accuracy at -6 dB
SNR. Furthermore, we provide a physical interpretation of the network's inner
workings through t-SNE visualizations, which analyze the feature separability
at different stages of the model. Finally, by integrating AWSPNet with a
time-domain sliding window approach, we present a complete algorithm capable of
not only identifying but also effectively suppressing various types of jamming,
thereby validating its potential for practical application in complex
electromagnetic environments.

</details>


### [15] [Microsecond Federated SVD on Grassmann Manifold for Real-time IoT Intrusion Detection](https://arxiv.org/abs/2510.18501)
*Tung-Anh Nguyen,Van-Phuc Bui,Shashi Raj Pandey,Kim Hue Ta,Nguyen H. Tran,Petar Popovski*

Main category: eess.SP

TL;DR: FedSVD是一个新颖的无监督联邦学习框架，用于物联网网络的实时异常检测。它使用SVD和Grassmann流形上的优化，在不依赖标签数据或集中式数据共享的情况下，准确检测已知和未知入侵。该方法针对低功耗设备进行了优化，显著降低了通信和计算成本，同时实现了与深度学习基线相当的性能，并将推理延迟降低了10倍以上。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是为物联网网络引入一个高效、准确的无监督联邦学习框架，用于实时异常检测，特别是在低功耗设备上，以解决标签数据稀缺和通信/计算成本高的问题。

Method: 该论文提出的方法是FedSVD，一个利用奇异值分解（SVD）和Grassmann流形上的优化来实现无监督联邦学习的框架。它旨在实现低功耗设备上的实时异常检测，并最小化通信开销和计算成本。

Result: 实验结果表明，FedSVD在性能上与深度学习基线相当，但推理延迟降低了10倍以上，这表明它适用于对延迟敏感的物联网应用。

Conclusion: FedSVD是一个有效的无监督联邦学习框架，适用于物联网网络的实时异常检测。它在不依赖标签数据的情况下，通过利用SVD和Grassmann流形优化，实现了高精度和低延迟，使其成为低功耗和对延迟敏感的物联网应用的理想选择。

Abstract: This paper introduces FedSVD, a novel unsupervised federated learning
framework for real-time anomaly detection in IoT networks. By leveraging
Singular Value Decomposition (SVD) and optimization on the Grassmann manifolds,
FedSVD enables accurate detection of both known and unknown intrusions without
relying on labeled data or centralized data sharing. Tailored for deployment on
low-power devices like the NVIDIA Jetson AGX Orin, the proposed method
significantly reduces communication overhead and computational cost.
Experimental results show that FedSVD achieves performance comparable to deep
learning baselines while reducing inference latency by over 10x, making it
suitable for latency-sensitive IoT applications.

</details>


### [16] [Channel-Aware Vector Quantization for Robust Semantic Communication on Discrete Channels](https://arxiv.org/abs/2510.18604)
*Zian Meng,Qiang Li,Wenqian Tang,Mingdie Yan,Xiaohu Ge*

Main category: eess.SP

TL;DR: CAVQ算法通过在JSCC框架下集成信道状态信息和多码本对齐机制，实现了更鲁棒、高效的数字语义通信，解决了现有方法在离散语义传输中对信道状态信息考虑不足的问题，并有效缓解了数字悬崖效应。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的语义通信方法大多依赖模拟或半数字传输，与现代数字通信基础设施兼容性有限。虽然已有研究采用向量量化（VQ）实现离散语义传输，但忽略了码本优化过程中的信道状态信息，导致鲁棒性不足。

Method: 提出一种信道感知向量量化（CAVQ）算法，并将其集成到离散无记忆信道下的联合信源信道编码（JSCC）框架（称为VQJSCC）。CAVQ将信道转移概率纳入量化过程，使语义上相似的码字更容易匹配，并引入多码本对齐机制处理码本顺序与调制顺序不匹配的问题。

Result: 实验结果表明，VQJSCC有效缓解了数字悬崖效应，在多种调制方案下实现了优于现有方法的重建质量，并在鲁棒性和效率方面优于最先进的数字语义通信基线。

Conclusion: CAVQ算法和VQJSCC框架能够通过在离散语义传输中集成信道状态信息和码本对齐机制，显著提升数字语义通信的鲁棒性和效率，克服了传统方法的局限性。

Abstract: Deep learning-based semantic communication has largely relied on analog or
semi-digital transmission, which limits compatibility with modern digital
communication infrastructures. Recent studies have employed vector quantization
(VQ) to enable discrete semantic transmission, yet existing methods neglect
channel state information during codebook optimization, leading to suboptimal
robustness. To bridge this gap, we propose a channel-aware vector quantization
(CAVQ) algorithm within a joint source-channel coding (JSCC) framework, termed
VQJSCC, established on a discrete memoryless channel. In this framework,
semantic features are discretized and directly mapped to modulation
constellation symbols, while CAVQ integrates channel transition probabilities
into the quantization process, aligning easily confused symbols with
semantically similar codewords. A multi-codebook alignment mechanism is further
introduced to handle mismatches between codebook order and modulation order by
decomposing the transmission stream into multiple independently optimized
subchannels. Experimental results demonstrate that VQJSCC effectively mitigates
the digital cliff effect, achieves superior reconstruction quality across
various modulation schemes, and outperforms state-of-the-art digital semantic
communication baselines in both robustness and efficiency.

</details>


### [17] [Delay Management Using Packet Fragmentation in Wireless Industrial Automation Systems](https://arxiv.org/abs/2510.18646)
*Anwar Ahmed Khan,Shama Siddiqui,Indrakshi Dey*

Main category: eess.SP

TL;DR: FROG-MAC 协议在工业自动化场景中，相较于 FPS-MAC 协议，在延迟和能效方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 工业自动化应用需要管理延迟，以保障设备和生命安全。高效的 MAC 协议能确保关键数据及时传输，尤其是在存在异构数据的工业环境中。

Method: 在 Contiki 仿真平台中，采用单跳星型拓扑，对比了 FROG-MAC 和 FPS-MAC 两种协议在工业环境下的性能。

Result: 仿真结果表明，FROG-MAC 协议通过中断低优先级传输的机制，在能效和延迟方面优于 FPS-MAC 协议。

Conclusion: FROG-MAC 协议在工业自动化应用中具有更高的能效和更低的延迟潜力。

Abstract: Managing delay is one of the core requirements of industrial automation
applications due to the high risk associated for equipment and human lives.
Using efficient Media Access Control (MAC) schemes guarantees the timely
transmission of critical data, particularly in the industrial environments
where heterogeneous data is inherently expected. This paper compares the
performance of Fragmentation based MAC (FROG-MAC) against Fuzzy Priority
Scheduling based MAC (FPS-MAC), both of which have been designed to optimize
the performance of heterogenous wireless networks. Contiki has been used as a
simulation platform and a single hop star topology has been assumed to resemble
the industrial environment. It has been shown that FROG-MAC has the potential
to outperform FPS-MAC in terms of energy efficiency and delay both, due to its
inherent feature of interrupting ongoing lower priority transmission on the
channel.

</details>


### [18] [A Comparative Analysis of High-Level vs. Low-Level Simulations for Dynamic MAC Protocols in Wireless Sensor Networks](https://arxiv.org/abs/2510.18662)
*Shama Siddiqui,Anwar Ahmed Khan,Indrakshi Dey*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Simulation studies are conducted at different levels of details for assessing
the performance of Media Access Control (MAC) protocols in Wireless Sensor
Networks (WSN). In the present-day scenario where hundreds of MAC protocols
have been proposed, it is important to assess the quality of performance
evaluation being conducted for each of the proposed protocols. It therefore
becomes crucial to compare the results of high-level theoretical simulations
with the detailed implementation results before any network protocol could be
deployed for a real-world scenario. In this work, we present a comparison of
high-level theoretical and detailed implementation results for Adaptive and
Dynamic Polling-MAC (ADP-MAC). MATLAB has been used for conducting initial
theoretical simulations and TinyOS has been used to develop the detailed
implementation of protocol for Mica2 platform. Performance evaluation of
ADP-MAC using the two levels of simulation has been conducted based on energy
and delay. In the high-level implementation, energy consumption was found to be
decreasing whereas delay was found to be increasing for increasing channel
polling intervals. On the other hand, when detailed implementation was
developed, it was observed that both energy consumption and delay revealed an
increasing trend with the increasing polling intervals. Therefore, it has been
shown that the trends for high- and low-level simulations for ADP-MAC are
significantly different, due to the lack of realistic assumptions in the
higher-level study.

</details>


### [19] [mSQUID: Model-Based Leanred Modulo Recovery at Low Sampling Rates](https://arxiv.org/abs/2510.18729)
*Yhonatan Kvich,Rotem Arie,Hana Hasan,Shaik Basheeruddin Shah,Yonina C. Eldar*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Modulo sampling enables acquisition of signals with unlimited dynamic range
by folding the input into a bounded interval prior to sampling, thus
eliminating the risk of signal clipping and preserving information without
requiring highresolution ADCs. While this enables low-cost hardware, the
nonlinear distortion introduced by folding presents recovery challenges,
particularly under noise and quantization. We propose a model-based deep
unfolding network tailored to this setting, combining the interpretability of
classical compress sensing (CS) solvers with the flexibility of learning. A key
innovation is a soft-quantization module that encodes the modulo prior by
guiding the solution toward discrete multiples of the folding range in a
differentiable and learnable way. Our method, modulo soft-quantized unfolded
iterative decoder (mSQUID), achieves superior reconstruction performance at low
sampling rates under additive Gaussian noise. We further demonstrate its
utility in a challenging case where signals with vastly different amplitudes
and disjoint frequency bands are acquired simultaneously and quantized. In this
scenario, classical sampling often struggles due to weak signal distortion or
strong signal clipping, while our approach is able to recover the input
signals. Our method also offers significantly reduced runtimes, making it
suitable for real-time, resource-limited systems.

</details>


### [20] [Wireless-Fed Pinching-Antenna Systems (Wi-PASS) for NextG Wireless Networks](https://arxiv.org/abs/2510.18743)
*Kasun R. Wijewardhana,Animesh Yadav,Ming Zeng,Mohamed Elsayed,Octavia A. Dobre,Zhiguo Ding*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Waveguide-based pinching-antenna systems (PASS) have recently emerged as a
promising solution to mitigate severe propagation losses in millimeter-wave and
terahertz bands by intelligently and flexibly establishing line-of-sight links.
However, their reliance on wire-based feeding confines deployment to areas near
the base station (BS), limiting installation flexibility and making them
cost-ineffective for serving distant users or regions. To overcome this
challenge, this article proposes wireless-fed pinchingantenna systems
(Wi-PASS), which employ wireless feeding to energize waveguides. Wi-PASS offer
a practical and cost-efficient means to extend coverage beyond the BS vicinity.
Several indoor and outdoor use cases demonstrate Wi-PASS advantages over PASS.
Numerical results further show that Wi-PASS deliver higher data rates than
conventional fixed-antenna systems, confirming the superior feasibility and
performance of Wi-PASS. Key future research directions are also discussed to
advance Wi-PASS deployment.

</details>


### [21] [Analyse comparative d'algorithmes de restauration en architecture dépliée pour des signaux chromatographiques parcimonieux](https://arxiv.org/abs/2510.18760)
*Mouna Gharbi,Silvia Villa,Emilie Chouzenoux,Jean-Christophe Pesquet,Laurent Duval*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Data restoration from degraded observations, of sparsity hypotheses, is an
active field of study. Traditional iterative optimization methods are now
complemented by deep learning techniques. The development of unfolded methods
benefits from both families. We carry out a comparative study of three
architectures on parameterized chromatographic signal databases, highlighting
the performance of these approaches, especially when employing metrics adapted
to physico-chemical peak signal characterization.

</details>


### [22] [SO(3)-invariant PCA with application to molecular data](https://arxiv.org/abs/2510.18827)
*Michael Fraiman,Paulina Hoyos,Tamir Bendory,Joe Kileel,Oscar Mickelin,Nir Sharon,Amit Singer*

Main category: eess.SP

TL;DR: Not available


<details>
  <summary>Details</summary>
Motivation: Not available

Method: Not available

Result: Not available

Conclusion: Not available

Abstract: Principal component analysis (PCA) is a fundamental technique for
dimensionality reduction and denoising; however, its application to
three-dimensional data with arbitrary orientations -- common in structural
biology -- presents significant challenges. A naive approach requires
augmenting the dataset with many rotated copies of each sample, incurring
prohibitive computational costs. In this paper, we extend PCA to 3D volumetric
datasets with unknown orientations by developing an efficient and principled
framework for SO(3)-invariant PCA that implicitly accounts for all rotations
without explicit data augmentation. By exploiting underlying algebraic
structure, we demonstrate that the computation involves only the square root of
the total number of covariance entries, resulting in a substantial reduction in
complexity. We validate the method on real-world molecular datasets,
demonstrating its effectiveness and opening up new possibilities for
large-scale, high-dimensional reconstruction problems.

</details>
