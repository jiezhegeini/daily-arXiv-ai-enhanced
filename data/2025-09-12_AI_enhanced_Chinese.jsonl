{"id": "2509.08830", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.08830", "abs": "https://arxiv.org/abs/2509.08830", "authors": ["Seong-A Park", "Jong-Eui Chae", "Sungdong Kim", "Hyung-Chul Lee", "Hyun-Lim Yang"], "title": "A Masked Representation Learning to Model Cardiac Functions Using Multiple Physiological Signals", "comment": "16 pages, 5 figures", "summary": "In clinical settings, monitoring hemodynamics is crucial for managing patient\nprognosis, necessitating the integrated analysis of multiple physiological\nsignals. While recent research has analyzed single signals such as\nelectrocardiography (ECG) or photoplethysmography (PPG), there has yet to be a\nproposal for an approach that encompasses the complex signal analysis required\nin actual clinical scenarios. In this study, we introduce the SNUPHY-M (Seoul\nNational University hospital PHYsiological signal Masked representation\nlearning) model extracts physiological features reflecting the electrical,\npressure, and fluid characteristics of the cardiac cycle in the process of\nrestoring three masked physiological signals based on self-supervised learning\n(SSL): ECG, PPG, and arterial blood pressure (ABP) signals. By employing\nmultiple physical characteristics, the model can extract more enriched features\nonly using non-invasive signals. We evaluated the model's performance in\nclinical downstream tasks such as hypotension, stroke volume, systolic blood\npressure, diastolic blood pressure, and age prediction. Our results showed that\nthe SNUPHY-M significantly outperformed supervised or SSL models, especially in\nprediction tasks using non-invasive signals. To the best of our knowledge,\nSNUPHY-M is the first model to apply multi-modal SSL to cardiovascular analysis\ninvolving ECG, PPG, and ABP signals. This approach effectively supports\nclinical decision-making and enables precise diagnostics, contributing\nsignificantly to the early diagnosis and management of hemodynamics without\ninvasiveness.", "AI": {"tldr": "SNUPHY-M\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u81ea\u76d1\u7763\u5b66\u4e60\u6a21\u578b\uff0c\u5b83\u7ed3\u5408ECG\u3001PPG\u548cABP\u4fe1\u53f7\u6765\u63d0\u53d6\u5fc3\u8840\u7ba1\u7279\u5f81\uff0c\u5e76\u5728\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u4e34\u5e8a\u4e0a\u9700\u8981\u96c6\u6210\u5206\u6790\u591a\u79cd\u751f\u7406\u4fe1\u53f7\u6765\u76d1\u6d4b\u8840\u6d41\u52a8\u529b\u5b66\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u5355\u4e00\u4fe1\u53f7\uff0c\u7f3a\u4e4f\u9002\u7528\u4e8e\u5b9e\u9645\u4e34\u5e8a\u573a\u666f\u7684\u590d\u6742\u4fe1\u53f7\u5206\u6790\u65b9\u6cd5\u3002", "method": "SNUPHY-M\u6a21\u578b\u5229\u7528\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u6062\u590d\u4e09\u4e2a\u88ab\u63a9\u853d\u7684\u751f\u7406\u4fe1\u53f7\uff08ECG\u3001PPG\u548cABP\uff09\uff0c\u63d0\u53d6\u80fd\u53cd\u6620\u5fc3\u52a8\u5468\u671f\u7684\u7535\u3001\u538b\u548c\u6d41\u4f53\u7279\u5f81\uff0c\u5e76\u5229\u7528\u591a\u7269\u7406\u7279\u6027\u4ece\u65e0\u521b\u4fe1\u53f7\u4e2d\u63d0\u53d6\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u3002", "result": "SNUPHY-M\u6a21\u578b\u5728\u4f4e\u8840\u538b\u3001\u6bcf\u640f\u91cf\u3001\u6536\u7f29\u538b\u3001\u8212\u5f20\u538b\u548c\u5e74\u9f84\u9884\u6d4b\u7b49\u4e34\u5e8a\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0c\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u76d1\u7763\u5b66\u4e60\u6216SSL\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528\u65e0\u521b\u4fe1\u53f7\u7684\u9884\u6d4b\u4efb\u52a1\u4e2d\u3002", "conclusion": "SNUPHY-M\u662f\u9996\u4e2a\u5c06\u591a\u6a21\u6001SSL\u5e94\u7528\u4e8e\u6d89\u53caECG\u3001PPG\u548cABP\u4fe1\u53f7\u7684\u5fc3\u8840\u7ba1\u5206\u6790\u7684\u6a21\u578b\uff0c\u80fd\u6709\u6548\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\uff0c\u5b9e\u73b0\u7cbe\u786e\u8bca\u65ad\uff0c\u5bf9\u65e0\u521b\u8840\u6d41\u52a8\u529b\u5b66\u65e9\u671f\u8bca\u65ad\u548c\u7ba1\u7406\u6709\u663e\u8457\u8d21\u732e\u3002"}}
{"id": "2509.08950", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.08950", "abs": "https://arxiv.org/abs/2509.08950", "authors": ["Jarvis Haupt", "Qin Lu", "Yanning Shen", "Jia Chen", "Yue Dong", "Dan McCreary", "Mehmet Ak\u00e7akaya", "Georgios B. Giannakis"], "title": "Deploying AI for Signal Processing education: Selected challenges and intriguing opportunities", "comment": "Accepted to the IEEE Signal Processing Magazine Special Issue on\n  Artificial Intelligence for Education: A Signal Processing Perspective", "summary": "Powerful artificial intelligence (AI) tools that have emerged in recent years\n-- including large language models, automated coding assistants, and advanced\nimage and speech generation technologies -- are the result of monumental human\nachievements. These breakthroughs reflect mastery across multiple technical\ndisciplines and the resolution of significant technological challenges.\nHowever, some of the most profound challenges may still lie ahead. These\nchallenges are not purely technical but pertain to the fair and responsible use\nof AI in ways that genuinely improve the global human condition. This article\nexplores one promising application aligned with that vision: the use of AI\ntools to facilitate and enhance education, with a specific focus on signal\nprocessing (SP). It presents two interrelated perspectives: identifying and\naddressing technical limitations, and applying AI tools in practice to improve\neducational experiences. Primers are provided on several core technical issues\nthat arise when using AI in educational settings, including how to ensure\nfairness and inclusivity, handle hallucinated outputs, and achieve efficient\nuse of resources. These and other considerations -- such as transparency,\nexplainability, and trustworthiness -- are illustrated through the development\nof an immersive, structured, and reliable \"smart textbook.\" The article serves\nas a resource for researchers and educators seeking to advance AI's role in\nengineering education.", "AI": {"tldr": "AI\u5728\u6559\u80b2\u9886\u57df\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u4fe1\u53f7\u5904\u7406\u65b9\u9762\uff0c\u9762\u4e34\u6280\u672f\u548c\u516c\u5e73\u6027\u6311\u6218\u3002", "motivation": "\u63a2\u7d22AI\u5728\u4fc3\u8fdb\u548c\u6539\u5584\u6559\u80b2\u65b9\u9762\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u4fe1\u53f7\u5904\u7406\u9886\u57df\uff0c\u5e76\u5173\u6ce8\u5176\u516c\u5e73\u548c\u8d1f\u8d23\u4efb\u7684\u4f7f\u7528\uff0c\u4ee5\u6539\u5584\u5168\u7403\u4eba\u7c7b\u798f\u7949\u3002", "method": "\u4ecb\u7ecdAI\u5728\u6559\u80b2\u73af\u5883\u4e2d\u4f7f\u7528\u7684\u6838\u5fc3\u6280\u672f\u95ee\u9898\uff0c\u5982\u516c\u5e73\u6027\u3001\u5305\u5bb9\u6027\u3001\u5904\u7406\u5e7b\u89c9\u8f93\u51fa\u548c\u8d44\u6e90\u5229\u7528\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u5f00\u53d1\u201c\u667a\u80fd\u6559\u79d1\u4e66\u201d\u6765\u9610\u8ff0\u8fd9\u4e9b\u95ee\u9898\uff0c\u5982\u900f\u660e\u5ea6\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "result": "\u901a\u8fc7\u5f00\u53d1\u6c89\u6d78\u5f0f\u3001\u7ed3\u6784\u5316\u548c\u53ef\u9760\u7684\u201c\u667a\u80fd\u6559\u79d1\u4e66\u201d\uff0c\u5c55\u793a\u4e86AI\u5728\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "AI\u5728\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u5e94\u7528\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u6280\u672f\u5c40\u9650\u6027\u5e76\u786e\u4fdd\u516c\u5e73\u548c\u8d1f\u8d23\u4efb\u7684\u4f7f\u7528\u3002"}}
{"id": "2509.08973", "categories": ["eess.SP", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.08973", "abs": "https://arxiv.org/abs/2509.08973", "authors": ["Harshit Agrawal", "Ari Hietanen", "Simo S\u00e4rkk\u00e4"], "title": "Ultrafast Deep Learning-Based Scatter Estimation in Cone-Beam Computed Tomography", "comment": null, "summary": "Purpose: Scatter artifacts drastically degrade the image quality of cone-beam\ncomputed tomography (CBCT) scans. Although deep learning-based methods show\npromise in estimating scatter from CBCT measurements, their deployment in\nmobile CBCT systems or edge devices is still limited due to the large memory\nfootprint of the networks. This study addresses the issue by applying networks\nat varying resolutions and suggesting an optimal one, based on speed and\naccuracy.\n  Methods: First, the reconstruction error in down-up sampling of CBCT scatter\nsignal was examined at six resolutions by comparing four interpolation methods.\nNext, a recent state-of-the-art method was trained across five image\nresolutions and evaluated for the reductions in floating-point operations\n(FLOPs), inference times, and GPU memory requirements.\n  Results: Reducing the input size and network parameters achieved a 78-fold\nreduction in FLOPs compared to the baseline method, while maintaining comarable\nperformance in terms of mean-absolute-percentage-error (MAPE) and\nmean-square-error (MSE). Specifically, the MAPE decreased to 3.85% compared to\n4.42%, and the MSE decreased to 1.34 \\times 10^{-2} compared to 2.01 \\times\n10^{-2}. Inference time and GPU memory usage were reduced by factors of 16 and\n12, respectively. Further experiments comparing scatter-corrected\nreconstructions on a large, simulated dataset and real CBCT scans from water\nand Sedentex CT phantoms clearly demonstrated the robustness of our method.\n  Conclusion: This study highlights the underappreciated role of downsampling\nin deep learning-based scatter estimation. The substantial reduction in FLOPs\nand GPU memory requirements achieved by our method enables scatter correction\nin resource-constrained environments, such as mobile CBCT and edge devices.", "AI": {"tldr": "\u901a\u8fc7\u4e0b\u91c7\u6837\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6765\u51cf\u5c0fCBCT\u6563\u5c04\u4f30\u7b97\u7684\u7f51\u7edc\u8d1f\u62c5\uff0c\u5b9e\u73b0\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u6563\u5c04\u6821\u6b63\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728CBCT\u6563\u5c04\u4f30\u7b97\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u5de8\u5927\u7684\u5185\u5b58\u5360\u7528\u9650\u5236\u4e86\u5176\u5728\u79fb\u52a8CBCT\u6216\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5e94\u7528\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5e94\u7528\u4e0d\u540c\u5206\u8fa8\u7387\u7684\u7f51\u7edc\u5e76\u63a8\u8350\u6700\u4f18\u5206\u8fa8\u7387\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u9996\u5148\u68c0\u67e5\u4e86\u516d\u79cd\u5206\u8fa8\u7387\u4e0bCBCT\u6563\u5c04\u4fe1\u53f7\u7684\u964d\u91c7\u6837-\u5347\u91c7\u6837\u91cd\u5efa\u8bef\u5dee\uff0c\u5e76\u6bd4\u8f83\u4e86\u56db\u79cd\u63d2\u503c\u65b9\u6cd5\u3002\u7136\u540e\uff0c\u5728\u4e94\u4e2a\u56fe\u50cf\u5206\u8fa8\u7387\u4e0b\u8bad\u7ec3\u4e86\u6700\u65b0\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u8bc4\u4f30\u4e86\u5176\u5728\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\uff08FLOPs\uff09\u3001\u63a8\u7406\u65f6\u95f4\u548cGPU\u5185\u5b58\u9700\u6c42\u65b9\u9762\u7684\u964d\u4f4e\u60c5\u51b5\u3002", "result": "\u901a\u8fc7\u51cf\u5c0f\u8f93\u5165\u5c3a\u5bf8\u548c\u7f51\u7edc\u53c2\u6570\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cFLOPs\u51cf\u5c11\u4e8678\u500d\uff0c\u540c\u65f6\u5728\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\uff08MAPE\uff09\u548c\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u65b9\u9762\u4fdd\u6301\u4e86\u53ef\u6bd4\u7684\u6027\u80fd\u3002\u5177\u4f53\u6765\u8bf4\uff0cMAPE\u4ece4.42%\u964d\u81f33.85%\uff0cMSE\u4ece2.01 x 10^-2\u964d\u81f31.34 x 10^-2\u3002\u63a8\u7406\u65f6\u95f4\u548cGPU\u5185\u5b58\u4f7f\u7528\u91cf\u5206\u522b\u51cf\u5c11\u4e8616\u500d\u548c12\u500d\u3002\u5728\u6a21\u62df\u6570\u636e\u96c6\u548c\u771f\u5b9eCBCT\u626b\u63cf\u4e0a\u8fdb\u884c\u7684\u8fdb\u4e00\u6b65\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u4e0b\u91c7\u6837\u5728\u6df1\u5ea6\u5b66\u4e60\u6563\u5c04\u4f30\u7b97\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86FLOPs\u548cGPU\u5185\u5b58\u9700\u6c42\uff0c\u4f7f\u5f97\u5728\u79fb\u52a8CBCT\u548c\u8fb9\u7f18\u8bbe\u5907\u7b49\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u8fdb\u884c\u6563\u5c04\u6821\u6b63\u6210\u4e3a\u53ef\u80fd\u3002"}}
{"id": "2509.09005", "categories": ["eess.SP", "cs.ET", "cs.SI"], "pdf": "https://arxiv.org/pdf/2509.09005", "abs": "https://arxiv.org/abs/2509.09005", "authors": ["Hirley Alves", "Nurul H. Mahmood", "Onel L. A. L\u00f3pez", "Sumudu Samarakoon", "Seppo Yrj\u00f6l\u00e4", "Matti Latva-Aho", "Markku Juntti", "Ari Pouttu", "Armin Dekorsy", "Arthur Sousa de Sena", "Aydin Sezgin", "Bho Matthiesen", "Chafika Benzaid", "Chathuranga Weeraddana", "David Hutchison", "Dileepa Marasinghe", "Doganalp Ergenc", "Eduard Jorswieck", "Erkki Harjula", "Falko Dressler", "Harri Saarnisaari", "Italo Atzeni", "Jaap Van De Beek", "Jacek Rak", "Konstantin Mikhaylov", "Lauri Loven", "Madhusanka Liyanage", "Marcos Katz", "Marja Matinmikko-Blue", "Mehdi Rasti", "Mika Ylianttila Nhan Nguyen", "Pawani Porambage", "Petar Popovski", "Petri Ahokangas", "Premanandana Rajatheva", "Robert-Jeron Reifert", "Tharaka Hewa", "Tommy Svensson"], "title": "6G Resilience -- White Paper", "comment": null, "summary": "6G must be designed to withstand, adapt to, and evolve amid prolonged,\ncomplex disruptions. Mobile networks' shift from efficiency-first to\nsustainability-aware has motivated this white paper to assert that resilience\nis a primary design goal, alongside sustainability and efficiency, encompassing\ntechnology, architecture, and economics. We promote resilience by analysing\ndependencies between mobile networks and other critical systems, such as\nenergy, transport, and emergency services, and illustrate how cascading\nfailures spread through infrastructures. We formalise resilience using the 3R\nframework: reliability, robustness, resilience. Subsequently, we translate this\ninto measurable capabilities: graceful degradation, situational awareness,\nrapid reconfiguration, and learning-driven improvement and recovery.\n  Architecturally, we promote edge-native and locality-aware designs, open\ninterfaces, and programmability to enable islanded operations, fallback modes,\nand multi-layer diversity (radio, compute, energy, timing). Key enablers\ninclude AI-native control loops with verifiable behaviour, zero-trust security\nrooted in hardware and supply-chain integrity, and networking techniques that\nprioritise critical traffic, time-sensitive flows, and inter-domain\ncoordination.\n  Resilience also has a techno-economic aspect: open platforms and high-quality\ncomplementors generate ecosystem externalities that enhance resilience while\nopening new markets. We identify nine business-model groups and several\npatterns aligned with the 3R objectives, and we outline governance and\nstandardisation. This white paper serves as an initial step and catalyst for 6G\nresilience. It aims to inspire researchers, professionals, government\nofficials, and the public, providing them with the essential components to\nunderstand and shape the development of 6G resilience.", "AI": {"tldr": "6G\u7f51\u7edc\u8bbe\u8ba1\u9700\u8003\u8651\u97e7\u6027\uff0c\u5e76\u63d0\u51fa3R\u6846\u67b6\uff08\u53ef\u9760\u6027\u3001\u9c81\u68d2\u6027\u3001\u6062\u590d\u529b\uff09\u53ca\u5176\u53ef\u8861\u91cf\u80fd\u529b\uff08\u4f18\u96c5\u964d\u7ea7\u3001\u6001\u52bf\u611f\u77e5\u3001\u5feb\u901f\u91cd\u6784\u3001\u5b66\u4e60\u9a71\u52a8\u7684\u6539\u8fdb\u548c\u6062\u590d\uff09\u3002\u67b6\u6784\u4e0a\u63d0\u5021\u8fb9\u7f18\u539f\u751f\u3001\u533a\u57df\u611f\u77e5\u8bbe\u8ba1\u3001\u5f00\u653e\u63a5\u53e3\u548c\u53ef\u7f16\u7a0b\u6027\uff0c\u5e76\u5f3a\u8c03AI\u539f\u751f\u63a7\u5236\u3001\u96f6\u4fe1\u4efb\u5b89\u5168\u548c\u4f18\u5148\u5173\u952e\u6d41\u91cf\u7684\u7f51\u7edc\u6280\u672f\u3002\u7ecf\u6d4e\u4e0a\uff0c\u5f00\u653e\u5e73\u53f0\u548c\u4f18\u8d28\u534f\u4f5c\u8005\u53ef\u589e\u5f3a\u97e7\u6027\u5e76\u5f00\u8f9f\u65b0\u5e02\u573a\uff0c\u63d0\u51fa\u4e86\u4e5d\u79cd\u5546\u4e1a\u6a21\u5f0f\u548c\u82e5\u5e72\u4e0e3R\u76ee\u6807\u4e00\u81f4\u7684\u6a21\u5f0f\u3002\u672c\u6587\u65e8\u5728\u4e3a6G\u97e7\u6027\u63d0\u4f9b\u57fa\u7840\uff0c\u6fc0\u53d1\u5404\u65b9\u53c2\u4e0e\u5176\u53d1\u5c55\u3002", "motivation": "\u9274\u4e8e\u79fb\u52a8\u7f51\u7edc\u5df2\u4ece\u6548\u7387\u4f18\u5148\u8f6c\u5411\u53ef\u6301\u7eed\u6027\u8003\u91cf\uff0c\u672c\u767d\u76ae\u4e66\u65e8\u5728\u63d0\u51fa\u97e7\u6027\u662f\u4e0e\u53ef\u6301\u7eed\u6027\u548c\u6548\u7387\u5e76\u5217\u7684\u5173\u952e\u8bbe\u8ba1\u76ee\u6807\uff0c\u5e76\u5168\u9762\u5206\u6790\u4e86\u5176\u6280\u672f\u3001\u67b6\u6784\u548c\u7ecf\u6d4e\u65b9\u9762\u3002", "method": "\u901a\u8fc7\u5206\u6790\u79fb\u52a8\u7f51\u7edc\u4e0e\u80fd\u6e90\u3001\u4ea4\u901a\u3001\u5e94\u6025\u670d\u52a1\u7b49\u5173\u952e\u7cfb\u7edf\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u9610\u8ff0\u4e86\u7ea7\u8054\u6545\u969c\u7684\u4f20\u64ad\u3002\u4f7f\u75283R\u6846\u67b6\uff08\u53ef\u9760\u6027\u3001\u9c81\u68d2\u6027\u3001\u97e7\u6027\uff09\u5f62\u5f0f\u5316\u97e7\u6027\uff0c\u5e76\u5c06\u5176\u8f6c\u5316\u4e3a\u4f18\u96c5\u964d\u7ea7\u3001\u6001\u52bf\u611f\u77e5\u3001\u5feb\u901f\u91cd\u6784\u3001\u5b66\u4e60\u9a71\u52a8\u7684\u6539\u8fdb\u548c\u6062\u590d\u7b49\u53ef\u8861\u91cf\u80fd\u529b\u3002\u67b6\u6784\u4e0a\uff0c\u63d0\u51fa\u8fb9\u7f18\u539f\u751f\u3001\u533a\u57df\u611f\u77e5\u8bbe\u8ba1\u3001\u5f00\u653e\u63a5\u53e3\u548c\u53ef\u7f16\u7a0b\u6027\uff0c\u4ee5\u5b9e\u73b0\u5b64\u5c9b\u5f0f\u64cd\u4f5c\u3001\u5907\u7528\u6a21\u5f0f\u548c\u591a\u5c42\u591a\u6837\u6027\u3002\u5173\u952e\u652f\u6491\u6280\u672f\u5305\u62ec\u5177\u6709\u53ef\u9a8c\u8bc1\u884c\u4e3a\u7684AI\u539f\u751f\u63a7\u5236\u56de\u8def\u3001\u57fa\u4e8e\u786c\u4ef6\u548c\u4f9b\u5e94\u94fe\u5b8c\u6574\u6027\u7684\u96f6\u4fe1\u4efb\u5b89\u5168\u4ee5\u53ca\u4f18\u5148\u8003\u8651\u5173\u952e\u6d41\u91cf\u3001\u65f6\u95f4\u654f\u611f\u6d41\u548c\u57df\u95f4\u534f\u8c03\u7684\u7f51\u7edc\u6280\u672f\u3002\u7ecf\u6d4e\u65b9\u9762\uff0c\u901a\u8fc7\u4e5d\u79cd\u5546\u4e1a\u6a21\u5f0f\u548c\u82e5\u5e72\u6a21\u5f0f\u6765\u4fc3\u8fdb\u97e7\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u6280\u672f\u3001\u67b6\u6784\u548c\u7ecf\u6d4e\u5c42\u9762\u76846G\u97e7\u6027\u6846\u67b6\uff0c\u5e76\u5217\u4e3e\u4e86\u5b9e\u73b0\u97e7\u6027\u7684\u5177\u4f53\u6280\u672f\u548c\u67b6\u6784\u7b56\u7565\uff0c\u4ee5\u53ca\u4e0e\u4e4b\u5339\u914d\u7684\u5546\u4e1a\u6a21\u5f0f\u3002", "conclusion": "\u672c\u767d\u76ae\u4e66\u662f6G\u97e7\u6027\u7684\u521d\u6b65\u63a2\u7d22\u548c\u50ac\u5316\u5242\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u4e13\u4e1a\u4eba\u58eb\u3001\u653f\u5e9c\u5b98\u5458\u548c\u516c\u4f17\u63d0\u4f9b\u4e86\u7406\u89e3\u548c\u5851\u90206G\u97e7\u6027\u53d1\u5c55\u7684\u57fa\u672c\u8981\u7d20\u3002"}}
{"id": "2509.09018", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09018", "abs": "https://arxiv.org/abs/2509.09018", "authors": ["Xueyi Wang", "C. J. C.", "Lamoth", "Elisabeth Wilhelm"], "title": "Personalized Sleep Prediction via Deep Adaptive Spatiotemporal Modeling and Sparse Data", "comment": "The paper has been acceptted and presented in the 47th Annual\n  International Conference of the IEEE Engineering in Medicine and Biology\n  Society", "summary": "A sleep forecast allows individuals and healthcare providers to anticipate\nand proactively address factors influencing restful rest, ultimately improving\nmental and physical well-being. This work presents an adaptive spatial and\ntemporal model (AdaST-Sleep) for predicting sleep scores. Our proposed model\ncombines convolutional layers to capture spatial feature interactions between\nmultiple features and recurrent neural network layers to handle longer-term\ntemporal health-related data. A domain classifier is further integrated to\ngeneralize across different subjects. We conducted several experiments using\nfive input window sizes (3, 5, 7, 9, 11 days) and five predicting window sizes\n(1, 3, 5, 7, 9 days). Our approach consistently outperformed four baseline\nmodels, achieving its lowest RMSE (0.282) with a seven-day input window and a\none-day predicting window. Moreover, the method maintained strong performance\neven when forecasting multiple days into the future, demonstrating its\nversatility for real-world applications. Visual comparisons reveal that the\nmodel accurately tracks both the overall sleep score level and daily\nfluctuations. These findings prove that the proposed framework provides a\nrobust and adaptable solution for personalized sleep forecasting using sparse\ndata from commercial wearable devices and domain adaptation techniques.", "AI": {"tldr": "\u4e00\u4e2a\u81ea\u9002\u5e94\u65f6\u7a7a\u6a21\u578bAdaST-Sleep\u53ef\u4ee5\u9884\u6d4b\u7761\u7720\u5206\u6570\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u4e3a\u4e86\u80fd\u591f\u9884\u6d4b\u7761\u7720\u5206\u6570\uff0c\u4ece\u800c\u4f7f\u4e2a\u4eba\u548c\u533b\u7597\u4fdd\u5065\u63d0\u4f9b\u8005\u80fd\u591f\u9884\u671f\u5e76\u4e3b\u52a8\u89e3\u51b3\u5f71\u54cd\u7761\u7720\u7684\u56e0\u7d20\uff0c\u4ece\u800c\u6539\u5584\u8eab\u5fc3\u5065\u5eb7\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u65f6\u7a7a\u6a21\u578b\uff08AdaST-Sleep\uff09\uff0c\u7ed3\u5408\u4e86\u5377\u79ef\u5c42\u548c\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u5c42\u6765\u6355\u6349\u7a7a\u95f4\u7279\u5f81\u4ea4\u4e92\u548c\u5904\u7406\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5e76\u96c6\u6210\u4e86\u57df\u5206\u7c7b\u5668\u4ee5\u5b9e\u73b0\u8de8\u4e3b\u4f53\u6cdb\u5316\u3002", "result": "\u5728\u4e94\u4e2a\u8f93\u5165\u7a97\u53e3\u5927\u5c0f\uff083\u30015\u30017\u30019\u300111\u5929\uff09\u548c\u4e94\u4e2a\u9884\u6d4b\u7a97\u53e3\u5927\u5c0f\uff081\u30013\u30015\u30017\u30019\u5929\uff09\u7684\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u6a21\u578b\u6301\u7eed\u4f18\u4e8e\u56db\u4e2a\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u4e03\u5929\u8f93\u5165\u7a97\u53e3\u548c\u4e00\u5929\u9884\u6d4b\u7a97\u53e3\u4e0b\u8fbe\u5230\u4e86\u6700\u4f4e\u7684RMSE\uff080.282\uff09\uff0c\u5e76\u4e14\u5728\u9884\u6d4b\u672a\u6765\u591a\u5929\u65f6\u4ecd\u4fdd\u6301\u5f3a\u52b2\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5229\u7528\u6765\u81ea\u5546\u4e1a\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u7a00\u758f\u6570\u636e\u548c\u57df\u81ea\u9002\u5e94\u6280\u672f\u8fdb\u884c\u4e2a\u6027\u5316\u7761\u7720\u9884\u6d4b\u63d0\u4f9b\u4e86\u5065\u58ee\u4e14\u53ef\u9002\u5e94\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.09056", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09056", "abs": "https://arxiv.org/abs/2509.09056", "authors": ["Michael Caulfield", "Randy Palamar", "Darren Dahunsi", "Mohammad Rahim Sobhani", "Negar Majidi", "Roger Zemp"], "title": "Improving the Elevational Focusing of Fast Orthogonal Row-Column Electronic Scanning (FORCES) Ultrasound Imaging using Retrospective Transmit Beamforming (RTB)", "comment": "6 pages, 8 figures", "summary": "Recent developments in Row Column Arrays (RCAs) have presented promising\noptions for volumetric imaging without the need for the excessive channel\ncounts of fully wired 2D-arrays. Bias programmable RCAs, also known as Top\nOrthogonal to Bottom Electrode (TOBE) Arrays, show further promise in that\nimaging schemes, such as Fast Orthogonal Row-Column Electronic Scanning\n(FORCES) allow for full transmit and receive focusing everywhere in the image\nplane. However, due to its fixed elevational focus and large transmit aperture,\nFORCES experiences poor elevational focusing away from the focal point. In this\nstudy we present a modification to the FORCES imaging scheme by applying\nRetrospective Transmit Beamforming (RTB) in the elevational direction to allow\nfor elevational transmit focusing everywhere in the imaging plane. We evaluate\nFORCES and uFORCES methods, with and without RTB applied, when imaging both a\ncyst and wire phantom. With experiment we show improved elevational focusing\ncapabilities away from the focal point when RTB is applied to both FORCES and\nuFORCES. At the focal point, performance with RTB remains comparable or\nimproved relative to standard FORCES. This is quantified by the measurement of\nFull Width Half Max when imaging the wire phantom, and by the generalized\nContrast to Noise Ratio when imaging the tubular cyst phantom. We also\ndemonstrate the volumetric imaging capabilities of FORCES RTB with the wire\nphantom.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684FORCES\u6210\u50cf\u65b9\u6848\uff0c\u79f0\u4e3auFORCES\uff0c\u901a\u8fc7\u5728\u5782\u76f4\u65b9\u5411\u5e94\u7528\u56de\u987e\u6027\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\uff08RTB\uff09\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5728\u6574\u4e2a\u6210\u50cf\u5e73\u9762\u5185\u7684\u5782\u76f4\u53d1\u5c04\u805a\u7126\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfFORCES\u5728\u975e\u7126\u70b9\u533a\u57df\u805a\u7126\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cuFORCES\u5728\u6539\u5584\u975e\u7126\u70b9\u533a\u57df\u7684\u805a\u7126\u80fd\u529b\u65b9\u9762\u4f18\u4e8e\u6807\u51c6FORCES\uff0c\u5e76\u4e14\u5728\u7126\u70b9\u533a\u57df\u7684\u6027\u80fd\u76f8\u5f53\u6216\u66f4\u597d\uff0c\u5e76\u901a\u8fc7\u6d4b\u91cf\u7ebf\u8c61\u9510\u5ea6\uff08FWIIM\uff09\u548c\u9020\u5f71\u566a\u58f0\u6bd4\uff08CNR\uff09\u8fdb\u884c\u4e86\u91cf\u5316\u3002", "motivation": "\u7531\u4e8eFORCES\u6210\u50cf\u65b9\u6848\u5b58\u5728\u56fa\u5b9a\u7684\u5782\u76f4\u7126\u6df1\u548c\u8f83\u5927\u7684\u53d1\u5c04\u5b54\u5f84\uff0c\u5bfc\u81f4\u5176\u5728\u975e\u7126\u70b9\u533a\u57df\u7684\u5782\u76f4\u805a\u7126\u80fd\u529b\u8f83\u5dee\uff0c\u56e0\u6b64\u9700\u8981\u6539\u8fdb\u4ee5\u5b9e\u73b0\u6574\u4e2a\u6210\u50cf\u5e73\u9762\u7684\u5782\u76f4\u53d1\u5c04\u805a\u7126\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6539\u8fdb\u7684FORCES\u6210\u50cf\u65b9\u6848\uff08uFORCES\uff09\uff0c\u901a\u8fc7\u5728\u5782\u76f4\u65b9\u5411\u5e94\u7528\u56de\u987e\u6027\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\uff08RTB\uff09\u6280\u672f\uff0c\u5b9e\u73b0\u5782\u76f4\u65b9\u5411\u7684\u53d1\u5c04\u805a\u7126\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u5e94\u7528RTB\u524d\u540e\u7684FORCES\u548cuFORCES\u65b9\u6cd5\u5728\u6210\u50cf\u56ca\u80bf\u548c\u7ebf\u9635\u6a21\u578b\u65f6\u7684\u6027\u80fd\u3002", "result": "\u4e0e\u6807\u51c6FORCES\u76f8\u6bd4\uff0c\u5e94\u7528RTB\u540e\u7684FORCES\u548cuFORCES\u5728\u975e\u7126\u70b9\u533a\u57df\u7684\u5782\u76f4\u805a\u7126\u80fd\u529b\u5f97\u5230\u6539\u5584\u3002\u5728\u7126\u70b9\u533a\u57df\uff0c\u5e94\u7528RTB\u540e\u7684\u6027\u80fd\u76f8\u5f53\u6216\u4f18\u4e8e\u6807\u51c6FORCES\u3002\u901a\u8fc7\u6d4b\u91cf\u7ebf\u9635\u6a21\u578b\u7684FWIIM\u548c\u56ca\u80bf\u6a21\u578b\u7684CNR\u8fdb\u884c\u4e86\u91cf\u5316\u3002\u540c\u65f6\uff0c\u5c55\u793a\u4e86FORCES RTB\u5728\u7ebf\u9635\u6a21\u578b\u4e0a\u7684\u5bb9\u79ef\u6210\u50cf\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5728\u5782\u76f4\u65b9\u5411\u5e94\u7528RTB\u6280\u672f\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8FORCES\u548cuFORCES\u6210\u50cf\u65b9\u6848\u5728\u6574\u4e2a\u6210\u50cf\u5e73\u9762\u5185\u7684\u5782\u76f4\u805a\u7126\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfFORCES\u5728\u975e\u7126\u70b9\u533a\u57df\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2509.09120", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09120", "abs": "https://arxiv.org/abs/2509.09120", "authors": ["Rong Ye", "Xue-Qin Jiang", "Hui Feng", "Jian Wang", "Runhe Qiu"], "title": "Signed Graph Learning with Hidden Nodes", "comment": "25 pages, 7 figures, published to Signal Processing", "summary": "Signed graphs, which are characterized by both positive and negative edge\nweights, have recently attracted significant attention in the field of graph\nsignal processing (GSP). Existing works on signed graph learning typically\nassume that all graph nodes are available. However, in some specific\napplications, only a subset of nodes can be observed while the remaining nodes\nstay hidden. To address this challenge, we propose a novel method for\nidentifying signed graph that accounts for hidden nodes, termed \\textit{signed\ngraph learning with hidden nodes under column-sparsity regularization}\n(SGL-HNCS). Our method is based on the assumption that graph signals are smooth\nover signed graphs, i.e., signal values of two nodes connected by positive\n(negative) edges are similar (dissimilar). Rooted in this prior assumption, the\ntopology inference of a signed graph is formulated as a constrained\noptimization problem with column-sparsity regularization, where the goal is to\nreconstruct the signed graph Laplacian matrix without disregarding the\ninfluence of hidden nodes. We solve the constrained optimization problem using\na tailored block coordinate descent (BCD) approach. Experimental results using\nsynthetic data and real-world data demonstrate the efficiency of the proposed\nSGL-HNCS method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSGL-HNCS\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5b58\u5728\u9690\u85cf\u8282\u70b9\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u5e26\u7b26\u53f7\u56fe\uff0c\u5e76\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5b9e\u9a8c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5e26\u7b26\u53f7\u56fe\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u6240\u6709\u56fe\u8282\u70b9\u90fd\u53ef\u7528\uff0c\u4f46\u5728\u67d0\u4e9b\u5e94\u7528\u4e2d\uff0c\u53ea\u6709\u90e8\u5206\u8282\u70b9\u53ef\u89c2\u6d4b\uff0c\u5176\u4f59\u8282\u70b9\u9690\u85cf\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSGL-HNCS\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u5e26\u7b26\u53f7\u56fe\u7684\u5e73\u6ed1\u6027\u5047\u8bbe\uff08\u5373\uff0c\u7531\u6b63\uff08\u8d1f\uff09\u8fb9\u8fde\u63a5\u7684\u4e24\u4e2a\u8282\u70b9\u4fe1\u53f7\u503c\u76f8\u4f3c\uff08\u4e0d\u76f8\u4f3c\uff09\uff09\u3002\u5c06\u5e26\u7b26\u53f7\u56fe\u7684\u62d3\u6251\u63a8\u7406\u8868\u8ff0\u4e3a\u4e00\u4e2a\u5e26\u5217\u7a00\u758f\u6027\u6b63\u5219\u5316\u7684\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u5b9a\u5236\u7684\u5757\u5750\u6807\u4e0b\u964d\uff08BCD\uff09\u65b9\u6cd5\u6c42\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\uff08\u5305\u62ec\u5408\u6210\u6570\u636e\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff09\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684SGL-HNCS\u65b9\u6cd5\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684SGL-HNCS\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5b66\u4e60\u5e26\u7b26\u53f7\u56fe\uff0c\u5373\u4f7f\u5728\u5b58\u5728\u9690\u85cf\u8282\u70b9\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8003\u8651\u5176\u5f71\u54cd\u3002"}}
{"id": "2509.09144", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09144", "abs": "https://arxiv.org/abs/2509.09144", "authors": ["G Dhinesh Chandran", "Kota Srinivas Reddy", "Srikrishna Bhashyam"], "title": "Sequential Spectral Clustering of Data Sequences", "comment": null, "summary": "We study the problem of nonparametric clustering of data sequences, where\neach data sequence comprises i.i.d. samples generated from an unknown\ndistribution. The true clusters are the clusters obtained using the Spectral\nclustering algorithm (SPEC) on the pairwise distance between the true\ndistributions corresponding to the data sequences. Since the true distributions\nare unknown, the objective is to estimate the clusters by observing the minimum\nnumber of samples from the data sequences for a given error probability. To\nsolve this problem, we propose the Sequential Spectral clustering algorithm\n(SEQ-SPEC), and show that it stops in finite time almost surely and is\nexponentially consistent. We also propose a computationally more efficient\nalgorithm called the Incremental Approximate Sequential Spectral clustering\nalgorithm (IA-SEQ-SPEC). Through simulations, we show that both our proposed\nalgorithms perform better than the fixed sample size SPEC, the Sequential\n$K$-Medoids clustering algorithm (SEQ-KMED) and the Sequential Single Linkage\nclustering algorithm (SEQ-SLINK). The IA-SEQ-SPEC, while being computationally\nefficient, performs close to SEQ-SPEC on both synthetic and real-world\ndatasets. To the best of our knowledge, this is the first work on spectral\nclustering of data sequences under a sequential framework.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86 SEQ-SPEC \u548c IA-SEQ-SPEC \u7b97\u6cd5\uff0c\u7528\u4e8e\u975e\u53c2\u6570\u805a\u7c7b\u6570\u636e\u5e8f\u5217\uff0c\u5e76\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u8bc1\u660e\u4e86\u5b83\u4eec\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u672c\u6587\u7814\u7a76\u7684\u662f\u6570\u636e\u5e8f\u5217\u7684\u975e\u53c2\u6570\u805a\u7c7b\u95ee\u9898\uff0c\u5176\u4e2d\u6bcf\u4e2a\u6570\u636e\u5e8f\u5217\u7531\u6765\u81ea\u672a\u77e5\u5206\u5e03\u7684 i.i.d. \u6837\u672c\u7ec4\u6210\u3002\u76ee\u6807\u662f\u5728\u7ed9\u5b9a\u9519\u8bef\u6982\u7387\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u89c2\u5bdf\u6570\u636e\u5e8f\u5217\u7684\u6700\u5c0f\u6837\u672c\u91cf\u6765\u4f30\u8ba1\u805a\u7c7b\u3002 ", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u987a\u5e8f\u8c31\u805a\u7c7b\u7b97\u6cd5 (SEQ-SPEC) \u548c\u589e\u91cf\u8fd1\u4f3c\u987a\u5e8f\u8c31\u805a\u7c7b\u7b97\u6cd5 (IA-SEQ-SPEC)\u3002SEQ-SPEC \u7b97\u6cd5\u51e0\u4e4e\u53ef\u4ee5\u80af\u5b9a\u5730\u5728\u6709\u9650\u65f6\u95f4\u5185\u505c\u6b62\uff0c\u5e76\u4e14\u5177\u6709\u6307\u6570\u4e00\u81f4\u6027\u3002IA-SEQ-SPEC \u7b97\u6cd5\u5728\u8ba1\u7b97\u4e0a\u66f4\u6709\u6548\u7387\u3002", "result": "\u901a\u8fc7\u6a21\u62df\uff0c\u6211\u4eec\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684 SEQ-SPEC \u548c IA-SEQ-SPEC \u7b97\u6cd5\u5728\u805a\u7c7b\u6548\u679c\u4e0a\u4f18\u4e8e\u56fa\u5b9a\u6837\u672c\u91cf\u7684 SPEC \u7b97\u6cd5\u3001\u987a\u5e8f K-Medoids \u805a\u7c7b\u7b97\u6cd5 (SEQ-KMED) \u548c\u987a\u5e8f\u5355\u4e00\u8fde\u63a5\u805a\u7c7b\u7b97\u6cd5 (SEQ-SLINK)\u3002IA-SEQ-SPEC \u7b97\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u805a\u7c7b\u6548\u679c\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5728\u987a\u5e8f\u6846\u67b6\u4e0b\u7814\u7a76\u4e86\u6570\u636e\u5e8f\u5217\u7684\u8c31\u805a\u7c7b\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u6709\u6548\u7684\u7b97\u6cd5\u3002IA-SEQ-SPEC \u7b97\u6cd5\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\uff0c\u53d6\u5f97\u4e86\u4e0e SEQ-SPEC \u7b97\u6cd5\u76f8\u5ab2\u7f8e\u7684\u805a\u7c7b\u6548\u679c\u3002"}}
{"id": "2509.09147", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09147", "abs": "https://arxiv.org/abs/2509.09147", "authors": ["Ziqi Yan", "Zhichao Zhang"], "title": "JFRFFNet: A Data-Model Co-Driven Graph Signal Denoising Model with Partial Prior Information", "comment": null, "summary": "Wiener filtering in the joint time-vertex fractional Fourier transform\n(JFRFT) domain has shown high effectiveness in denoising time-varying graph\nsignals. Traditional filtering models use grid search to determine the\ntransform-order pair and compute filter coefficients, while learnable ones\nemploy gradient-descent strategies to optimize them; both require complete\nprior information of graph signals. To overcome this shortcoming, this letter\nproposes a data-model co-driven denoising approach, termed neural-network-aided\njoint time-vertex fractional Fourier filtering (JFRFFNet), which embeds the\nJFRFT-domain Wiener filter model into a neural network and updates the\ntransform-order pair and filter coefficients through a data-driven approach.\nThis design enables effective denoising using only partial prior information.\nExperiments demonstrate that JFRFFNet achieves significant improvements in\noutput signal-to-noise ratio compared with some state-of-the-art methods.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aJFRFFNet\u7684\u65b0\u578b\u795e\u7ecf\u7f51\u7edc\u8f85\u52a9\u8054\u5408\u65f6\u57df-\u9876\u70b9\u5206\u6570\u5085\u91cc\u53f6\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u7528\u4e8e\u53bb\u9664\u65f6\u53d8\u56fe\u4fe1\u53f7\u4e2d\u7684\u566a\u58f0\u3002\u8be5\u65b9\u6cd5\u5c06JFRFT\u57df\u7684\u7ef4\u7eb3\u6ee4\u6ce2\u6a21\u578b\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u5f0f\u66f4\u65b0\u53d8\u6362\u9636\u6570\u5bf9\u548c\u6ee4\u6ce2\u5668\u7cfb\u6570\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5b8c\u6574\u5148\u9a8c\u4fe1\u606f\u7684\u5c40\u9650\u6027\uff0c\u4ec5\u9700\u90e8\u5206\u5148\u9a8c\u4fe1\u606f\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u53bb\u566a\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cJFRFFNet\u5728\u8f93\u51fa\u4fe1\u566a\u6bd4\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfJFRFT\u57df\u7ef4\u7eb3\u6ee4\u6ce2\u65b9\u6cd5\u5728\u786e\u5b9a\u53d8\u6362\u9636\u6570\u5bf9\u548c\u8ba1\u7b97\u6ee4\u6ce2\u5668\u7cfb\u6570\u65f6\uff0c\u9700\u8981\u5b8c\u6574\u7684\u56fe\u4fe1\u53f7\u5148\u9a8c\u4fe1\u606f\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u96be\u4ee5\u6ee1\u8db3\u3002\u672c\u7814\u7a76\u65e8\u5728\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aJFRFFNet\u7684\u6570\u636e-\u6a21\u578b\u534f\u540c\u9a71\u52a8\u53bb\u566a\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5c06JFRFT\u57df\u7684\u7ef4\u7eb3\u6ee4\u6ce2\u6a21\u578b\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u66f4\u65b0\u53d8\u6362\u9636\u6570\u5bf9\u548c\u6ee4\u6ce2\u5668\u7cfb\u6570\uff0c\u4ece\u800c\u4ec5\u9700\u90e8\u5206\u5148\u9a8c\u4fe1\u606f\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u53bb\u566a\u3002", "result": "JFRFFNet\u5728\u8f93\u51fa\u4fe1\u566a\u6bd4\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\uff0c\u4f18\u4e8e\u4e00\u4e9b\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "JFRFFNet\u901a\u8fc7\u5c06JFRFT\u57df\u7ef4\u7eb3\u6ee4\u6ce2\u6a21\u578b\u4e0e\u795e\u7ecf\u7f51\u7edc\u76f8\u7ed3\u5408\uff0c\u5e76\u91c7\u7528\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u8fdb\u884c\u4f18\u5316\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u65f6\u53d8\u56fe\u4fe1\u53f7\u53bb\u566a\u95ee\u9898\uff0c\u5373\u4f7f\u5728\u53ea\u6709\u90e8\u5206\u5148\u9a8c\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\u3002"}}
{"id": "2509.09225", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09225", "abs": "https://arxiv.org/abs/2509.09225", "authors": ["Lin Jin", "Hang Sheng", "Hui Feng", "Bo Hu"], "title": "On Sampling of Multiple Correlated Stochastic Signals", "comment": null, "summary": "Multiple stochastic signals possess inherent statistical correlations, yet\nconventional sampling methods that process each channel independently result in\ndata redundancy. To leverage this correlation for efficient sampling, we model\ncorrelated channels as a linear combination of a smaller set of uncorrelated,\nwide-sense stationary latent sources. We establish a theoretical lower bound on\nthe total sampling density for zero mean-square error reconstruction, proving\nit equals the ratio of the joint spectral bandwidth of latent sources to the\nnumber of correlated signal channels. We then develop a constructive multi-band\nsampling scheme that attains this bound. The proposed method operates via\nspectral partitioning of the latent sources, followed by spatio-temporal\nsampling and interpolation. Experiments on synthetic and real datasets confirm\nthat our scheme achieves near-lossless reconstruction precisely at the\ntheoretical sampling density, validating its efficiency.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u76f8\u5173\u4fe1\u9053\u5efa\u6a21\u4e3a\u8f83\u5c11\u6570\u91cf\u7684\u975e\u76f8\u5173\u6f5c\u5728\u6e90\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5e76\u5f00\u53d1\u4e00\u79cd\u57fa\u4e8e\u5149\u8c31\u5212\u5206\u3001\u65f6\u7a7a\u91c7\u6837\u548c\u63d2\u503c\u7684\u591a\u5e26\u91c7\u6837\u65b9\u6848\uff0c\u8bc1\u660e\u4e86\u7406\u8bba\u4e0b\u754c\uff0c\u5e76\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u65e0\u635f\u7684\u91cd\u6784\u3002", "motivation": "\u4f20\u7edf\u7684\u72ec\u7acb\u4fe1\u9053\u91c7\u6837\u65b9\u6cd5\u5b58\u5728\u6570\u636e\u5197\u4f59\uff0c\u9700\u8981\u4e00\u79cd\u5229\u7528\u4fe1\u9053\u95f4\u76f8\u5173\u6027\u8fdb\u884c\u9ad8\u6548\u91c7\u6837\u7684\u673a\u5236\u3002", "method": "\u5c06\u76f8\u5173\u4fe1\u9053\u5efa\u6a21\u4e3a\u5c11\u91cf\u975e\u76f8\u5173\u6f5c\u5728\u6e90\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u63a8\u5bfc\u51fa\u603b\u91c7\u6837\u5bc6\u5ea6\u4e0b\u754c\uff0c\u5e76\u8bbe\u8ba1\u4e00\u79cd\u901a\u8fc7\u5bf9\u6f5c\u5728\u6e90\u8fdb\u884c\u5149\u8c31\u5212\u5206\u3001\u65f6\u7a7a\u91c7\u6837\u548c\u63d2\u503c\u6765\u5b9e\u73b0\u8be5\u4e0b\u754c\u7684\u591a\u5e26\u91c7\u6837\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u7684\u91c7\u6837\u65b9\u6848\u5728\u7406\u8bba\u91c7\u6837\u5bc6\u5ea6\u4e0b\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u65e0\u635f\u7684\u91cd\u6784\uff0c\u5b9e\u9a8c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6548\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u4fe1\u9053\u95f4\u76f8\u5173\u6027\u8fdb\u884c\u9ad8\u6548\u91c7\u6837\u7684\u591a\u5e26\u91c7\u6837\u65b9\u6848\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2509.09264", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09264", "abs": "https://arxiv.org/abs/2509.09264", "authors": ["Davoud Hajhassani", "Quentin Barth\u00e9lemy", "J\u00e9r\u00e9mie Mattout", "Marco Congedo"], "title": "Improved Riemannian potato field: an Automatic Artifact Rejection Method for EEG", "comment": null, "summary": "Electroencephalography (EEG) signal cleaning has long been a critical\nchallenge in the research community. The presence of artifacts can\nsignificantly degrade EEG data quality, complicating analysis and potentially\nleading to erroneous interpretations. While various artifact rejection methods\nhave been proposed, the gold standard remains manual visual inspection by human\nexperts-a process that is time-consuming, subjective, and impractical for\nlarge-scale EEG studies. Existing techniques are often hindered by a strong\nreliance on manual hyperparameter tuning, sensitivity to outliers, and high\ncomputational costs. In this paper, we introduce the improved Riemannian Potato\nField (iRPF), a fast and fully automated method for EEG artifact rejection that\naddresses key limitations of current approaches. We evaluate iRPF against\nseveral state-of-the-art artifact rejection methods, using two publicly\navailable EEG databases, labeled for various artifact types, comprising 226 EEG\nrecordings. Our results demonstrate that iRPF outperforms all competitors\nacross multiple metrics, with gains of up to 22% in recall, 102% in\nspecificity, 54% in precision, and 24% in F1-score, compared to Isolation\nForest, Autoreject, Riemannian Potato, and Riemannian Potato Field,\nrespectively. Statistical analysis confirmed the significance of these\nimprovements (p < 0.001) with large effect sizes (Cohen's d > 0.8) in most\ncomparisons. Additionally, on a typical EEG recording iRPF performs artifact\ncleaning in under 8 milliseconds per epoch using a standard laptop,\nhighlighting its efficiency for large-scale EEG data processing and real-time\napplications. iRPF offers a robust and data-driven artifact rejection solution\nfor high-quality EEG pre-processing in brain-computer interfaces and clinical\nneuroimaging applications.", "AI": {"tldr": "EEG\u4fe1\u53f7\u53bb\u4f2a\u5f71\u65b9\u6cd5iRPF\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u901f\u5ea6\u5feb\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21EEG\u7814\u7a76\u3002", "motivation": "\u73b0\u6709EEG\u4f2a\u5f71\u53bb\u9664\u65b9\u6cd5\u8017\u65f6\u3001\u4e3b\u89c2\u4e14\u4e0d\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u5e76\u4e14\u5728\u8d85\u53c2\u6570\u8c03\u6574\u3001\u5bf9\u5f02\u5e38\u503c\u654f\u611f\u6027\u548c\u8ba1\u7b97\u6210\u672c\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u4e00\u79cd\u540d\u4e3a\u6539\u8fdb\u9ece\u66fc\u9a6c\u94c3\u85af\u7530\uff08iRPF\uff09\u7684\u5feb\u901f\u3001\u5168\u81ea\u52a8EEG\u4f2a\u5f71\u53bb\u9664\u65b9\u6cd5\u3002", "result": "iRPF\u5728\u4e24\u4e2a\u516c\u5f00EEG\u6570\u636e\u5e93\u7684226\u4e2a\u8bb0\u5f55\u4e0a\uff0c\u76f8\u6bd4\u4e8eIsolation Forest\u3001Autoreject\u3001\u9ece\u66fc\u9a6c\u94c3\u85af\u7530\u548c\u9ece\u66fc\u9a6c\u94c3\u85af\u7530\u65b9\u6cd5\uff0c\u5728\u53ec\u56de\u7387\u3001\u7279\u5f02\u6027\u3001\u7cbe\u786e\u7387\u548cF1\u5206\u6570\u4e0a\u5206\u522b\u63d0\u9ad8\u4e86\u9ad8\u8fbe22%\u3001102%\u300154%\u548c24%\uff0c\u4e14\u7edf\u8ba1\u5b66\u663e\u8457\uff08p < 0.001\uff09\uff0c\u6548\u5e94\u91cf\u5927\uff08Cohen's d > 0.8\uff09\u3002", "conclusion": "iRPF\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u6570\u636e\u9a71\u52a8\u7684\u4f2a\u5f71\u53bb\u9664\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21EEG\u6570\u636e\u5904\u7406\u3001\u5b9e\u65f6\u5e94\u7528\u4ee5\u53ca\u8111\u673a\u63a5\u53e3\u548c\u4e34\u5e8a\u795e\u7ecf\u5f71\u50cf\u5b66\u4e2d\u7684\u9ad8\u8d28\u91cfEEG\u9884\u5904\u7406\u3002"}}
{"id": "2509.09282", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09282", "abs": "https://arxiv.org/abs/2509.09282", "authors": ["Leonardo M\u00f6rlein", "Dirk Manteuffel"], "title": "On the Relation of Characteristic Modes of Different Conducting Structures", "comment": null, "summary": "A formalism is derived to analyze the scattering of a conducting structure\nbased on the characteristic modes of another structure whose surface is a\nsuperset of the first structure. This enables the analysis and comparison of\ndifferent structures using a common basis of characteristic modes.\nAdditionally, it is shown that the scattering matrices and perturbation\nmatrices are no longer diagonal in these cases. Based on this, a modal\ntransformation matrix is defined to describe the mapping between the\ncharacteristic fields and the weighting coefficients of the two structures.\nThis matrix enables the conversion of the perturbation matrices in different\nbases. Finally, two examples are provided along with a discussion of some\naspects of the theory. The first example aims to validate and illustrate the\nformalism. The second example shows how the formalism can be applied in the\ndesign process of an antenna element that is gradually modified, starting from\na base structure.", "AI": {"tldr": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u6a21\u6001\u5206\u6790\u5bfc\u7535\u5668\u4ef6\u6563\u5c04\u7684\u65b0\u65b9\u6cd5\uff0c\u5141\u8bb8\u5728\u4e0d\u540c\u4f46\u76f8\u5173\u7684\u7ed3\u6784\u4e4b\u95f4\u8fdb\u884c\u6709\u6548\u6bd4\u8f83\u548c\u8bbe\u8ba1\u3002", "motivation": "\u4e3a\u4e86\u5206\u6790\u548c\u6bd4\u8f83\u4e0d\u540c\u5bfc\u7535\u5668\u4ef6\u7684\u6563\u5c04\u7279\u6027\uff0c\u5e76\u4e3a\u5929\u7ebf\u8bbe\u8ba1\u63d0\u4f9b\u4e00\u79cd\u65b0\u65b9\u6cd5\u3002", "method": "\u63a8\u5bfc\u4e86\u4e00\u79cd\u57fa\u4e8e\u7279\u5f81\u6a21\u6001\u5206\u6790\u7684\u6563\u5c04\u5206\u6790\u5f62\u5f0f\uff0c\u5b9a\u4e49\u4e86\u6a21\u6001\u53d8\u6362\u77e9\u9635\u6765\u8f6c\u6362\u4e0d\u540c\u7ed3\u6784\u4e0b\u7684\u5fae\u6270\u77e9\u9635\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e24\u4e2a\u7b97\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u548c\u8bf4\u660e\u3002", "result": "\u8bc1\u660e\u4e86\u6563\u5c04\u77e9\u9635\u548c\u5fae\u6270\u77e9\u9635\u5728\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e2d\u4e0d\u518d\u662f\u5bf9\u89d2\u7684\uff0c\u5e76\u5b9a\u4e49\u4e86\u6a21\u6001\u53d8\u6362\u77e9\u9635\u6765\u5b9e\u73b0\u4e0d\u540c\u57fa\u4e0b\u7684\u5fae\u6270\u77e9\u9635\u8f6c\u6362\u3002", "conclusion": "\u8be5\u5f62\u5f0f\u6cd5\u4e3a\u5206\u6790\u548c\u8bbe\u8ba1\u6563\u5c04\u5bfc\u7535\u5668\u4ef6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5929\u7ebf\u8bbe\u8ba1\u7684\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u3002"}}
{"id": "2509.09373", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09373", "abs": "https://arxiv.org/abs/2509.09373", "authors": ["Huayan Guo", "Jichen Zhang", "Junhui Rao", "Ross Murch", "Vincent K. N. Lau"], "title": "Channel Estimation and Analog Precoding for Pixel-based Fluid-Antenna-Assisted Multiuser MIMO-OFDM Systems", "comment": "13 pages, 12 figures", "summary": "Pixel-based fluid antennas provide enhanced multiplexing gains and quicker\nradiation pattern switching than traditional designs. However, this innovation\nintroduces challenges for channel estimation and analog precoding due to the\nstate-non-separable channel response problem. This paper explores a multiuser\nMIMO-OFDM system utilizing pixel-based fluid antennas, informed by measurements\nfrom a real-world prototype. We present a sparse channel recovery framework for\nuplink channel sounding, employing an approximate separable channel response\nmodel with DNN-based antenna radiation functions. We then propose two\nlow-complexity channel estimation algorithms that leverage orthogonal matching\npursuit and variational Bayesian inference to accurately recover channel\nresponses across various scattering cluster angles. These estimations enable\nthe prediction of composite channels for all fluid antenna states, leading to\nan analog precoding scheme that optimally selects switching states for\ndifferent antennas. Our simulation results indicate that the proposed approach\nsignificantly outperforms several baseline methods, especially in high\nsignal-to-noise ratio environments with numerous users.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u50cf\u7d20\u5316\u6d41\u4f53\u5929\u7ebf\u591a\u7528\u6237MIMO-OFDM\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u548c\u6a21\u62df\u9884\u7f16\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u4fe1\u9053\u6062\u590d\u548c\u4f18\u5316\u7684\u72b6\u6001\u5207\u6362\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u50cf\u7d20\u5316\u6d41\u4f53\u5929\u7ebf\u867d\u7136\u5728\u590d\u7528\u589e\u76ca\u548c\u8f90\u5c04\u65b9\u5411\u56fe\u5207\u6362\u65b9\u9762\u6709\u4f18\u52bf\uff0c\u4f46\u5728\u4fe1\u9053\u4f30\u8ba1\u548c\u6a21\u62df\u9884\u7f16\u7801\u65b9\u9762\u5b58\u5728\u72b6\u6001\u975e\u53ef\u5206\u79bb\u4fe1\u9053\u54cd\u5e94\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u7a00\u758f\u4fe1\u9053\u6062\u590d\u6846\u67b6\uff0c\u5229\u7528\u8fd1\u4f3c\u53ef\u5206\u79bb\u4fe1\u9053\u54cd\u5e94\u6a21\u578b\u548c\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u5929\u7ebf\u8f90\u5c04\u51fd\u6570\u3002 \u8fdb\u4e00\u6b65\u63d0\u51fa\u4e24\u79cd\u4f4e\u590d\u6742\u5ea6\u4fe1\u9053\u4f30\u8ba1\u7b97\u6cd5\uff0c\u5206\u522b\u91c7\u7528\u6b63\u4ea4\u5339\u914d\u8ffd\u8e2a\u548c\u53d8\u5206\u8d1d\u53f6\u65af\u63a8\u65ad\u3002\u6700\u540e\uff0c\u57fa\u4e8e\u4f30\u8ba1\u7684\u4fe1\u9053\u4fe1\u606f\uff0c\u63d0\u51fa\u4e00\u79cd\u6700\u4f18\u5316\u7684\u6a21\u62df\u9884\u7f16\u7801\u65b9\u6848\uff0c\u4e3a\u4e0d\u540c\u5929\u7ebf\u9009\u62e9\u6700\u4f18\u7684\u72b6\u6001\u5207\u6362\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u7528\u6237\u6570\u91cf\u4f17\u591a\u548c\u9ad8\u4fe1\u566a\u6bd4\u73af\u5883\u4e0b\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u51e0\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7a00\u758f\u4fe1\u9053\u6062\u590d\u548c\u4f4e\u590d\u6742\u5ea6\u4fe1\u9053\u4f30\u8ba1\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u50cf\u7d20\u5316\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u4e2d\u7684\u4fe1\u9053\u4f30\u8ba1\u96be\u9898\uff0c\u5e76\u5b9e\u73b0\u6700\u4f18\u7684\u6a21\u62df\u9884\u7f16\u7801\uff0c\u4ece\u800c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2509.09606", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.09606", "abs": "https://arxiv.org/abs/2509.09606", "authors": ["Sajjad Hussain"], "title": "A Multi-Scale Feature Extraction and Fusion UNet for Pathloss Prediction in UAV-Assisted mmWave Radio Networks", "comment": "Submitted to IEEE Transactions on Wireless Communications", "summary": "Accurate pathloss prediction is essential for the design and optimization of\nUAV-assisted millimeter-wave (mmWave) networks. While deep learning approaches\nhave shown strong potential, their generalization across diverse environments,\nrobustness to noisy inputs, and sensitivity to UAV altitude remain\nunderexplored. To address these challenges, we propose a UNet-based deep\nlearning architecture that combines multi-scale feature extraction,\nconvolution-based feature fusion, and an atrous spatial pyramid pooling (ASPP)\nbottleneck for efficient context aggregation. The model predicts pathloss maps\nfrom log-distance, line-of-sight (LOS) mask, and building mask inputs. In\naddition, we develop a fully vectorized LOS mask computation algorithm that\nsignificantly accelerates pre-processing and enables large-scale dataset\ngeneration. Extensive evaluations on both in-house ray-tracing data and the\nRadioMapSeer benchmark demonstrate that the proposed model outperforms several\nstate-of-the-art baselines in accuracy and efficiency. All source code is\npublicly released to support reproducibility and future research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eUNet\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8eUAV\u8f85\u52a9\u6beb\u7c73\u6ce2\u7f51\u7edc\u7684\u8def\u5f84\u635f\u8017\u9884\u6d4b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u578b\u6cdb\u5316\u6027\u3001\u9c81\u68d2\u6027\u548c\u5bf9UAV\u9ad8\u5ea6\u654f\u611f\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728UAV\u8f85\u52a9\u6beb\u7c73\u6ce2\u7f51\u7edc\u8def\u5f84\u635f\u8017\u9884\u6d4b\u65b9\u9762\u5b58\u5728\u6cdb\u5316\u6027\u4e0d\u8db3\u3001\u9c81\u68d2\u6027\u5dee\u4ee5\u53ca\u5bf9UAV\u9ad8\u5ea6\u654f\u611f\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u4f18\u5316\u7684\u6a21\u578b\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eUNet\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u7ed3\u5408\u4e86\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u3001\u57fa\u4e8e\u5377\u79ef\u7684\u7279\u5f81\u878d\u5408\u4ee5\u53ca\u7a7a\u6d1e\u7a7a\u95f4\u91d1\u5b57\u5854\u6c60\u5316\uff08ASPP\uff09\u74f6\u9888\uff0c\u7528\u4e8e\u4ece\u5bf9\u6570\u8ddd\u79bb\u3001\u89c6\u8ddd\uff08LOS\uff09\u63a9\u7801\u548c\u5efa\u7b51\u63a9\u7801\u8f93\u5165\u4e2d\u9884\u6d4b\u8def\u5f84\u635f\u8017\u56fe\u3002\u6b64\u5916\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u5168\u5411\u91cf\u5316\u7684LOS\u63a9\u7801\u8ba1\u7b97\u7b97\u6cd5\u6765\u52a0\u901f\u9884\u5904\u7406\u548c\u751f\u6210\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002", "result": "\u5728\u5185\u90e8\u5c04\u7ebf\u8ffd\u8e2a\u6570\u636e\u548cRadioMapSeer\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u591a\u79cd\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eUNet\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u9884\u6d4bUAV\u8f85\u52a9\u6beb\u7c73\u6ce2\u7f51\u7edc\u7684\u8def\u5f84\u635f\u8017\uff0c\u5e76\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u901a\u8fc7\u516c\u5f00\u6e90\u4ee3\u7801\u4fc3\u8fdb\u4e86\u53ef\u590d\u73b0\u6027\u548c\u672a\u6765\u7814\u7a76\u3002"}}
